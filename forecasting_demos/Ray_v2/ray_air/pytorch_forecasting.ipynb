{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3e5bf94",
   "metadata": {},
   "source": [
    "# Batch (parallel) Demand Forecasting using PyTorch Forecasting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c05e74",
   "metadata": {},
   "source": [
    "**Batch training, tuning, and deploying** are common tasks in machine learning. They require training simple models, on data batches, typcially corresponding to different locations, products, etc. Batch training can take less time to process all the data at once, but only if those batches can run in parallel!\n",
    "\n",
    "This notebook showcases how to conduct batch forecasting using the <a href=\"https://github.com/ray-project/ray_lightning\">Ray Lightning plugin</a> (which runs on top <a href=\"https://docs.ray.io\">Ray</a>) to speed up training and inference of Google's <a href=\"https://github.com/google-research/google-research/tree/master/tft\">TemporalFusionTransformer</a> algorithm for RNN with LSTM, which has been adapted by <a href=\"https://pytorch-forecasting.readthedocs.io\">PyTorch Forecasting</a>, which in turn is built on <a href=\"https://pytorch-lightning.readthedocs.io\">PyTorch Lightning</a>. PyTorch Lightning is a set of APIs to simplify PyTorch, similar to the relationship of Keras to TensorFlow.\n",
    "\n",
    "<img src=\"../../../../AnyscaleDemos/ray_air_demos/images/embarrassingly_parallel.png\" style=\"width: 50%\"/>\n",
    "\n",
    "For the data, we will use the [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This popular tabular dataset contains historical taxi pickups by timestamp and location in NYC.\n",
    "\n",
    "For the training, we will train a separate forecasting model to predict #pickups at each location in NYC at hourly level for the next week. Specifically, we will train multiple TemporalFusionTransformer models using different hyperparameters, on different segments of data, to find the best model per segment of data.  For convenience, we have already clustered the `pickup_location_id` column in the dataset into 2 groups (or clusters of data).\n",
    "\n",
    "**Demo notes** <br>\n",
    "See [README](https://github.com/christy/AnyscaleDemos/tree/main/forecasting_demos#-setup-instructions-for-anyscale) for instructions how to run this notebook on Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd8ef7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contents\n",
    "\n",
    "In this this tutorial, you will learn how to:\n",
    " 1. [Define how to load and prepare Parquet data](#prepare_data) \n",
    " 2. [Define a train and evaluate functions](#define_trainable)\n",
    " 3. [Run batch training and inference with Ray Tune](#run_tune_search)\n",
    " 4. [Load a model from checkpoint](#load_checkpoint)\n",
    " 5. [Create a validation forecast from restored checkpoint model](#create_inference)\n",
    " 6. [Deploy a model from checkpoint using Ray Serve](#deploy_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d41150",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "\n",
    "```{tip}\n",
    "Prerequisite for this notebook: Read the [Key Concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) page for Ray Tune.\n",
    "```\n",
    "\n",
    "Let us start by importing a few required libraries, including open-source [Ray](https://github.com/ray-project/ray) itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b886d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.15\n",
      "Number of CPUs in this system: 8\n",
      "numpy: 1.22.3\n",
      "pyarrow: 10.0.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "import os, random\n",
    "import typing\n",
    "num_cpu = os.cpu_count()\n",
    "\n",
    "print(f\"Number of CPUs in this system: {num_cpu}\")\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pds\n",
    "\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc1e0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import GPUtil #GPU status from NVIDA GPUs\n",
    "# len(GPUtil.getGPUs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1950fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234492f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node:127.0.0.1': 1.0, 'memory': 7033421824.0, 'CPU': 8.0, 'object_store_memory': 2147483648.0}\n"
     ]
    }
   ],
   "source": [
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562c874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 1.13.1\n",
      "PyTorch Lightning: 1.6.5\n",
      "pytorch forecasting: 0.10.3\n",
      "tensorboard: 2.11.2\n"
     ]
    }
   ],
   "source": [
    "# Import forecasting libraries.\n",
    "import torch \n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "#PyTorch Forecasting convenience APIs for PyTorch Lightning\n",
    "import pytorch_forecasting as ptf\n",
    "pl.seed_everything(415)  # Set global random seed\n",
    "# PyTorch visualization uses Tensorboard\n",
    "import tensorboard as tb\n",
    "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile  #compatibility for PyTorch\n",
    "\n",
    "print(f\"torch: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning: {pl.__version__}\")\n",
    "print(f\"pytorch forecasting: {ptf.__version__}\")\n",
    "print(f\"tensorboard: {tb.__version__}\")\n",
    "# Import ray libraries.\n",
    "import ray_lightning\n",
    "from ray_lightning import RayStrategy\n",
    "from ray_lightning.tune import get_tune_resources, TuneReportCheckpointCallback\n",
    "from ray import air, tune\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c7d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For benchmarking purposes, we can print the times of various operations.\n",
    "# In order to reduce clutter in the output, this is set to False by default.\n",
    "PRINT_TIMES = False\n",
    "\n",
    "def print_time(msg: str):\n",
    "    if PRINT_TIMES:\n",
    "        print(msg)\n",
    "\n",
    "# To speed things up, we’ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "SMOKE_TEST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c583f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define how to load and prepare Parquet data <a class=\"anchor\" id=\"prepare_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c2d00",
   "metadata": {},
   "source": [
    "First, we need to load some data. Since the NYC Taxi dataset is fairly large, we will filter files first into a PyArrow dataset. And then in the next cell after, we will filter the data on read into a PyArrow table and convert that to a pandas dataframe.\n",
    "\n",
    "```{tip}\n",
    "Use PyArrow dataset and table for reading or writing large parquet files, since its native multithreaded C++ adapter is faster than pandas read_parquet, even using engine=pyarrow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b3a356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file: /Users/christy/Documents/github_christy_latest/AnyscaleDemos/forecasting_demos/Ray_v2/data/clean_taxi_hourly_clustered.parquet\n",
      "Clusters: ['smooth', 'erratic']\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "TARGET = \"trip_quantity\"\n",
    "FORECAST_LENGTH = 28\n",
    "# TODO: Change this according to where your git files are located.\n",
    "# data_dir = \"/home/ray/christy-air/forecasting_demos/Ray_v2/data\"\n",
    "data_dir = \"~/Documents/github_christy_latest/AnyscaleDemos/forecasting_demos/Ray_v2/data\"\n",
    "data_dir = os.path.expanduser(data_dir)\n",
    "DATA_FILENAME = data_dir + \"/clean_taxi_hourly_clustered.parquet\"\n",
    "\n",
    "# Use smoke testing or not.\n",
    "# sample_clusters = [\"erratic\"] if SMOKE_TEST else [\"smooth\", \"erratic\"]\n",
    "sample_clusters = [\"erratic\"]\n",
    "\n",
    "# Display what data will be used.\n",
    "print(f\"data file: {DATA_FILENAME}\")\n",
    "print(f\"Clusters: {sample_clusters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d470aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# STEP 1. Define Python functions to read and prepare data.\n",
    "############\n",
    "\n",
    "# Function to read a pyarrow.Table object using pyarrow parquet, pq\n",
    "def read_data_from_clean(\n",
    "    file: str, \n",
    "    sample_id: np.int32) -> pd.DataFrame:\n",
    "\n",
    "    df = pq.read_table(\n",
    "        file,\n",
    "        filters=[\n",
    "            (\"pulocationid\", \"not in\", ['264', '265', '199']),\n",
    "            (\"ts_type\", \"=\", sample_id),\n",
    "        ],\n",
    "        columns=[\n",
    "            \"time_idx\",\n",
    "            \"pulocationid\",\n",
    "            \"day_hour\",\n",
    "            \"trip_quantity\",\n",
    "            \"ts_type\",\n",
    "        ],\n",
    "    ).to_pandas()\n",
    "    return df\n",
    "\n",
    "def prepare_data_from_clean(\n",
    "    file: str, \n",
    "    sample_cluster_id: str) -> pd.DataFrame:\n",
    "\n",
    "    # Load data from clean sample.\n",
    "    df = read_data_from_clean(file, sample_cluster_id)\n",
    "    df.rename(columns={\"pulocationid\": \"pickup_location_id\"}, inplace=True)\n",
    "    df['trip_quantity'] = df['trip_quantity'].astype(np.float32)\n",
    "\n",
    "    # Abort Tune to avoid Tune Error if df has too few rows\n",
    "    if df.shape[0] < FORECAST_LENGTH:\n",
    "        print_time(\n",
    "            f\"Location {sample_cluster_id} has only {df.shape[0]} rows\"\n",
    "        )\n",
    "        session.report(dict(error=None))\n",
    "        return None\n",
    "    else:\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774478d1-8bfa-4ed4-95c8-93f2f7ee58f5",
   "metadata": {},
   "source": [
    "## Define a train and evaluate functions <a class=\"anchor\" id=\"define_trainable\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01f6e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# STEP 2.  Define Python functions to train and evaluate a model.\n",
    "############\n",
    "# Convert pandas data to PyTorch tensors.\n",
    "def convert_pandas_pytorch_timeseriesdata(\n",
    "    input_data_pandas_df:pd.DataFrame, \n",
    "    config:dict\n",
    ") -> typing.Union['pytorch_forecasting.data.timeseries.TimeSeriesDataSet',\n",
    "                  'torch.utils.data.dataloader.DataLoader']:\n",
    "\n",
    "    \"\"\"Converts pandas dataframe into TimeSeries folded tensors following \n",
    "       the backtesting technique.  A generator for doing the folding is \n",
    "       per batch also created.  One for the training data.  \n",
    "       Another for the validation data.  \n",
    "\n",
    "    Inputs:\n",
    "        pd.DataFrame: All the input data\n",
    "        dict: config is a configuration file containing hard-coded settings.\n",
    "\n",
    "    Returns:\n",
    "        'pytorch_forecasting.data.timeseries.TimeSeriesDataSet': training data\n",
    "        'torch.utils.data.dataloader.DataLoader': training data loader\n",
    "        'torch.utils.data.dataloader.DataLoader': validation data loader\n",
    "    \"\"\"\n",
    "    \n",
    "    # specify data parameters\n",
    "    FORECAST_HORIZON = config.get(\"forecast_horizon\", 168)\n",
    "    CONTEXT_LENGTH = config.get(\"context_length\", 63)\n",
    "    BATCH_SIZE = config.get(\"batch_size\", 32)\n",
    "    NUM_TRAINING_WORKERS = config.get(\"num_training_workers\", 4)\n",
    "    id_col_name = \"pickup_location_id\"\n",
    "    target_value = \"trip_quantity\"\n",
    "    \n",
    "    df = input_data_pandas_df.copy()\n",
    "    \n",
    "    # define forecast horizon and training cutoff\n",
    "    max_prediction_length = FORECAST_HORIZON  #decoder length = 1 week forecast horizon\n",
    "    max_encoder_length = CONTEXT_LENGTH  # window or context length\n",
    "    training_cutoff = df[\"time_idx\"].max() - max_prediction_length \n",
    "\n",
    "    # convert pandas to PyTorch tensor\n",
    "    training_data = ptf.data.TimeSeriesDataSet(\n",
    "        df[lambda x: x.time_idx <= training_cutoff],\n",
    "        allow_missing_timesteps=True,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=target_value,\n",
    "        group_ids=[id_col_name],\n",
    "        min_encoder_length=5,  # min 5 historical values must exist\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[id_col_name],\n",
    "        # static_reals=[\"avg_population_2017\", \"avg_yearly_household_income_2017\"],\n",
    "        static_reals=[],\n",
    "        time_varying_known_categoricals=[\"day_hour\"],\n",
    "        # group of categorical variables can be treated as one variable\n",
    "        # variable_groups={\"special_days\": special_days},  \n",
    "        time_varying_known_reals=[\"time_idx\", ],\n",
    "                            # \"mean_item_loc_weekday\",\n",
    "                            # \"binned_max_item\"],\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[target_value,],\n",
    "\n",
    "        # https://pytorch-forecasting.readthedocs.io/en/v0.2.4/_modules/pytorch_forecasting/data.html\n",
    "        target_normalizer=ptf.data.GroupNormalizer(\n",
    "            groups=[\"pickup_location_id\"], \n",
    "            transformation=\"softplus\"  #forces positive values\n",
    "        ), \n",
    "        add_relative_time_idx=True, # add as feature\n",
    "        add_target_scales=True, # add avg target_value as feature\n",
    "        add_encoder_length=True, # add as feature\n",
    "    )\n",
    "    \n",
    "    # create PyTorch dataloader for training\n",
    "    train_loader = training_data\\\n",
    "                        .to_dataloader(\n",
    "                            train=True, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            num_workers=NUM_TRAINING_WORKERS)\n",
    "    \n",
    "    # create validation PyTorch data \n",
    "    # (predict=True) means make do inference using the validation data\n",
    "    val_dataset = ptf.data.TimeSeriesDataSet\\\n",
    "                    .from_dataset(\n",
    "                        training_data, \n",
    "                        data=df, \n",
    "                        predict=True, \n",
    "                        stop_randomization=True)\n",
    "\n",
    "    # create PyTorch dataloaders for inference on validation data\n",
    "    validation_loader = val_dataset\\\n",
    "                    .to_dataloader(\n",
    "                        train=False, \n",
    "                        batch_size=BATCH_SIZE * 10, \n",
    "                        num_workers=NUM_TRAINING_WORKERS)\n",
    "    \n",
    "    # return original df converted to PyTorch tensors, and pytorch loaders\n",
    "    return training_data, train_loader, validation_loader\n",
    "\n",
    "################\n",
    "# calculate WQL, MAE\n",
    "# note: to get a single item quantile prediction:\n",
    "# example: quantile p50 for itemid=\"140\"\n",
    "# y_quantiles[1].detach().cpu()[43, : x[\"decoder_lengths\"][43]] \n",
    "# raw predictions are a dictionary from which quantiles can be extracte\n",
    "# TIP:  Use x to figure out mappings indexes to locations [141, 43, 144]\n",
    "################\n",
    "def evaluate_model(y_actual:'torch.Tensor', \n",
    "             y_quantiles:'torch.Tensor', \n",
    "             quantile_list:list)->'torch.Tensor':\n",
    "    \"\"\"Calculate weighted quantile loss given actuals, quantile predictions,\n",
    "       and list of desired quantiles to average over.\n",
    "    Inputs:\n",
    "        'torch.Tensor': y_actual is a tensor of actual values \n",
    "        'torch.Tensor': y_quantiles is a tensor of quantile predictions\n",
    "        'list': List of quantiles to average over\n",
    "\n",
    "    Returns:\n",
    "        'torch.Tensor': weighted quantile loss over all the desired quantiles\n",
    "    \"\"\"\n",
    "\n",
    "    assert not y_actual.requires_grad\n",
    "    \n",
    "    all_losses = []\n",
    "    for i, q in enumerate(quantile_list):\n",
    "        sum_actuals = torch.sum(torch.abs(y_actual[i]))\n",
    "        errors = torch.abs(y_actual[i] - y_quantiles[i][:, i])\n",
    "        all_losses.append(\n",
    "            torch.where(y_quantiles[i][:, i] > y_actual[i],\n",
    "                        (1-q) * errors, \n",
    "                        q * errors ).unsqueeze(1))\n",
    "        \n",
    "        if torch.is_nonzero(sum_actuals):\n",
    "            all_losses[i] = torch.sum(all_losses[i]).div(sum_actuals)\n",
    "        else:\n",
    "            all_losses[i] = torch.empty_like(all_losses[i])\n",
    "            \n",
    "        # Only for 50th percentile, calculate MAE\n",
    "        if q == 0.5:\n",
    "            MAE = torch.sum(errors)/y_actual.shape[0]\n",
    "    \n",
    "    WQL = torch.mean(torch.stack(all_losses), dim=0)\n",
    "    MAE = torch.mean(MAE)\n",
    "    return WQL, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e9ce3",
   "metadata": {},
   "source": [
    "## Create and train a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184c24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   time_idx pickup_location_id      day_hour  trip_quantity  ts_type\n",
      "0      4371                 10      Monday_3            0.0  erratic\n",
      "1      3926                 10  Wednesday_14            1.0  erratic\n",
      "2      4773                 10  Wednesday_21            2.0  erratic\n",
      "3      5046                 10      Monday_6            2.0  erratic\n",
      "4      3911                 10    Tuesday_23            1.0  erratic\n",
      "Input data type: <class 'pandas.core.frame.DataFrame'>\n",
      "Converted data type: <class 'pytorch_forecasting.data.timeseries.TimeSeriesDataSet'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model MAE: 71.43466186523438\n",
      "CPU times: user 1.1 s, sys: 242 ms, total: 1.34 s\n",
      "Wall time: 6.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Config parameters for baseline model.\n",
    "num_training_workers = min(num_cpu - 2, 32)\n",
    "FORECAST_CONFIG = {\"forecast_horizon\": 168, \"context_length\": 63,\n",
    "          \"num_gpus\":0, \"batch_size\": 128, \n",
    "          \"num_training_workers\": num_training_workers,\n",
    "          \"sample_cluster_id\": ['erratic'],\n",
    "         }\n",
    "\n",
    "# Test reading data pandas from sample clean data.\n",
    "df = prepare_data_from_clean(DATA_FILENAME, sample_clusters[1])\n",
    "# Display what data will be used.\n",
    "sample_locations = df.loc[(df.ts_type.isin(sample_clusters)), 'pickup_location_id'].unique()\n",
    "print(df.head())\n",
    "\n",
    "# convert data from pandas to PyTorch tensors\n",
    "print(f\"Input data type: {type(df)}\")\n",
    "train_dataset, train_loader, validation_loader = convert_pandas_pytorch_timeseriesdata(\n",
    "    df, FORECAST_CONFIG\n",
    ")\n",
    "print(f\"Converted data type: {type(train_dataset)}\")\n",
    "\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(validation_loader)])\n",
    "baseline_predictions = ptf.models.Baseline().predict(validation_loader)\n",
    "\n",
    "## EVALUATE THE BASELINE MODEL\n",
    "# print MAE\n",
    "baseline_error = (actuals - baseline_predictions).abs().mean()\n",
    "print(f\"baseline model MAE: {baseline_error}\")\n",
    "\n",
    "# Erratic cluster\n",
    "# baseline model MAE: 71.43466186523438\n",
    "\n",
    "# Smooth cluster\n",
    "# baseline model MAE: 20.886438369750977\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7130a533-4714-46e4-a747-2b129189a3da",
   "metadata": {},
   "source": [
    "## Run batch training and inference with Ray Tune <a class=\"anchor\" id=\"run_tune_search\"></a>\n",
    "\n",
    "**Recall what we are doing, high level, is training several different models per cluster of pickup locations.** To do this, we need to be able to:\n",
    " - Pre-process all the data per model, distributing the runtime.\n",
    " - Run parallel trials, which compare different hyperparameter settings per model.\n",
    " - Inspect the results of the tuning experiment and deploy only the best model per cluster of pickup locations.\n",
    "\n",
    "**Below are the general steps to preprocess data and automatically tune models from any combination of AI/ML Python libraries using distributed computing with [Ray AIR](https://docs.ray.io/en/latest/ray-air/getting-started.html) and [APIs](https://docs.ray.io/en/latest/ray-air/package-ref.html):**\n",
    "\n",
    "<ol>\n",
    "    <li>Define Python functions <b>`preprocess`</b> to read and prepare a segment of data.\n",
    "    <li>Define Python functions to `<b>train`</b> and <b>`evaluate`</b> a model on a segment of data.\n",
    "    <li>Define a calling function <b>`train_models`</b>, which calls all the above functions, and will be called in parallel for every permutation in the Tune search space!<br>\n",
    "    Inside this <a href=\"https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs\">`train_models`</a> function:\n",
    "    <ul>\n",
    "        <li>📖 The input parameters must include a config dictionary argument.\n",
    "        <li>📈 The tuning metric (a model's loss or error) must be calculated and reported using session.report().\n",
    "        <li>✔️ Checkpoint (save) the model is recommended for fault tolerance and easy deployment later.\n",
    "    </ul>\n",
    "    <li><b>Configure distributed compute scaling</b>.\n",
    "    <li><b>Define a Ray Tune search space</b> of all training parameters.\n",
    "    <li><b>Specify a hyperparameter search strategy.</b>  In this example, we use an <a href=\"https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/\">Asynchronous Hyperband scheduler</a>. This scheduler decides at each iteration which trials are likely to perform badly, and stops these trials. This way we don’t waste any resources on bad hyperparameter configurations.\n",
    "    <li><b>Run the experiment</b> using Ray AIR APIs with Ray Lightning.\n",
    "</ol>\n",
    "\n",
    "Below is the additional code we would add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef762ec0-4018-46e3-ad60-a97bff9c5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# STEP 3.  Define a calling function `train_models`, which calls all \n",
    "#          the above functions, and will be called in parallel for every \n",
    "#          permutation in the Tune search space.\n",
    "############\n",
    "def train_models(\n",
    "    config: dict,\n",
    "    strategy: 'ray_lightning.ray_ddp.RayStrategy',\n",
    "    filename: str):\n",
    "    \"\"\"Define a calling function to read data, define a model and train it.\n",
    "\n",
    "    Inputs:\n",
    "        dict: configuration dictionary with hard-coded runtime values\n",
    "        str:  data filename where to read a segment of data\n",
    "    \"\"\"\n",
    "    # Get data segment ID from Tune search parameters\n",
    "    sample_cluster_id = config.get(\"sample_cluster_id\", [\"erratic\"])\n",
    "    print_time(f\"Data segment: {sample_cluster_id}\")\n",
    "    \n",
    "    # Read a segment of data for multi-model training in parallel.\n",
    "    df = prepare_data_from_clean(filename, sample_cluster_id)\n",
    "        \n",
    "    # Convert data from pandas to PyTorch Forecasting tensors.\n",
    "    train_dataset, train_loader, validation_loader = \\\n",
    "        convert_pandas_pytorch_timeseriesdata(df, config)\n",
    "    \n",
    "    # Checkpoint a custom object.\n",
    "    # PyTorch Lightning checkpointing not yet fully integrated with Ray AIR.\n",
    "    with open('val_loader.pickle', 'wb') as handle:\n",
    "        pickle.dump(validation_loader, handle)\n",
    "    \n",
    "    # Create your PTF model.\n",
    "    model = ptf.models.TemporalFusionTransformer.from_dataset(\n",
    "        train_dataset,\n",
    "        learning_rate=config.get(\"lr\", 0.01),\n",
    "        hidden_size=config.get(\"hidden_size\", 40), # num neurons in each layer, bigger runs more slowly\n",
    "        # lstm_layers=HIDDEN_LAYERS, #LSTM layers=1 is default for tft architecture\n",
    "        attention_head_size=config.get(\"attention_head_size\", 4),  #default 4 cells in LSTM layer\n",
    "        dropout=config.get(\"droupout\", 0.1),\n",
    "        hidden_continuous_size=config.get(\"hidden_continuous_size\", 1),  #similar to categorical embedding size\n",
    "        # 7 quantiles by default: [0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]\n",
    "        # optimizer loss metric\n",
    "        loss=ptf.metrics.QuantileLoss([0.25, 0.5, 0.75]),\n",
    "        log_interval=10, #learning-rate logging every 10 batches\n",
    "        reduce_on_plateau_patience=4, # reduce learning automatically\n",
    "    )\n",
    "    print(f\"Number of parameters in network: {model.size()/1e3:.1f}k\")\n",
    "    \n",
    "    # Configure early stopping.\n",
    "    early_stop_callback = \\\n",
    "        pl.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                      min_delta=1e-4, \n",
    "                      patience=10, \n",
    "                      verbose=False, \n",
    "                      mode=\"min\")\n",
    "    \n",
    "    # Configure logging.\n",
    "    log_dir = os.getcwd() # + \"/lightning_logs\"\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=log_dir, name=\"\", version=\"\")\n",
    "    \n",
    "    # Create the Tune Reporting Callback.\n",
    "    metrics = dict(loss=\"val_loss\")\n",
    "    callbacks = [\n",
    "             early_stop_callback, \n",
    "             TuneReportCheckpointCallback(\n",
    "                 metrics,\n",
    "                 on=\"validation_end\")]\n",
    "\n",
    "    # Configure PyTorch trainer with Ray Lightning plugin.\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.get(\"epochs\", 30),\n",
    "        gradient_clip_val=config.get(\"gradient_clip_val\", 0.1),\n",
    "        limit_train_batches=config.get(\"limit_train_batches\", 30),  \n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "        strategy=strategy, \n",
    "        # Suggest always use fast_mode, uses Tune instead of ptf logging.\n",
    "        fast_dev_run=True,\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=validation_loader,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c1792-e3d6-4568-adfd-d7730b2d0362",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# STEP 4. Customize distributed compute scaling.\n",
    "# https://docs.ray.io/en/master/train/config_guide.html\n",
    "############\n",
    "num_training_workers = min(num_cpu - 2, 32)\n",
    "strategy = RayStrategy(num_workers=num_training_workers, \n",
    "                       num_cpus_per_worker=1, \n",
    "                       use_gpu=False,\n",
    "                       find_unused_parameters=False,)\n",
    "\n",
    "############\n",
    "# STEP 5. Define a search space dict of all config parameters.\n",
    "# https://docs.ray.io/en/latest/ray-air/tuner.html\n",
    "############\n",
    "FORECAST_CONFIG = {\n",
    "    \"forecast_horizon\": 168,\n",
    "    \"context_length\": 63,\n",
    "    \"num_gpus\": 0,\n",
    "    \"num_training_workers\": num_training_workers,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 2,\n",
    "    \"lr\": tune.grid_search([0.0005, 0.005, 0.05]),\n",
    "    \"hidden_size\": 20,\n",
    "    \"dropout\": 0.1,\n",
    "    \"hidden_continuous_size\": 4,\n",
    "    \"attention_head_size\": num_training_workers,\n",
    "    \"limit_train_batches\": 1, \n",
    "    \"sample_cluster_id\": tune.grid_search(sample_clusters),\n",
    "}\n",
    "print(f\"Data segment IDs: {sample_clusters}\")\n",
    "\n",
    "############\n",
    "# Optional STEP 6. Specify the hyperparameter tuning search strategy.\n",
    "# https://docs.ray.io/en/latest/tune/key-concepts.html#search-algorithms\n",
    "############\n",
    "# Select scheduler https://blog.ml.cmu.edu/2018/12/12/massively-parallel-hyperparameter-optimization/\n",
    "scheduler = ASHAScheduler(\n",
    "    max_t=FORECAST_CONFIG['epochs'],\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caedeb18-a0bd-4269-a752-305e60c8f5d8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "💡 After you run the cell below, right-click on it and choose \"Enable Scrolling for Outputs\"! This will make it easier to view, since tuning output can be very long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09769826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data segment IDs: ['smooth', 'erratic']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-23 12:21:45</td></tr>\n",
       "<tr><td>Running for: </td><td>13:42:57.85        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.6/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=1<br>Bracket: Iter 2.000: None | Iter 1.000: -18.34697723388672<br>Resources requested: 7.0/8 CPUs, 0/0 GPUs, 0.0/8.72 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_96e1b_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/christy/Documents/github_christy_latest/AnyscaleDemos/forecasting_demos/Ray_v2/ray_air/my_Tune_logs/ptf_nyc/train_model_96e1b_00000_0_lr=0.0005,sample_cluster_id=smooth_2023-01-22_22-38-47/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">    lr</th><th>sample_cluster_id  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_96e1b_00004</td><td>RUNNING   </td><td>127.0.0.1:2669</td><td style=\"text-align: right;\">0.005 </td><td>erratic            </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_model_96e1b_00005</td><td>PENDING   </td><td>              </td><td style=\"text-align: right;\">0.05  </td><td>erratic            </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "<tr><td>train_model_96e1b_00001</td><td>TERMINATED</td><td>127.0.0.1:2669</td><td style=\"text-align: right;\">0.005 </td><td>smooth             </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         69.4644</td><td style=\"text-align: right;\">18.347 </td></tr>\n",
       "<tr><td>train_model_96e1b_00002</td><td>TERMINATED</td><td>127.0.0.1:2669</td><td style=\"text-align: right;\">0.05  </td><td>smooth             </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         68.151 </td><td style=\"text-align: right;\">16.5322</td></tr>\n",
       "<tr><td>train_model_96e1b_00003</td><td>TERMINATED</td><td>127.0.0.1:2669</td><td style=\"text-align: right;\">0.0005</td><td>erratic            </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         60.754 </td><td style=\"text-align: right;\">37.8973</td></tr>\n",
       "<tr><td>train_model_96e1b_00000</td><td>ERROR     </td><td>127.0.0.1:2629</td><td style=\"text-align: right;\">0.0005</td><td>smooth             </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m `Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m `Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2629)\u001b[0m Number of parameters in network: 32.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: ParallelStrategy.torch_distributed_backend was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2653)\u001b[0m Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "2023-01-22 22:39:03,280\tWARNING worker.py:1851 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,282\tWARNING worker.py:1851 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,283\tWARNING worker.py:1851 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,283\tWARNING worker.py:1851 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,285\tWARNING worker.py:1851 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd7315dd3f32d5eedcbe79cc001000000 Worker ID: a0a6b9fba20cdad3a059f48db8ea68e1056bb838bddb4d1aa2dc65ba Node ID: ec48c899064056c1cf86fee735157b3e2b3fe1194705e5570acdd137 Worker IP address: 127.0.0.1 Worker port: 50954 Worker PID: 2633 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,291\tWARNING worker.py:1851 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff602ee0347c4dae3e2114e6e001000000 Worker ID: 9d14eb546bbdcd93fc6b0cbf6a153b00d106525f9603c17188252e24 Node ID: ec48c899064056c1cf86fee735157b3e2b3fe1194705e5570acdd137 Worker IP address: 127.0.0.1 Worker port: 50918 Worker PID: 2631 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m 2023-01-22 22:39:03,273\tERROR worker.py:763 -- Worker exits with an exit code None.2023-01-22 22:39:03,295\tWARNING worker.py:1851 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffec682b86535d92d70ca159d101000000 Worker ID: 2b59e3dd76f272b9a7029146a8290252e9e7b1e1fb43e0be842880bf Node ID: ec48c899064056c1cf86fee735157b3e2b3fe1194705e5570acdd137 Worker IP address: 127.0.0.1 Worker port: 50935 Worker PID: 2630 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m  Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1176, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m SystemExit\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Exception ignored in: <function tqdm.__del__ at 0x11ee9eca0>\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1281, in close\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m     if self.disable:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2631)\u001b[0m AttributeError: 'Tqdm' object has no attribute 'disable'\n",
      "2023-01-22 22:39:03,297\tWARNING worker.py:1851 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff3f5a718a832f29a9835705a401000000 Worker ID: 1bc070b219cdb80667663b23e90a7f25b42bf3c9d5f394c2e1f2fa4e Node ID: ec48c899064056c1cf86fee735157b3e2b3fe1194705e5570acdd137 Worker IP address: 127.0.0.1 Worker port: 50943 Worker PID: 2628 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m distributed_backend=gloo\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m All distributed processes registered. Starting with 6 processes\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCheckpointCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m    | Name                               | Type                            | Params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 0  | loss                               | QuantileLoss                    | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 1  | logging_metrics                    | ModuleList                      | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 2  | input_embeddings                   | MultiEmbedding                  | 7.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 3  | prescalers                         | ModuleDict                      | 48    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 4  | static_variable_selection          | VariableSelectionNetwork        | 1.3 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 6  | decoder_variable_selection         | VariableSelectionNetwork        | 954   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 7  | static_context_variable_selection  | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 10 | static_context_enrichment          | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 11 | lstm_encoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 12 | lstm_decoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 840   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 14 | post_lstm_add_norm_encoder         | AddNorm                         | 40    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 15 | static_enrichment                  | GatedResidualNetwork            | 2.1 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 16 | multihead_attn                     | InterpretableMultiHeadAttention | 879   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 17 | post_attn_gate_norm                | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 18 | pos_wise_ff                        | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 19 | pre_output_gate_norm               | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 20 | output_layer                       | Linear                          | 63    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 32.4 K    Trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 32.4 K    Total params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 0.129     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: UserWarning: num_workers>0, persistent_workers=False, and strategy=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m 2023-01-22 22:39:03,272\tERROR worker.py:763 -- Worker exits with an exit code None.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m  Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1176, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m SystemExit\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Exception ignored in: <function tqdm.__del__ at 0x13745eca0>\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1281, in close\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m     if self.disable:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2633)\u001b[0m AttributeError: 'Tqdm' object has no attribute 'disable'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m 2023-01-22 22:39:03,276\tERROR worker.py:763 -- Worker exits with an exit code None.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m  Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1176, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m SystemExit\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Exception ignored in: <function tqdm.__del__ at 0x13699fca0>\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1281, in close\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m     if self.disable:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2628)\u001b[0m AttributeError: 'Tqdm' object has no attribute 'disable'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m 2023-01-22 22:39:03,281\tERROR worker.py:763 -- Worker exits with an exit code None.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m  Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1176, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m SystemExit\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Exception ignored in: <function tqdm.__del__ at 0x118c1fca0>\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1281, in close\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m     if self.disable:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2632)\u001b[0m AttributeError: 'Tqdm' object has no attribute 'disable'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m 2023-01-22 22:39:03,273\tERROR worker.py:763 -- Worker exits with an exit code None.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m  Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = function(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     results = self._run_stage()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return self._run_train()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.fit_loop.run()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.on_run_start(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     fn(self, self.lightning_module, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.main_progress_bar = self.init_train_tqdm()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     bar = Tqdm(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     with cls.get_lock():  # also constructs lock if non-existent\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls._lock = TqdmDefaultWriteLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls.create_mp_lock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     cls.mp_lock = RLock()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     return RLock(ctx=self.get_context())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     register(self._semlock.name, \"semaphore\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self._send('REGISTER', name, rtype)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.ensure_running()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m KeyboardInterrupt\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1176, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m SystemExit\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Exception ignored in: <function tqdm.__del__ at 0x1177dfca0>\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1162, in __del__\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m   File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 1281, in close\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m     if self.disable:\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2630)\u001b[0m AttributeError: 'Tqdm' object has no attribute 'disable'\n",
      "2023-01-22 22:39:03,300\tWARNING worker.py:1851 -- Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2653)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "2023-01-22 22:39:03,315\tWARNING worker.py:1851 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff0d47119e3e5ff52f2a3e9f4e01000000 Worker ID: 1636d04aded2019416f3a82742ede64389a0341cd324dae031c2328b Node ID: ec48c899064056c1cf86fee735157b3e2b3fe1194705e5570acdd137 Worker IP address: 127.0.0.1 Worker port: 50927 Worker PID: 2632 Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
      "  File \"python/ray/_raylet.pyx\", line 1074, in ray._raylet.execute_task_with_cancellation_handler\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n",
      "2023-01-22 22:39:03,396\tERROR trial_runner.py:1088 -- Trial train_model_96e1b_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1070, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/_private/worker.py\", line 2309, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2629, ip=127.0.0.1, repr=train_model)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 367, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 335, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 652, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 394, in _inner\n",
      "    return inner(config, checkpoint_dir=None)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 386, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/var/folders/cx/j9s41z_97kd3g0jh0qf987m00000gn/T/ipykernel_2002/3708825603.py\", line 224, in train_model\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 770, in fit\n",
      "    self._call_and_handle_interrupt(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 721, in _call_and_handle_interrupt\n",
      "    return self.strategy.launcher.launch(trainer_fn, *args, trainer=self, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 58, in launch\n",
      "    ray_output = self.run_function_on_workers(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 249, in run_function_on_workers\n",
      "    results = process_results(self._futures, self.tune_queue)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/util.py\", line 64, in process_results\n",
      "    ray.get(ready)\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: RayExecutor\n",
      "\tactor_id: d7315dd3f32d5eedcbe79cc001000000\n",
      "\tpid: 2633\n",
      "\tnamespace: 930d2b0a-6312-4e3e-9448-d75f98f80fd5\n",
      "\tip: 127.0.0.1\n",
      "The actor is dead because its worker process has died. Worker exit type: SYSTEM_ERROR Worker exit detail: Worker exits unexpectedly. Worker exits with an exit code None.\n",
      " Traceback (most recent call last):\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/utils.py\", line 52, in execute\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/ray_lightning/launchers/ray_launcher.py\", line 301, in _wrapping_function\n",
      "    results = function(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 811, in _fit_impl\n",
      "    results = self._run(model, ckpt_path=self.ckpt_path)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1236, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1323, in _run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1353, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/base.py\", line 199, in run\n",
      "    self.on_run_start(*args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py\", line 217, in on_run_start\n",
      "    self.trainer._call_callback_hooks(\"on_train_start\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\", line 1636, in _call_callback_hooks\n",
      "    fn(self, self.lightning_module, *args, **kwargs)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 255, in on_train_start\n",
      "    self.main_progress_bar = self.init_train_tqdm()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/callbacks/progress/tqdm_progress.py\", line 194, in init_train_tqdm\n",
      "    bar = Tqdm(\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 562, in __new__\n",
      "    with cls.get_lock():  # also constructs lock if non-existent\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 661, in get_lock\n",
      "    cls._lock = TqdmDefaultWriteLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 99, in __init__\n",
      "    cls.create_mp_lock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/tqdm/std.py\", line 123, in create_mp_lock\n",
      "    cls.mp_lock = RLock()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/context.py\", line 73, in RLock\n",
      "    return RLock(ctx=self.get_context())\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 187, in __init__\n",
      "    SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/synchronize.py\", line 80, in __init__\n",
      "    register(self._semlock.name, \"semaphore\")\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 147, in register\n",
      "    self._send('REGISTER', name, rtype)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 154, in _send\n",
      "    self.ensure_running()\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py\", line 124, in ensure_running\n",
      "    signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n",
      "  File \"/Users/christy/miniconda3/envs/dev38/lib/python3.8/signal.py\", line 60, in pthread_sigmask\n",
      "    sigs_set = _signal.pthread_sigmask(how, mask)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2629, ip=127.0.0.1, repr=train_model)\n",
      "AttributeError: 'ray._raylet.CoreWorker' object has no attribute 'actors'\n",
      "An unexpected internal error occurred while the worker was executing a task.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname                  </th><th>iterations_since_restore  </th><th>loss             </th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th>time_since_restore  </th><th>time_this_iter_s  </th><th>time_total_s     </th><th style=\"text-align: right;\">  timestamp</th><th>timesteps_since_restore  </th><th>timesteps_total  </th><th>training_iteration  </th><th>trial_id   </th><th>warmup_time          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_96e1b_00000</td><td>2023-01-22_22-38-49</td><td>      </td><td>                </td><td>ef376bdc89414d4eb44ded94af7260ba</td><td>christys-MacBook-Pro.local</td><td>                          </td><td>                 </td><td>127.0.0.1</td><td style=\"text-align: right;\"> 2629</td><td>                   </td><td>                    </td><td>                  </td><td>                 </td><td style=\"text-align: right;\"> 1674455929</td><td>                         </td><td>                 </td><td>                    </td><td>96e1b_00000</td><td>                     </td></tr>\n",
       "<tr><td>train_model_96e1b_00001</td><td>2023-01-22_22-40-15</td><td>True  </td><td>                </td><td>fa8b83dbabd647a0a3a51dfb8c6a0e8f</td><td>christys-MacBook-Pro.local</td><td>1                         </td><td>18.34697723388672</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 2669</td><td>True               </td><td>69.46443486213684   </td><td>69.46443486213684 </td><td>69.46443486213684</td><td style=\"text-align: right;\"> 1674456015</td><td>0                        </td><td>                 </td><td>1                   </td><td>96e1b_00001</td><td>0.0016338825225830078</td></tr>\n",
       "<tr><td>train_model_96e1b_00002</td><td>2023-01-22_22-41-44</td><td>True  </td><td>                </td><td>fa8b83dbabd647a0a3a51dfb8c6a0e8f</td><td>christys-MacBook-Pro.local</td><td>1                         </td><td>16.53215217590332</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 2669</td><td>True               </td><td>68.1510100364685    </td><td>68.1510100364685  </td><td>68.1510100364685 </td><td style=\"text-align: right;\"> 1674456104</td><td>0                        </td><td>                 </td><td>1                   </td><td>96e1b_00002</td><td>0.0016338825225830078</td></tr>\n",
       "<tr><td>train_model_96e1b_00003</td><td>2023-01-22_22-43-13</td><td>True  </td><td>                </td><td>fa8b83dbabd647a0a3a51dfb8c6a0e8f</td><td>christys-MacBook-Pro.local</td><td>1                         </td><td>37.89729690551758</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 2669</td><td>True               </td><td>60.75404596328735   </td><td>60.75404596328735 </td><td>60.75404596328735</td><td style=\"text-align: right;\"> 1674456193</td><td>0                        </td><td>                 </td><td>1                   </td><td>96e1b_00003</td><td>0.0016338825225830078</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2653)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 12 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2653)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Number of parameters in network: 32.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: ParallelStrategy.torch_distributed_backend was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2675)\u001b[0m Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2674)\u001b[0m Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2676)\u001b[0m Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2677)\u001b[0m Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2678)\u001b[0m Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2675)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2676)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2674)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m distributed_backend=gloo\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m All distributed processes registered. Starting with 6 processes\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCheckpointCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2677)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2678)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m    | Name                               | Type                            | Params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 0  | loss                               | QuantileLoss                    | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 1  | logging_metrics                    | ModuleList                      | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 2  | input_embeddings                   | MultiEmbedding                  | 7.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 3  | prescalers                         | ModuleDict                      | 48    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 4  | static_variable_selection          | VariableSelectionNetwork        | 1.3 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 6  | decoder_variable_selection         | VariableSelectionNetwork        | 954   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 7  | static_context_variable_selection  | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 10 | static_context_enrichment          | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 11 | lstm_encoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 12 | lstm_decoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 840   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 14 | post_lstm_add_norm_encoder         | AddNorm                         | 40    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 15 | static_enrichment                  | GatedResidualNetwork            | 2.1 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 16 | multihead_attn                     | InterpretableMultiHeadAttention | 879   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 17 | post_attn_gate_norm                | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 18 | pos_wise_ff                        | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 19 | pre_output_gate_norm               | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 20 | output_layer                       | Linear                          | 63    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 32.4 K    Trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 32.4 K    Total params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m 0.129     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: UserWarning: num_workers>0, persistent_workers=False, and strategy=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|█████     | 1/2 [00:17<00:17, 17.69s/it, loss=13.8, v_num=, train_loss_step=13.80]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:52<00:00, 26.14s/it, loss=13.8, v_num=, train_loss_step=13.80]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:55<00:00, 27.52s/it, loss=13.8, v_num=, train_loss_step=13.80, val_loss=18.30]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:55<00:00, 27.52s/it, loss=13.8, v_num=, train_loss_step=13.80, val_loss=18.30, train_loss_epoch=18.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2674)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2674)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2673)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2675)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2675)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2676)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2676)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2677)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2677)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2678)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2678)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Number of parameters in network: 32.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: ParallelStrategy.torch_distributed_backend was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2885)\u001b[0m Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2882)\u001b[0m Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2883)\u001b[0m Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2884)\u001b[0m Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2886)\u001b[0m Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2885)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2882)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2883)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2884)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m distributed_backend=gloo\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m All distributed processes registered. Starting with 6 processes\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCheckpointCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m    | Name                               | Type                            | Params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 0  | loss                               | QuantileLoss                    | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 1  | logging_metrics                    | ModuleList                      | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 2  | input_embeddings                   | MultiEmbedding                  | 7.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 3  | prescalers                         | ModuleDict                      | 48    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 4  | static_variable_selection          | VariableSelectionNetwork        | 1.3 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 6  | decoder_variable_selection         | VariableSelectionNetwork        | 954   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 7  | static_context_variable_selection  | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 10 | static_context_enrichment          | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 11 | lstm_encoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 12 | lstm_decoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 840   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 14 | post_lstm_add_norm_encoder         | AddNorm                         | 40    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 15 | static_enrichment                  | GatedResidualNetwork            | 2.1 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 16 | multihead_attn                     | InterpretableMultiHeadAttention | 879   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 17 | post_attn_gate_norm                | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 18 | pos_wise_ff                        | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 19 | pre_output_gate_norm               | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 20 | output_layer                       | Linear                          | 63    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 32.4 K    Trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 32.4 K    Total params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m 0.129     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2886)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: UserWarning: num_workers>0, persistent_workers=False, and strategy=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] \n",
      "Epoch 0:  50%|█████     | 1/2 [00:17<00:17, 17.30s/it, loss=12.5, v_num=, train_loss_step=12.50]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:50<00:00, 25.15s/it, loss=12.5, v_num=, train_loss_step=12.50]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:52<00:00, 26.36s/it, loss=12.5, v_num=, train_loss_step=12.50, val_loss=16.50]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:52<00:00, 26.37s/it, loss=12.5, v_num=, train_loss_step=12.50, val_loss=16.50, train_loss_epoch=16.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2881)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2886)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2886)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2884)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2884)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2885)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2885)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2883)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2883)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2882)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=2882)\u001b[0m   warnings.warn('resource_tracker: There appear to be %d '\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Number of parameters in network: 28.6k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   new_rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: ParallelStrategy.torch_distributed_backend was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   return new_rank_zero_deprecation(*args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3101)\u001b[0m Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3102)\u001b[0m Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3099)\u001b[0m Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3100)\u001b[0m Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3103)\u001b[0m Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/6\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3102)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3099)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3100)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3101)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m distributed_backend=gloo\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m All distributed processes registered. Starting with 6 processes\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m ----------------------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:335: LightningDeprecationWarning: The `on_keyboard_interrupt` callback hook was deprecated in v1.5 and will be removed in v1.7. Please use the `on_exception` callback hook instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:347: LightningDeprecationWarning: The `on_init_start` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:351: LightningDeprecationWarning: The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\"The `on_init_end` callback hook was deprecated in v1.6 and will be removed in v1.8.\")\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:354: LightningDeprecationWarning: The `on_configure_sharded_model` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:359: LightningDeprecationWarning: The `on_before_accelerator_backend_setup` callback hook was deprecated in v1.6 and will be removed in v1.8. Use `setup()` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:364: LightningDeprecationWarning: `TuneReportCheckpointCallback.on_load_checkpoint` will change its signature and behavior in v1.8. If you wish to load the state of the callback, use `load_state_dict` instead. In v1.8 `on_load_checkpoint(..., checkpoint)` will receive the entire loaded checkpoint dictionary instead of callback state.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:376: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_start` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:385: LightningDeprecationWarning: The `Callback.on_epoch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_<train/validation/test>_epoch_end` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_start` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:391: LightningDeprecationWarning: The `Callback.on_pretrain_routine_end` hook has been deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_fit_start` instead.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_deprecation(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3103)\u001b[0m [W ProcessGroupGloo.cpp:724] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m    | Name                               | Type                            | Params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 0  | loss                               | QuantileLoss                    | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 1  | logging_metrics                    | ModuleList                      | 0     \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 2  | input_embeddings                   | MultiEmbedding                  | 3.9 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 3  | prescalers                         | ModuleDict                      | 48    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 4  | static_variable_selection          | VariableSelectionNetwork        | 1.3 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 5  | encoder_variable_selection         | VariableSelectionNetwork        | 1.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 6  | decoder_variable_selection         | VariableSelectionNetwork        | 954   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 7  | static_context_variable_selection  | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 10 | static_context_enrichment          | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 11 | lstm_encoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 12 | lstm_decoder                       | LSTM                            | 3.4 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 840   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 14 | post_lstm_add_norm_encoder         | AddNorm                         | 40    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 15 | static_enrichment                  | GatedResidualNetwork            | 2.1 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 16 | multihead_attn                     | InterpretableMultiHeadAttention | 879   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 17 | post_attn_gate_norm                | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 18 | pos_wise_ff                        | GatedResidualNetwork            | 1.7 K \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 19 | pre_output_gate_norm               | GateAddNorm                     | 880   \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 20 | output_layer                       | Linear                          | 63    \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m ----------------------------------------------------------------------------------------\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 28.6 K    Trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 0         Non-trainable params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 28.6 K    Total params\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m 0.114     Total estimated model params size (MB)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: UserWarning: num_workers>0, persistent_workers=False, and strategy=ddp_spawn may result in data loading bottlenecks. Consider setting persistent_workers=True (this is a limitation of Python .spawn() and PyTorch)\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1933: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m   rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s] \n",
      "Epoch 0:  50%|█████     | 1/2 [00:15<00:15, 15.87s/it, loss=52.3, v_num=, train_loss_step=52.30]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A0m \n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m \n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "\u001b[2m\u001b[36m(RayExecutor pid=3098)\u001b[0m \n",
      "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 2/2 [00:44<00:00, 22.45s/it, loss=52.3, v_num=, train_loss_step=52.30]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:49<00:00, 24.65s/it, loss=52.3, v_num=, train_loss_step=52.30, val_loss=37.90]\n",
      "Epoch 0: 100%|██████████| 2/2 [00:49<00:00, 24.66s/it, loss=52.3, v_num=, train_loss_step=52.30, val_loss=37.90, train_loss_epoch=40.40]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m /Users/christy/miniconda3/envs/dev38/lib/python3.8/site-packages/pytorch_lightning/utilities/parsing.py:261: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m   rank_zero_warn(\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m GPU available: False, used: False\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m IPU available: False, using: 0 IPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m HPU available: False, using: 0 HPUs\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m `Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=2669)\u001b[0m Number of parameters in network: 28.6k\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +33m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +34m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +34m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +35m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +36m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +37m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +38m11s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +38m46s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +39m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +55m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +56m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h12m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h12m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h28m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h28m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h44m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1h44m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h1m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h2m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h17m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h18m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h34m51s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h35m27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h53m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +2h53m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h11m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h12m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h28m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h28m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h45m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +3h46m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h3m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h4m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h21m23s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h21m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h39m7s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h39m42s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h55m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +4h56m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h11m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h12m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h29m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h29m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h45m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +5h46m11s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h4m7s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h4m42s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h21m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h22m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h39m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h39m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h55m46s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +6h56m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h12m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h12m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h28m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h29m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h47m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +7h48m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h5m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h6m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h22m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h23m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h40m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h40m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h57m1s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +8h57m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h15m2s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h15m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h32m1s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h32m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h49m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +9h49m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h7m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h8m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h11m2s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h14m57s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h20m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h21m11s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +10h38m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +11h7m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +11h24m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +11h41m7s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +11h57m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +12h15m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +12h48m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +12h58m52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h14m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h17m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h18m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h18m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h19m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h19m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h20m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h20m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h23m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h27m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h37m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h38m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h38m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h39m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h40m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h40m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h41m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h41m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h42m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h43m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h43m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h44m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h44m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h45m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h46m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h46m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h47m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h47m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h48m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h48m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h49m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h50m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h50m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h51m16s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h51m51s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h52m26s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h53m1s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h53m36s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h54m12s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h54m47s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h55m22s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h55m57s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h56m32s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h57m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h57m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h58m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h58m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +13h59m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h1m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h1m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h2m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h2m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h3m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h4m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h4m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h5m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h5m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h6m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h7m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h7m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h8m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h8m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h9m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h10m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h10m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h11m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +14h11m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# STEP 7. Run the experiment with Ray AIR APIs and Ray Lightning.\n",
    "# https://docs.ray.io/en/latest/tune/examples/tune-pytorch-lightning.html\n",
    "############\n",
    "start = time.time()\n",
    "\n",
    "# By default Callable function accepts only 1 input parameter called \"config\".\n",
    "# Wrap Callable train function inside tune.with_parameters().\n",
    "train_with_parameters = \\\n",
    "    tune.with_parameters(\n",
    "        train_models,\n",
    "        strategy=strategy,\n",
    "        filename=DATA_FILENAME)\n",
    "\n",
    "# Define a tuner object.\n",
    "tuner = tune.Tuner(\n",
    "        tune.with_resources(\n",
    "            train_with_parameters,\n",
    "            resources=get_tune_resources(num_workers=num_training_workers),\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "        ),\n",
    "        run_config=air.RunConfig(\n",
    "            # Redirect logs to relative path instead of default ~/ray_results/.\n",
    "            local_dir=\"my_Tune_logs\",\n",
    "            # Specify name to make logs easier to find in log path.\n",
    "            name=\"ptf_nyc\",\n",
    "        ),\n",
    "        param_space=FORECAST_CONFIG,\n",
    "    )\n",
    "\n",
    "# Fit the tuner object.\n",
    "results = tuner.fit()\n",
    "\n",
    "total_time_taken = time.time() - start\n",
    "print(f\"Total number of models: {len(results)}\")\n",
    "print(f\"Finished in: {(time.time()-start)/60} minutes\")\n",
    "\n",
    "# Total number of models: 6\n",
    "# Finished in: 1.1374133070309957 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa2c5c",
   "metadata": {},
   "source": [
    "## Load a model from checkpoint  <a class=\"anchor\" id=\"load_checkpoint\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b686d3",
   "metadata": {},
   "source": [
    "- After the Tune experiment has run, we can assemble the Tune ResultGrid object into a pandas dataframe.\n",
    "\n",
    "- Next, we'll sort the pandas dataframe by data segment and error, and keep only the best model with minimum error per data segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd924f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [print(i.checkpoint) for i in results]\n",
    "[print(i.config) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05e9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of training loss errors\n",
    "loss = [i.metrics.get(\"loss\", 10000.0) for i in results]\n",
    "\n",
    "# get a list of model params\n",
    "# batch_size = [i.config[\"batch_size\"] for i in results]\n",
    "lr = [i.config[\"lr\"] for i in results]\n",
    "dropout = [i.config[\"dropout\"] for i in results]\n",
    "data_segment = [i.config[\"sample_cluster_id\"] for i in results]\n",
    "\n",
    "# get a list of checkpoints\n",
    "checkpoints = [i.checkpoint for i in results]\n",
    "\n",
    "# Assemble a pandas dataframe from Tune results\n",
    "results_df = pd.DataFrame(\n",
    "    zip(loss, lr, dropout, data_segment, checkpoints),\n",
    "    columns=[\"loss\", \"learning_rate\", \"droput\", \"data_segment\", \"checkpoint\"],\n",
    ")\n",
    "print(results_df.dtypes)\n",
    "print(results_df.head(8))\n",
    "\n",
    "# Get model error for a specific model.\n",
    "best_model_error = results_df.loc[(results_df.data_segment==\"erratic\"), 'loss'].min()\n",
    "print(\"#########\")\n",
    "print(f\"Baseline error cluster1: {baseline_error}\")\n",
    "print(f\"Best tuned error cluster1: {best_model_error}\")\n",
    "print(\"#########\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model path for a specific model.\n",
    "model_path = results_df.iloc[5, -1:][0]  #Pick row num from df displayed above\n",
    "model_path = str(model_path).split(\"local_path=\")[1]\n",
    "model_dir = str(model_path).split(\"checkpoint_000001\")[0]\n",
    "model_path = model_path.split(\")\")[0] + \"/checkpoint\"\n",
    "print(f\"model_dir: {model_dir}\")\n",
    "print(f\"checkpoint_path: {model_path}\")\n",
    "\n",
    "# Restore a model from checkpoint.\n",
    "best_model = ptf.models.TemporalFusionTransformer.load_from_checkpoint(model_path)\n",
    "print(f\"Restored model type: {type(best_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5196a54d",
   "metadata": {},
   "source": [
    "## Create a validation forecast from restored checkpoint model <a class=\"anchor\" id=\"create_inference\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd3cdd",
   "metadata": {},
   "source": [
    "Finally, we will restore the best models per cluster of data from checkpoint, perform inference on validation data, and inspect the \"backtest\" forecasts.\n",
    "\n",
    "- We will easily obtain AIR Checkpoint objects from the Tune results. \n",
    "- We will restore a PyTorch Forecasting model directly from checkpoint, and demonstrate it can be used for prediction.\n",
    "\n",
    "```{tip}\n",
    "[Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) make batch inference easy since they have internal logic to parallelize the inference.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad8c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore a validation loader from pickle file.\n",
    "filename = model_dir + \"val_loader.pickle\"\n",
    "print(f\"filename: {filename}\")\n",
    "with open(filename, 'rb') as handle:\n",
    "    validation_loader = pickle.load(handle)\n",
    "type(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73771aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################\n",
    "# calculate WQL, MAE\n",
    "# note: to get a single item quantile prediction:\n",
    "# example: quantile p50 for itemid=\"140\"\n",
    "# y_quantiles[1].detach().cpu()[43, : x[\"decoder_lengths\"][43]] \n",
    "# raw predictions are a dictionary from which quantiles can be extracte\n",
    "# TIP:  Use x to figure out mappings indexes to locations [141, 43, 144]\n",
    "################\n",
    "print(f\"available quantiles: {best_model.loss.quantiles}\")\n",
    "raw_predictions, x = best_model.predict(validation_loader, mode=\"raw\", return_x=True)\n",
    "desired_quantiles = [0.25, 0.5, 0.75]\n",
    "y_quantiles = best_model.to_quantiles(raw_predictions, desired_quantiles)\n",
    "WQL, MAE = evaluate_model(actuals, y_quantiles, desired_quantiles)\n",
    "print(f\"Mean WQL over {desired_quantiles}: {WQL}\")\n",
    "print(f\"Mean AE at p50: {MAE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c22cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inference forecasts for some unique_ids.\n",
    "# some_unique_ids = random.sample(range(0, pred.shape[0]), 10)\n",
    "some_unique_ids = [25, 41, 14, 24, 4]\n",
    "for idx in some_unique_ids:\n",
    "    best_model.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1340387",
   "metadata": {},
   "source": [
    "## Deploy a model from checkpoint using Ray Serve\n",
    "<a class=\"anchor\" id=\"deploy_model\"></a>\n",
    "\n",
    "Coding steps for Deployment:\n",
    "- **Step 1**. Instantiate a batch predictor using Ray AIR checkpoints.\n",
    "- **Step 2**. Create some test data.\n",
    "- **Step 3**. Run `batch_predictor.predict(test_data)`.\n",
    "\n",
    "Replace Step 3 above with these steps for a custom predictor:\n",
    "- **Step 3**.  Define a Ray Serve deployment class by using a Ray decorator @serve.deployment.\n",
    "- **Step 4**.  Deploy the predictor.\n",
    "- **Step 5**.  Query the deployment and get the result.\n",
    "\n",
    "Steps 3-5 above are only required if you are using a custom predictor (such as ARIMA, Prophet, or PyTorch Forecasting).  Otherwise for Ray AIR-integrated ML Libraries (HuggingFace transformers, PyTorch, TensorFlow, Scikit-learn, XGBoost, or LightGBM models), all you have to do is call `batch_predictor.predict(test_data)`.\n",
    "\n",
    "For more details see [Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) and [Ray Serve](https://docs.ray.io/en/latest/serve/getting_started.html) docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae16f1c-8ab1-44cc-9bab-536439758e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "# Import forecasting libraries. \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import pytorch_forecasting as ptf\n",
    "# Import ray libraries.\n",
    "import ray\n",
    "from ray import serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88818bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get location to saved model.\n",
    "# print(model_dir)\n",
    "# print(model_path)\n",
    "\n",
    "##########\n",
    "# STEP 1. Instantiate a batch predictor from checkpoint.\n",
    "##########\n",
    "batch_predictor = ptf.models.TemporalFusionTransformer.load_from_checkpoint(model_path)\n",
    "print(f\"Batch predictor type: {type(batch_predictor)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8969336",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# STEP 2. Create some test data. \n",
    "##########\n",
    "# Being lazy, pretend the last test data is our out-of-sample test data.\n",
    "max_prediction_length = FORECAST_CONFIG['forecast_horizon']\n",
    "new_prediction_data = df.copy()\n",
    "new_prediction_data[\"time_idx\"] = new_prediction_data[\"time_idx\"] + max_prediction_length\n",
    "\n",
    "# Convert data from pandas to PyTorch tensors.\n",
    "print(f\"Input data type: {type(df)}\")\n",
    "_, _, test_loader = convert_pandas_pytorch_timeseriesdata(\n",
    "    new_prediction_data, FORECAST_CONFIG\n",
    ")\n",
    "# Checkpoint a custom object.\n",
    "pickle_dir = model_dir + \"test_loader.pickle\"\n",
    "with open(pickle_dir, 'wb') as handle:\n",
    "    pickle.dump(validation_loader, handle)\n",
    "    \n",
    "# Restore a test loader from pickle file.\n",
    "filename = model_dir + \"test_loader.pickle\"\n",
    "with open(filename, 'rb') as handle:\n",
    "    test_loader = pickle.load(handle)\n",
    "\n",
    "print(f\"Output data type: {type(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0bd0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# STEP 3. Define a Ray Serve deployment class.\n",
    "##########\n",
    "@serve.deployment\n",
    "class ForecastPredictor:\n",
    "    def __init__(self, predictor, test_data):\n",
    "        self.predictor = predictor\n",
    "        self.test_data = test_data\n",
    "        \n",
    "    def predict(self):\n",
    "        raw_predictions, x = \\\n",
    "          self.predictor.predict(self.test_data, mode=\"raw\", return_x=True)\n",
    "        return x, raw_predictions\n",
    "\n",
    "    def __call__(self):\n",
    "        x, raw_predictions = self.predict()\n",
    "        return [x, raw_predictions]\n",
    "\n",
    "##########\n",
    "# STEP 4. Deploy the predictor.\n",
    "##########\n",
    "# Bind arguments to the Class constructor.\n",
    "my_first_deployment = ForecastPredictor.bind(\n",
    "    predictor=batch_predictor,\n",
    "    test_data=test_loader)\n",
    "\n",
    "##########\n",
    "# STEP 5. Query the deployment and get the result.\n",
    "##########\n",
    "# Get handle from serve.run().\n",
    "handle = serve.run(my_first_deployment)\n",
    "\n",
    "# ray.get() the results from the handle.\n",
    "ray_return = ray.get(handle.remote())\n",
    "new_x = ray_return[0]\n",
    "new_pred = ray_return[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some predictions from deployed predictor.\n",
    "for idx in plot_locations:\n",
    "    batch_predictor.plot_prediction(new_x, new_pred, idx=idx, show_future_observed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec3d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
