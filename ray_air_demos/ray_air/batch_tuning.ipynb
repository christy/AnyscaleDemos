{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f5c2fbd-31d7-4262-94c8-1f6cea6f5938",
   "metadata": {},
   "source": [
    "# Batch training & tuning on Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ca5cc-6337-4569-b508-3784b3b6ab0c",
   "metadata": {},
   "source": [
    "Batch training and tuning are common tasks in simple machine learning use-cases such as time series forecasting. They require fitting of simple models on multiple data batches corresponding to locations, products, etc.\n",
    "\n",
    "In the context of this notebook, batch training is understood as creating the same model(s) for different and separate data, or subsets of a dataset. This notebook showcases how to conduct batch training using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).\n",
    "\n",
    "![Batch training diagram](../../data/examples/images/batch-training.svg)\n",
    "\n",
    "For the data, we will use the [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This popular tabular dataset contains historical taxi pickups by timestamp and location in NYC. To demonstrate batch training, we will simplify the data to a regression problem to predict `trip_duration` and use scikit-learn.\n",
    "\n",
    "To demonstrate how batch training can be parallelized, we will train a separate model for each dropoff location. This means we can use the `dropoff_location_id` column in the dataset to group the dataset into data batches. Then we will fit a separate model for each batch and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaee275-9cb1-4fa9-9393-a04a6fe00d84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contents\n",
    "\n",
    "In this this tutorial, you will learn about:\n",
    " 1. [Introduction to Ray Tune](#intro_tune)\n",
    " 2. [Define how to load and prepare Parquet data](#load_data)\n",
    " 3. [Define your Ray Tune Search Space and Search Algorithm](#define_search_space)\n",
    " 4. [Define a Trainable (callable) function](#define_trainable)\n",
    " 5. [Run independent trials in Parallel using Ray AIR Tune](#run_tune_search)\n",
    " 6. [Load a model from checkpoint and perform inference](#load_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb02a92-a603-48b8-a23e-887ecaaf5470",
   "metadata": {},
   "source": [
    "# Introduction to Ray Tune <a class=\"anchor\" id=\"intro_tune\"></a>\n",
    "\n",
    "**While Tune's main purpose is hyperparameter optimization, you can also use it as an execution engine to run parallel trials in any search space.**  \n",
    "\n",
    "In this notebook, we will use [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) to run separate, parallel training jobs per dropoff location.  After your Tune experiment (all the trials) has run, we will pick the best model per dropoff location.\n",
    "> An experiment in Tune is defined as a set of trials. \n",
    "\n",
    "Let us quickly walk through the [key concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) you need to know to use Tune.\n",
    "\n",
    "- First, you define a *Search space* and pass that into a `Trainable` or `callable` function, that specifies the objective you want to tune.  The trainable function will be called for every trial in the search space.\n",
    "\n",
    "- Then you select a *Search algorithm* and optionally use a\n",
    "scheduler to stop searches early and speed up your experiment.  We will use simple **grid search** (run every permutation as a separate trial).\n",
    "\n",
    "- Together with other configurations, the Trainable, Search algorithm, and Scheduler are passed into `Tuner`, which runs your experiment trials in parallel.\n",
    "\n",
    "- The output from `Tuner.fit()` can be analyzed to inspect your experiment results.  The following figure shows an overview of the Ray Tune flow, which we will use in this tutorial.\n",
    "\n",
    "![Tune flow diagram](../../tune/images/tune_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869e809-fd60-4258-ae53-e2fdd71ba234",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "\n",
    "Let us start by importing a few required libraries, including open-source [Ray](https://github.com/ray-project/ray) itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ec7c35-5810-460c-9cf9-5cd7b62eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 8\n",
      "pyarrow: 10.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f'Number of CPUs in this system: {os.cpu_count()}')\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pds\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba8f73a-e47f-469d-a116-31fc5da8ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:45:16,654\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-09_17-45-14_702430_61827/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-09_17-45-14_702430_61827/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-11-09_17-45-14_702430_61827', 'metrics_export_port': 62937, 'gcs_address': '127.0.0.1:61263', 'address': '127.0.0.1:61263', 'dashboard_agent_listen_port': 52365, 'node_id': '25fdf2d42ea17dafa395380793f927341768af6e55fe2b1d652e0b20'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54a9528-defe-4102-a179-d779f0dc2f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object_store_memory': 2147483648.0, 'memory': 8220162458.0, 'node:127.0.0.1': 1.0, 'CPU': 8.0}\n"
     ]
    }
   ],
   "source": [
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd4b4a0-bcc8-49c3-8b5e-2590f9100a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# import standard sklearn libraries\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f\"sklearn: {sklearn.__version__}\")\n",
    "\n",
    "# import ray libraries\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "\n",
    "# set global random seed for sklearn models\n",
    "np.random.seed(415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0af2c6-7c90-42bc-8687-3c9b2dc9a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For benchmarking purposes, we can print the times of various operations.\n",
    "# In order to reduce clutter in the output, this is set to False by default.\n",
    "PRINT_TIMES = False\n",
    "\n",
    "def print_time(msg: str):\n",
    "    if PRINT_TIMES:\n",
    "        print(msg)\n",
    "        \n",
    "# To speed things up, we’ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d69835-0104-4a89-8418-b1986e45a15c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define how to load and prepare Parquet data <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558f234-b7af-489d-8aaa-42a7c49f2194",
   "metadata": {},
   "source": [
    "First, we need to load some data.  Since the NYC Taxi dataset is fairly large, we will filter files first into a PyArrow dataset. And then in the next cell after, we will filter the data on read into a PyArrow table and convert that to a pandas dataframe.\n",
    "\n",
    "```{tip}\n",
    "Use PyArrow dataset and table for reading or writing large parquet files, since its native multithreaded C++ adpater is faster than pandas read_parquet, even using engine=pyarrow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5076160a-07c5-4ceb-83d6-22c14d3d05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Taxi using 1 file(s)!\n",
      "s3_files: ['s3://air-example-data/ursa-labs-taxi-data/by_year/2019/06/data.parquet/ab5b9d2b8cc94be19346e260b543ec35_000000.parquet']\n",
      "Locations: [145, 166, 152]\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "target = \"trip_duration\"\n",
    "s3_partitions = pds.dataset(\n",
    "    \"s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/\",\n",
    "    partitioning=[\"year\", \"month\"],\n",
    ")\n",
    "s3_files = [f\"s3://{file}\" for file in s3_partitions.files]\n",
    "\n",
    "# Obtain all location IDs\n",
    "all_location_ids = (\n",
    "    pq.read_table(s3_files[0], columns=[\"dropoff_location_id\"])[\"dropoff_location_id\"]\n",
    "    .unique()\n",
    "    .to_pylist()\n",
    ")\n",
    "\n",
    "# Use smoke testing or not.\n",
    "starting_idx = -1 if SMOKE_TEST else 0\n",
    "sample_locations = [145, 166, 152] if SMOKE_TEST else all_location_ids\n",
    "\n",
    "# Display what data will be used.\n",
    "s3_files = s3_files[starting_idx:]\n",
    "print(f\"NYC Taxi using {len(s3_files)} file(s)!\")\n",
    "print(f\"s3_files: {s3_files}\")\n",
    "print(f\"Locations: {sample_locations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf5b850-fa35-4397-bea6-b8c21fd754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a pyarrow.Table object using pyarrow parquet \n",
    "def read_data(file: str, sample_id: np.int32) -> pd.DataFrame:\n",
    "    \n",
    "    df = pq.read_table(\n",
    "        file,\n",
    "        filters=[\n",
    "            (\"passenger_count\", \">\", 0),\n",
    "            (\"trip_distance\", \">\", 0),\n",
    "            (\"fare_amount\", \">\", 0),\n",
    "            (\"pickup_location_id\", \"in\", [264, 265]),\n",
    "            (\"dropoff_location_id\", \"not in\", [264, 265]), \n",
    "            (\"dropoff_location_id\", \"=\", sample_id)\n",
    "        ],\n",
    "        columns=[\n",
    "            \"pickup_at\",\n",
    "            \"dropoff_at\",\n",
    "            \"pickup_location_id\",\n",
    "            \"dropoff_location_id\",\n",
    "            \"passenger_count\",\n",
    "            \"trip_distance\",\n",
    "            \"fare_amount\",\n",
    "        ],\n",
    "    ).to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to transform a pandas dataframe\n",
    "def transform_df(the_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = the_df.copy()\n",
    "    \n",
    "    df[\"trip_duration\"] = (df[\"dropoff_at\"] - df[\"pickup_at\"]).dt.seconds\n",
    "    df = df[df[\"trip_duration\"] > 60]\n",
    "    df = df[df[\"trip_duration\"] < 24 * 60 * 60] \n",
    "    df.drop([\"dropoff_at\", \"pickup_at\", \"pickup_location_id\", \"fare_amount\"]\n",
    "            , axis=1, inplace=True)\n",
    "    df[\"dropoff_location_id\"] = df[\"dropoff_location_id\"].fillna(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb4399c-7edd-47ca-8362-cd565a91a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Test reading data.\n",
    "# import itertools\n",
    "# my_list = itertools.product(s3_files, sample_locations)\n",
    "\n",
    "# # [print(f[0], f[1]) for f in my_list]  \n",
    "# df_list = [read_data(f[0], f[1]) for f in my_list]\n",
    "# df_raw = pd.concat(df_list, ignore_index=True)\n",
    "# # Transform data.\n",
    "# df = transform_batch(df_raw)\n",
    "\n",
    "# # Inspect the pandas dataframe.\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72369cbf-e346-441c-b7e3-9280ccabc7f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define your Ray Tune Search Space and Search Algorithm <a class=\"anchor\" id=\"define_search_space\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310b13e-ba83-4c47-84e6-d1e916483b2b",
   "metadata": {},
   "source": [
    "**First, define a search space of experiment trials to run.** \n",
    "> The search space together with a search algorithm determine which trials will be run.  \n",
    "\n",
    "Common search algorithms include grid search, random search, Bayesian search, Hyperopt, and Optuna.  For more details, see [Working with Tune Search Spaces](https://docs.ray.io/en/master/tune/tutorials/tune-search-spaces.html#tune-search-space-tutorial).  Deciding the best combination of search space and search algorithm is part of the art of being a Data Scientist and depends on the data, algorithm, and problem being solved!  \n",
    "\n",
    "**Below, we define our search space is:**\n",
    "- 2 different Scikit-learn algorithms \n",
    "- Some or all NYC taxi drop-off locations. \n",
    "\n",
    "**And we define the search algorithm is:**\n",
    "- Grid search.\n",
    "\n",
    "> This means every permutation of each algorithm and each NYC Taxi drop-off location will be run as a separate trial!  \n",
    "\n",
    "Ray Tune partitions the Search space using the specified Search algorithm and takes care of running a Tune job on each partition in parallel.  Specifically, Ray Tune will pass a config dictionary to each partition and make a Trainable function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de03814-4eec-4363-a623-790f040b99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define a search space.\n",
    "sample_locations = [145, 166, 152] if SMOKE_TEST else all_location_ids\n",
    "search_space = {\n",
    "    \"model\": tune.grid_search([LinearRegression(fit_intercept=True), \n",
    "                                DecisionTreeRegressor(max_depth=3)]),\n",
    "    \"location\": tune.grid_search(sample_locations),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28814e79-f53e-4527-a959-e952f7d57fe5",
   "metadata": {},
   "source": [
    "## Define a Trainable (callable) function <a class=\"anchor\" id=\"define_trainable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3c9a4-b2df-4063-8c04-f5e0136c90bf",
   "metadata": {},
   "source": [
    "🧪 Typically when you are running Data Science experiments, you want to be able to keep track of summary metrics for each trial, so you can decide at the end which trials were the best.  That way, you can decide which model to deploy.\n",
    "\n",
    "📋 Ray Tune produces an experiment Summary table with metrics which you specify how to calculate inside a \"Trainable\" or \"callable\" function.\n",
    "\n",
    "<b>Define a \"Trainable\" or \"callable\" function that can be called by every parallel Tune trial.</b> \n",
    ">Ray Tune has two ways of defining a trainable, namely the [Function API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs) and the Class API. Both are valid ways of defining a trainable, but *the Function API is generally recommended*.\n",
    "\n",
    "**In the cell below, we define a \"Trainable\" function called `train_model()`**.  \n",
    "- It takes as input a config dictionary argument. \n",
    "- The output can be a simple dictionary of metrics which will be reported back to the Tune Summary table.  In our case, we've chosen to checkpoint save each model in addition to reporting each trial's metrics.\n",
    "- `train_model()` will be called in parallel by Tune for each partition of the Tune search space.  \n",
    "- Since we are using **grid search**, this means `train_model()` will be run *in parallel for every permutation* in the Tune search space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03c0ff8-0c42-4703-91f4-57fc0df8f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a custom train function\n",
    "def train_model(config: dict):\n",
    "\n",
    "    model = config['model']\n",
    "    the_location = config['location']\n",
    "    \n",
    "    # Load data.\n",
    "    df_list = [read_data(f, the_location) for f in s3_files]   \n",
    "    df_raw = pd.concat(df_list, ignore_index=True)\n",
    "    df = transform_df(df_raw)\n",
    "    \n",
    "    # Train/valid split.\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "    train_X = train_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    train_y = train_df.trip_duration\n",
    "    valid_X = valid_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    valid_y = valid_df.trip_duration\n",
    "\n",
    "    # Train model.\n",
    "    model = model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(valid_X)\n",
    "    \n",
    "    # Evaluate.\n",
    "    error = sklearn.metrics.mean_absolute_error(valid_y, pred_y)\n",
    "    \n",
    "    # Save the model as a Tune Checkpoint.  \n",
    "    # This is done through ray.air.session.report() API.\n",
    "    # https://docs.ray.io/en/latest/tune/tutorials/tune-checkpoints.html\n",
    "    \n",
    "    # Define a model checkpoint.\n",
    "    checkpoint = Checkpoint.from_dict({\n",
    "        \"model\": model, \n",
    "        \"location_id\": the_location})\n",
    "\n",
    "    # Save checkpoint and report back metrics, using ray.air.session.report()\n",
    "    metrics = dict(error = error)\n",
    "    session.report(\n",
    "            metrics, \n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb435c-8485-4146-9e22-cff77b3f4946",
   "metadata": {},
   "source": [
    "## Run independent trials in Parallel using Ray Tune <a class=\"anchor\" id=\"run_tune_search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d0d25-a5b0-4887-9d1a-a775d0107d12",
   "metadata": {},
   "source": [
    "Now we are ready to use Ray Tune to run separate, parallel training jobs, each as a different model training job, per dropoff location.\n",
    "\n",
    "**Configure the resources allocated per trial.** Tune uses this resources allocation to control the parallelism. For example, if each trial was configured to use 4 CPUs, and the cluster had only 32 CPUs, then Tune will limit the number of concurrent trials to 8 to avoid overloading the cluster. For more information, see [A Guide To Parallelism and Resources](https://docs.ray.io/en/master/tune/tutorials/tune-resources.html#tune-parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fa9df92-a412-42a8-b833-98dc86d58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Customize resources per trial, here we set 1 CPU each.\n",
    "train_model = tune.with_resources(train_model, {\"cpu\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36ca20-54ad-4400-88fe-ca8cc7ffbf84",
   "metadata": {},
   "source": [
    "**Below, we introduce AIR configs and run the experiment using `tuner.fit()`.** Tune will report on experiment status, and after the experiment finishes, you can inspect the results. \n",
    "\n",
    "Notice in the AIR config, we have specified a local directory `my_Tune_logs` for logging instead of the default `~/ray_results` directory. Learn more about logging Tune results at [How to configure logging in Tune](https://docs.ray.io/en/master/tune/tutorials/tune-output.html#tune-logging).\n",
    "\n",
    "Tune can [retry failed experiments automatically](https://docs.ray.io/en/master/tune/tutorials/tune-stopping.html#tune-stopping-guide), as well as entire experiments.  This is necessary in case a node on your remote cluster fails (when running on a cloud such as AWS or GCP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670d4015-4b0e-4a1a-88d7-07ac4a4e2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:45:21,801\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-09 17:46:51 (running for 00:01:29.49)<br>Memory usage on this node: 11.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/7.66 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/christy/Documents/github_ray_temp/ray/doc/source/ray-air/examples/my_Tune_logs/batch_tuning<br>Number of trials: 6/6 (6 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  location</th><th>model               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_56a1a_00000</td><td>TERMINATED</td><td>127.0.0.1:61901</td><td style=\"text-align: right;\">       145</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         81.2605</td><td style=\"text-align: right;\"> 796.212</td></tr>\n",
       "<tr><td>train_model_56a1a_00001</td><td>TERMINATED</td><td>127.0.0.1:61914</td><td style=\"text-align: right;\">       166</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         86.0153</td><td style=\"text-align: right;\"> 186.399</td></tr>\n",
       "<tr><td>train_model_56a1a_00002</td><td>TERMINATED</td><td>127.0.0.1:61915</td><td style=\"text-align: right;\">       152</td><td>LinearRegression()  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         82.262 </td><td style=\"text-align: right;\"> 239.382</td></tr>\n",
       "<tr><td>train_model_56a1a_00003</td><td>TERMINATED</td><td>127.0.0.1:61916</td><td style=\"text-align: right;\">       145</td><td>DecisionTreeReg_0310</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         81.233 </td><td style=\"text-align: right;\"> 438.619</td></tr>\n",
       "<tr><td>train_model_56a1a_00004</td><td>TERMINATED</td><td>127.0.0.1:61917</td><td style=\"text-align: right;\">       166</td><td>DecisionTreeReg_01c0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         84.8817</td><td style=\"text-align: right;\"> 220.351</td></tr>\n",
       "<tr><td>train_model_56a1a_00005</td><td>TERMINATED</td><td>127.0.0.1:61918</td><td style=\"text-align: right;\">       152</td><td>DecisionTreeReg_efd0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         85.0561</td><td style=\"text-align: right;\">1508.17 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:44,996\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_56a1a_00000 reported error=796.2115275065104,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 145}.\n",
      "Trial train_model_56a1a_00000 completed. Last result: error=796.2115275065104,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:47,015\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_56a1a_00003 reported error=438.61904761904765,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 145}.\n",
      "Trial train_model_56a1a_00003 completed. Last result: error=438.61904761904765,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:48,015\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_56a1a_00002 reported error=239.38207092285157,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 152}.\n",
      "Trial train_model_56a1a_00002 completed. Last result: error=239.38207092285157,should_checkpoint=True\n",
      "Trial train_model_56a1a_00004 reported error=220.3514275885793,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 166}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:50,670\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n",
      "2022-11-09 17:46:50,831\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': DecisionTreeRegressor(max_depth=3)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_56a1a_00004 completed. Last result: error=220.3514275885793,should_checkpoint=True\n",
      "Trial train_model_56a1a_00005 reported error=1508.175,should_checkpoint=True with parameters={'model': DecisionTreeRegressor(max_depth=3), 'location': 152}.\n",
      "Trial train_model_56a1a_00005 completed. Last result: error=1508.175,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:51,671\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': LinearRegression()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_56a1a_00001 reported error=186.39885796440973,should_checkpoint=True with parameters={'model': LinearRegression(), 'location': 166}.\n",
      "Trial train_model_56a1a_00001 completed. Last result: error=186.39885796440973,should_checkpoint=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 17:46:51,786\tINFO tune.py:758 -- Total run time: 89.99 seconds (89.48 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 6\n",
      "TOTAL TIME TAKEN: 90.00 seconds\n",
      "Best result: {'model': LinearRegression(), 'location': 166}\n"
     ]
    }
   ],
   "source": [
    "# Define a tuner object using Ray AIR Tuner API\n",
    "tuner = tune.Tuner(\n",
    "    train_model, \n",
    "    param_space=search_space,\n",
    "    run_config=air.RunConfig(\n",
    "        \n",
    "        #redirect logs to relative path instead of default ~/ray_results/\n",
    "        local_dir = \"my_Tune_logs\",\n",
    "        name = \"batch_tuning\",\n",
    "\n",
    "        # Set Ray Tune verbosity.  Print summary table only with levels 2 or 3.\n",
    "        verbose=2,\n",
    "        ),\n",
    ")\n",
    "\n",
    "# 4. Run the experiment with Ray Tune\n",
    "start = time.time()\n",
    "results = tuner.fit()\n",
    "total_time_taken = time.time() - start\n",
    "\n",
    "# Print some training stats\n",
    "print(f\"Total number of models: {len(results)}\")\n",
    "print(f\"TOTAL TIME TAKEN: {total_time_taken:.2f} seconds\")\n",
    "best_result = results.get_best_result(metric=\"error\", mode=\"min\").config\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af943052-bd4b-421b-bc89-c62ed5f65e57",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b>After the Tune experiment has run, pick the best model per dropoff location. </b>\n",
    "\n",
    "We can assemble the Tune results ([ResultGrid object](https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html)) into a pandas dataframe, then sort by minimum error, to select the best model per dropoff location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203d9c7e-59d8-4f55-973f-0b225ce581b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id      int64\n",
      "model           object\n",
      "error          float64\n",
      "checkpoint      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>796.211528</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>186.398858</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>239.382071</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>DecisionTreeRegressor(max_depth=3)</td>\n",
       "      <td>438.619048</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>DecisionTreeRegressor(max_depth=3)</td>\n",
       "      <td>220.351428</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id                               model       error  \\\n",
       "0          145                  LinearRegression()  796.211528   \n",
       "1          166                  LinearRegression()  186.398858   \n",
       "2          152                  LinearRegression()  239.382071   \n",
       "3          145  DecisionTreeRegressor(max_depth=3)  438.619048   \n",
       "4          166  DecisionTreeRegressor(max_depth=3)  220.351428   \n",
       "\n",
       "                                          checkpoint  \n",
       "0  Checkpoint(local_path=/Users/christy/Documents...  \n",
       "1  Checkpoint(local_path=/Users/christy/Documents...  \n",
       "2  Checkpoint(local_path=/Users/christy/Documents...  \n",
       "3  Checkpoint(local_path=/Users/christy/Documents...  \n",
       "4  Checkpoint(local_path=/Users/christy/Documents...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of errors\n",
    "errors = []\n",
    "[errors.append(i.metrics['error']) for i in results]\n",
    "\n",
    "# get a list of checkpoints\n",
    "checkpoints = []\n",
    "[checkpoints.append(i.checkpoint) for i in results] \n",
    "\n",
    "# get a list of locations\n",
    "locations = []\n",
    "[locations.append(i.to_dict()['location_id']) for i in checkpoints]\n",
    "\n",
    "# get a list of models\n",
    "models = []\n",
    "[models.append(i.to_dict()['model']) for i in checkpoints]\n",
    "\n",
    "# Assemble a pandas dataframe from Tune results\n",
    "results_df = pd.DataFrame(zip(locations, models, errors,checkpoints),\n",
    "                          columns = ['location_id', 'model', 'error', 'checkpoint']\n",
    "                         )\n",
    "print(results_df.dtypes)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "612b4bc3-72e4-478f-b59c-83c78ebd7900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model          object\n",
      "error         float64\n",
      "checkpoint     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>186.398858</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>239.382071</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>DecisionTreeRegressor(max_depth=3)</td>\n",
       "      <td>438.619048</td>\n",
       "      <td>Checkpoint(local_path=/Users/christy/Documents...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          model       error  \\\n",
       "location_id                                                   \n",
       "166                          LinearRegression()  186.398858   \n",
       "152                          LinearRegression()  239.382071   \n",
       "145          DecisionTreeRegressor(max_depth=3)  438.619048   \n",
       "\n",
       "                                                    checkpoint  \n",
       "location_id                                                     \n",
       "166          Checkpoint(local_path=/Users/christy/Documents...  \n",
       "152          Checkpoint(local_path=/Users/christy/Documents...  \n",
       "145          Checkpoint(local_path=/Users/christy/Documents...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 1 model per location_id with minimum error\n",
    "final_df = results_df.loc[results_df.groupby('location_id')['error'].idxmin()].copy()\n",
    "final_df.sort_values(by=[\"error\"], inplace=True)\n",
    "final_df.set_index('location_id', inplace=True, drop=True)\n",
    "print(final_df.dtypes)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4554830-1546-4353-a41e-621bdf46aeab",
   "metadata": {},
   "source": [
    "## Load a model from checkpoint and perform inference  <a class=\"anchor\" id=\"load_checkpoint\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b218d5-3e64-4b1d-9ad7-5ae3c8a8a78d",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "[Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) make batch inference easy since they have internal logic to parallelize the inference.\n",
    "```\n",
    "\n",
    "However, in this notebook, we will just restore a single scikit-learn model directly from checkpoint, and demonstrate it can be used for inference.  \n",
    "\n",
    "Below, we can easily obtain AIR Checkpoint objects from the Tune results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "180ebc5a-3cd2-4b1d-a807-0b228729069e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dropoff location\n",
    "the_location = final_df.index[0]\n",
    "the_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2c759c-f164-4004-986c-dc2990765db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ray.air.checkpoint.Checkpoint'>\n",
      "<class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    }
   ],
   "source": [
    "# Get a checkpoint directly from Ray Tune results\n",
    "checkpoint = final_df.checkpoint[the_location]\n",
    "print(type(checkpoint))\n",
    "\n",
    "# Restore a model from checkpoint\n",
    "model = checkpoint.to_dict()['model']\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb844fc1-2ae3-43dd-8737-5f8b7d0cbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test data\n",
    "df_list = [read_data(f, the_location) for f in s3_files[:1]]   \n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "df = transform_df(df_raw)\n",
    "\n",
    "# Train/test split.\n",
    "_, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "test_X = test_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "test_y = np.array(test_df.trip_duration)  #actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b35ffd80-a5ed-4eb0-9bb0-bc5774aa2c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_y</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>829.598083</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>868.933838</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>829.598083</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>484.389069</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>573.915955</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1104.947998</td>\n",
       "      <td>2832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>521.681763</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>711.590942</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1262.290894</td>\n",
       "      <td>1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1891.662354</td>\n",
       "      <td>2212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred_y  trip_duration\n",
       "0   829.598083            632\n",
       "1   868.933838            787\n",
       "2   829.598083            647\n",
       "3   484.389069            305\n",
       "4   573.915955            387\n",
       "5  1104.947998           2832\n",
       "6   521.681763            471\n",
       "7   711.590942            675\n",
       "8  1262.290894           1292\n",
       "9  1891.662354           2212"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform inference using restored model from checkpoint\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# Zip together predictions and actuals to visualize\n",
    "pd.DataFrame(zip(pred_y, test_y), \n",
    "             columns = [\"pred_y\", \"trip_duration\"])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde96350-e13d-4c37-9acb-50e2f3a0f48e",
   "metadata": {},
   "source": [
    "<b>Compare validation and test error.</b>\n",
    "\n",
    "During model training we reported error on \"validation\" data (random sample).  Below, we will report error on a pretend \"test\" data set (a different random sample).\n",
    "\n",
    "Do a quick validation that both errors are reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "243a7f6c-3d74-42c1-b2d4-caba0cfa1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 248.83761427137586\n"
     ]
    }
   ],
   "source": [
    "# Evaluate restored model on test data.\n",
    "error = sklearn.metrics.mean_absolute_error(test_y, pred_y)\n",
    "print(f\"Test error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526709cc-be4c-4cbf-99c0-ee10a916ef0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation error: 186.39885796440973\n"
     ]
    }
   ],
   "source": [
    "# Compare test error with training validation error\n",
    "print(f\"Validation error: {final_df.error[the_location]}\")\n",
    "\n",
    "# Validation and test errors should be reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff0e586-a6b2-4c30-b627-8e50c9a525a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
