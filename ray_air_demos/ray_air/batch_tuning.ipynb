{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f5c2fbd-31d7-4262-94c8-1f6cea6f5938",
   "metadata": {},
   "source": [
    "# Batch Tuning with Ray AIR Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d69835-0104-4a89-8418-b1986e45a15c",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06ec7c35-5810-460c-9cf9-5cd7b62eab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f'Number of CPUs in this system: {os.cpu_count()}')\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.dataset as pds\n",
    "from pyarrow import fs\n",
    "from pyarrow import parquet as pq\n",
    "from ray.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba8f73a-e47f-469d-a116-31fc5da8ecf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 13:57:13,506\tINFO worker.py:1509 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.0.1</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.8.13', ray_version='2.0.1', ray_commit='03b6bc7b5a305877501110ec04710a9c57011479', address_info={'node_ip_address': '127.0.0.1', 'raylet_ip_address': '127.0.0.1', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-02_13-57-11_514237_15311/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-02_13-57-11_514237_15311/sockets/raylet', 'webui_url': '127.0.0.1:8265', 'session_dir': '/tmp/ray/session_2022-11-02_13-57-11_514237_15311', 'metrics_export_port': 56214, 'gcs_address': '127.0.0.1:64305', 'address': '127.0.0.1:64305', 'dashboard_agent_listen_port': 52365, 'node_id': '2ec602a8c40a211861be591fecb64a8b973ef8ecfa437b3ac215bcca'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68cfa00-3db1-43e9-9822-97594e12984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed things up, we’ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "\n",
    "SMOKE_TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5076160a-07c5-4ceb-83d6-22c14d3d05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Taxi using 1 file(s)!\n",
      "s3_files: ['s3://air-example-data/ursa-labs-taxi-data/by_year/2019/06/data.parquet/ab5b9d2b8cc94be19346e260b543ec35_000000.parquet']\n",
      "Locations: [145, 166, 152]\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "target = \"trip_duration\"\n",
    "s3_partitions = pds.dataset(\n",
    "    \"s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/\",\n",
    "    partitioning=[\"year\", \"month\"],\n",
    ")\n",
    "s3_files = [f\"s3://{file}\" for file in s3_partitions.files]\n",
    "\n",
    "# Obtain all location IDs\n",
    "location_ids = (\n",
    "    pq.read_table(s3_files[0], columns=[\"dropoff_location_id\"])[\"dropoff_location_id\"]\n",
    "    .unique()\n",
    "    .to_pylist()\n",
    ")\n",
    "\n",
    "# Use smoke testing or not.\n",
    "starting_idx = -1 if SMOKE_TEST else 0\n",
    "sample_locations = [145, 166, 152] if SMOKE_TEST else location_ids\n",
    "\n",
    "# Display what data will be used.\n",
    "s3_files = s3_files[starting_idx:]\n",
    "print(f\"NYC Taxi using {len(s3_files)} file(s)!\")\n",
    "print(f\"s3_files: {s3_files}\")\n",
    "print(f\"Locations: {sample_locations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf5b850-fa35-4397-bea6-b8c21fd754cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pushdown_read_data(files_list: list, sample_ids: list) -> Dataset:\n",
    "    start = time.time()\n",
    "\n",
    "    filter_expr = (\n",
    "        (pds.field(\"passenger_count\") > 0)\n",
    "        & (pds.field(\"trip_distance\") > 0)\n",
    "        & (pds.field(\"fare_amount\") > 0)\n",
    "        & (~pds.field(\"pickup_location_id\").isin([264, 265]))\n",
    "        & (~pds.field(\"dropoff_location_id\").isin([264, 265]))\n",
    "        & (pds.field(\"dropoff_location_id\").isin(sample_ids))\n",
    "    )\n",
    "\n",
    "    dataset = ray.data.read_parquet(\n",
    "        files_list,\n",
    "        columns=[\n",
    "            \"pickup_at\",\n",
    "            \"dropoff_at\",\n",
    "            \"pickup_location_id\",\n",
    "            \"dropoff_location_id\",\n",
    "            \"passenger_count\",\n",
    "            \"trip_distance\",\n",
    "            \"fare_amount\",\n",
    "        ],\n",
    "        filter=filter_expr,\n",
    "    )\n",
    "\n",
    "    data_loading_time = time.time() - start\n",
    "    print(f\"Data loading time: {data_loading_time:.2f} seconds\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# A pandas DataFrame UDF for transforming the Dataset in parallel.\n",
    "def transform_batch(the_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = the_df.copy()\n",
    "    \n",
    "    df[\"trip_duration\"] = (df[\"dropoff_at\"] - df[\"pickup_at\"]).dt.seconds\n",
    "    df = df[df[\"trip_duration\"] > 60]\n",
    "    df = df[df[\"trip_duration\"] < 24 * 60 * 60] \n",
    "    df.drop([\"dropoff_at\", \"pickup_at\", \"pickup_location_id\", \"fare_amount\"]\n",
    "            , axis=1, inplace=True)\n",
    "    df[\"dropoff_location_id\"] = df[\"dropoff_location_id\"].fillna(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca8ecb6-61ae-49bf-946c-e7cc1ef6b69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 13:57:46,699\tWARNING read_api.py:291 -- ⚠️  The number of blocks in this dataset (1) limits its parallelism to 1 concurrent tasks. This is much less than the number of available CPU slots in the cluster. Use `.repartition(n)` to increase the number of dataset blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading time: 5.18 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test the pushdown_read_data function\n",
    "ds_raw = pushdown_read_data(s3_files, sample_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5edbba-4aa1-476e-ac96-d59a8a36fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before transformation: 6941024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read: 100%|██████████████████████████████████████| 1/1 [03:58<00:00, 238.70s/it]\n",
      "Repartition: 100%|████████████████████████████████| 5/5 [00:00<00:00, 19.69it/s]\n",
      "Map_Batches: 100%|████████████████████████████████| 5/5 [00:00<00:00, 49.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after transformation: 82704\n",
      "CPU times: user 1.87 s, sys: 828 ms, total: 2.7 s\n",
      "Wall time: 3min 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Test the transform UDF.\n",
    "print(f\"Number of rows before transformation: {ds_raw.count()}\")\n",
    "\n",
    "# # Repartition the dataset to allow for higher parallelism.\n",
    "ds = ds_raw.repartition(5, shuffle=False) \n",
    "\n",
    "# .map_batches applies a UDF to each partition of the data in parallel.\n",
    "ds = ds.map_batches(transform_batch, batch_format=\"pandas\")\n",
    "\n",
    "# Verify row count.\n",
    "print(f\"Number of rows after transformation: {ds.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b409ed1a-591d-421a-bfe7-d1a2b8be2033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 82704\n",
      "Size bytes (from parquet metadata): 1406608\n",
      "\n",
      "Schema data types:\n",
      "dropoff_location_id: int32\n",
      "passenger_count: int8\n",
      "trip_distance: float32\n",
      "trip_duration: int64\n",
      "\n",
      "Sample row:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PandasRow({'dropoff_location_id': 166,\n",
       "            'passenger_count': 1,\n",
       "            'trip_distance': 6.5,\n",
       "            'trip_duration': 1248})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect ray data.\n",
    "print(f\"Number of rows: {ds.count()}\")\n",
    "print(f\"Size bytes (from parquet metadata): {ds.size_bytes()}\")\n",
    "\n",
    "print(\"\\nSchema data types:\")\n",
    "data_types = list(zip(ds.schema().names, ds.schema().types))\n",
    "for s in data_types:\n",
    "    print(f\"{s[0]}: {s[1]}\")\n",
    "    \n",
    "print(\"\\nSample row:\")\n",
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72369cbf-e346-441c-b7e3-9280ccabc7f6",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd4b4a0-bcc8-49c3-8b5e-2590f9100a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.1.2\n"
     ]
    }
   ],
   "source": [
    "# import standard sklearn libraries\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(f\"sklearn: {sklearn.__version__}\")\n",
    "\n",
    "# import ray AIR libraries\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "# set global random seed for sklearn models\n",
    "np.random.seed(415)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3c9a4-b2df-4063-8c04-f5e0136c90bf",
   "metadata": {},
   "source": [
    "Step 1: First, we define the model training function that we want to run variations of. The function takes in a config dictionary as argument, and returns a simple dict output. Learn more about logging Tune results at [How to configure logging in Tune?](https://docs.ray.io/en/master/tune/tutorials/tune-output.html#tune-logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b709abd-d595-49a8-9dd6-08e28f014340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LinearRegression(), key: fit_intercept, value: True\n",
      "model: LinearRegression(), key: fit_intercept, value: False\n",
      "model: DecisionTreeRegressor(), key: max_depth, value: 2\n",
      "model: DecisionTreeRegressor(), key: max_depth, value: 4\n",
      "model: DecisionTreeRegressor(), key: max_depth, value: 6\n"
     ]
    }
   ],
   "source": [
    "# TODO add the scikit-learn model training, eval\n",
    "def evaluation_fn(test_y: pd.Series, pred_y: pd.Series):\n",
    "    error = sklearn.metrics.mean_absolute_error(test_y, pred_y)\n",
    "    return error\n",
    "        \n",
    "# 1. Define an objective function.\n",
    "def objective(config: dict):\n",
    "    \n",
    "    # Get model choices from top-level dictionary keys\n",
    "    models = list(config.keys())\n",
    "    for model in models:\n",
    "        \n",
    "        # Get param choices from nested-level dictionary keys\n",
    "        param_name = list(config[model].keys())\n",
    "        param_values = config[model][param_name[0]]\n",
    "        for i in param_values:\n",
    "            print(f\"model: {model}, key: {param_name[0]}, value: {i}\")\n",
    "            # TODO put more meaningful score here later\n",
    "            score = 1000.0\n",
    "    \n",
    "# 2. Define a search space.\n",
    "search_space = {\n",
    "    'LinearRegression()': {\n",
    "        \"fit_intercept\": [True, False]},\n",
    "    'DecisionTreeRegressor()': {\n",
    "        \"max_depth\": [2,4,6]}\n",
    "}\n",
    "\n",
    "# Test objective function call.\n",
    "objective(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a03c0ff8-0c42-4703-91f4-57fc0df8f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_df: pd.DataFrame, \n",
    "                test_df: pd.DataFrame,\n",
    "                config: dict):\n",
    "\n",
    "    # Import model libraries, etc...\n",
    "    # Load data and train model code here...\n",
    "    # Assemble train/test pandas dfs\n",
    "    train_X = train_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    train_y = train_df.trip_duration\n",
    "    test_X = test_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "    test_y = test_df.trip_duration\n",
    "    \n",
    "    # 3. Define a tuner using Ray AIR Tuner API\n",
    "    stop_criteria = {\n",
    "        \"done\": True,\n",
    "        # \"training_iteration\": 1 if args.smoke_test else 4,\n",
    "        \"training_iteration\": 1 if SMOKE_TEST else 4,\n",
    "    }\n",
    "    tuner = tune.Tuner(\n",
    "        objective, \n",
    "        param_space=search_space,\n",
    "        run_config=air.RunConfig(\n",
    "            #redirect logs to relative path instead of default ~/ray_results/\n",
    "            local_dir = \"my_Tune_logs\",\n",
    "            name = \"batch_tuning\",\n",
    "\n",
    "            # Stopping criteria whichever occurs first: average reward over training episodes, or ...\n",
    "            stop=stop_criteria,\n",
    "\n",
    "            # Set Ray Tune verbosity.  Summary table only with levels 2 or 3.\n",
    "            verbose=2,\n",
    "            )\n",
    "    )\n",
    "    print(f\"type(tuner): {type(tuner)}\")\n",
    "    results = tuner.fit()\n",
    "\n",
    "    # Return final stats. You can also return intermediate progress\n",
    "    # using ray.air.session.report() if needed.\n",
    "    # To return your model, you could write it to storage and return its\n",
    "    # URI in this dict, or return it as a Tune Checkpoint:\n",
    "    # https://docs.ray.io/en/latest/tune/tutorials/tune-checkpoints.html\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3701500-e333-4363-923d-614fd6560f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:04:27,545\tWARNING function_trainable.py:619 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66163, 4) (16541, 4)\n",
      "type(tuner): <class 'ray.tune.tuner.Tuner'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-11-02 14:04:29 (running for 00:00:01.55)<br>Memory usage on this node: 12.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/8.04 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/christy/Documents/github_ray_temp/ray/doc/source/data/examples/my_Tune_logs/batch_tuning<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_efd1d_00000</td><td>TERMINATED</td><td>127.0.0.1:16185</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial objective_efd1d_00000 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:04:29,792\tINFO tune.py:758 -- Total run time: 2.25 seconds (1.55 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=16185)\u001b[0m model: LinearRegression(), key: fit_intercept, value: True\n",
      "\u001b[2m\u001b[36m(objective pid=16185)\u001b[0m model: LinearRegression(), key: fit_intercept, value: False\n",
      "\u001b[2m\u001b[36m(objective pid=16185)\u001b[0m model: DecisionTreeRegressor(), key: max_depth, value: 2\n",
      "\u001b[2m\u001b[36m(objective pid=16185)\u001b[0m model: DecisionTreeRegressor(), key: max_depth, value: 4\n",
      "\u001b[2m\u001b[36m(objective pid=16185)\u001b[0m model: DecisionTreeRegressor(), key: max_depth, value: 6\n",
      "{'LinearRegression()': {'fit_intercept': [True, False]}, 'DecisionTreeRegressor()': {'max_depth': [2, 4, 6]}}\n"
     ]
    }
   ],
   "source": [
    "# test the function call\n",
    "\n",
    "# Randomly split the data into 80/20 train/test.\n",
    "df = ds.to_pandas()\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "    \n",
    "results = train_model(train_df, test_df, search_space)\n",
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e310b13e-ba83-4c47-84e6-d1e916483b2b",
   "metadata": {},
   "source": [
    "Step 2: Next, define the space of trials to run. Here, we define a simple grid sweep from 0..NUM_MODELS, which will generate the config dicts to be passed to each model function. Learn more about what features Tune offers for defining spaces at [Working with Tune Search Spaces](https://docs.ray.io/en/master/tune/tutorials/tune-search-spaces.html#tune-search-space-tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de03814-4eec-4363-a623-790f040b99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# # Define trial parameters as a single grid sweep.\n",
    "# trial_space = {\n",
    "#     # This is an example parameter. You could replace it with filesystem paths,\n",
    "#     # model types, or even full nested Python dicts of model configurations, etc.,\n",
    "#     # that enumerate the set of trials to run.\n",
    "#     \"model_id\": tune.grid_search([\n",
    "#         \"model_{}\".format(i)\n",
    "#         for i in range(NUM_MODELS)\n",
    "#     ])\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d0d25-a5b0-4887-9d1a-a775d0107d12",
   "metadata": {},
   "source": [
    "Step 3: Optionally, configure the resources allocated per trial. Tune uses this resources allocation to control the parallelism. For example, if each trial was configured to use 4 CPUs, and the cluster had only 32 CPUs, then Tune will limit the number of concurrent trials to 8 to avoid overloading the cluster. For more information, see [A Guide To Parallelism and Resources](https://docs.ray.io/en/master/tune/tutorials/tune-resources.html#tune-parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa9df92-a412-42a8-b833-98dc86d58350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# print(type(train_model))\n",
    "\n",
    "# # Can customize resources per trial, here we set 1 CPU each.\n",
    "# train_model = tune.with_resources(train_model, {\"cpu\": 1})\n",
    "\n",
    "# print(type(train_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36ca20-54ad-4400-88fe-ca8cc7ffbf84",
   "metadata": {},
   "source": [
    "Step 4: Run the trial with Tune. Tune will report on experiment status, and after the experiment finishes, you can inspect the results. Tune can retry failed trials automatically, as well as entire experiments; see [Stopping and Resuming a Tune Run](https://docs.ray.io/en/master/tune/tutorials/tune-stopping.html#tune-stopping-guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e2beb-888c-40c0-8c0b-e90fe27b7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# # Start a Tune run and print the best result.\n",
    "# tuner = tune.Tuner(train_model, param_space=trial_space)\n",
    "# results = tuner.fit()\n",
    "\n",
    "# # Access individual results.\n",
    "# print(results[0])\n",
    "# print(results[1])\n",
    "# print(results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d4015-4b0e-4a1a-88d7-07ac4a4e2df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
