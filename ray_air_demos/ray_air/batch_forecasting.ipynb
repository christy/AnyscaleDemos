{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cdd62bd",
   "metadata": {},
   "source": [
    "# Batch forecasting on Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5552788",
   "metadata": {},
   "source": [
    "Batch training and tuning are common tasks in simple machine learning use-cases such as time series forecasting. They require fitting of simple models on multiple data batches corresponding to locations, products, etc.\n",
    "\n",
    "**'Batch training'** is a workload that trains model(s) on subsets of a dataset. This notebook showcases how to conduct batch training using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).\n",
    "\n",
    "![Batch training diagram](../../data/examples/images/batch-training.svg)\n",
    "\n",
    "For the data, we will use the [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This popular tabular dataset contains historical taxi pickups by timestamp and location in NYC.\n",
    "\n",
    "In this notebook, we will split the data by pickup location and train a separate forecasting model to predict #pickups at each location in NYC at monthly level for the next 2 months. Specifically, we will use the `pickup_location_id` column in the dataset to group the dataset into data batches. Then we will fit a separate model for each batch and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013f9d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contents\n",
    "\n",
    "In this this tutorial, you will learn about:\n",
    " 1. [Define how to load and prepare Parquet data](#prepare_data)\n",
    " 2. [Define your Ray Tune Search Space and Search Algorithm](#define_search_space2)\n",
    " 3. [Define a Trainable (callable) function](#define_trainable2)\n",
    " 4. [Run batch training on Ray Tune](#run_tune_search2)\n",
    " 5. [Load a model from checkpoint and perform inference](#load_checkpoint2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59f937a",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "\n",
    "```{tip}\n",
    "Prerequisite for this notebook: Read the [Key Concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) page for Ray Tune.\n",
    "```\n",
    "\n",
    "Let us start by importing a few required libraries, including open-source [Ray](https://github.com/ray-project/ray) itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81a132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 8\n",
      "pyarrow: 10.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f'Number of CPUs in this system: {os.cpu_count()}')\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pds\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fede5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-15 10:53:13,671\tINFO worker.py:1230 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "2022-11-15 10:53:13,672\tINFO worker.py:1342 -- Connecting to existing Ray cluster at address: 172.31.79.31:9031...\n",
      "2022-11-15 10:53:13,707\tINFO worker.py:1519 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard', python_version='3.8.13', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '172.31.79.31', 'raylet_ip_address': '172.31.79.31', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-15_10-45-31_335880_147/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-15_10-45-31_335880_147/sockets/raylet', 'webui_url': 'console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2022-11-15_10-45-31_335880_147', 'metrics_export_port': 65240, 'gcs_address': '172.31.79.31:9031', 'address': '172.31.79.31:9031', 'dashboard_agent_listen_port': 52365, 'node_id': '740e2757d1043e03a9b57a1809a124c722228170d38f843f0649dce2'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853deb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': 66320753459.0, 'CPU': 24.0, 'object_store_memory': 27553038336.0, 'node:172.31.79.31': 1.0, 'node:172.31.84.43': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d764c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.23.4\n",
      "prophet: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "# import forecasting libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import prophet\n",
    "from prophet import Prophet\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"prophet: {prophet.__version__}\")\n",
    "\n",
    "# import ray libraries\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "\n",
    "# set global random seed for sklearn models\n",
    "np.random.seed(415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92cb5a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For benchmarking purposes, we can print the times of various operations.\n",
    "# In order to reduce clutter in the output, this is set to False by default.\n",
    "PRINT_TIMES = False\n",
    "\n",
    "def print_time(msg: str):\n",
    "    if PRINT_TIMES:\n",
    "        print(msg)\n",
    "        \n",
    "# To speed things up, weâ€™ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c748ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define how to load and prepare Parquet data <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d7937",
   "metadata": {},
   "source": [
    "First, we need to load some data.  Since the NYC Taxi dataset is fairly large, we will filter files first into a PyArrow dataset. And then in the next cell after, we will filter the data on read into a PyArrow table and convert that to a pandas dataframe.\n",
    "\n",
    "```{tip}\n",
    "Use PyArrow dataset and table for reading or writing large parquet files, since its native multithreaded C++ adpater is faster than pandas read_parquet, even using engine=pyarrow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83e8a6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Taxi using 5 file(s)!\n",
      "s3_files: ['s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/02/data.parquet/5bc40cf9bc1145cbb0867d39064daa01_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/03/data.parquet/8b894872a484458cbd5a6cd0425b77df_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/04/data.parquet/7e490662e39c4bfe8c64c6a2c45c9e8b_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/05/data.parquet/359c21b3e28f40328e68cf66f7ba40e2_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/06/data.parquet/ab5b9d2b8cc94be19346e260b543ec35_000000.parquet']\n",
      "Locations: [1, 10, 199]\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "TARGET = \"trip_duration\"\n",
    "FORECAST_LENGTH = 6\n",
    "s3_partitions = pds.dataset(\n",
    "    \"s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/\",\n",
    "    partitioning=[\"year\", \"month\"],\n",
    ")\n",
    "s3_files = [f\"s3://anonymous@{file}\" for file in s3_partitions.files]\n",
    "\n",
    "# Obtain all location IDs\n",
    "all_location_ids = (\n",
    "    pq.read_table(s3_files[0], columns=[\"dropoff_location_id\"])[\"dropoff_location_id\"]\n",
    "    .unique()\n",
    "    .to_pylist()\n",
    ")\n",
    "# drop [264, 265]\n",
    "all_location_ids.remove(264)\n",
    "all_location_ids.remove(265)\n",
    "\n",
    "# Use smoke testing or not.\n",
    "starting_idx = -5 if SMOKE_TEST else 0\n",
    "#TODO - drop error-handling test location 199\n",
    "sample_locations = [1, 10, 199] if SMOKE_TEST else all_location_ids\n",
    "\n",
    "# Display what data will be used.\n",
    "s3_files = s3_files[starting_idx:]\n",
    "print(f\"NYC Taxi using {len(s3_files)} file(s)!\")\n",
    "print(f\"s3_files: {s3_files}\")\n",
    "print(f\"Locations: {sample_locations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a35289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a pyarrow.Table object using pyarrow parquet \n",
    "def read_data(file: str, sample_id: np.int32) -> pd.DataFrame:\n",
    "    \n",
    "    df = pq.read_table(\n",
    "        file,\n",
    "        filters=[\n",
    "            (\"passenger_count\", \">\", 0),\n",
    "            (\"trip_distance\", \">\", 0),\n",
    "            (\"fare_amount\", \">\", 0),\n",
    "            (\"pickup_location_id\", \"not in\", [264, 265]),\n",
    "            (\"dropoff_location_id\", \"not in\", [264, 265]), \n",
    "            (\"pickup_location_id\", \"=\", sample_id)\n",
    "        ],\n",
    "        columns=[\n",
    "            \"pickup_at\",\n",
    "            \"dropoff_at\",\n",
    "            \"pickup_location_id\",\n",
    "            \"dropoff_location_id\",\n",
    "            \"passenger_count\",\n",
    "            \"trip_distance\",\n",
    "            \"fare_amount\",\n",
    "        ],\n",
    "    ).to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to transform a pandas dataframe\n",
    "def transform_df(the_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = the_df.copy()\n",
    "    \n",
    "    # calculate trip_duration\n",
    "    df[\"trip_duration\"] = (df[\"dropoff_at\"] - df[\"pickup_at\"]).dt.seconds\n",
    "    # filter trip_durations > 1 minute and less than 24 hours\n",
    "    df = df[df[\"trip_duration\"] > 60]\n",
    "    df = df[df[\"trip_duration\"] < 24 * 60 * 60]\n",
    "    \n",
    "    # Prophet requires time is 'ds' and target_value name is 'y'\n",
    "    \n",
    "    # add year_month and concat into a unique column to use as groupby key\n",
    "    df['ds'] = df['pickup_at'].dt.to_period('M').dt.to_timestamp()\n",
    "    df['loc_year_month'] = df['pickup_location_id'].astype(str) + \"_\"  + \\\n",
    "                            df[\"pickup_at\"].dt.year.astype(str) + \"_\"  + \\\n",
    "                            df[\"pickup_at\"].dt.month.astype(str)\n",
    "    # add target_value quantity for groupby count later\n",
    "    df['y'] = 1\n",
    "    # drop unnecessary columns\n",
    "    df.drop([\"dropoff_at\", \"pickup_at\", \"dropoff_location_id\", \"fare_amount\",\n",
    "            \"passenger_count\", \"trip_distance\", \n",
    "             \"trip_duration\"]\n",
    "            , axis=1, inplace=True)\n",
    "    # return df\n",
    "    \n",
    "    # groupby aggregregate\n",
    "    g = df.groupby(\"loc_year_month\")\\\n",
    "                .agg({'pickup_location_id': min,\n",
    "                      'ds': min,\n",
    "                      'y': sum})\n",
    "    # having num rows in group > 10\n",
    "    g = g[g['y'] > 10].copy()\n",
    "    \n",
    "    # Drop groupby variable since we do not need it anymore\n",
    "    g.reset_index(inplace=True)\n",
    "    g.drop([\"loc_year_month\"], axis=1, inplace=True)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02eb69bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_location_id             int32\n",
      "ds                    datetime64[ns]\n",
      "y                              int64\n",
      "dtype: object\n",
      "CPU times: user 9.98 s, sys: 4.31 s, total: 14.3 s\n",
      "Wall time: 15.6 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_location_id         ds     y\n",
       "0                  10 2019-02-01  2298\n",
       "1                  10 2019-03-01  2608\n",
       "2                  10 2019-04-01  2084\n",
       "3                  10 2019-05-01  2382\n",
       "4                  10 2019-06-01  2296"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test reading data.\n",
    "the_location = 10\n",
    "df_list = [read_data(f, the_location) for f in s3_files] \n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "df = transform_df(df_raw)\n",
    "print(df.dtypes)\n",
    "df.head()\n",
    "\n",
    "# # # without groupby\n",
    "# # CPU times: user 6.23 s, sys: 2.76 s, total: 9 s\n",
    "# # Wall time: 7.66 s\n",
    "\n",
    "# # # with groupby\n",
    "# # CPU times: user 6.36 s, sys: 2.86 s, total: 9.22 s\n",
    "# # Wall time: 7.01 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9aaf073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # test the groupby\n",
    "# g = df_raw.groupby(\"loc_year_month\")\\\n",
    "#             .agg({'pickup_location_id': min,\n",
    "#                   'ds': min,\n",
    "#                   'trip_quantity': sum})\n",
    "# # # having num rows in group > 10\n",
    "# g = g[g['trip_quantity'] > 10].copy()\n",
    "# g.reset_index(inplace=True)\n",
    "# df = g.copy()\n",
    "# g.head()\n",
    "\n",
    "# check we don't have any missing or 0 y-values\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f624ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot a timeseries\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# ax = plt.gca()\n",
    "# df.plot(x=\"ds\", y=\"y\", ax=ax, label=f\"pickup_location_id={the_location}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89311ae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define your Ray Tune Search Space and Search Algorithm <a class=\"anchor\" id=\"define_search_space\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7624b",
   "metadata": {},
   "source": [
    "In this notebook, we will use Ray Tune to run parallel training jobs per dropoff location.  The training jobs will be defined using a search space and simple grid search.  Depending on your need, fancier search spaces and search algorithms are possible with Tune. \n",
    "\n",
    "**First, define a search space of experiment trials to run.**  \n",
    "> The typical use case for Tune search spaces are for hypterparameter tuning.  In our case, we are defining a Tune search space in a way to allow for training jobs to be conducted automatically.  Each training job will run on a different data partition (taxi dropoff location) and use a different model.\n",
    "\n",
    "Common search algorithms include grid search, random search, and Bayesian optimization.  For more details, see [Working with Tune Search Spaces](https://docs.ray.io/en/master/tune/tutorials/tune-search-spaces.html#tune-search-space-tutorial).  Deciding the best combination of search space and search algorithm is part of the art of being a Data Scientist and depends on the data, algorithm, and problem being solved!  \n",
    "\n",
    "**Next, define a search algorithm.**\n",
    ">Ray Tune will use the search space and the specified search algorithm to generate multiple configurations, each of which will be evaluated in a separate Trial on a Ray Cluster. Ray Tune will take care of orchestrating those Trials automatically.  Specifically, Ray Tune will pass a config dictionary to each partition and make a Trainable function call.\n",
    "\n",
    "**Below, we define our search space consists of:**\n",
    "- 2 different Scikit-learn algorithms \n",
    "- Some or all NYC taxi drop-off locations. \n",
    "\n",
    "**Also below, we define our search algorithm is:**\n",
    "- Grid search.\n",
    "\n",
    "What this means is every algorithm will be applied to every NYC Taxi drop-off location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a32ec911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "INFO:prophet:n_changepoints greater than number of observations. Using 3.\n",
      "INFO:cmdstanpy:start chain 1\n",
      "INFO:cmdstanpy:finish chain 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<prophet.forecaster.Prophet object at 0x7f808c164a90>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x7f808c164a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test prophet model\n",
    "model = Prophet(seasonality_mode=\"additive\")\n",
    "model = Prophet(seasonality_mode=\"multiplicative\")\n",
    "print(model)\n",
    "\n",
    "# Keep only columns Prophet needs\n",
    "model.fit(df[['ds', 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b407040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "          ds       pred_y  test_y  forecast_error\n",
      "0 2019-02-01  2380.707584  2298.0       82.707584\n",
      "1 2019-03-01  2358.389807  2608.0      249.610193\n",
      "2 2019-04-01  2333.680851  2084.0      249.680851\n",
      "3 2019-05-01  2309.768960  2382.0       72.231040\n",
      "4 2019-06-01  2285.059997  2296.0       10.940003\n",
      "mean_absolute_error: 133.03393416093377\n"
     ]
    }
   ],
   "source": [
    "# test prophet prediction\n",
    "FORECAST_LENGTH = 1\n",
    "future_dates = model.make_future_dataframe(periods=FORECAST_LENGTH, freq='MS')\n",
    "# print(future_dates)\n",
    "# make a prediction\n",
    "future = model.predict(future_dates)\n",
    "print(type(future))\n",
    "\n",
    "# assemble actual values\n",
    "test_y = df.loc[(df.ds.isin(future_dates.ds)), :]\n",
    "\n",
    "# assemble actual vs predicted values\n",
    "pred_y = future[['ds', 'trend']]\n",
    "# print(pred_y)\n",
    "# Concat together predictions and actuals to visualize\n",
    "temp = pd.concat([pred_y, test_y[['y']]], axis=1, ignore_index=True)\n",
    "temp.columns = ['ds', 'pred_y', 'test_y']\n",
    "temp = temp.iloc[0:-FORECAST_LENGTH]\n",
    "\n",
    "# calculate mean absolute forecast error\n",
    "temp['forecast_error'] = np.abs(temp['test_y'] - temp['pred_y'])\n",
    "print(temp)\n",
    "mean_absolute_error = np.mean(temp['forecast_error'])\n",
    "print(f\"mean_absolute_error: {mean_absolute_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89bde06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'grid_search': [<prophet.forecaster.Prophet at 0x7f807c71aa60>,\n",
       "   <prophet.forecaster.Prophet at 0x7f808c03be80>]},\n",
       " 'location': {'grid_search': [1, 10, 199]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define a search space.\n",
    "\n",
    "# TODO: 1. add longer forecast window; 2. keep additive, 3. try kats additive instead\n",
    "search_space = {\n",
    "    \"model\": tune.grid_search([Prophet(seasonality_mode=\"multiplicative\"), \n",
    "                               Prophet(seasonality_mode=\"additive\")]),\n",
    "    \"location\": tune.grid_search(sample_locations),\n",
    "}\n",
    "search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4425790",
   "metadata": {},
   "source": [
    "## Define a Trainable (callable) function <a class=\"anchor\" id=\"define_trainable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebaea26",
   "metadata": {},
   "source": [
    "ðŸ“ˆ Typically when you are running Data Science experiments, you want to be able to keep track of summary metrics for each trial, so you can decide at the end which trials were best.  That way, you can decide which model to deploy.\n",
    "\n",
    "ðŸ‡« Next, we define a trainable function in order to train and evaluate a scikit-learn model on a data partition.  This function will be called in parallel by every Tune trial.  Inside this trainable function, we will:\n",
    "- Add detailed metrics we want to report (each model's loss or error). \n",
    "- Checkpoint each model for easy deployment later.\n",
    "\n",
    "ðŸ“– **The metrics defined inside the trainable function will appear in the Ray Tune experiment summary table.**\n",
    "```{tip}\n",
    "Ray Tune has two ways of defining a trainable, namely the [Function API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs) and the Class API. Both are valid ways of defining a trainable, but *the Function API is generally recommended*.\n",
    "```\n",
    "\n",
    "**In the cell below, we define a \"Trainable\" function called `train_model()`**.  \n",
    "- The input is a config dictionary argument. \n",
    "- The output can be a simple dictionary of metrics which will be reported back to Tune.  \n",
    "- We will [checkpoint](https://docs.ray.io/en/master/ray-air/key-concepts.html#checkpoints) save each model in addition to reporting each trial's metrics.\n",
    "  > For checkpointing, we use `ray.air.checkpoint.Checkpoint`.  *Ray AIR includes integrations to popular ML libraries, including Scikit-learn*.  This makes it possible to use the convenient AIR API abstractions, without having to specify code details of the Scikit-learn library itself.\n",
    "- Since we are using **grid search**, this means `train_model()` will be run *in parallel for every permutation* in the Tune search space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8ba0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a custom train function\n",
    "def train_model(config: dict):\n",
    "\n",
    "    model = config['model']\n",
    "    the_location = config['location']\n",
    "    \n",
    "    # Load data.\n",
    "    df_list = [read_data(f, the_location) for f in s3_files]   \n",
    "    df_raw = pd.concat(df_list, ignore_index=True)\n",
    "    df = transform_df(df_raw)\n",
    "\n",
    "    # Train model.\n",
    "    model = model.fit(df[['ds', 'y']])\n",
    "    \n",
    "    ### START move to evaluate_model()\n",
    "    # TODO - move this to error, test_df, pred_df = evaluate_model(model)\n",
    "    # Inference model.\n",
    "    future_dates = model.make_future_dataframe(periods=FORECAST_LENGTH, freq='MS')\n",
    "    future = model.predict(future_dates)\n",
    "\n",
    "    # assemble actual vs predicted values\n",
    "    test_y = df.loc[(df.ds.isin(future_dates.ds)), :]\n",
    "    pred_y = future[['ds', 'trend']].iloc[0:-FORECAST_LENGTH]\n",
    "    temp = pd.concat([pred_y, test_y[['y']]], \n",
    "                     axis=1, ignore_index=True)\n",
    "    temp.columns = ['ds', 'pred_y', 'test_y']\n",
    "\n",
    "    # Evaluate mean absolute forecast error.\n",
    "    temp['forecast_error'] = np.abs(temp['test_y'] - temp['pred_y'])\n",
    "    error = np.mean(temp['forecast_error'])\n",
    "\n",
    "    # calculate mean absolute forecast error\n",
    "    temp['forecast_error'] = np.abs(temp['test_y'] - temp['pred_y'])\n",
    "    mean_absolute_error = np.mean(temp['forecast_error'])\n",
    "    ### END move to evaluate_model()\n",
    "    \n",
    "    # Define a model checkpoint using AIR API.  \n",
    "    # https://docs.ray.io/en/latest/tune/tutorials/tune-checkpoints.html\n",
    "    checkpoint = ray.air.checkpoint.Checkpoint.from_dict({\n",
    "        \"model\": model, \n",
    "        \"forecast_df\": future,\n",
    "        \"location_id\": the_location})\n",
    "\n",
    "    # Save checkpoint and report back metrics, using ray.air.session.report()\n",
    "    # The metrics you specify here will appear in Tune summary table.\n",
    "    # They will also be recorded in Tune results under `metrics`.\n",
    "    metrics = dict(error = error)\n",
    "    session.report(\n",
    "            metrics, \n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5160731",
   "metadata": {},
   "source": [
    "## Run batch training on Ray Tune <a class=\"anchor\" id=\"run_tune_search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d15ad",
   "metadata": {},
   "source": [
    "**In the cell below, we configure the resources allocated per trial.** \n",
    "\n",
    "Tune uses this resources allocation to control the parallelism. For example, if each trial was configured to use 4 CPUs, and the cluster had only 32 CPUs, then Tune will limit the number of concurrent trials to 8 to avoid overloading the cluster. For more information, see [A Guide To Parallelism and Resources](https://docs.ray.io/en/master/tune/tutorials/tune-resources.html#tune-parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce080e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Customize resources per trial, here we set 1 CPU each.\n",
    "train_model = tune.with_resources(train_model, {\"cpu\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87ce3b3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Now we are ready to kick off a Ray Tune experiment!**  \n",
    "\n",
    "Recall what we are doing, high level, is training several different models per dropoff location.  We are using Ray Tune so we can run all these trials in parallel.  At the end, we will inspect the results of the experiment and deploy only the best model per dropoff location.\n",
    "\n",
    "**In the cell below, we use AIR configs and run the experiment using `tuner.fit()`.** \n",
    "\n",
    "Tune will report on experiment status, and after the experiment finishes, you can inspect the results. \n",
    "\n",
    "In the AIR config below, we have specified a local directory `my_Tune_logs` for logging instead of the default `~/ray_results` directory. Giving your logs a project name makes them easier to find.  Also giving a relative path, means you can see your logs inside the Jupyter browser.  Learn more about logging Tune results at [How to configure logging in Tune](https://docs.ray.io/en/master/tune/tutorials/tune-output.html#tune-logging).\n",
    "\n",
    "Tune can [retry failed experiments automatically](https://docs.ray.io/en/master/tune/tutorials/tune-stopping.html#tune-stopping-guide), as well as entire experiments.  This is necessary in case a node on your remote cluster fails (when running on a cloud such as AWS or GCP).\n",
    "\n",
    "ðŸ’¡ Right-click on the cell below and choose \"Enable Scrolling for Outputs\"! This will make it easier to view, since model training output can be very long!\n",
    "\n",
    "**In the output below and in the Ray Dashboard, you can see that 518 models, using 18 NYC Taxi S3 files dating from 2018/01 to 2019/06 (split into partitions approx 7GiB each), were simultaneously trained on a 23-node AWS cluster of [m5.4xlarge](https://aws.amazon.com/ec2/instance-types/m5/)s, within 37 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a243fbae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-15 10:59:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:24.55        </td></tr>\n",
       "<tr><td>Memory:      </td><td>2.6/30.9 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/61.77 GiB heap, 0.0/25.66 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_92abc_00002</td><td style=\"text-align: right;\">           1</td><td>/home/ray/christy-air/my_Tune_logs/batch_tuning/train_model_92abc_00002_2_location=199,model=prophet_forecaster_Prophet_object_at_0x7f802de31d90_2022-11-15_10-59-06/error.txt</td></tr>\n",
       "<tr><td>train_model_92abc_00005</td><td style=\"text-align: right;\">           1</td><td>/home/ray/christy-air/my_Tune_logs/batch_tuning/train_model_92abc_00005_5_location=199,model=prophet_forecaster_Prophet_object_at_0x7f802c23ebe0_2022-11-15_10-59-06/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  location</th><th>model               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_92abc_00000</td><td>TERMINATED</td><td>172.31.84.43:1865</td><td style=\"text-align: right;\">         1</td><td>&lt;prophet.foreca_11f0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        10.1811 </td><td style=\"text-align: right;\">  2.2321</td></tr>\n",
       "<tr><td>train_model_92abc_00001</td><td>TERMINATED</td><td>172.31.84.43:1896</td><td style=\"text-align: right;\">        10</td><td>&lt;prophet.foreca_1b80</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.49834</td><td style=\"text-align: right;\">133.034 </td></tr>\n",
       "<tr><td>train_model_92abc_00003</td><td>TERMINATED</td><td>172.31.84.43:1898</td><td style=\"text-align: right;\">         1</td><td>&lt;prophet.foreca_48e0</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.53897</td><td style=\"text-align: right;\">  2.2321</td></tr>\n",
       "<tr><td>train_model_92abc_00004</td><td>TERMINATED</td><td>172.31.84.43:1899</td><td style=\"text-align: right;\">        10</td><td>&lt;prophet.foreca_c190</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         9.57942</td><td style=\"text-align: right;\">133.034 </td></tr>\n",
       "<tr><td>train_model_92abc_00002</td><td>ERROR     </td><td>172.31.84.43:1897</td><td style=\"text-align: right;\">       199</td><td>&lt;prophet.foreca_1d90</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>train_model_92abc_00005</td><td>ERROR     </td><td>172.31.84.43:1900</td><td style=\"text-align: right;\">       199</td><td>&lt;prophet.foreca_ebe0</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=1865, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:start chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1865, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:finish chain 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>error             </th><th>should_checkpoint  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_92abc_00000</td><td>2.2321022029248   </td><td>True               </td></tr>\n",
       "<tr><td>train_model_92abc_00001</td><td>133.03393416093377</td><td>True               </td></tr>\n",
       "<tr><td>train_model_92abc_00002</td><td>                  </td><td>                   </td></tr>\n",
       "<tr><td>train_model_92abc_00003</td><td>2.2321022029248   </td><td>True               </td></tr>\n",
       "<tr><td>train_model_92abc_00004</td><td>133.03393416093377</td><td>True               </td></tr>\n",
       "<tr><td>train_model_92abc_00005</td><td>                  </td><td>                   </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_model pid=1899, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:start chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1896, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:start chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1896, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:finish chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1898, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:start chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1899, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:finish chain 1\n",
      "\u001b[2m\u001b[36m(train_model pid=1898, ip=172.31.84.43)\u001b[0m INFO:cmdstanpy:finish chain 1\n",
      "2022-11-15 10:59:19,410\tWARNING util.py:244 -- The `process_trial_save` operation took 2.642 s, which may be a performance bottleneck.\n",
      "2022-11-15 10:59:19,412\tERROR trial_runner.py:993 -- Trial train_model_92abc_00005: Error processing event.\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1900, ip=172.31.84.43, repr=train_model)\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_1791/1335225448.py\", line 13, in train_model\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/prophet/forecaster.py\", line 1116, in fit\n",
      "    raise ValueError('Dataframe has less than 2 non-NaN rows.')\n",
      "ValueError: Dataframe has less than 2 non-NaN rows.\n",
      "2022-11-15 10:59:19,420\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': <prophet.forecaster.Prophet object at 0x7f802c2811f0>}\n",
      "2022-11-15 10:59:20,549\tERROR trial_runner.py:993 -- Trial train_model_92abc_00002: Error processing event.\n",
      "ray.exceptions.RayTaskError(ValueError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1897, ip=172.31.84.43, repr=train_model)\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 355, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 325, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/tune/trainable/function_trainable.py\", line 651, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_1791/1335225448.py\", line 13, in train_model\n",
      "  File \"/home/ray/anaconda3/lib/python3.8/site-packages/prophet/forecaster.py\", line 1116, in fit\n",
      "    raise ValueError('Dataframe has less than 2 non-NaN rows.')\n",
      "ValueError: Dataframe has less than 2 non-NaN rows.\n",
      "2022-11-15 10:59:22,802\tWARNING util.py:244 -- The `process_trial_save` operation took 2.236 s, which may be a performance bottleneck.\n",
      "2022-11-15 10:59:22,811\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': <prophet.forecaster.Prophet object at 0x7f802c2e48e0>}\n",
      "2022-11-15 10:59:24,994\tWARNING util.py:244 -- The `process_trial_save` operation took 1.084 s, which may be a performance bottleneck.\n",
      "2022-11-15 10:59:25,008\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': <prophet.forecaster.Prophet object at 0x7f802c23c190>}\n",
      "2022-11-15 10:59:27,200\tWARNING util.py:244 -- The `process_trial_save` operation took 1.085 s, which may be a performance bottleneck.\n",
      "2022-11-15 10:59:27,226\tINFO tensorboardx.py:267 -- Removed the following hyperparameter values when logging to tensorboard: {'model': <prophet.forecaster.Prophet object at 0x7f802c281b80>}\n",
      "2022-11-15 10:59:28,437\tERROR tune.py:773 -- Trials did not complete: [train_model_92abc_00002, train_model_92abc_00005]\n",
      "2022-11-15 10:59:28,438\tINFO tune.py:777 -- Total run time: 24.67 seconds (24.55 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 6\n",
      "TOTAL TIME TAKEN: 24.69 seconds\n",
      "Best result: {'model': <prophet.forecaster.Prophet object at 0x7f8322b59670>, 'location': 1}\n"
     ]
    }
   ],
   "source": [
    "# Define a tuner object using Ray AIR Tuner API\n",
    "tuner = tune.Tuner(\n",
    "    train_model, \n",
    "    param_space=search_space,\n",
    "    run_config=air.RunConfig(\n",
    "        \n",
    "        #redirect logs to relative path instead of default ~/ray_results/\n",
    "        local_dir = \"my_Tune_logs\",\n",
    "        name = \"batch_tuning\",\n",
    "\n",
    "        # Set Ray Tune verbosity.  Print summary table only with levels 2 or 3.\n",
    "        verbose=2,\n",
    "        ),\n",
    ")\n",
    "\n",
    "# 4. Run the experiment with Ray Tune\n",
    "start = time.time()\n",
    "results = tuner.fit()\n",
    "total_time_taken = time.time() - start\n",
    "\n",
    "# Print some training stats\n",
    "print(f\"Total number of models: {len(results)}\")\n",
    "print(f\"TOTAL TIME TAKEN: {total_time_taken:.2f} seconds\")\n",
    "best_result = results.get_best_result(metric=\"error\", mode=\"min\").config\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246872d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**After the Tune experiment has run, select the best model per dropoff location.**\n",
    "\n",
    "We can assemble the Tune results ([ResultGrid object](https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html)) into a pandas dataframe, then sort by minimum error, to select the best model per dropoff location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c98072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id      int64\n",
      "model           object\n",
      "error          float64\n",
      "checkpoint      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f8322...</td>\n",
       "      <td>2.232102</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f802c...</td>\n",
       "      <td>133.033934</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f8322...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f802c...</td>\n",
       "      <td>2.232102</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f802c...</td>\n",
       "      <td>133.033934</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id                                              model  \\\n",
       "0            1  <prophet.forecaster.Prophet object at 0x7f8322...   \n",
       "1           10  <prophet.forecaster.Prophet object at 0x7f802c...   \n",
       "2          199  <prophet.forecaster.Prophet object at 0x7f8322...   \n",
       "3            1  <prophet.forecaster.Prophet object at 0x7f802c...   \n",
       "4           10  <prophet.forecaster.Prophet object at 0x7f802c...   \n",
       "\n",
       "          error                                         checkpoint  \n",
       "0      2.232102  Checkpoint(local_path=/home/ray/christy-air/my...  \n",
       "1    133.033934  Checkpoint(local_path=/home/ray/christy-air/my...  \n",
       "2  10000.000000                                               None  \n",
       "3      2.232102  Checkpoint(local_path=/home/ray/christy-air/my...  \n",
       "4    133.033934  Checkpoint(local_path=/home/ray/christy-air/my...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of training loss errors\n",
    "errors = []\n",
    "[errors.append(i.metrics.get('error',10000.0)) for i in results]\n",
    "\n",
    "# get a list of checkpoints\n",
    "checkpoints = []\n",
    "[checkpoints.append(i.checkpoint) for i in results] \n",
    "\n",
    "# get a list of locations\n",
    "locations = []\n",
    "[locations.append(i.config['location']) for i in results]\n",
    "\n",
    "# get a list of models\n",
    "models = []\n",
    "[models.append(i.config['model']) for i in results]\n",
    "\n",
    "# Assemble a pandas dataframe from Tune results\n",
    "results_df = pd.DataFrame(zip(locations, models, errors,checkpoints),\n",
    "                          columns = ['location_id', 'model', 'error', 'checkpoint']\n",
    "                         )\n",
    "print(results_df.dtypes)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d191b027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prophet.forecaster.Prophet"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results_df.model[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d906c2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model          object\n",
      "error         float64\n",
      "checkpoint     object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f8322...</td>\n",
       "      <td>2.232102</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f802c...</td>\n",
       "      <td>133.033934</td>\n",
       "      <td>Checkpoint(local_path=/home/ray/christy-air/my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         model       error  \\\n",
       "location_id                                                                  \n",
       "1            <prophet.forecaster.Prophet object at 0x7f8322...    2.232102   \n",
       "10           <prophet.forecaster.Prophet object at 0x7f802c...  133.033934   \n",
       "\n",
       "                                                    checkpoint  \n",
       "location_id                                                     \n",
       "1            Checkpoint(local_path=/home/ray/christy-air/my...  \n",
       "10           Checkpoint(local_path=/home/ray/christy-air/my...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only 1 model per location_id with minimum error\n",
    "final_df = results_df.dropna()\n",
    "final_df = final_df.loc[final_df.groupby('location_id')['error'].idxmin()].copy()\n",
    "final_df.sort_values(by=[\"error\"], inplace=True)\n",
    "final_df.set_index('location_id', inplace=True, drop=True)\n",
    "print(final_df.dtypes)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740e66e",
   "metadata": {},
   "source": [
    "## Load a model from checkpoint and perform inference  <a class=\"anchor\" id=\"load_checkpoint\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b44f3",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "[Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) make batch inference easy since they have internal logic to parallelize the inference.\n",
    "```\n",
    "  \n",
    "In this notebook, we will restore a single scikit-learn model directly from checkpoint, and demonstrate it can be used for inference.\n",
    "\n",
    "Below, we can easily obtain AIR Checkpoint objects from the Tune results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08ae54ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dropoff location\n",
    "the_location = final_df.index[0]\n",
    "the_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dfb4712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ray.air.checkpoint.Checkpoint'>\n",
      "<class 'prophet.forecaster.Prophet'>\n"
     ]
    }
   ],
   "source": [
    "# Get a checkpoint directly from the pandas dataframe of Tune results\n",
    "checkpoint = final_df.checkpoint[the_location]\n",
    "print(type(checkpoint))\n",
    "\n",
    "# Restore a model from checkpoint\n",
    "model = checkpoint.to_dict()['model']\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c74eaad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_location_id         ds   y\n",
       "0                   1 2019-02-01  34"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create some test data\n",
    "df_list = [read_data(f, the_location) for f in s3_files[:1]]   \n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "df = transform_df(df_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e03aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference using restored model from checkpoint\n",
    "future_dates = model.make_future_dataframe(periods=FORECAST_LENGTH, freq='MS')\n",
    "future = model.predict(future_dates)\n",
    "\n",
    "# Assemble actual vs predicted pandas dfs to visualize\n",
    "error, test_df, pred_df = evaluate_model(model)\n",
    "\n",
    "# TODO create plot training + backtesting w/actuals, CIs, and future preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc0a9b3",
   "metadata": {},
   "source": [
    "**Compare validation and test error.**\n",
    "\n",
    "During model training we reported error on \"validation\" data (random sample).  Below, we will report error on a pretend \"test\" data set (a different random sample).\n",
    "\n",
    "Do a quick validation that both errors are reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813a85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate restored model on test data.\n",
    "error = sklearn.metrics.mean_absolute_error(test_y, pred_y)\n",
    "print(f\"Test error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d258238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test error with training validation error\n",
    "print(f\"Validation error: {final_df.error[the_location]}\")\n",
    "\n",
    "# Validation and test errors should be reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabc6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
