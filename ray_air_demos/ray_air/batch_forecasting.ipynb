{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db627f48",
   "metadata": {},
   "source": [
    "# Batch forecasting on Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc8e24",
   "metadata": {},
   "source": [
    "Batch training and tuning are common tasks in simple machine learning use-cases such as time series forecasting. They require fitting of simple models on multiple data batches corresponding to locations, products, etc.\n",
    "\n",
    "**'Batch training'** is a workload that trains model(s) on subsets of a dataset. This notebook showcases how to conduct batch training using [Ray Tune](https://docs.ray.io/en/latest/tune/index.html).\n",
    "\n",
    "![Batch training diagram](../../data/examples/images/batch-training.svg)\n",
    "\n",
    "For the data, we will use the [NYC Taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). This popular tabular dataset contains historical taxi pickups by timestamp and location in NYC.\n",
    "\n",
    "In this notebook, we will split the data by pickup location and train a separate forecasting model to predict #pickups at each location in NYC at monthly level for the next 2 months. Specifically, we will use the `pickup_location_id` column in the dataset to group the dataset into data batches. Then we will fit a separate model for each batch and evaluate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcb778",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Contents\n",
    "\n",
    "In this this tutorial, you will learn about:\n",
    " 1. [Define how to load and prepare Parquet data](#prepare_data)\n",
    " 2. [Define your Ray Tune Search Space and Search Algorithm](#define_search_space2)\n",
    " 3. [Define a Trainable (callable) function](#define_trainable2)\n",
    " 4. [Run batch training on Ray Tune](#run_tune_search2)\n",
    " 5. [Load a model from checkpoint and perform inference](#load_checkpoint2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d070c",
   "metadata": {},
   "source": [
    "# Walkthrough\n",
    "\n",
    "```{tip}\n",
    "Prerequisite for this notebook: Read the [Key Concepts](https://docs.ray.io/en/latest/tune/key-concepts.html) page for Ray Tune.\n",
    "```\n",
    "\n",
    "Let us start by importing a few required libraries, including open-source [Ray](https://github.com/ray-project/ray) itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25a5d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs in this system: 8\n",
      "pyarrow: 10.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f'Number of CPUs in this system: {os.cpu_count()}')\n",
    "from typing import Tuple, List, Union, Optional, Callable\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as pds\n",
    "print(f\"pyarrow: {pyarrow.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924d8e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 19:15:02,728\tINFO worker.py:1230 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "2022-11-14 19:15:02,729\tINFO worker.py:1342 -- Connecting to existing Ray cluster at address: 172.31.95.102:9031...\n",
      "2022-11-14 19:15:02,779\tINFO worker.py:1519 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.8.13</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.1.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard\" target=\"_blank\">http://console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard', python_version='3.8.13', ray_version='2.1.0', ray_commit='be49bde7ee4f6adb3f8710aee0665c27f9f0bb62', address_info={'node_ip_address': '172.31.95.102', 'raylet_ip_address': '172.31.95.102', 'redis_address': None, 'object_store_address': '/tmp/ray/session_2022-11-14_19-12-43_157257_147/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-11-14_19-12-43_157257_147/sockets/raylet', 'webui_url': 'console.anyscale-staging.com/api/v2/sessions/ses_b5q8xHd42BTdukSgFqTxejLT/services?redirect_to=dashboard', 'session_dir': '/tmp/ray/session_2022-11-14_19-12-43_157257_147', 'metrics_export_port': 49622, 'gcs_address': '172.31.95.102:9031', 'address': '172.31.95.102:9031', 'dashboard_agent_listen_port': 52365, 'node_id': '2bb682d7d79d6a58043ae217f61911d66c48176038841f74529e9529'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c62c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CPU': 8.0, 'node:172.31.95.102': 1.0, 'object_store_memory': 9108648345.0, 'memory': 18217296692.0}\n"
     ]
    }
   ],
   "source": [
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f220348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.23.4\n",
      "prophet: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "# import forecasting libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import prophet\n",
    "from prophet import Prophet\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"prophet: {prophet.__version__}\")\n",
    "\n",
    "# import ray libraries\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "\n",
    "# set global random seed for sklearn models\n",
    "np.random.seed(415)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2011368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For benchmarking purposes, we can print the times of various operations.\n",
    "# In order to reduce clutter in the output, this is set to False by default.\n",
    "PRINT_TIMES = False\n",
    "\n",
    "def print_time(msg: str):\n",
    "    if PRINT_TIMES:\n",
    "        print(msg)\n",
    "        \n",
    "# To speed things up, weâ€™ll only use a small subset of the full dataset consisting of two last months of 2019.\n",
    "# You can choose to use the full dataset for 2018-2019 by setting the SMOKE_TEST variable to False.\n",
    "SMOKE_TEST = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588ce33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define how to load and prepare Parquet data <a class=\"anchor\" id=\"load_data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1df7a0",
   "metadata": {},
   "source": [
    "First, we need to load some data.  Since the NYC Taxi dataset is fairly large, we will filter files first into a PyArrow dataset. And then in the next cell after, we will filter the data on read into a PyArrow table and convert that to a pandas dataframe.\n",
    "\n",
    "```{tip}\n",
    "Use PyArrow dataset and table for reading or writing large parquet files, since its native multithreaded C++ adpater is faster than pandas read_parquet, even using engine=pyarrow.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "581d1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Taxi using 3 file(s)!\n",
      "s3_files: ['s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/04/data.parquet/7e490662e39c4bfe8c64c6a2c45c9e8b_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/05/data.parquet/359c21b3e28f40328e68cf66f7ba40e2_000000.parquet', 's3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/2019/06/data.parquet/ab5b9d2b8cc94be19346e260b543ec35_000000.parquet']\n",
      "Locations: [1, 10, 199]\n"
     ]
    }
   ],
   "source": [
    "# Define some global variables.\n",
    "target = \"trip_duration\"\n",
    "s3_partitions = pds.dataset(\n",
    "    \"s3://anonymous@air-example-data/ursa-labs-taxi-data/by_year/\",\n",
    "    partitioning=[\"year\", \"month\"],\n",
    ")\n",
    "s3_files = [f\"s3://anonymous@{file}\" for file in s3_partitions.files]\n",
    "\n",
    "# Obtain all location IDs\n",
    "all_location_ids = (\n",
    "    pq.read_table(s3_files[0], columns=[\"dropoff_location_id\"])[\"dropoff_location_id\"]\n",
    "    .unique()\n",
    "    .to_pylist()\n",
    ")\n",
    "# drop [264, 265]\n",
    "all_location_ids.remove(264)\n",
    "all_location_ids.remove(265)\n",
    "\n",
    "# Use smoke testing or not.\n",
    "starting_idx = -3 if SMOKE_TEST else 0\n",
    "#TODO - drop error-handling test location 199\n",
    "sample_locations = [1, 10, 199] if SMOKE_TEST else all_location_ids\n",
    "\n",
    "# Display what data will be used.\n",
    "s3_files = s3_files[starting_idx:]\n",
    "print(f\"NYC Taxi using {len(s3_files)} file(s)!\")\n",
    "print(f\"s3_files: {s3_files}\")\n",
    "print(f\"Locations: {sample_locations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93d7bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +19s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[2m\u001b[1m\u001b[36m(scheduler +19s)\u001b[0m Resized to 24 CPUs.\n"
     ]
    }
   ],
   "source": [
    "# Function to read a pyarrow.Table object using pyarrow parquet \n",
    "def read_data(file: str, sample_id: np.int32) -> pd.DataFrame:\n",
    "    \n",
    "    df = pq.read_table(\n",
    "        file,\n",
    "        filters=[\n",
    "            (\"passenger_count\", \">\", 0),\n",
    "            (\"trip_distance\", \">\", 0),\n",
    "            (\"fare_amount\", \">\", 0),\n",
    "            (\"pickup_location_id\", \"not in\", [264, 265]),\n",
    "            (\"dropoff_location_id\", \"not in\", [264, 265]), \n",
    "            (\"pickup_location_id\", \"=\", sample_id)\n",
    "        ],\n",
    "        columns=[\n",
    "            \"pickup_at\",\n",
    "            \"dropoff_at\",\n",
    "            \"pickup_location_id\",\n",
    "            \"dropoff_location_id\",\n",
    "            \"passenger_count\",\n",
    "            \"trip_distance\",\n",
    "            \"fare_amount\",\n",
    "        ],\n",
    "    ).to_pandas()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to transform a pandas dataframe\n",
    "def transform_df(the_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = the_df.copy()\n",
    "    \n",
    "    # Prophet requires time is 'ds' and target_value name is 'y'\n",
    "    \n",
    "    # calculate trip_duration\n",
    "    df[\"trip_duration\"] = (df[\"dropoff_at\"] - df[\"pickup_at\"]).dt.seconds\n",
    "    # filter trip_durations > 1 minute and less than 24 hours\n",
    "    df = df[df[\"trip_duration\"] > 60]\n",
    "    df = df[df[\"trip_duration\"] < 24 * 60 * 60]\n",
    "    \n",
    "    # add year_month and concat into a unique column to use as groupby key\n",
    "    df['ds'] = df['pickup_at'].dt.to_period('M').dt.to_timestamp()\n",
    "    df['loc_year_month'] = df['pickup_location_id'].astype(str) + \"_\"  + \\\n",
    "                            df[\"pickup_at\"].dt.year.astype(str) + \"_\"  + \\\n",
    "                            df[\"pickup_at\"].dt.month.astype(str)\n",
    "    # add target_value quantity for groupby count later\n",
    "    df['y'] = 1\n",
    "    # drop unnecessary columns\n",
    "    df.drop([\"dropoff_at\", \"pickup_at\", \"dropoff_location_id\", \"fare_amount\",\n",
    "            \"passenger_count\", \"trip_distance\", \n",
    "             \"trip_duration\"]\n",
    "            , axis=1, inplace=True)\n",
    "    # return df\n",
    "    \n",
    "    # groupby aggregregate\n",
    "    g = df.groupby(\"loc_year_month\")\\\n",
    "                .agg({'pickup_location_id': min,\n",
    "                      'ds': min,\n",
    "                      'y': sum})\n",
    "    # having num rows in group > 10\n",
    "    g = g[g['y'] > 10].copy()\n",
    "    \n",
    "    # Drop groupby variable since we do not need it anymore\n",
    "    g.reset_index(inplace=True)\n",
    "    g.drop([\"loc_year_month\"], axis=1, inplace=True)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58b5183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_location_id             int32\n",
      "ds                    datetime64[ns]\n",
      "y                              int64\n",
      "dtype: object\n",
      "CPU times: user 6.36 s, sys: 2.86 s, total: 9.22 s\n",
      "Wall time: 7.01 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>2382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>2296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_location_id         ds     y\n",
       "0                  10 2019-04-01  2084\n",
       "1                  10 2019-05-01  2382\n",
       "2                  10 2019-06-01  2296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # Test reading data.\n",
    "# the_location = 10\n",
    "# df_list = [read_data(f, the_location) for f in s3_files] \n",
    "# df_raw = pd.concat(df_list, ignore_index=True)\n",
    "# df = transform_df(df_raw)\n",
    "# print(df.dtypes)\n",
    "# df.head()\n",
    "\n",
    "# # # without groupby\n",
    "# # CPU times: user 6.23 s, sys: 2.76 s, total: 9 s\n",
    "# # Wall time: 7.66 s\n",
    "\n",
    "# # # with groupby\n",
    "# # CPU times: user 6.36 s, sys: 2.86 s, total: 9.22 s\n",
    "# # Wall time: 7.01 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # test the groupby\n",
    "# g = df_raw.groupby(\"loc_year_month\")\\\n",
    "#             .agg({'pickup_location_id': min,\n",
    "#                   'ds': min,\n",
    "#                   'trip_quantity': sum})\n",
    "# # # having num rows in group > 10\n",
    "# g = g[g['trip_quantity'] > 10].copy()\n",
    "# g.reset_index(inplace=True)\n",
    "# df = g.copy()\n",
    "# g.head()\n",
    "\n",
    "# check we don't have any missing or 0 y-values\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9417f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot a timeseries\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# ax = plt.gca()\n",
    "# df.plot(x=\"ds\", y=\"y\", ax=ax, label=f\"pickup_location_id={the_location}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d858cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define your Ray Tune Search Space and Search Algorithm <a class=\"anchor\" id=\"define_search_space\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b640273",
   "metadata": {},
   "source": [
    "In this notebook, we will use Ray Tune to run parallel training jobs per dropoff location.  The training jobs will be defined using a search space and simple grid search.  Depending on your need, fancier search spaces and search algorithms are possible with Tune. \n",
    "\n",
    "**First, define a search space of experiment trials to run.**  \n",
    "> The typical use case for Tune search spaces are for hypterparameter tuning.  In our case, we are defining a Tune search space in a way to allow for training jobs to be conducted automatically.  Each training job will run on a different data partition (taxi dropoff location) and use a different model.\n",
    "\n",
    "Common search algorithms include grid search, random search, and Bayesian optimization.  For more details, see [Working with Tune Search Spaces](https://docs.ray.io/en/master/tune/tutorials/tune-search-spaces.html#tune-search-space-tutorial).  Deciding the best combination of search space and search algorithm is part of the art of being a Data Scientist and depends on the data, algorithm, and problem being solved!  \n",
    "\n",
    "**Next, define a search algorithm.**\n",
    ">Ray Tune will use the search space and the specified search algorithm to generate multiple configurations, each of which will be evaluated in a separate Trial on a Ray Cluster. Ray Tune will take care of orchestrating those Trials automatically.  Specifically, Ray Tune will pass a config dictionary to each partition and make a Trainable function call.\n",
    "\n",
    "**Below, we define our search space consists of:**\n",
    "- 2 different Scikit-learn algorithms \n",
    "- Some or all NYC taxi drop-off locations. \n",
    "\n",
    "**Also below, we define our search algorithm is:**\n",
    "- Grid search.\n",
    "\n",
    "What this means is every algorithm will be applied to every NYC Taxi drop-off location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141322b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test prophet model\n",
    "# model = Prophet(interval_width=0.5, monthly_seasonality=True)\n",
    "# model = Prophet(seasonality_mode=\"multiplicative\")\n",
    "# print(model)\n",
    "\n",
    "# # Keep only columns Prophet needs\n",
    "# model.fit(df[['ds', 'y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c431ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test prophet prediction\n",
    "# FORECAST_LENGTH = 1\n",
    "# future_dates = model.make_future_dataframe(periods=FORECAST_LENGTH, freq='MS')\n",
    "# # print(future_dates)\n",
    "# # make a prediction\n",
    "# future = model.predict(future_dates)\n",
    "# # print(type(future))\n",
    "\n",
    "# # assemble actual values\n",
    "# test_y = df.loc[(df.ds.isin(future_dates.ds)), :]\n",
    "\n",
    "# # assemble actual vs predicted values\n",
    "# pred_y = future[['ds', 'trend']]\n",
    "# # print(pred_y)\n",
    "# # Concat together predictions and actuals to visualize\n",
    "# temp = pd.concat([pred_y, test_y[['pickup_location_id', 'y']]], axis=1, ignore_index=True)\n",
    "# temp.columns = ['ds', 'pred_y', 'pickup_location_id', 'test_y']\n",
    "# temp = temp.iloc[0:-FORECAST_LENGTH]\n",
    "\n",
    "# # calculate mean absolute forecast error\n",
    "# temp['forecast_error'] = np.abs(temp['test_y'] - temp['pred_y'])\n",
    "# print(temp)\n",
    "# mean_absolute_error = np.mean(temp['forecast_error'])\n",
    "# print(f\"mean_absolute_error: {mean_absolute_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "873003c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'grid_search': [<prophet.forecaster.Prophet at 0x7f4961aac790>,\n",
       "   <prophet.forecaster.Prophet at 0x7f4961aacd30>]},\n",
       " 'location': {'grid_search': [1, 10, 199]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define a search space.\n",
    "search_space = {\n",
    "    \"model\": tune.grid_search([Prophet(seasonality_mode=\"multiplicative\"), \n",
    "                                Prophet()]),\n",
    "    \"location\": tune.grid_search(sample_locations),\n",
    "}\n",
    "search_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dcdfdc",
   "metadata": {},
   "source": [
    "## Define a Trainable (callable) function <a class=\"anchor\" id=\"define_trainable\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91106791",
   "metadata": {},
   "source": [
    "ðŸ“ˆ Typically when you are running Data Science experiments, you want to be able to keep track of summary metrics for each trial, so you can decide at the end which trials were best.  That way, you can decide which model to deploy.\n",
    "\n",
    "ðŸ‡« Next, we define a trainable function in order to train and evaluate a scikit-learn model on a data partition.  This function will be called in parallel by every Tune trial.  Inside this trainable function, we will:\n",
    "- Add detailed metrics we want to report (each model's loss or error). \n",
    "- Checkpoint each model for easy deployment later.\n",
    "\n",
    "ðŸ“– **The metrics defined inside the trainable function will appear in the Ray Tune experiment summary table.**\n",
    "```{tip}\n",
    "Ray Tune has two ways of defining a trainable, namely the [Function API](https://docs.ray.io/en/latest/tune/api_docs/trainable.html#trainable-docs) and the Class API. Both are valid ways of defining a trainable, but *the Function API is generally recommended*.\n",
    "```\n",
    "\n",
    "**In the cell below, we define a \"Trainable\" function called `train_model()`**.  \n",
    "- The input is a config dictionary argument. \n",
    "- The output can be a simple dictionary of metrics which will be reported back to Tune.  \n",
    "- We will [checkpoint](https://docs.ray.io/en/master/ray-air/key-concepts.html#checkpoints) save each model in addition to reporting each trial's metrics.\n",
    "  > For checkpointing, we use `ray.air.checkpoint.Checkpoint`.  *Ray AIR includes integrations to popular ML libraries, including Scikit-learn*.  This makes it possible to use the convenient AIR API abstractions, without having to specify code details of the Scikit-learn library itself.\n",
    "- Since we are using **grid search**, this means `train_model()` will be run *in parallel for every permutation* in the Tune search space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69fa47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define a custom train function\n",
    "def train_model(config: dict):\n",
    "\n",
    "    model = config['model']\n",
    "    the_location = config['location']\n",
    "    FORECAST_LENGTH = 1\n",
    "    \n",
    "    # Load data.\n",
    "    df_list = [read_data(f, the_location) for f in s3_files]   \n",
    "    df_raw = pd.concat(df_list, ignore_index=True)\n",
    "    df = transform_df(df_raw)\n",
    "    \n",
    "    # We need at least 10 rows to create a train / test split.\n",
    "    if len(df) < 10:\n",
    "        print_time(f\"Data batch for LocID {the_location} is empty or smaller than 10 rows\")\n",
    "        return\n",
    "\n",
    "    # Train model.\n",
    "    model = model.fit(df[['ds', 'y']])\n",
    "    \n",
    "    # Inference model.\n",
    "    future_dates = model.make_future_dataframe(periods=FORECAST_LENGTH, freq='MS')\n",
    "    future = model.predict(future_dates)\n",
    "\n",
    "    # assemble actual vs predicted values\n",
    "    test_y = df.loc[(df.ds.isin(future_dates.ds)), :]\n",
    "    pred_y = future[['ds', 'trend']].iloc[0:-FORECAST_LENGTH]\n",
    "    temp = pd.concat([pred_y, test_y[['y']]], \n",
    "                     axis=1, ignore_index=True)\n",
    "    temp.columns = ['ds', 'pred_y', 'test_y']\n",
    "    print(f\"location {the_location} temp: {temp.head()}\")\n",
    "\n",
    "    # Evaluate mean absolute forecast error.\n",
    "    temp['forecast_error'] = np.abs(temp['test_y'] - temp['pred_y'])\n",
    "    error = np.mean(temp['forecast_error'])\n",
    "    print(f\"location {the_location} error: {error}\")\n",
    "\n",
    "    # Define a model checkpoint using AIR API.  \n",
    "    # https://docs.ray.io/en/latest/tune/tutorials/tune-checkpoints.html\n",
    "    checkpoint = ray.air.checkpoint.Checkpoint.from_dict({\n",
    "        \"model\": model, \n",
    "        \"location_id\": the_location})\n",
    "\n",
    "    # Save checkpoint and report back metrics, using ray.air.session.report()\n",
    "    # The metrics you specify here will appear in Tune summary table.\n",
    "    # They will also be recorded in Tune results under `metrics`.\n",
    "    metrics = dict(error = error)\n",
    "    session.report(\n",
    "            metrics, \n",
    "            checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cadfadd",
   "metadata": {},
   "source": [
    "## Run batch training on Ray Tune <a class=\"anchor\" id=\"run_tune_search\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385dfd26",
   "metadata": {},
   "source": [
    "**In the cell below, we configure the resources allocated per trial.** \n",
    "\n",
    "Tune uses this resources allocation to control the parallelism. For example, if each trial was configured to use 4 CPUs, and the cluster had only 32 CPUs, then Tune will limit the number of concurrent trials to 8 to avoid overloading the cluster. For more information, see [A Guide To Parallelism and Resources](https://docs.ray.io/en/master/tune/tutorials/tune-resources.html#tune-parallelism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fda822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Customize resources per trial, here we set 1 CPU each.\n",
    "train_model = tune.with_resources(train_model, {\"cpu\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29313c22",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Now we are ready to kick off a Ray Tune experiment!**  \n",
    "\n",
    "Recall what we are doing, high level, is training several different models per dropoff location.  We are using Ray Tune so we can run all these trials in parallel.  At the end, we will inspect the results of the experiment and deploy only the best model per dropoff location.\n",
    "\n",
    "**In the cell below, we use AIR configs and run the experiment using `tuner.fit()`.** \n",
    "\n",
    "Tune will report on experiment status, and after the experiment finishes, you can inspect the results. \n",
    "\n",
    "In the AIR config below, we have specified a local directory `my_Tune_logs` for logging instead of the default `~/ray_results` directory. Giving your logs a project name makes them easier to find.  Also giving a relative path, means you can see your logs inside the Jupyter browser.  Learn more about logging Tune results at [How to configure logging in Tune](https://docs.ray.io/en/master/tune/tutorials/tune-output.html#tune-logging).\n",
    "\n",
    "Tune can [retry failed experiments automatically](https://docs.ray.io/en/master/tune/tutorials/tune-stopping.html#tune-stopping-guide), as well as entire experiments.  This is necessary in case a node on your remote cluster fails (when running on a cloud such as AWS or GCP).\n",
    "\n",
    "ðŸ’¡ Right-click on the cell below and choose \"Enable Scrolling for Outputs\"! This will make it easier to view, since model training output can be very long!\n",
    "\n",
    "**In the output below and in the Ray Dashboard, you can see that 518 models, using 18 NYC Taxi S3 files dating from 2018/01 to 2019/06 (split into partitions approx 7GiB each), were simultaneously trained on a 23-node AWS cluster of [m5.4xlarge](https://aws.amazon.com/ec2/instance-types/m5/)s, within 37 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eb3a59d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2022-11-14 19:34:40</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:15.97        </td></tr>\n",
       "<tr><td>Memory:      </td><td>2.4/30.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/61.77 GiB heap, 0.0/25.66 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc              </th><th style=\"text-align: right;\">  location</th><th>model               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_66a36_00000</td><td>TERMINATED</td><td>172.31.83.53:2836</td><td style=\"text-align: right;\">         1</td><td>&lt;prophet.foreca_fb80</td></tr>\n",
       "<tr><td>train_model_66a36_00001</td><td>TERMINATED</td><td>172.31.83.53:2867</td><td style=\"text-align: right;\">        10</td><td>&lt;prophet.foreca_ad60</td></tr>\n",
       "<tr><td>train_model_66a36_00002</td><td>TERMINATED</td><td>172.31.83.53:2868</td><td style=\"text-align: right;\">       199</td><td>&lt;prophet.foreca_cbb0</td></tr>\n",
       "<tr><td>train_model_66a36_00003</td><td>TERMINATED</td><td>172.31.83.53:2869</td><td style=\"text-align: right;\">         1</td><td>&lt;prophet.foreca_b580</td></tr>\n",
       "<tr><td>train_model_66a36_00004</td><td>TERMINATED</td><td>172.31.83.53:2870</td><td style=\"text-align: right;\">        10</td><td>&lt;prophet.foreca_6f40</td></tr>\n",
       "<tr><td>train_model_66a36_00005</td><td>TERMINATED</td><td>172.31.83.53:2871</td><td style=\"text-align: right;\">       199</td><td>&lt;prophet.foreca_6d90</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial train_model_66a36_00000 completed. Last result: \n",
      "Trial train_model_66a36_00003 completed. Last result: \n",
      "Trial train_model_66a36_00001 completed. Last result: \n",
      "Trial train_model_66a36_00004 completed. Last result: \n",
      "Trial train_model_66a36_00002 completed. Last result: \n",
      "Trial train_model_66a36_00005 completed. Last result: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-14 19:34:40,900\tINFO tune.py:777 -- Total run time: 16.09 seconds (15.96 seconds for the tuning loop).\n",
      "2022-11-14 19:34:40,905\tWARNING experiment_analysis.py:627 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models: 6\n",
      "TOTAL TIME TAKEN: 16.09 seconds\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: error. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOTAL TIME TAKEN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time_taken\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merror\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest result: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ray/tune/result_grid.py:150\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    139\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: error. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "# Define a tuner object using Ray AIR Tuner API\n",
    "tuner = tune.Tuner(\n",
    "    train_model, \n",
    "    param_space=search_space,\n",
    "    run_config=air.RunConfig(\n",
    "        \n",
    "        #redirect logs to relative path instead of default ~/ray_results/\n",
    "        local_dir = \"my_Tune_logs\",\n",
    "        name = \"batch_tuning\",\n",
    "\n",
    "        # Set Ray Tune verbosity.  Print summary table only with levels 2 or 3.\n",
    "        verbose=2,\n",
    "        ),\n",
    ")\n",
    "\n",
    "# 4. Run the experiment with Ray Tune\n",
    "start = time.time()\n",
    "results = tuner.fit()\n",
    "total_time_taken = time.time() - start\n",
    "\n",
    "# Print some training stats\n",
    "print(f\"Total number of models: {len(results)}\")\n",
    "print(f\"TOTAL TIME TAKEN: {total_time_taken:.2f} seconds\")\n",
    "best_result = results.get_best_result(metric=\"error\", mode=\"min\").config\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c54d0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**After the Tune experiment has run, select the best model per dropoff location.**\n",
    "\n",
    "We can assemble the Tune results ([ResultGrid object](https://docs.ray.io/en/master/tune/examples/tune_analyze_results.html)) into a pandas dataframe, then sort by minimum error, to select the best model per dropoff location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d0388da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trial_id': '66a36_00000', 'experiment_id': 'd9262ac74cfe4f0d850c489e54530844', 'date': '2022-11-14_19-34-27', 'timestamp': 1668483267, 'pid': 2836, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21f34b50>, 'location': 1}, 'done': True}\n",
      "{'trial_id': '66a36_00001', 'experiment_id': '432a471538694138946b87990ae1a1ba', 'date': '2022-11-14_19-34-30', 'timestamp': 1668483270, 'pid': 2867, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21f2fa30>, 'location': 10}, 'done': True}\n",
      "{'trial_id': '66a36_00002', 'experiment_id': '730609ad8d774d33a35bd8714f3ed212', 'date': '2022-11-14_19-34-30', 'timestamp': 1668483270, 'pid': 2868, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21e3c370>, 'location': 199}, 'done': True}\n",
      "{'trial_id': '66a36_00003', 'experiment_id': '6033ac857d2142608b857bf231bea405', 'date': '2022-11-14_19-34-30', 'timestamp': 1668483270, 'pid': 2869, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21e3cf40>, 'location': 1}, 'done': True}\n",
      "{'trial_id': '66a36_00004', 'experiment_id': '95d9dea89c744c8899a6744e5926b861', 'date': '2022-11-14_19-34-30', 'timestamp': 1668483270, 'pid': 2870, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21e3c3d0>, 'location': 10}, 'done': True}\n",
      "{'trial_id': '66a36_00005', 'experiment_id': '37c179d2c44040439693aaa58a53a64f', 'date': '2022-11-14_19-34-30', 'timestamp': 1668483270, 'pid': 2871, 'hostname': 'ip-172-31-83-53', 'node_ip': '172.31.83.53', 'config': {'model': <prophet.forecaster.Prophet object at 0x7f4c21e3c460>, 'location': 199}, 'done': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i.metrics) for i in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbe62f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location_id      int64\n",
      "model           object\n",
      "error          float64\n",
      "checkpoint      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>model</th>\n",
       "      <th>error</th>\n",
       "      <th>checkpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f4c21...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f4c21...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f4c21...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f4c21...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>&lt;prophet.forecaster.Prophet object at 0x7f4c21...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location_id                                              model    error  \\\n",
       "0            1  <prophet.forecaster.Prophet object at 0x7f4c21...  10000.0   \n",
       "1           10  <prophet.forecaster.Prophet object at 0x7f4c21...  10000.0   \n",
       "2          199  <prophet.forecaster.Prophet object at 0x7f4c21...  10000.0   \n",
       "3            1  <prophet.forecaster.Prophet object at 0x7f4c21...  10000.0   \n",
       "4           10  <prophet.forecaster.Prophet object at 0x7f4c21...  10000.0   \n",
       "\n",
       "  checkpoint  \n",
       "0       None  \n",
       "1       None  \n",
       "2       None  \n",
       "3       None  \n",
       "4       None  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of training loss errors\n",
    "errors = []\n",
    "[errors.append(i.metrics.get('error',10000.0)) for i in results]\n",
    "\n",
    "# get a list of checkpoints\n",
    "checkpoints = []\n",
    "[checkpoints.append(i.checkpoint) for i in results] \n",
    "\n",
    "# get a list of locations\n",
    "locations = []\n",
    "[locations.append(i.config['location']) for i in results]\n",
    "\n",
    "# get a list of models\n",
    "models = []\n",
    "[models.append(i.config['model']) for i in results]\n",
    "\n",
    "# Assemble a pandas dataframe from Tune results\n",
    "results_df = pd.DataFrame(zip(locations, models, errors,checkpoints),\n",
    "                          columns = ['location_id', 'model', 'error', 'checkpoint']\n",
    "                         )\n",
    "print(results_df.dtypes)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89c5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 1 model per location_id with minimum error\n",
    "final_df = results_df.dropna()\n",
    "final_df = final_df.loc[results_df.groupby('location_id')['error'].idxmin()].copy()\n",
    "final_df.sort_values(by=[\"error\"], inplace=True)\n",
    "final_df.set_index('location_id', inplace=True, drop=True)\n",
    "print(final_df.dtypes)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa81e4",
   "metadata": {},
   "source": [
    "## Load a model from checkpoint and perform inference  <a class=\"anchor\" id=\"load_checkpoint\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5733d9",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "[Ray AIR Predictors](https://docs.ray.io/en/latest/ray-air/predictors.html) make batch inference easy since they have internal logic to parallelize the inference.\n",
    "```\n",
    "  \n",
    "In this notebook, we will restore a single scikit-learn model directly from checkpoint, and demonstrate it can be used for inference.\n",
    "\n",
    "Below, we can easily obtain AIR Checkpoint objects from the Tune results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84f17ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dropoff location\n",
    "the_location = final_df.index[25]\n",
    "the_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d8cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a checkpoint directly from the pandas dataframe of Tune results\n",
    "checkpoint = final_df.checkpoint[the_location]\n",
    "print(type(checkpoint))\n",
    "\n",
    "# Restore a model from checkpoint\n",
    "model = checkpoint.to_dict()['model']\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd49ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test data\n",
    "df_list = [read_data(f, the_location) for f in s3_files[:1]]   \n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "df = transform_df(df_raw)\n",
    "\n",
    "# Train/test split.\n",
    "_, test_df = train_test_split(df, test_size=0.2, shuffle=True)\n",
    "test_X = test_df[[\"passenger_count\", \"trip_distance\"]]\n",
    "test_y = np.array(test_df.trip_duration)  #actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e160537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inference using restored model from checkpoint\n",
    "pred_y = model.predict(test_X)\n",
    "\n",
    "# Zip together predictions and actuals to visualize\n",
    "pd.DataFrame(zip(pred_y, test_y), \n",
    "             columns = [\"pred_y\", \"trip_duration\"])[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d4b518",
   "metadata": {},
   "source": [
    "**Compare validation and test error.**\n",
    "\n",
    "During model training we reported error on \"validation\" data (random sample).  Below, we will report error on a pretend \"test\" data set (a different random sample).\n",
    "\n",
    "Do a quick validation that both errors are reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate restored model on test data.\n",
    "error = sklearn.metrics.mean_absolute_error(test_y, pred_y)\n",
    "print(f\"Test error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec8406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare test error with training validation error\n",
    "print(f\"Validation error: {final_df.error[the_location]}\")\n",
    "\n",
    "# Validation and test errors should be reasonably close together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7f0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
