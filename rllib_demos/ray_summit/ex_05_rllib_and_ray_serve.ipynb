{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 05. Using RLlib with Ray Serve to deploy a policy into production\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved\n",
    "\n",
    "### Learning objectives\n",
    "In this this notebook, you will learn:\n",
    "\n",
    " * [How to deploy a trained policy into production using Ray Serve](#ray_serve)\n",
    " * [How to send requests to a deployed policy via HTTP](#ray_serve_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym: 0.21.0\n",
      "ray: 3.0.0.dev0\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Discrete, MultiDiscrete\n",
    "import numpy as np\n",
    "import requests\n",
    "from requests import Request\n",
    "import tree  # pip install dm_tree\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "from ray.rllib.algorithms.crr import CRRConfig\n",
    "\n",
    "print(f\"gym: {gym.__version__}\")\n",
    "print(f\"ray: {ray.__version__}\")\n",
    "\n",
    "# !ale-import-roms --import-from-pkg atari_py.atari_roms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ray Serve to deploy a trained policy into production <a class=\"anchor\" id=\"ray_serve\"></a>\n",
    "\n",
    "<img src=\"images/rllib_and_ray_serve.png\" width=800 />\n",
    "\n",
    "This is a quick demo on how to use our already (offline RL) trained CRR policy and deploy it using Ray Serve.\n",
    "All you need to run the following code and produce a serve deployment is one of the checkpoints files from the previous notebook. Let's take checkpoint number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 12:32:41,219\tINFO services.py:1477 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(ServeController pid=56782)\u001b[0m INFO 2022-07-28 12:32:44,662 controller 56782 checkpoint_path.py:17 - Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(ServeController pid=56782)\u001b[0m INFO 2022-07-28 12:32:44,665 controller 56782 http_state.py:115 - Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:vdkxiM:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n"
     ]
    }
   ],
   "source": [
    "# Call `serve.start()` to get \n",
    "serve.start()\n",
    "\n",
    "\n",
    "@serve.deployment(route_prefix=\"/serve-deployment\")\n",
    "class ServeModel:\n",
    "    def __init__(self, config, checkpoint) -> None:\n",
    "        # Create new algo from scratch.\n",
    "        self.algo = config.build()\n",
    "        # Restore state of algo to a already trained one (using a checkpoint).\n",
    "        self.algo.restore(checkpoint)\n",
    "\n",
    "    async def __call__(self, request):\n",
    "        json_input = await request.json()\n",
    "        # Extract observation from input.\n",
    "        obs = json_input[\"observation\"]\n",
    "        # Translate obs back to np.arrays.\n",
    "        np_obs = np.array(obs)\n",
    "        action = self.algo.compute_single_action(np_obs, explore=False)\n",
    "        return {\"action\": action}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, you will be asked to provide the path to an already existing checkpoint file.\n",
    "\n",
    "We have created Pendulum-v1 CRR checkpoints in the previous notebook and you should by now be able to navigate to one of these checkpoints using your notebook file browser on the left side:\n",
    "\n",
    "<img src=\"images/copy_checkpoint_path.png\" width=400>\n",
    "\n",
    "Once you copied the path, you can paste it into the `checkpoint = \"...\"` code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO:     Started server process [56783]\n",
      "/var/folders/j4/brrn254576lgnbqqtp5p1z280000gn/T/ipykernel_56746/1740442777.py:14: UserWarning: From /var/folders/j4/brrn254576lgnbqqtp5p1z280000gn/T/ipykernel_56746/1740442777.py:14: deploy (from ray.serve.deployment) is deprecated and will be removed in a future version Please see https://docs.ray.io/en/latest/serve/index.html\n",
      "  ServeModel.deploy(config, checkpoint)\n",
      "\u001b[2m\u001b[36m(ServeController pid=56782)\u001b[0m INFO 2022-07-28 12:32:46,454 controller 56782 deployment_state.py:1280 - Adding 1 replicas to deployment 'ServeModel'.\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:32:53,767\tWARNING deprecation.py:47 -- DeprecationWarning: `min_iter_time_s` has been deprecated. Use `min_time_s_per_iteration` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:32:53,768\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:32:53,768\tINFO algorithm.py:332 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:33:01,352\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:33:01,353\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:33:01,366\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56789)\u001b[0m 2022-07-28 12:33:01,329\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56789)\u001b[0m 2022-07-28 12:33:01,333\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56791)\u001b[0m 2022-07-28 12:33:01,330\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56791)\u001b[0m 2022-07-28 12:33:01,334\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56788)\u001b[0m 2022-07-28 12:33:01,315\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56788)\u001b[0m 2022-07-28 12:33:01,319\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56790)\u001b[0m 2022-07-28 12:33:01,331\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=56790)\u001b[0m 2022-07-28 12:33:01,335\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:33:01,384\tINFO trainable.py:654 -- Restored on 127.0.0.1 from checkpoint: results/CRR/CRR_Pendulum-v1_93a30_00000_0_2022-07-26_23-26-14/checkpoint_000028\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m 2022-07-28 12:33:01,384\tINFO trainable.py:663 -- Current state after restoring: {'_iteration': 28, '_timesteps_total': None, '_time_total': 372.1818161010742, '_episodes_total': 0}\n"
     ]
    }
   ],
   "source": [
    "# In order to create a deployment from the tagge class above, simply call its `deploy()`\n",
    "# method and pass this method the `ServeModel` constructor arguments:\n",
    "\n",
    "# Create config to use. Same as before, but lighter:\n",
    "# 1) No evaluation necessary (model only used for inference).\n",
    "# 2) No `offline_data` settings necessary (model only used for inference).\n",
    "\n",
    "config = CRRConfig().environment(env=\"Pendulum-v1\")\n",
    "config.framework(\"torch\")\n",
    "\n",
    "# Pick a solid checkpoint from the previous notebook's CRR experiment:\n",
    "checkpoint = \"results/CRR/CRR_Pendulum-v1_93a30_00000_0_2022-07-26_23-26-14/checkpoint_000028/checkpoint-28\"\n",
    "\n",
    "ServeModel.deploy(config, checkpoint)\n",
    "    \n",
    "# That's it: Deployment created!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the deployment for serving actions <a class=\"anchor\" id=\"ray_serve_requests\"></a>\n",
    "\n",
    "Now let's send action inference requests to the existing deployment.\n",
    "We'll be using a test `Pendulum-v1` environment here, pretending we are some client that would like to query the server for good Pendulum actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Sending observation [0.7845883369445801, -0.6200169920921326, 0.0003206760447937995]\n",
      "<- got {'action': [1.449544906616211]}\n",
      "-> Sending observation [0.7768633365631104, -0.6296692490577698, -0.24726034700870514]\n",
      "<- got {'action': [1.591677188873291]}\n",
      "-> Sending observation [0.7615043520927429, -0.6481598019599915, -0.48076072335243225]\n",
      "<- got {'action': [1.6422221660614014]}\n",
      "-> Sending observation [0.737663745880127, -0.6751682758331299, -0.7205472588539124]\n",
      "<- got {'action': [1.6735374927520752]}\n",
      "-> Sending observation [0.7038542032241821, -0.7103444337844849, -0.9758928418159485]\n",
      "<- got {'action': [1.555694580078125]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO 2022-07-28 12:33:26,716 http_proxy 127.0.0.1 http_proxy.py:316 - GET /in-game-recommendations 200 3.9ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO 2022-07-28 12:33:26,724 http_proxy 127.0.0.1 http_proxy.py:316 - GET /in-game-recommendations 200 3.9ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO 2022-07-28 12:33:26,733 http_proxy 127.0.0.1 http_proxy.py:316 - GET /in-game-recommendations 200 4.5ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO 2022-07-28 12:33:26,741 http_proxy 127.0.0.1 http_proxy.py:316 - GET /in-game-recommendations 200 3.7ms\n",
      "\u001b[2m\u001b[36m(HTTPProxyActor pid=56783)\u001b[0m INFO 2022-07-28 12:33:26,749 http_proxy 127.0.0.1 http_proxy.py:316 - GET /in-game-recommendations 200 3.8ms\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m INFO 2022-07-28 12:33:26,714 ServeModel ServeModel#DlCdxY replica.py:467 - HANDLE __call__ OK 1.2ms\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m INFO 2022-07-28 12:33:26,723 ServeModel ServeModel#DlCdxY replica.py:467 - HANDLE __call__ OK 1.3ms\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m INFO 2022-07-28 12:33:26,731 ServeModel ServeModel#DlCdxY replica.py:467 - HANDLE __call__ OK 1.3ms\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m INFO 2022-07-28 12:33:26,740 ServeModel ServeModel#DlCdxY replica.py:467 - HANDLE __call__ OK 1.2ms\n",
      "\u001b[2m\u001b[36m(ServeModel pid=56784)\u001b[0m INFO 2022-07-28 12:33:26,747 ServeModel ServeModel#DlCdxY replica.py:467 - HANDLE __call__ OK 1.4ms\n"
     ]
    }
   ],
   "source": [
    "# Create a environment so we can step through episodes using requested, served actions.\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "# Get the initial observation.\n",
    "obs = env.reset()\n",
    "\n",
    "# Request 5 actions of an episode from served policy and step through the env using the received actions.\n",
    "for _ in range(3):\n",
    "    # Convert numpy array to list (needed for http transfer).\n",
    "    obs = obs.tolist()\n",
    "\n",
    "    print(f\"-> Sending observation {obs}\")\n",
    "    resp = requests.get(\n",
    "        \"http://localhost:8000/serve-deployment\", json={\"observation\": obs}\n",
    "    )\n",
    "    # Convert to response to JSON.\n",
    "    # The received JSON should include an \"action\" field (see our ServeModel class for details).\n",
    "    response_json = resp.json()\n",
    "    print(f\"<- got {response_json}\")\n",
    "\n",
    "    # Convert to numpy array.\n",
    "    action = np.array(response_json[\"action\"])\n",
    "\n",
    "    # Perform a step with the served action.\n",
    "    obs, _, _, _ = env.step(action)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook, we have learnt:\n",
    "\n",
    "* How to create a Ray Serve \"deployment\" using a custom `@serve.deployment`-tagged class\n",
    "* How to query actions from this custom deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "#### 1) Run a complete episode using our Policy deployment\n",
    "\n",
    "Use the code in the cell above and now run a complete episode through a Pendulum environment, then report the episode's rewards at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new environment using gym.make():\n",
    "# ...\n",
    "\n",
    "# Get the initial observation via the env's `reset()` method.\n",
    "# ...\n",
    "\n",
    "total_reward = 0.0\n",
    "\n",
    "# Loop through an entire episode using a while loop.\n",
    "# while True:\n",
    "\n",
    "    # Remember to convert all np-arrays to lists prior to sending them via the Convert numpy array to list (needed for http transfer).\n",
    "    # obs = obs.tolist()\n",
    "\n",
    "    # Send the action request using `resp = request.get([address], json={\"observation\": [current observation]})`.\n",
    "    # ...\n",
    "\n",
    "    # Convert response to JSON and extract the \"action\" field, then convert the action to a numpy array.\n",
    "    # ...\n",
    "\n",
    "    # Perform an env step with the served action (using the env's `step([some action])` method).\n",
    "    # obs, reward, done, info = env.step(...)\n",
    "    \n",
    "    # Add up reward.\n",
    "    \n",
    "    # Check done flag; if True -> break out of while loop.\n",
    "\n",
    "    \n",
    "print(f\"Played one episode entirely using served actions; Total episode reward is {total_reward}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) What would happen, if we had a \"stateful\" policy?\n",
    "\n",
    "Think about the problem of having trained a neural network that uses one or more memory-capable (stateful) layers, like an LSTM layer.\n",
    "Given the problem of distributed deployment (across several endpoints accessible through different addresses/ports), what do you think would be the best solution for keeping or passing around the layer's state (e.g. the LSTM's internal c- and h- states)?\n",
    "\n",
    "* Should the server side (Ray Serve deployment) keep these tensors in between action requests?\n",
    "* Or should the clients handle these states and pass them back via each new requests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## References\n",
    " * [Ray Serve: Scalable and Programmable Serving](https://docs.ray.io/en/latest/serve/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚û°Ô∏è [Link to previous notebook](./ex_04_offline_rl_with_rllib.ipynb) <br>\n",
    "‚û°Ô∏è [Link to next notebook](./ex_06_rllib_end_to_end_demo.ipynb) <br>\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_rllib_notebooks_table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
