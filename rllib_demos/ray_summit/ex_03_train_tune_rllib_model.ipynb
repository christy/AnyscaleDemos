{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03. Introduction to Ray Tune and hyperparameter optimization (HPO)\n",
    "\n",
    "¬© 2019-2022, Anyscale. All Rights Reserved <br>\n",
    "üìñ [Back to Table of Contents](./ex_00_rllib_notebooks_table_of_contents.ipynb) <br>\n",
    "‚û°Ô∏è [Next notebook](./ex_04_offline_rl_with_rllib.ipynb) <br>\n",
    "‚¨ÖÔ∏è [Previous notebook](./ex_02_create_multiagent_rllib_env.ipynb) <br>\n",
    "\n",
    "### Learning objectives\n",
    "In this this notebook, you will learn:\n",
    " * [How to configure Ray Tune to find solid hyperparameters more easily](#configure_ray_tune)\n",
    " * [The details behind Ray RLlib resource allocation](#resource_allocation)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym: 0.21.0\n",
      "ray: 3.0.0.dev0\n"
     ]
    }
   ],
   "source": [
    "# Import required packages.\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import tune\n",
    "\n",
    "# Importing the very same environment class that we have coded together in\n",
    "# the previous notebook.\n",
    "from multi_agent_arena.multi_agent_arena import MultiAgentArena\n",
    "\n",
    "\n",
    "print(f\"gym: {gym.__version__}\")\n",
    "print(f\"ray: {ray.__version__}\")\n",
    "\n",
    "# !ale-import-roms --import-from-pkg atari_py.atari_roms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to configure Ray Tune to find solid hyperparameters more easily <a class=\"anchor\" id=\"configure_ray_tune\"></a>\n",
    "\n",
    "In the previous experiments, we used a single algorithm's (PPO) configuration to create\n",
    "exactly one Algorithm object and call its `train()` method manually a couple of times.\n",
    "\n",
    "A common thing to try when doing ML or RL is to look for better choices of hyperparameters, neural network architectures, or algorithm settings. This hyperparameter optimization\n",
    "problem can be tackled in a scalable fashion using Ray Tune (in combination with RLlib!).\n",
    "\n",
    "<img src=\"images/rllib_and_tune.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell demonstrates, how you can setup a simple grid-search for one very important hyperparameter (the learning rate), using our already existing PPO config object and Ray Tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.rllib.algorithms.ppo.ppo.PPOConfig at 0x7fc075b352e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a PPOConfig object (same as we did in the previous notebook):\n",
    "config = PPOConfig()\n",
    "\n",
    "# Setup our config object the exact same way as before:\n",
    "# Point to our MultiAgentArena env:\n",
    "config.environment(env=MultiAgentArena)\n",
    "\n",
    "# Setup multi-agent mapping:\n",
    "\n",
    "# Environment provides M agent IDs.\n",
    "# RLlib has N policies (neural networks).\n",
    "# The `policy_mapping_fn` maps M agent IDs to N policies (M <= N).\n",
    "\n",
    "# If you don't provide a policy_mapping_fn, all agent IDs will map to \"default_policy\".\n",
    "config.multi_agent(\n",
    "    # Tell RLlib to create 2 policies with these IDs here:\n",
    "    policies=[\"policy1\", \"policy2\"],\n",
    "    # Tell RLlib to map agent1 to policy1 and agent2 to policy2.\n",
    "    policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\",\n",
    ")\n",
    "\n",
    "# Reduce the number of workers from 2 (default) to 1 to save some resources on the expensive hyperparameter sweep.\n",
    "# IMPORTANT: More information on resource requirements for tune hyperparameter sweeps and different RLlib algorithm setups\n",
    "# below.\n",
    "config.rollouts(num_rollout_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore how a very simple hyperparameter search should be configured with RLlib and Tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default learning rate for PPO is: 5e-05\n",
      "Default train batch size for PPO is: 4000\n"
     ]
    }
   ],
   "source": [
    "# Before setting up the learning rate hyperparam sweep,\n",
    "# let's see what the default learning rate and train batch size is for PPO:\n",
    "print(f\"Default learning rate for PPO is: {config.lr}\")\n",
    "print(f\"Default train batch size for PPO is: {config.train_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.rllib.algorithms.ppo.ppo.PPOConfig at 0x7fc075b352e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's change our existing config object and add a simple\n",
    "# grid-search over two different learning rates to it:\n",
    "config.training(\n",
    "    lr=tune.grid_search([5e-5, 1e-4]),\n",
    "    train_batch_size=tune.grid_search([3000, 4000]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° <b>Right-click on the cell below and choose \"Enable Scrolling for Outputs\"!</b>  This will make it easier to view, since model training output can be very long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 12:15:59,207\tINFO services.py:1477 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8267\u001b[39m\u001b[22m\n",
      "2022-07-27 12:16:02,088\tWARNING deprecation.py:47 -- DeprecationWarning: `ray.rllib.execution.buffers` has been deprecated. Use `ray.rllib.utils.replay_buffers` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-27 12:24:03 (running for 00:08:01.20)<br>Memory usage on this node: 10.2/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/16 CPUs, 0/0 GPUs, 0.0/4.05 GiB heap, 0.0/2.0 GiB objects<br>Current best trial: 1dedd_00000 with episode_reward_mean=20.141999999999936 and parameters={'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'multi_agent_arena.multi_agent_arena.MultiAgentArena'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 1, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 3000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'evaluation_config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': <class 'multi_agent_arena.multi_agent_arena.MultiAgentArena'>, 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_workers': 1, 'num_envs_per_worker': 1, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'gamma': 0.99, 'lr': 5e-05, 'train_batch_size': 3000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_parallel_to_training': False, 'evaluation_config': {}, 'off_policy_estimation_methods': {}, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': True, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'policy1': <ray.rllib.policy.policy.PolicySpec object at 0x7fc077c1cca0>, 'policy2': <ray.rllib.policy.policy.PolicySpec object at 0x7fc077c1c910>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': <function <lambda> at 0x7fc077ba9670>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1}, 'off_policy_estimation_methods': {}, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 180, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': True, 'monitor': -1, 'evaluation_num_episodes': -1, 'metrics_smoothing_episodes': -1, 'timesteps_per_iteration': -1, 'min_iter_time_s': -1, 'collect_metrics_timeout': -1, 'buffer_size': -1, 'prioritized_replay': -1, 'learning_starts': -1, 'replay_batch_size': -1, 'replay_sequence_length': None, 'prioritized_replay_alpha': -1, 'prioritized_replay_beta': -1, 'prioritized_replay_eps': -1, 'min_time_s_per_reporting': -1, 'min_train_timesteps_per_reporting': -1, 'min_sample_timesteps_per_reporting': -1, 'input_evaluation': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'multiagent': {'policies': {'policy1': <ray.rllib.policy.policy.PolicySpec object at 0x7fc077c1c790>, 'policy2': <ray.rllib.policy.policy.PolicySpec object at 0x7fc077c1c370>}, 'policy_map_capacity': 100, 'policy_map_cache': None, 'policy_mapping_fn': <function <lambda> at 0x7fc077ba9670>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'tf', 'num_cpus_for_driver': 1}<br>Result logdir: /Users/sven/Dropbox/Projects/ray-summit-2022-training/ray-rllib/results/PPO<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_MultiAgentArena_1dedd_00000</td><td>TERMINATED</td><td>127.0.0.1:48430</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">              3000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         299.73 </td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  20.142</td><td style=\"text-align: right;\">                37.8</td><td style=\"text-align: right;\">                 1.2</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "<tr><td>PPO_MultiAgentArena_1dedd_00001</td><td>TERMINATED</td><td>127.0.0.1:48438</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              3000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         301.605</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\">  12.525</td><td style=\"text-align: right;\">                39.3</td><td style=\"text-align: right;\">               -13.2</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "<tr><td>PPO_MultiAgentArena_1dedd_00002</td><td>TERMINATED</td><td>127.0.0.1:48452</td><td style=\"text-align: right;\">5e-05 </td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         380.07 </td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">  19.011</td><td style=\"text-align: right;\">                36.6</td><td style=\"text-align: right;\">               -10.8</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "<tr><td>PPO_MultiAgentArena_1dedd_00003</td><td>TERMINATED</td><td>127.0.0.1:48457</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">              4000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         381.545</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\">  18.681</td><td style=\"text-align: right;\">                39.9</td><td style=\"text-align: right;\">               -20.1</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 12:16:03,082\tINFO plugin_schema_manager.py:51 -- Loading the default runtime env schemas: ['/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/runtime_env/../../runtime_env/schemas/working_dir_schema.json', '/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/runtime_env/../../runtime_env/schemas/pip_schema.json'].\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:12,997\tINFO algorithm.py:1774 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:12,997\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:12,997\tINFO algorithm.py:332 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48432)\u001b[0m 2022-07-27 12:16:22,764\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48432)\u001b[0m 2022-07-27 12:16:22,764\tWARNING env.py:223 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48432)\u001b[0m 2022-07-27 12:16:22,917\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48432)\u001b[0m 2022-07-27 12:16:23,706\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:24,282\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:24,386\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:25,060\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:25,626\tINFO trainable.py:160 -- Trainable.setup took 12.630 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:25,627\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48432)\u001b[0m 2022-07-27 12:16:26,019\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:29,680\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:29,689\tWARNING deprecation.py:47 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48430)\u001b[0m 2022-07-27 12:16:29,689\tWARNING deprecation.py:47 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:36,417\tINFO algorithm.py:1774 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:36,417\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:36,417\tINFO algorithm.py:332 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48450)\u001b[0m 2022-07-27 12:16:46,166\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48450)\u001b[0m 2022-07-27 12:16:46,167\tWARNING env.py:223 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48450)\u001b[0m 2022-07-27 12:16:46,275\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48450)\u001b[0m 2022-07-27 12:16:46,953\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:47,507\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:47,610\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:48,291\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:48,856\tINFO trainable.py:160 -- Trainable.setup took 12.440 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:48,856\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48450)\u001b[0m 2022-07-27 12:16:49,260\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:53,007\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:53,016\tWARNING deprecation.py:47 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48438)\u001b[0m 2022-07-27 12:16:53,016\tWARNING deprecation.py:47 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:16:59,657\tINFO algorithm.py:1774 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:16:59,657\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:16:59,658\tINFO algorithm.py:332 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:17:09,440\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:17:09,440\tWARNING env.py:223 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:17:09,553\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:17:10,233\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:10,785\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:10,890\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:11,543\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:12,139\tINFO trainable.py:160 -- Trainable.setup took 12.483 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:12,140\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:17:12,520\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:17,571\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:17,582\tWARNING deprecation.py:47 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48452)\u001b[0m 2022-07-27 12:17:17,582\tWARNING deprecation.py:47 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:23,236\tINFO algorithm.py:1774 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:23,236\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:23,236\tINFO algorithm.py:332 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:17:33,188\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:17:33,188\tWARNING env.py:223 -- Your MultiAgentEnv <MultiAgentArena instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:17:33,295\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:17:33,990\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:34,559\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:34,669\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:35,350\tWARNING deprecation.py:47 -- DeprecationWarning: `on_trainer_init(trainer, **kwargs)` has been deprecated. Use `on_algorithm_init(algorithm, **kwargs)` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 6000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 6000\n",
      "    num_env_steps_sampled: 3000\n",
      "    num_env_steps_trained: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-16-56\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 4.500000000000011\n",
      "  episode_reward_mean: -11.609999999999996\n",
      "  episode_reward_min: -39.00000000000004\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 30\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3687132596969604\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01779901050031185\n",
      "          model: {}\n",
      "          policy_loss: -0.046466317027807236\n",
      "          total_loss: 6.718165397644043\n",
      "          vf_explained_var: 0.0067339022643864155\n",
      "          vf_loss: 6.761071681976318\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.371106505393982\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015384905971586704\n",
      "          model: {}\n",
      "          policy_loss: -0.04392954707145691\n",
      "          total_loss: 3.1795806884765625\n",
      "          vf_explained_var: 0.27979862689971924\n",
      "          vf_loss: 3.220433235168457\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 6000\n",
      "    num_env_steps_sampled: 3000\n",
      "    num_env_steps_trained: 3000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 6000\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 3000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 23.916666666666668\n",
      "    ram_util_percent: 59.60833333333332\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 11.5\n",
      "    policy2: -4.499999999999986\n",
      "  policy_reward_mean:\n",
      "    policy1: -2.2333333333333334\n",
      "    policy2: -9.37666666666665\n",
      "  policy_reward_min:\n",
      "    policy1: -29.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09640659025930155\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04191002977645145\n",
      "    mean_inference_ms: 1.012483782388496\n",
      "    mean_raw_obs_processing_ms: 0.19245972358477353\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 4.500000000000011\n",
      "    episode_reward_mean: -11.609999999999996\n",
      "    episode_reward_min: -39.00000000000004\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.500000000000011\n",
      "      - -9.899999999999979\n",
      "      - -5.999999999999999\n",
      "      - -22.500000000000007\n",
      "      - 1.5000000000000004\n",
      "      - 1.7999999999999958\n",
      "      - -5.399999999999984\n",
      "      - -12.000000000000005\n",
      "      - -11.999999999999982\n",
      "      - -31.500000000000064\n",
      "      - -19.800000000000022\n",
      "      - -14.999999999999973\n",
      "      - -9.00000000000001\n",
      "      - -39.00000000000004\n",
      "      - -19.500000000000032\n",
      "      - -13.499999999999984\n",
      "      - -10.499999999999979\n",
      "      - -16.499999999999993\n",
      "      - -7.799999999999988\n",
      "      - -1.499999999999989\n",
      "      - 6.078471059822732e-15\n",
      "      - -22.500000000000004\n",
      "      - -10.499999999999979\n",
      "      - -19.500000000000014\n",
      "      - 3.3000000000000096\n",
      "      - -13.499999999999993\n",
      "      - -13.499999999999979\n",
      "      - -7.499999999999993\n",
      "      - -7.499999999999979\n",
      "      - -13.499999999999968\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - -12.5\n",
      "      - 11.5\n",
      "      - 8.5\n",
      "      - 3.5\n",
      "      - -2.0\n",
      "      - -2.0\n",
      "      - -21.5\n",
      "      - -12.0\n",
      "      - -5.0\n",
      "      - 1.0\n",
      "      - -29.0\n",
      "      - -9.5\n",
      "      - -3.5\n",
      "      - -0.5\n",
      "      - -6.5\n",
      "      - 0.0\n",
      "      - 8.5\n",
      "      - 10.0\n",
      "      - -12.5\n",
      "      - -0.5\n",
      "      - -9.5\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - -3.5\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -3.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 11.5\n",
      "      policy2: -4.499999999999986\n",
      "    policy_reward_mean:\n",
      "      policy1: -2.2333333333333334\n",
      "      policy2: -9.37666666666665\n",
      "    policy_reward_min:\n",
      "      policy1: -29.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09640659025930155\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04191002977645145\n",
      "      mean_inference_ms: 1.012483782388496\n",
      "      mean_raw_obs_processing_ms: 0.19245972358477353\n",
      "  time_since_restore: 8.085082054138184\n",
      "  time_this_iter_s: 8.085082054138184\n",
      "  time_total_s: 8.085082054138184\n",
      "  timers:\n",
      "    learn_throughput: 762.886\n",
      "    learn_time_ms: 3932.435\n",
      "    synch_weights_time_ms: 2.62\n",
      "    training_iteration_time_ms: 8080.234\n",
      "  timestamp: 1658917016\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 1\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:35,931\tINFO trainable.py:160 -- Trainable.setup took 12.696 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:35,931\tWARNING util.py:65 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 6000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 6000\n",
      "    num_env_steps_sampled: 3000\n",
      "    num_env_steps_trained: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-16-33\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.900000000000032\n",
      "  episode_reward_mean: -10.750000000000004\n",
      "  episode_reward_min: -36.00000000000005\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 30\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3750505447387695\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011448928155004978\n",
      "          model: {}\n",
      "          policy_loss: -0.029521968215703964\n",
      "          total_loss: 7.369980335235596\n",
      "          vf_explained_var: -0.0010922867804765701\n",
      "          vf_loss: 7.397212505340576\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3814774751663208\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.004818372894078493\n",
      "          model: {}\n",
      "          policy_loss: -0.022169917821884155\n",
      "          total_loss: 3.8489835262298584\n",
      "          vf_explained_var: 0.1670660376548767\n",
      "          vf_loss: 3.870189666748047\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 6000\n",
      "    num_env_steps_sampled: 3000\n",
      "    num_env_steps_trained: 3000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 6000\n",
      "  num_agent_steps_trained: 6000\n",
      "  num_env_steps_sampled: 3000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 3000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 27.924999999999997\n",
      "    ram_util_percent: 59.83333333333332\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 18.5\n",
      "    policy2: -2.2999999999999976\n",
      "  policy_reward_mean:\n",
      "    policy1: -2.5833333333333335\n",
      "    policy2: -8.16666666666665\n",
      "  policy_reward_min:\n",
      "    policy1: -26.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09388686894814358\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04151319512046605\n",
      "    mean_inference_ms: 0.9945656847294387\n",
      "    mean_raw_obs_processing_ms: 0.1851847393438841\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 12.900000000000032\n",
      "    episode_reward_mean: -10.750000000000004\n",
      "    episode_reward_min: -36.00000000000005\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -28.50000000000008\n",
      "      - 1.799999999999999\n",
      "      - -21.29999999999999\n",
      "      - -13.199999999999987\n",
      "      - -4.499999999999986\n",
      "      - -27.00000000000003\n",
      "      - 1.5000000000000138\n",
      "      - 3.6000000000000116\n",
      "      - -24.000000000000007\n",
      "      - -36.00000000000005\n",
      "      - -14.399999999999979\n",
      "      - -1.7999999999999932\n",
      "      - -10.499999999999984\n",
      "      - -3.8999999999999946\n",
      "      - -1.4999999999999925\n",
      "      - -33.00000000000003\n",
      "      - 4.500000000000005\n",
      "      - 0.6000000000000033\n",
      "      - -10.799999999999997\n",
      "      - -18.00000000000005\n",
      "      - -0.5999999999999744\n",
      "      - 12.900000000000032\n",
      "      - -18.000000000000036\n",
      "      - -24.300000000000026\n",
      "      - -8.399999999999977\n",
      "      - -10.79999999999997\n",
      "      - -27.000000000000075\n",
      "      - -10.499999999999988\n",
      "      - -7.499999999999977\n",
      "      - 8.100000000000014\n",
      "      policy_policy1_reward:\n",
      "      - -18.5\n",
      "      - 8.5\n",
      "      - -13.5\n",
      "      - -6.5\n",
      "      - 5.5\n",
      "      - -17.0\n",
      "      - 11.5\n",
      "      - 12.5\n",
      "      - -14.0\n",
      "      - -26.0\n",
      "      - -11.0\n",
      "      - 0.5\n",
      "      - -0.5\n",
      "      - 5.0\n",
      "      - 3.0\n",
      "      - -23.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - -3.0\n",
      "      - -8.0\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - -8.0\n",
      "      - -16.5\n",
      "      - -5.0\n",
      "      - -3.0\n",
      "      - -17.0\n",
      "      - -0.5\n",
      "      - 2.5\n",
      "      - 17.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -2.2999999999999976\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 18.5\n",
      "      policy2: -2.2999999999999976\n",
      "    policy_reward_mean:\n",
      "      policy1: -2.5833333333333335\n",
      "      policy2: -8.16666666666665\n",
      "    policy_reward_min:\n",
      "      policy1: -26.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09388686894814358\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04151319512046605\n",
      "      mean_inference_ms: 0.9945656847294387\n",
      "      mean_raw_obs_processing_ms: 0.1851847393438841\n",
      "  time_since_restore: 7.834223985671997\n",
      "  time_this_iter_s: 7.834223985671997\n",
      "  time_total_s: 7.834223985671997\n",
      "  timers:\n",
      "    learn_throughput: 795.213\n",
      "    learn_time_ms: 3772.572\n",
      "    synch_weights_time_ms: 2.885\n",
      "    training_iteration_time_ms: 7832.277\n",
      "  timestamp: 1658916993\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 1\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 8000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_env_steps_sampled: 4000\n",
      "    num_env_steps_trained: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-22\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.099999999999916\n",
      "  episode_reward_mean: -10.62\n",
      "  episode_reward_min: -43.500000000000064\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 40\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3719314336776733\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01464066281914711\n",
      "          model: {}\n",
      "          policy_loss: -0.02798277512192726\n",
      "          total_loss: 7.317825794219971\n",
      "          vf_explained_var: 0.014600998722016811\n",
      "          vf_loss: 7.3428802490234375\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3805248737335205\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0057960436679422855\n",
      "          model: {}\n",
      "          policy_loss: -0.019295597448945045\n",
      "          total_loss: 3.4183473587036133\n",
      "          vf_explained_var: 0.23472853004932404\n",
      "          vf_loss: 3.436483860015869\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_env_steps_sampled: 4000\n",
      "    num_env_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 8000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 4000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 18.5\n",
      "    ram_util_percent: 59.733333333333334\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 29.0\n",
      "    policy2: -4.5000000000000036\n",
      "  policy_reward_mean:\n",
      "    policy1: -1.6375\n",
      "    policy2: -8.982499999999982\n",
      "  policy_reward_min:\n",
      "    policy1: -33.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09637801416573957\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04185125012005666\n",
      "    mean_inference_ms: 1.0020299066278047\n",
      "    mean_raw_obs_processing_ms: 0.19104896083947154\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 20.099999999999916\n",
      "    episode_reward_mean: -10.62\n",
      "    episode_reward_min: -43.500000000000064\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -43.500000000000064\n",
      "      - 9.600000000000017\n",
      "      - -28.50000000000003\n",
      "      - -13.499999999999975\n",
      "      - 20.099999999999916\n",
      "      - -7.4999999999999805\n",
      "      - -7.499999999999998\n",
      "      - -10.499999999999984\n",
      "      - -14.399999999999986\n",
      "      - -30.000000000000085\n",
      "      - -13.499999999999984\n",
      "      - -15.599999999999985\n",
      "      - -17.99999999999999\n",
      "      - 0.6000000000000189\n",
      "      - -1.4999999999999791\n",
      "      - 2.017830347256222e-14\n",
      "      - -33.000000000000064\n",
      "      - -1.199999999999974\n",
      "      - -17.39999999999999\n",
      "      - 8.400000000000013\n",
      "      - -12.299999999999976\n",
      "      - -20.700000000000024\n",
      "      - -1.1379786002407855e-15\n",
      "      - -10.499999999999988\n",
      "      - -11.399999999999977\n",
      "      - -16.49999999999998\n",
      "      - -11.999999999999991\n",
      "      - -13.499999999999982\n",
      "      - -7.799999999999979\n",
      "      - -8.999999999999975\n",
      "      - 3.6000000000000116\n",
      "      - -15.900000000000025\n",
      "      - -4.499999999999988\n",
      "      - -9.899999999999991\n",
      "      - -18.000000000000014\n",
      "      - -22.500000000000004\n",
      "      - -5.999999999999989\n",
      "      - 3.900000000000032\n",
      "      - -2.3999999999999946\n",
      "      - -22.500000000000007\n",
      "      policy_policy1_reward:\n",
      "      - -33.5\n",
      "      - 18.5\n",
      "      - -18.5\n",
      "      - -3.5\n",
      "      - 29.0\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -0.5\n",
      "      - -5.5\n",
      "      - -20.0\n",
      "      - -3.5\n",
      "      - -10.0\n",
      "      - -8.0\n",
      "      - 9.5\n",
      "      - 8.5\n",
      "      - 10.0\n",
      "      - -23.0\n",
      "      - 5.5\n",
      "      - -8.5\n",
      "      - 14.0\n",
      "      - -4.5\n",
      "      - -14.0\n",
      "      - 10.0\n",
      "      - -0.5\n",
      "      - -2.5\n",
      "      - -6.5\n",
      "      - -2.0\n",
      "      - -9.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 12.5\n",
      "      - -7.0\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -8.0\n",
      "      - -12.5\n",
      "      - 4.0\n",
      "      - 9.5\n",
      "      - 6.5\n",
      "      - -12.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.59999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999985\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.0\n",
      "      policy2: -4.5000000000000036\n",
      "    policy_reward_mean:\n",
      "      policy1: -1.6375\n",
      "      policy2: -8.982499999999982\n",
      "    policy_reward_min:\n",
      "      policy1: -33.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09637801416573957\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04185125012005666\n",
      "      mean_inference_ms: 1.0020299066278047\n",
      "      mean_raw_obs_processing_ms: 0.19104896083947154\n",
      "  time_since_restore: 10.479931116104126\n",
      "  time_this_iter_s: 10.479931116104126\n",
      "  time_total_s: 10.479931116104126\n",
      "  timers:\n",
      "    learn_throughput: 792.844\n",
      "    learn_time_ms: 5045.127\n",
      "    synch_weights_time_ms: 2.299\n",
      "    training_iteration_time_ms: 10475.014\n",
      "  timestamp: 1658917042\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:17:36,339\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:42,953\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:42,968\tWARNING deprecation.py:47 -- DeprecationWarning: `_get_slice_indices` has been deprecated. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(PPO pid=48457)\u001b[0m 2022-07-27 12:17:42,968\tWARNING deprecation.py:47 -- DeprecationWarning: `slice` has been deprecated. Use `SampleBatch[start:stop]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_env_steps_sampled: 6000\n",
      "    num_env_steps_trained: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.000000000000007\n",
      "  episode_reward_mean: -6.989999999999994\n",
      "  episode_reward_min: -36.00000000000005\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 60\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.353236198425293\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009822160936892033\n",
      "          model: {}\n",
      "          policy_loss: -0.033334940671920776\n",
      "          total_loss: 6.9307169914245605\n",
      "          vf_explained_var: -0.0036104300525039434\n",
      "          vf_loss: 6.962087631225586\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.349312663078308\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010148129425942898\n",
      "          model: {}\n",
      "          policy_loss: -0.036046817898750305\n",
      "          total_loss: 2.1591742038726807\n",
      "          vf_explained_var: 0.2998386025428772\n",
      "          vf_loss: 2.194206476211548\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_env_steps_sampled: 6000\n",
      "    num_env_steps_trained: 6000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 12000\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 6000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 21.309615384615384\n",
      "    ram_util_percent: 59.74038461538461\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 28.0\n",
      "    policy2: -2.2999999999999976\n",
      "  policy_reward_mean:\n",
      "    policy1: 1.3416666666666666\n",
      "    policy2: -8.331666666666651\n",
      "  policy_reward_min:\n",
      "    policy1: -26.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09694029918831047\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.043232544663938374\n",
      "    mean_inference_ms: 1.025018493549727\n",
      "    mean_raw_obs_processing_ms: 0.19172418077608697\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 18.000000000000007\n",
      "    episode_reward_mean: -6.989999999999994\n",
      "    episode_reward_min: -36.00000000000005\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -28.50000000000008\n",
      "      - 1.799999999999999\n",
      "      - -21.29999999999999\n",
      "      - -13.199999999999987\n",
      "      - -4.499999999999986\n",
      "      - -27.00000000000003\n",
      "      - 1.5000000000000138\n",
      "      - 3.6000000000000116\n",
      "      - -24.000000000000007\n",
      "      - -36.00000000000005\n",
      "      - -14.399999999999979\n",
      "      - -1.7999999999999932\n",
      "      - -10.499999999999984\n",
      "      - -3.8999999999999946\n",
      "      - -1.4999999999999925\n",
      "      - -33.00000000000003\n",
      "      - 4.500000000000005\n",
      "      - 0.6000000000000033\n",
      "      - -10.799999999999997\n",
      "      - -18.00000000000005\n",
      "      - -0.5999999999999744\n",
      "      - 12.900000000000032\n",
      "      - -18.000000000000036\n",
      "      - -24.300000000000026\n",
      "      - -8.399999999999977\n",
      "      - -10.79999999999997\n",
      "      - -27.000000000000075\n",
      "      - -10.499999999999988\n",
      "      - -7.499999999999977\n",
      "      - 8.100000000000014\n",
      "      - -16.49999999999998\n",
      "      - -10.499999999999973\n",
      "      - -25.5\n",
      "      - 1.2000000000000006\n",
      "      - 3.600000000000031\n",
      "      - 3.000000000000025\n",
      "      - 3.0000000000000187\n",
      "      - -4.499999999999986\n",
      "      - -5.399999999999993\n",
      "      - 11.700000000000019\n",
      "      - 4.200000000000014\n",
      "      - -13.499999999999988\n",
      "      - 11.100000000000021\n",
      "      - 6.000000000000027\n",
      "      - 6.000000000000016\n",
      "      - -11.999999999999984\n",
      "      - -10.499999999999988\n",
      "      - -6.299999999999981\n",
      "      - -11.399999999999979\n",
      "      - -5.999999999999982\n",
      "      - -8.999999999999986\n",
      "      - 4.500000000000019\n",
      "      - -14.09999999999999\n",
      "      - 10.200000000000026\n",
      "      - 0.6000000000000059\n",
      "      - -14.399999999999983\n",
      "      - 18.000000000000007\n",
      "      - -8.99999999999998\n",
      "      - -1.4999999999999833\n",
      "      - -9.899999999999975\n",
      "      policy_policy1_reward:\n",
      "      - -18.5\n",
      "      - 8.5\n",
      "      - -13.5\n",
      "      - -6.5\n",
      "      - 5.5\n",
      "      - -17.0\n",
      "      - 11.5\n",
      "      - 12.5\n",
      "      - -14.0\n",
      "      - -26.0\n",
      "      - -11.0\n",
      "      - 0.5\n",
      "      - -0.5\n",
      "      - 5.0\n",
      "      - 3.0\n",
      "      - -23.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - -3.0\n",
      "      - -8.0\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - -8.0\n",
      "      - -16.5\n",
      "      - -5.0\n",
      "      - -3.0\n",
      "      - -17.0\n",
      "      - -0.5\n",
      "      - 2.5\n",
      "      - 17.0\n",
      "      - -6.5\n",
      "      - -0.5\n",
      "      - -15.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - 19.5\n",
      "      - 12.0\n",
      "      - -3.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - -0.5\n",
      "      - -4.0\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - 1.0\n",
      "      - 14.5\n",
      "      - -8.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - -5.5\n",
      "      - 28.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      - -1.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -2.2999999999999976\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -3.3999999999999915\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999986\n",
      "      - -8.899999999999983\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 28.0\n",
      "      policy2: -2.2999999999999976\n",
      "    policy_reward_mean:\n",
      "      policy1: 1.3416666666666666\n",
      "      policy2: -8.331666666666651\n",
      "    policy_reward_min:\n",
      "      policy1: -26.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09694029918831047\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.043232544663938374\n",
      "      mean_inference_ms: 1.025018493549727\n",
      "      mean_raw_obs_processing_ms: 0.19172418077608697\n",
      "  time_since_restore: 18.137134790420532\n",
      "  time_this_iter_s: 10.302910804748535\n",
      "  time_total_s: 18.137134790420532\n",
      "  timers:\n",
      "    learn_throughput: 627.681\n",
      "    learn_time_ms: 4779.496\n",
      "    synch_weights_time_ms: 3.897\n",
      "    training_iteration_time_ms: 9064.151\n",
      "  timestamp: 1658917066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 2\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 12000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_env_steps_sampled: 6000\n",
      "    num_env_steps_trained: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 7.500000000000021\n",
      "  episode_reward_mean: -8.389999999999995\n",
      "  episode_reward_min: -39.00000000000004\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 60\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3230104446411133\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021032778546214104\n",
      "          model: {}\n",
      "          policy_loss: -0.057578541338443756\n",
      "          total_loss: 6.592222690582275\n",
      "          vf_explained_var: 0.04051642864942551\n",
      "          vf_loss: 6.645594596862793\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3288041353225708\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018000604584813118\n",
      "          model: {}\n",
      "          policy_loss: -0.05305508151650429\n",
      "          total_loss: 1.7492181062698364\n",
      "          vf_explained_var: 0.4424205422401428\n",
      "          vf_loss: 1.798673152923584\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 12000\n",
      "    num_env_steps_sampled: 6000\n",
      "    num_env_steps_trained: 6000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 12000\n",
      "  num_agent_steps_trained: 12000\n",
      "  num_env_steps_sampled: 6000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 6000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 24.466197183098597\n",
      "    ram_util_percent: 59.794366197183095\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 17.5\n",
      "    policy2: -2.3000000000000043\n",
      "  policy_reward_mean:\n",
      "    policy1: 0.5833333333333334\n",
      "    policy2: -8.973333333333317\n",
      "  policy_reward_min:\n",
      "    policy1: -29.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.09907622197994662\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04338153811051093\n",
      "    mean_inference_ms: 1.0400337755594982\n",
      "    mean_raw_obs_processing_ms: 0.19788898532164384\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 7.500000000000021\n",
      "    episode_reward_mean: -8.389999999999995\n",
      "    episode_reward_min: -39.00000000000004\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.500000000000011\n",
      "      - -9.899999999999979\n",
      "      - -5.999999999999999\n",
      "      - -22.500000000000007\n",
      "      - 1.5000000000000004\n",
      "      - 1.7999999999999958\n",
      "      - -5.399999999999984\n",
      "      - -12.000000000000005\n",
      "      - -11.999999999999982\n",
      "      - -31.500000000000064\n",
      "      - -19.800000000000022\n",
      "      - -14.999999999999973\n",
      "      - -9.00000000000001\n",
      "      - -39.00000000000004\n",
      "      - -19.500000000000032\n",
      "      - -13.499999999999984\n",
      "      - -10.499999999999979\n",
      "      - -16.499999999999993\n",
      "      - -7.799999999999988\n",
      "      - -1.499999999999989\n",
      "      - 6.078471059822732e-15\n",
      "      - -22.500000000000004\n",
      "      - -10.499999999999979\n",
      "      - -19.500000000000014\n",
      "      - 3.3000000000000096\n",
      "      - -13.499999999999993\n",
      "      - -13.499999999999979\n",
      "      - -7.499999999999993\n",
      "      - -7.499999999999979\n",
      "      - -13.499999999999968\n",
      "      - 4.500000000000007\n",
      "      - -2.9999999999999973\n",
      "      - -11.999999999999979\n",
      "      - 7.500000000000021\n",
      "      - -16.19999999999999\n",
      "      - -6.89999999999999\n",
      "      - -2.6999999999999966\n",
      "      - -11.99999999999998\n",
      "      - 4.200000000000024\n",
      "      - -7.199999999999974\n",
      "      - 2.9999999999999982\n",
      "      - -27.000000000000014\n",
      "      - -1.5000000000000173\n",
      "      - -2.399999999999985\n",
      "      - -2.9999999999999933\n",
      "      - -5.399999999999981\n",
      "      - -8.999999999999977\n",
      "      - 1.500000000000019\n",
      "      - 3.0000000000000115\n",
      "      - -21.90000000000002\n",
      "      - -25.500000000000057\n",
      "      - 6.000000000000014\n",
      "      - -4.499999999999992\n",
      "      - -5.399999999999997\n",
      "      - -19.500000000000004\n",
      "      - 1.0297318553398327e-14\n",
      "      - 1.2628786905111156e-14\n",
      "      - -5.999999999999972\n",
      "      - 4.8000000000000185\n",
      "      - 1.5000000000000195\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - -12.5\n",
      "      - 11.5\n",
      "      - 8.5\n",
      "      - 3.5\n",
      "      - -2.0\n",
      "      - -2.0\n",
      "      - -21.5\n",
      "      - -12.0\n",
      "      - -5.0\n",
      "      - 1.0\n",
      "      - -29.0\n",
      "      - -9.5\n",
      "      - -3.5\n",
      "      - -0.5\n",
      "      - -6.5\n",
      "      - 0.0\n",
      "      - 8.5\n",
      "      - 10.0\n",
      "      - -12.5\n",
      "      - -0.5\n",
      "      - -9.5\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - -3.5\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -3.5\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - -2.0\n",
      "      - 17.5\n",
      "      - -9.5\n",
      "      - 2.0\n",
      "      - 4.0\n",
      "      - -7.5\n",
      "      - 6.5\n",
      "      - -0.5\n",
      "      - 13.0\n",
      "      - -17.0\n",
      "      - 3.0\n",
      "      - 6.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - -13.0\n",
      "      - -15.5\n",
      "      - 16.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - -15.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 17.5\n",
      "      policy2: -2.3000000000000043\n",
      "    policy_reward_mean:\n",
      "      policy1: 0.5833333333333334\n",
      "      policy2: -8.973333333333317\n",
      "    policy_reward_min:\n",
      "      policy1: -29.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.09907622197994662\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04338153811051093\n",
      "      mean_inference_ms: 1.0400337755594982\n",
      "      mean_raw_obs_processing_ms: 0.19788898532164384\n",
      "  time_since_restore: 18.435698986053467\n",
      "  time_this_iter_s: 10.350616931915283\n",
      "  time_total_s: 18.435698986053467\n",
      "  timers:\n",
      "    learn_throughput: 616.381\n",
      "    learn_time_ms: 4867.118\n",
      "    synch_weights_time_ms: 3.541\n",
      "    training_iteration_time_ms: 9213.826\n",
      "  timestamp: 1658917066\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 2\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 16000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_env_steps_sampled: 8000\n",
      "    num_env_steps_trained: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.099999999999916\n",
      "  episode_reward_mean: -5.493749999999994\n",
      "  episode_reward_min: -43.500000000000064\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 80\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3541768789291382\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.008718699216842651\n",
      "          model: {}\n",
      "          policy_loss: -0.02651202492415905\n",
      "          total_loss: 7.034997463226318\n",
      "          vf_explained_var: 0.01099539827555418\n",
      "          vf_loss: 7.059765815734863\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3546005487442017\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.009792426601052284\n",
      "          model: {}\n",
      "          policy_loss: -0.030662957578897476\n",
      "          total_loss: 2.091494083404541\n",
      "          vf_explained_var: 0.33757928013801575\n",
      "          vf_loss: 2.1201984882354736\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_env_steps_sampled: 8000\n",
      "    num_env_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 16000\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 8000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 29.753658536585363\n",
      "    ram_util_percent: 60.046341463414635\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 29.0\n",
      "    policy2: 1.0000000000000009\n",
      "  policy_reward_mean:\n",
      "    policy1: 3.26875\n",
      "    policy2: -8.762499999999983\n",
      "  policy_reward_min:\n",
      "    policy1: -33.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10403435018550503\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0453657643127557\n",
      "    mean_inference_ms: 1.086998265677796\n",
      "    mean_raw_obs_processing_ms: 0.2059007653858011\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 20.099999999999916\n",
      "    episode_reward_mean: -5.493749999999994\n",
      "    episode_reward_min: -43.500000000000064\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -43.500000000000064\n",
      "      - 9.600000000000017\n",
      "      - -28.50000000000003\n",
      "      - -13.499999999999975\n",
      "      - 20.099999999999916\n",
      "      - -7.4999999999999805\n",
      "      - -7.499999999999998\n",
      "      - -10.499999999999984\n",
      "      - -14.399999999999986\n",
      "      - -30.000000000000085\n",
      "      - -13.499999999999984\n",
      "      - -15.599999999999985\n",
      "      - -17.99999999999999\n",
      "      - 0.6000000000000189\n",
      "      - -1.4999999999999791\n",
      "      - 2.017830347256222e-14\n",
      "      - -33.000000000000064\n",
      "      - -1.199999999999974\n",
      "      - -17.39999999999999\n",
      "      - 8.400000000000013\n",
      "      - -12.299999999999976\n",
      "      - -20.700000000000024\n",
      "      - -1.1379786002407855e-15\n",
      "      - -10.499999999999988\n",
      "      - -11.399999999999977\n",
      "      - -16.49999999999998\n",
      "      - -11.999999999999991\n",
      "      - -13.499999999999982\n",
      "      - -7.799999999999979\n",
      "      - -8.999999999999975\n",
      "      - 3.6000000000000116\n",
      "      - -15.900000000000025\n",
      "      - -4.499999999999988\n",
      "      - -9.899999999999991\n",
      "      - -18.000000000000014\n",
      "      - -22.500000000000004\n",
      "      - -5.999999999999989\n",
      "      - 3.900000000000032\n",
      "      - -2.3999999999999946\n",
      "      - -22.500000000000007\n",
      "      - 10.500000000000014\n",
      "      - 6.000000000000002\n",
      "      - -7.499999999999995\n",
      "      - 11.100000000000007\n",
      "      - -2.9999999999999876\n",
      "      - -4.499999999999987\n",
      "      - -4.499999999999977\n",
      "      - -13.499999999999988\n",
      "      - 1.5000000000000098\n",
      "      - 9.000000000000021\n",
      "      - -2.999999999999983\n",
      "      - -7.499999999999988\n",
      "      - -2.9999999999999796\n",
      "      - -6.0000000000000036\n",
      "      - 8.100000000000023\n",
      "      - 6.000000000000027\n",
      "      - -4.19999999999999\n",
      "      - -1.799999999999994\n",
      "      - -2.9999999999999782\n",
      "      - -14.999999999999984\n",
      "      - -6.899999999999997\n",
      "      - -12.899999999999983\n",
      "      - 2.9999999999999916\n",
      "      - 1.5000000000000244\n",
      "      - 14.999999999999954\n",
      "      - 7.2000000000000295\n",
      "      - -0.2999999999999797\n",
      "      - 8.999999999999979\n",
      "      - -7.499999999999989\n",
      "      - 7.5000000000000195\n",
      "      - 6.600000000000026\n",
      "      - 3.3000000000000167\n",
      "      - 11.99999999999997\n",
      "      - 16.5\n",
      "      - -4.499999999999981\n",
      "      - -8.999999999999982\n",
      "      - -15.299999999999985\n",
      "      - -4.199999999999983\n",
      "      - -0.8999999999999844\n",
      "      - -10.499999999999975\n",
      "      policy_policy1_reward:\n",
      "      - -33.5\n",
      "      - 18.5\n",
      "      - -18.5\n",
      "      - -3.5\n",
      "      - 29.0\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -0.5\n",
      "      - -5.5\n",
      "      - -20.0\n",
      "      - -3.5\n",
      "      - -10.0\n",
      "      - -8.0\n",
      "      - 9.5\n",
      "      - 8.5\n",
      "      - 10.0\n",
      "      - -23.0\n",
      "      - 5.5\n",
      "      - -8.5\n",
      "      - 14.0\n",
      "      - -4.5\n",
      "      - -14.0\n",
      "      - 10.0\n",
      "      - -0.5\n",
      "      - -2.5\n",
      "      - -6.5\n",
      "      - -2.0\n",
      "      - -9.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 12.5\n",
      "      - -7.0\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -8.0\n",
      "      - -12.5\n",
      "      - 4.0\n",
      "      - 9.5\n",
      "      - 6.5\n",
      "      - -12.5\n",
      "      - 20.5\n",
      "      - 16.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 7.0\n",
      "      - 0.0\n",
      "      - 5.5\n",
      "      - -3.5\n",
      "      - 11.5\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - -7.0\n",
      "      - 17.0\n",
      "      - 16.0\n",
      "      - 2.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -10.5\n",
      "      - 2.0\n",
      "      - -4.0\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 25.0\n",
      "      - 15.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 17.5\n",
      "      - 15.5\n",
      "      - 10.0\n",
      "      - 16.5\n",
      "      - 26.5\n",
      "      - 5.5\n",
      "      - 1.0\n",
      "      - -13.0\n",
      "      - 2.5\n",
      "      - 8.0\n",
      "      - -0.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.59999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999985\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000009\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.0\n",
      "      policy2: 1.0000000000000009\n",
      "    policy_reward_mean:\n",
      "      policy1: 3.26875\n",
      "      policy2: -8.762499999999983\n",
      "    policy_reward_min:\n",
      "      policy1: -33.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10403435018550503\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0453657643127557\n",
      "      mean_inference_ms: 1.086998265677796\n",
      "      mean_raw_obs_processing_ms: 0.2059007653858011\n",
      "  time_since_restore: 24.98495101928711\n",
      "  time_this_iter_s: 14.505019903182983\n",
      "  time_total_s: 24.98495101928711\n",
      "  timers:\n",
      "    learn_throughput: 647.466\n",
      "    learn_time_ms: 6177.927\n",
      "    synch_weights_time_ms: 3.448\n",
      "    training_iteration_time_ms: 12486.712\n",
      "  timestamp: 1658917070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 8000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_env_steps_sampled: 4000\n",
      "    num_env_steps_trained: 4000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.499999999999925\n",
      "  episode_reward_mean: -8.444999999999997\n",
      "  episode_reward_min: -39.000000000000064\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 40\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3654625415802002\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.021295059472322464\n",
      "          model: {}\n",
      "          policy_loss: -0.041958484798669815\n",
      "          total_loss: 7.066775798797607\n",
      "          vf_explained_var: 0.0011152948718518019\n",
      "          vf_loss: 7.104475975036621\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3691790103912354\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017410513013601303\n",
      "          model: {}\n",
      "          policy_loss: -0.042352139949798584\n",
      "          total_loss: 2.7472169399261475\n",
      "          vf_explained_var: 0.28479400277137756\n",
      "          vf_loss: 2.7860872745513916\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 8000\n",
      "    num_env_steps_sampled: 4000\n",
      "    num_env_steps_trained: 4000\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 8000\n",
      "  num_agent_steps_trained: 8000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 4000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.849999999999994\n",
      "    ram_util_percent: 60.26818181818181\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: -0.09999999999999432\n",
      "  policy_reward_mean:\n",
      "    policy1: 0.4\n",
      "    policy2: -8.844999999999981\n",
      "  policy_reward_min:\n",
      "    policy1: -29.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1236350200856158\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05324635914461937\n",
      "    mean_inference_ms: 1.3065110501930792\n",
      "    mean_raw_obs_processing_ms: 0.24327329622748733\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 19.499999999999925\n",
      "    episode_reward_mean: -8.444999999999997\n",
      "    episode_reward_min: -39.000000000000064\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -5.999999999999993\n",
      "      - -20.39999999999999\n",
      "      - 0.6000000000000166\n",
      "      - 6.000000000000012\n",
      "      - -13.499999999999995\n",
      "      - -5.999999999999988\n",
      "      - -28.50000000000001\n",
      "      - -4.799999999999978\n",
      "      - 10.20000000000002\n",
      "      - -2.3999999999999986\n",
      "      - -9.599999999999989\n",
      "      - -2.9999999999999996\n",
      "      - -13.799999999999983\n",
      "      - 2.700000000000028\n",
      "      - 10.200000000000028\n",
      "      - -13.499999999999998\n",
      "      - -39.000000000000064\n",
      "      - -27.900000000000013\n",
      "      - -10.19999999999998\n",
      "      - -4.500000000000004\n",
      "      - -7.499999999999995\n",
      "      - -17.999999999999993\n",
      "      - -6.0\n",
      "      - -11.999999999999977\n",
      "      - -11.09999999999998\n",
      "      - 19.499999999999925\n",
      "      - -15.900000000000016\n",
      "      - -7.799999999999979\n",
      "      - -33.000000000000036\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000002\n",
      "      - -11.999999999999979\n",
      "      - 5.700000000000003\n",
      "      - -20.999999999999986\n",
      "      - -0.2999999999999775\n",
      "      - -0.2999999999999944\n",
      "      - -0.8999999999999826\n",
      "      - -17.39999999999999\n",
      "      - 13.499999999999934\n",
      "      - -29.400000000000034\n",
      "      policy_policy1_reward:\n",
      "      - 4.0\n",
      "      - -11.5\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - -3.5\n",
      "      - 4.0\n",
      "      - -18.5\n",
      "      - 3.0\n",
      "      - 18.0\n",
      "      - 6.5\n",
      "      - -4.0\n",
      "      - 7.0\n",
      "      - -6.0\n",
      "      - 10.5\n",
      "      - 18.0\n",
      "      - -3.5\n",
      "      - -29.0\n",
      "      - -19.0\n",
      "      - -3.5\n",
      "      - 5.5\n",
      "      - 2.5\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - -2.0\n",
      "      - -11.0\n",
      "      - 29.5\n",
      "      - -7.0\n",
      "      - 0.0\n",
      "      - -23.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - 13.5\n",
      "      - -11.0\n",
      "      - 7.5\n",
      "      - 7.5\n",
      "      - 8.0\n",
      "      - -8.5\n",
      "      - 23.5\n",
      "      - -20.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -5.599999999999991\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999432\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: -0.09999999999999432\n",
      "    policy_reward_mean:\n",
      "      policy1: 0.4\n",
      "      policy2: -8.844999999999981\n",
      "    policy_reward_min:\n",
      "      policy1: -29.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1236350200856158\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05324635914461937\n",
      "      mean_inference_ms: 1.3065110501930792\n",
      "      mean_raw_obs_processing_ms: 0.24327329622748733\n",
      "  time_since_restore: 14.97492790222168\n",
      "  time_this_iter_s: 14.97492790222168\n",
      "  time_total_s: 14.97492790222168\n",
      "  timers:\n",
      "    learn_throughput: 503.953\n",
      "    learn_time_ms: 7937.254\n",
      "    synch_weights_time_ms: 4.468\n",
      "    training_iteration_time_ms: 14972.495\n",
      "  timestamp: 1658917070\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 4000\n",
      "  training_iteration: 1\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 18000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 18000\n",
      "    num_env_steps_sampled: 9000\n",
      "    num_env_steps_trained: 9000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 18.000000000000007\n",
      "  episode_reward_mean: -4.60666666666666\n",
      "  episode_reward_min: -36.00000000000005\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 90\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3102447986602783\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01289469562470913\n",
      "          model: {}\n",
      "          policy_loss: -0.04054800048470497\n",
      "          total_loss: 6.278268814086914\n",
      "          vf_explained_var: 0.04890468344092369\n",
      "          vf_loss: 6.316237449645996\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3021631240844727\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012444743886590004\n",
      "          model: {}\n",
      "          policy_loss: -0.04228581488132477\n",
      "          total_loss: 2.3139498233795166\n",
      "          vf_explained_var: 0.2467099130153656\n",
      "          vf_loss: 2.3549914360046387\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 18000\n",
      "    num_env_steps_sampled: 9000\n",
      "    num_env_steps_trained: 9000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 18000\n",
      "  num_agent_steps_trained: 18000\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 9000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.31875\n",
      "    ram_util_percent: 60.5125\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 28.0\n",
      "    policy2: -1.2000000000000017\n",
      "  policy_reward_mean:\n",
      "    policy1: 3.6944444444444446\n",
      "    policy2: -8.301111111111096\n",
      "  policy_reward_min:\n",
      "    policy1: -26.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10286146111927148\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04597855450505894\n",
      "    mean_inference_ms: 1.085320154884013\n",
      "    mean_raw_obs_processing_ms: 0.20283368808617772\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 18.000000000000007\n",
      "    episode_reward_mean: -4.60666666666666\n",
      "    episode_reward_min: -36.00000000000005\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -28.50000000000008\n",
      "      - 1.799999999999999\n",
      "      - -21.29999999999999\n",
      "      - -13.199999999999987\n",
      "      - -4.499999999999986\n",
      "      - -27.00000000000003\n",
      "      - 1.5000000000000138\n",
      "      - 3.6000000000000116\n",
      "      - -24.000000000000007\n",
      "      - -36.00000000000005\n",
      "      - -14.399999999999979\n",
      "      - -1.7999999999999932\n",
      "      - -10.499999999999984\n",
      "      - -3.8999999999999946\n",
      "      - -1.4999999999999925\n",
      "      - -33.00000000000003\n",
      "      - 4.500000000000005\n",
      "      - 0.6000000000000033\n",
      "      - -10.799999999999997\n",
      "      - -18.00000000000005\n",
      "      - -0.5999999999999744\n",
      "      - 12.900000000000032\n",
      "      - -18.000000000000036\n",
      "      - -24.300000000000026\n",
      "      - -8.399999999999977\n",
      "      - -10.79999999999997\n",
      "      - -27.000000000000075\n",
      "      - -10.499999999999988\n",
      "      - -7.499999999999977\n",
      "      - 8.100000000000014\n",
      "      - -16.49999999999998\n",
      "      - -10.499999999999973\n",
      "      - -25.5\n",
      "      - 1.2000000000000006\n",
      "      - 3.600000000000031\n",
      "      - 3.000000000000025\n",
      "      - 3.0000000000000187\n",
      "      - -4.499999999999986\n",
      "      - -5.399999999999993\n",
      "      - 11.700000000000019\n",
      "      - 4.200000000000014\n",
      "      - -13.499999999999988\n",
      "      - 11.100000000000021\n",
      "      - 6.000000000000027\n",
      "      - 6.000000000000016\n",
      "      - -11.999999999999984\n",
      "      - -10.499999999999988\n",
      "      - -6.299999999999981\n",
      "      - -11.399999999999979\n",
      "      - -5.999999999999982\n",
      "      - -8.999999999999986\n",
      "      - 4.500000000000019\n",
      "      - -14.09999999999999\n",
      "      - 10.200000000000026\n",
      "      - 0.6000000000000059\n",
      "      - -14.399999999999983\n",
      "      - 18.000000000000007\n",
      "      - -8.99999999999998\n",
      "      - -1.4999999999999833\n",
      "      - -9.899999999999975\n",
      "      - 5.999999999999947\n",
      "      - 5.9674487573602164e-15\n",
      "      - -7.499999999999972\n",
      "      - 8.999999999999966\n",
      "      - -7.499999999999993\n",
      "      - -2.3999999999999884\n",
      "      - 7.499999999999973\n",
      "      - 3.3\n",
      "      - -12.899999999999997\n",
      "      - 2.700000000000022\n",
      "      - -5.699999999999989\n",
      "      - 7.500000000000028\n",
      "      - -2.9999999999999782\n",
      "      - 1.5000000000000187\n",
      "      - 2.100000000000014\n",
      "      - 7.50000000000003\n",
      "      - -13.499999999999986\n",
      "      - 10.499999999999947\n",
      "      - -5.999999999999998\n",
      "      - -1.4999999999999867\n",
      "      - 1.200000000000022\n",
      "      - 10.499999999999975\n",
      "      - 5.700000000000012\n",
      "      - 3.600000000000024\n",
      "      - -2.999999999999985\n",
      "      - 7.800000000000011\n",
      "      - 13.500000000000016\n",
      "      - -16.49999999999998\n",
      "      - -11.69999999999998\n",
      "      - -3.9000000000000017\n",
      "      policy_policy1_reward:\n",
      "      - -18.5\n",
      "      - 8.5\n",
      "      - -13.5\n",
      "      - -6.5\n",
      "      - 5.5\n",
      "      - -17.0\n",
      "      - 11.5\n",
      "      - 12.5\n",
      "      - -14.0\n",
      "      - -26.0\n",
      "      - -11.0\n",
      "      - 0.5\n",
      "      - -0.5\n",
      "      - 5.0\n",
      "      - 3.0\n",
      "      - -23.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - -3.0\n",
      "      - -8.0\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - -8.0\n",
      "      - -16.5\n",
      "      - -5.0\n",
      "      - -3.0\n",
      "      - -17.0\n",
      "      - -0.5\n",
      "      - 2.5\n",
      "      - 17.0\n",
      "      - -6.5\n",
      "      - -0.5\n",
      "      - -15.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - 19.5\n",
      "      - 12.0\n",
      "      - -3.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - -0.5\n",
      "      - -4.0\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - 1.0\n",
      "      - 14.5\n",
      "      - -8.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - -5.5\n",
      "      - 28.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      - -1.0\n",
      "      - 10.5\n",
      "      - 10.0\n",
      "      - 2.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 4.5\n",
      "      - -4.0\n",
      "      - 10.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 7.0\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      - -9.0\n",
      "      - 20.5\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - -6.5\n",
      "      - -5.0\n",
      "      - -0.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -2.2999999999999976\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -3.3999999999999915\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999986\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000001\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -3.3999999999999893\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 28.0\n",
      "      policy2: -1.2000000000000017\n",
      "    policy_reward_mean:\n",
      "      policy1: 3.6944444444444446\n",
      "      policy2: -8.301111111111096\n",
      "    policy_reward_min:\n",
      "      policy1: -26.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10286146111927148\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04597855450505894\n",
      "      mean_inference_ms: 1.085320154884013\n",
      "      mean_raw_obs_processing_ms: 0.20283368808617772\n",
      "  time_since_restore: 29.352863550186157\n",
      "  time_this_iter_s: 11.215728759765625\n",
      "  time_total_s: 29.352863550186157\n",
      "  timers:\n",
      "    learn_throughput: 612.008\n",
      "    learn_time_ms: 4901.895\n",
      "    synch_weights_time_ms: 3.569\n",
      "    training_iteration_time_ms: 9779.321\n",
      "  timestamp: 1658917078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 3\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 18000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 18000\n",
      "    num_env_steps_sampled: 9000\n",
      "    num_env_steps_trained: 9000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-17-58\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 12.600000000000009\n",
      "  episode_reward_mean: -6.8199999999999905\n",
      "  episode_reward_min: -39.00000000000004\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 90\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2743884325027466\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02145744487643242\n",
      "          model: {}\n",
      "          policy_loss: -0.061341509222984314\n",
      "          total_loss: 6.709244728088379\n",
      "          vf_explained_var: 0.06188493221998215\n",
      "          vf_loss: 6.764149188995361\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2875301837921143\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019859321415424347\n",
      "          model: {}\n",
      "          policy_loss: -0.057298287749290466\n",
      "          total_loss: 1.9365546703338623\n",
      "          vf_explained_var: 0.34923088550567627\n",
      "          vf_loss: 1.9898810386657715\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 18000\n",
      "    num_env_steps_sampled: 9000\n",
      "    num_env_steps_trained: 9000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 18000\n",
      "  num_agent_steps_trained: 18000\n",
      "  num_env_steps_sampled: 9000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 9000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.15\n",
      "    ram_util_percent: 60.5125\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 21.5\n",
      "    policy2: -2.3000000000000043\n",
      "  policy_reward_mean:\n",
      "    policy1: 1.9333333333333333\n",
      "    policy2: -8.753333333333316\n",
      "  policy_reward_min:\n",
      "    policy1: -29.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.10482136804382275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04591547665005042\n",
      "    mean_inference_ms: 1.098875162650363\n",
      "    mean_raw_obs_processing_ms: 0.20831794116437793\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 12.600000000000009\n",
      "    episode_reward_mean: -6.8199999999999905\n",
      "    episode_reward_min: -39.00000000000004\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.500000000000011\n",
      "      - -9.899999999999979\n",
      "      - -5.999999999999999\n",
      "      - -22.500000000000007\n",
      "      - 1.5000000000000004\n",
      "      - 1.7999999999999958\n",
      "      - -5.399999999999984\n",
      "      - -12.000000000000005\n",
      "      - -11.999999999999982\n",
      "      - -31.500000000000064\n",
      "      - -19.800000000000022\n",
      "      - -14.999999999999973\n",
      "      - -9.00000000000001\n",
      "      - -39.00000000000004\n",
      "      - -19.500000000000032\n",
      "      - -13.499999999999984\n",
      "      - -10.499999999999979\n",
      "      - -16.499999999999993\n",
      "      - -7.799999999999988\n",
      "      - -1.499999999999989\n",
      "      - 6.078471059822732e-15\n",
      "      - -22.500000000000004\n",
      "      - -10.499999999999979\n",
      "      - -19.500000000000014\n",
      "      - 3.3000000000000096\n",
      "      - -13.499999999999993\n",
      "      - -13.499999999999979\n",
      "      - -7.499999999999993\n",
      "      - -7.499999999999979\n",
      "      - -13.499999999999968\n",
      "      - 4.500000000000007\n",
      "      - -2.9999999999999973\n",
      "      - -11.999999999999979\n",
      "      - 7.500000000000021\n",
      "      - -16.19999999999999\n",
      "      - -6.89999999999999\n",
      "      - -2.6999999999999966\n",
      "      - -11.99999999999998\n",
      "      - 4.200000000000024\n",
      "      - -7.199999999999974\n",
      "      - 2.9999999999999982\n",
      "      - -27.000000000000014\n",
      "      - -1.5000000000000173\n",
      "      - -2.399999999999985\n",
      "      - -2.9999999999999933\n",
      "      - -5.399999999999981\n",
      "      - -8.999999999999977\n",
      "      - 1.500000000000019\n",
      "      - 3.0000000000000115\n",
      "      - -21.90000000000002\n",
      "      - -25.500000000000057\n",
      "      - 6.000000000000014\n",
      "      - -4.499999999999992\n",
      "      - -5.399999999999997\n",
      "      - -19.500000000000004\n",
      "      - 1.0297318553398327e-14\n",
      "      - 1.2628786905111156e-14\n",
      "      - -5.999999999999972\n",
      "      - 4.8000000000000185\n",
      "      - 1.5000000000000195\n",
      "      - -4.499999999999981\n",
      "      - -11.699999999999976\n",
      "      - 12.600000000000009\n",
      "      - 6.411537967210279e-15\n",
      "      - -3.2999999999999923\n",
      "      - 5.700000000000006\n",
      "      - -2.999999999999978\n",
      "      - -2.9999999999999813\n",
      "      - -12.899999999999979\n",
      "      - 3.600000000000019\n",
      "      - -9.899999999999993\n",
      "      - -3.899999999999985\n",
      "      - 12.300000000000022\n",
      "      - -1.5000000000000058\n",
      "      - 9.000000000000025\n",
      "      - -6.599999999999994\n",
      "      - -16.49999999999998\n",
      "      - 2.8171909249863347e-14\n",
      "      - -12.899999999999991\n",
      "      - -2.9999999999999933\n",
      "      - 4.500000000000028\n",
      "      - -18.299999999999983\n",
      "      - -5.9999999999999885\n",
      "      - -0.2999999999999997\n",
      "      - -8.99999999999999\n",
      "      - -8.999999999999988\n",
      "      - -8.099999999999985\n",
      "      - 5.999999999999997\n",
      "      - -14.399999999999975\n",
      "      - -6.299999999999978\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - -12.5\n",
      "      - 11.5\n",
      "      - 8.5\n",
      "      - 3.5\n",
      "      - -2.0\n",
      "      - -2.0\n",
      "      - -21.5\n",
      "      - -12.0\n",
      "      - -5.0\n",
      "      - 1.0\n",
      "      - -29.0\n",
      "      - -9.5\n",
      "      - -3.5\n",
      "      - -0.5\n",
      "      - -6.5\n",
      "      - 0.0\n",
      "      - 8.5\n",
      "      - 10.0\n",
      "      - -12.5\n",
      "      - -0.5\n",
      "      - -9.5\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - -3.5\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -3.5\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - -2.0\n",
      "      - 17.5\n",
      "      - -9.5\n",
      "      - 2.0\n",
      "      - 4.0\n",
      "      - -7.5\n",
      "      - 6.5\n",
      "      - -0.5\n",
      "      - 13.0\n",
      "      - -17.0\n",
      "      - 3.0\n",
      "      - 6.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - -13.0\n",
      "      - -15.5\n",
      "      - 16.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - -15.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - 21.5\n",
      "      - 4.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - 7.0\n",
      "      - 7.0\n",
      "      - -4.0\n",
      "      - 12.5\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - -1.0\n",
      "      - -6.5\n",
      "      - 10.0\n",
      "      - -4.0\n",
      "      - 1.5\n",
      "      - 9.0\n",
      "      - -10.5\n",
      "      - 4.0\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 1.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999989\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -6.699999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 21.5\n",
      "      policy2: -2.3000000000000043\n",
      "    policy_reward_mean:\n",
      "      policy1: 1.9333333333333333\n",
      "      policy2: -8.753333333333316\n",
      "    policy_reward_min:\n",
      "      policy1: -29.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.10482136804382275\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04591547665005042\n",
      "      mean_inference_ms: 1.098875162650363\n",
      "      mean_raw_obs_processing_ms: 0.20831794116437793\n",
      "  time_since_restore: 29.659615993499756\n",
      "  time_this_iter_s: 11.223917007446289\n",
      "  time_total_s: 29.659615993499756\n",
      "  timers:\n",
      "    learn_throughput: 605.079\n",
      "    learn_time_ms: 4958.026\n",
      "    synch_weights_time_ms: 3.324\n",
      "    training_iteration_time_ms: 9882.151\n",
      "  timestamp: 1658917078\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 9000\n",
      "  training_iteration: 3\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 16000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_env_steps_sampled: 8000\n",
      "    num_env_steps_trained: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-07\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.499999999999925\n",
      "  episode_reward_mean: -5.902499999999992\n",
      "  episode_reward_min: -39.000000000000064\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 80\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3268150091171265\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019257700070738792\n",
      "          model: {}\n",
      "          policy_loss: -0.049909789115190506\n",
      "          total_loss: 7.012207984924316\n",
      "          vf_explained_var: 0.005113744642585516\n",
      "          vf_loss: 7.05634069442749\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.3261035680770874\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019946403801441193\n",
      "          model: {}\n",
      "          policy_loss: -0.05308373644948006\n",
      "          total_loss: 1.70530104637146\n",
      "          vf_explained_var: 0.4154221713542938\n",
      "          vf_loss: 1.7543952465057373\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 16000\n",
      "    num_env_steps_sampled: 8000\n",
      "    num_env_steps_trained: 8000\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 16000\n",
      "  num_agent_steps_trained: 16000\n",
      "  num_env_steps_sampled: 8000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 8000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.03478260869565\n",
      "    ram_util_percent: 60.42608695652175\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: -0.09999999999999432\n",
      "  policy_reward_mean:\n",
      "    policy1: 2.8875\n",
      "    policy2: -8.789999999999983\n",
      "  policy_reward_min:\n",
      "    policy1: -29.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1300689181681457\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.056163765978310395\n",
      "    mean_inference_ms: 1.3761674309723877\n",
      "    mean_raw_obs_processing_ms: 0.2560035008911034\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 19.499999999999925\n",
      "    episode_reward_mean: -5.902499999999992\n",
      "    episode_reward_min: -39.000000000000064\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -5.999999999999993\n",
      "      - -20.39999999999999\n",
      "      - 0.6000000000000166\n",
      "      - 6.000000000000012\n",
      "      - -13.499999999999995\n",
      "      - -5.999999999999988\n",
      "      - -28.50000000000001\n",
      "      - -4.799999999999978\n",
      "      - 10.20000000000002\n",
      "      - -2.3999999999999986\n",
      "      - -9.599999999999989\n",
      "      - -2.9999999999999996\n",
      "      - -13.799999999999983\n",
      "      - 2.700000000000028\n",
      "      - 10.200000000000028\n",
      "      - -13.499999999999998\n",
      "      - -39.000000000000064\n",
      "      - -27.900000000000013\n",
      "      - -10.19999999999998\n",
      "      - -4.500000000000004\n",
      "      - -7.499999999999995\n",
      "      - -17.999999999999993\n",
      "      - -6.0\n",
      "      - -11.999999999999977\n",
      "      - -11.09999999999998\n",
      "      - 19.499999999999925\n",
      "      - -15.900000000000016\n",
      "      - -7.799999999999979\n",
      "      - -33.000000000000036\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000002\n",
      "      - -11.999999999999979\n",
      "      - 5.700000000000003\n",
      "      - -20.999999999999986\n",
      "      - -0.2999999999999775\n",
      "      - -0.2999999999999944\n",
      "      - -0.8999999999999826\n",
      "      - -17.39999999999999\n",
      "      - 13.499999999999934\n",
      "      - -29.400000000000034\n",
      "      - 0.6000000000000069\n",
      "      - 10.500000000000034\n",
      "      - -11.399999999999975\n",
      "      - 2.100000000000023\n",
      "      - 4.500000000000018\n",
      "      - -5.999999999999993\n",
      "      - -16.499999999999993\n",
      "      - -13.499999999999982\n",
      "      - -18.0\n",
      "      - 6.600000000000026\n",
      "      - 2.7000000000000113\n",
      "      - 5.100000000000026\n",
      "      - 2.699999999999987\n",
      "      - -7.499999999999988\n",
      "      - -25.500000000000046\n",
      "      - 6.600000000000023\n",
      "      - -7.499999999999995\n",
      "      - -8.399999999999983\n",
      "      - 6.000000000000016\n",
      "      - -2.400000000000001\n",
      "      - 3.0000000000000187\n",
      "      - 9.00000000000002\n",
      "      - -0.599999999999972\n",
      "      - -8.99999999999998\n",
      "      - -7.499999999999991\n",
      "      - 6.6000000000000085\n",
      "      - -1.499999999999989\n",
      "      - -8.39999999999999\n",
      "      - -17.99999999999999\n",
      "      - -8.399999999999983\n",
      "      - 0.6000000000000167\n",
      "      - 4.800000000000004\n",
      "      - -9.299999999999983\n",
      "      - 1.2000000000000146\n",
      "      - 3.3000000000000034\n",
      "      - -4.499999999999973\n",
      "      - -10.499999999999993\n",
      "      - 9.900000000000006\n",
      "      - -9.299999999999988\n",
      "      - -16.499999999999975\n",
      "      policy_policy1_reward:\n",
      "      - 4.0\n",
      "      - -11.5\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - -3.5\n",
      "      - 4.0\n",
      "      - -18.5\n",
      "      - 3.0\n",
      "      - 18.0\n",
      "      - 6.5\n",
      "      - -4.0\n",
      "      - 7.0\n",
      "      - -6.0\n",
      "      - 10.5\n",
      "      - 18.0\n",
      "      - -3.5\n",
      "      - -29.0\n",
      "      - -19.0\n",
      "      - -3.5\n",
      "      - 5.5\n",
      "      - 2.5\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - -2.0\n",
      "      - -11.0\n",
      "      - 29.5\n",
      "      - -7.0\n",
      "      - 0.0\n",
      "      - -23.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - 13.5\n",
      "      - -11.0\n",
      "      - 7.5\n",
      "      - 7.5\n",
      "      - 8.0\n",
      "      - -8.5\n",
      "      - 23.5\n",
      "      - -20.5\n",
      "      - 9.5\n",
      "      - 20.5\n",
      "      - -2.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 4.0\n",
      "      - -6.5\n",
      "      - -3.5\n",
      "      - -8.0\n",
      "      - 15.5\n",
      "      - 10.5\n",
      "      - 14.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      - -15.5\n",
      "      - 15.5\n",
      "      - 2.5\n",
      "      - 0.5\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 13.0\n",
      "      - 19.0\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 15.5\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - -8.0\n",
      "      - 0.5\n",
      "      - 9.5\n",
      "      - 11.5\n",
      "      - -1.5\n",
      "      - 9.0\n",
      "      - 10.0\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 15.5\n",
      "      - -1.5\n",
      "      - -6.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -5.599999999999991\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999432\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999988\n",
      "      - -6.699999999999988\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: -0.09999999999999432\n",
      "    policy_reward_mean:\n",
      "      policy1: 2.8875\n",
      "      policy2: -8.789999999999983\n",
      "    policy_reward_min:\n",
      "      policy1: -29.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1300689181681457\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.056163765978310395\n",
      "      mean_inference_ms: 1.3761674309723877\n",
      "      mean_raw_obs_processing_ms: 0.2560035008911034\n",
      "  time_since_restore: 31.208117961883545\n",
      "  time_this_iter_s: 16.233190059661865\n",
      "  time_total_s: 31.208117961883545\n",
      "  timers:\n",
      "    learn_throughput: 509.63\n",
      "    learn_time_ms: 7848.835\n",
      "    synch_weights_time_ms: 4.273\n",
      "    training_iteration_time_ms: 15598.146\n",
      "  timestamp: 1658917087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 2\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 24000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-07\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.500000000000018\n",
      "  episode_reward_mean: -2.3459999999999877\n",
      "  episode_reward_min: -22.500000000000007\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 120\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3044935464859009\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013068359345197678\n",
      "          model: {}\n",
      "          policy_loss: -0.03482355549931526\n",
      "          total_loss: 6.549254894256592\n",
      "          vf_explained_var: 0.04158273711800575\n",
      "          vf_loss: 6.581464767456055\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.3100597858428955\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013127213343977928\n",
      "          model: {}\n",
      "          policy_loss: -0.03728572651743889\n",
      "          total_loss: 2.0088915824890137\n",
      "          vf_explained_var: 0.3589147627353668\n",
      "          vf_loss: 2.0435519218444824\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 12000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.234782608695646\n",
      "    ram_util_percent: 60.41739130434783\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: 1.0000000000000009\n",
      "  policy_reward_mean:\n",
      "    policy1: 5.96\n",
      "    policy2: -8.305999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -14.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11375599075115626\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.04963252162178726\n",
      "    mean_inference_ms: 1.1933400854434109\n",
      "    mean_raw_obs_processing_ms: 0.22467372303126504\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 19.500000000000018\n",
      "    episode_reward_mean: -2.3459999999999877\n",
      "    episode_reward_min: -22.500000000000007\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -12.299999999999976\n",
      "      - -20.700000000000024\n",
      "      - -1.1379786002407855e-15\n",
      "      - -10.499999999999988\n",
      "      - -11.399999999999977\n",
      "      - -16.49999999999998\n",
      "      - -11.999999999999991\n",
      "      - -13.499999999999982\n",
      "      - -7.799999999999979\n",
      "      - -8.999999999999975\n",
      "      - 3.6000000000000116\n",
      "      - -15.900000000000025\n",
      "      - -4.499999999999988\n",
      "      - -9.899999999999991\n",
      "      - -18.000000000000014\n",
      "      - -22.500000000000004\n",
      "      - -5.999999999999989\n",
      "      - 3.900000000000032\n",
      "      - -2.3999999999999946\n",
      "      - -22.500000000000007\n",
      "      - 10.500000000000014\n",
      "      - 6.000000000000002\n",
      "      - -7.499999999999995\n",
      "      - 11.100000000000007\n",
      "      - -2.9999999999999876\n",
      "      - -4.499999999999987\n",
      "      - -4.499999999999977\n",
      "      - -13.499999999999988\n",
      "      - 1.5000000000000098\n",
      "      - 9.000000000000021\n",
      "      - -2.999999999999983\n",
      "      - -7.499999999999988\n",
      "      - -2.9999999999999796\n",
      "      - -6.0000000000000036\n",
      "      - 8.100000000000023\n",
      "      - 6.000000000000027\n",
      "      - -4.19999999999999\n",
      "      - -1.799999999999994\n",
      "      - -2.9999999999999782\n",
      "      - -14.999999999999984\n",
      "      - -6.899999999999997\n",
      "      - -12.899999999999983\n",
      "      - 2.9999999999999916\n",
      "      - 1.5000000000000244\n",
      "      - 14.999999999999954\n",
      "      - 7.2000000000000295\n",
      "      - -0.2999999999999797\n",
      "      - 8.999999999999979\n",
      "      - -7.499999999999989\n",
      "      - 7.5000000000000195\n",
      "      - 6.600000000000026\n",
      "      - 3.3000000000000167\n",
      "      - 11.99999999999997\n",
      "      - 16.5\n",
      "      - -4.499999999999981\n",
      "      - -8.999999999999982\n",
      "      - -15.299999999999985\n",
      "      - -4.199999999999983\n",
      "      - -0.8999999999999844\n",
      "      - -10.499999999999975\n",
      "      - 4.200000000000002\n",
      "      - 3.3000000000000282\n",
      "      - 0.6000000000000184\n",
      "      - 7.500000000000034\n",
      "      - -6.899999999999972\n",
      "      - 6.900000000000029\n",
      "      - -0.8999999999999723\n",
      "      - 2.100000000000026\n",
      "      - -7.499999999999982\n",
      "      - -13.79999999999999\n",
      "      - -0.2999999999999782\n",
      "      - -1.7999999999999914\n",
      "      - -6.8999999999999915\n",
      "      - -0.2999999999999913\n",
      "      - -2.6999999999999775\n",
      "      - -12.29999999999998\n",
      "      - 7.500000000000027\n",
      "      - -3.8999999999999972\n",
      "      - -5.399999999999984\n",
      "      - 3.900000000000017\n",
      "      - 1.5000000000000182\n",
      "      - -2.999999999999978\n",
      "      - -1.499999999999992\n",
      "      - 5.400000000000016\n",
      "      - 0.6000000000000221\n",
      "      - 11.100000000000032\n",
      "      - 2.0999999999999757\n",
      "      - 0.6000000000000023\n",
      "      - 19.500000000000018\n",
      "      - -8.399999999999979\n",
      "      - 7.7999999999999705\n",
      "      - 3.3000000000000247\n",
      "      - -5.3999999999999755\n",
      "      - -2.099999999999996\n",
      "      - -8.999999999999977\n",
      "      - -7.499999999999977\n",
      "      - 6.900000000000015\n",
      "      - -8.999999999999996\n",
      "      - 1.2000000000000146\n",
      "      - 0.6000000000000113\n",
      "      policy_policy1_reward:\n",
      "      - -4.5\n",
      "      - -14.0\n",
      "      - 10.0\n",
      "      - -0.5\n",
      "      - -2.5\n",
      "      - -6.5\n",
      "      - -2.0\n",
      "      - -9.0\n",
      "      - 0.0\n",
      "      - 1.0\n",
      "      - 12.5\n",
      "      - -7.0\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -8.0\n",
      "      - -12.5\n",
      "      - 4.0\n",
      "      - 9.5\n",
      "      - 6.5\n",
      "      - -12.5\n",
      "      - 20.5\n",
      "      - 16.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 7.0\n",
      "      - 0.0\n",
      "      - 5.5\n",
      "      - -3.5\n",
      "      - 11.5\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - -7.0\n",
      "      - 17.0\n",
      "      - 16.0\n",
      "      - 2.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -10.5\n",
      "      - 2.0\n",
      "      - -4.0\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 25.0\n",
      "      - 15.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 17.5\n",
      "      - 15.5\n",
      "      - 10.0\n",
      "      - 16.5\n",
      "      - 26.5\n",
      "      - 5.5\n",
      "      - 1.0\n",
      "      - -13.0\n",
      "      - 2.5\n",
      "      - 8.0\n",
      "      - -0.5\n",
      "      - 12.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 17.5\n",
      "      - 2.0\n",
      "      - 12.5\n",
      "      - 8.0\n",
      "      - 11.0\n",
      "      - 2.5\n",
      "      - -6.0\n",
      "      - 7.5\n",
      "      - 6.0\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - -4.5\n",
      "      - 12.0\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - 9.5\n",
      "      - 0.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 20.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 29.5\n",
      "      - 0.5\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000009\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.69999999999999\n",
      "      - -3.3999999999999932\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999983\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999895\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999996\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -5.5999999999999845\n",
      "      - 0.999999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: 1.0000000000000009\n",
      "    policy_reward_mean:\n",
      "      policy1: 5.96\n",
      "      policy2: -8.305999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -14.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11375599075115626\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.04963252162178726\n",
      "      mean_inference_ms: 1.1933400854434109\n",
      "      mean_raw_obs_processing_ms: 0.22467372303126504\n",
      "  time_since_restore: 41.39379692077637\n",
      "  time_this_iter_s: 16.408845901489258\n",
      "  time_total_s: 41.39379692077637\n",
      "  timers:\n",
      "    learn_throughput: 591.641\n",
      "    learn_time_ms: 6760.86\n",
      "    synch_weights_time_ms: 3.616\n",
      "    training_iteration_time_ms: 13791.059\n",
      "  timestamp: 1658917087\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 24000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.999999999999936\n",
      "  episode_reward_mean: -1.8389999999999886\n",
      "  episode_reward_min: -27.000000000000075\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 120\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2868760824203491\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011454641819000244\n",
      "          model: {}\n",
      "          policy_loss: -0.03977867588400841\n",
      "          total_loss: 6.730567932128906\n",
      "          vf_explained_var: 0.06104029715061188\n",
      "          vf_loss: 6.768056392669678\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.267507553100586\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01060517132282257\n",
      "          model: {}\n",
      "          policy_loss: -0.042662348598241806\n",
      "          total_loss: 2.842129707336426\n",
      "          vf_explained_var: 0.20511697232723236\n",
      "          vf_loss: 2.8837313652038574\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 12000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.60000000000001\n",
      "    ram_util_percent: 60.35\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 0.9999999999999948\n",
      "  policy_reward_mean:\n",
      "    policy1: 6.005\n",
      "    policy2: -7.843999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -17.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11364168492398961\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05073635994788006\n",
      "    mean_inference_ms: 1.196395814573412\n",
      "    mean_raw_obs_processing_ms: 0.22384471582509924\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.999999999999936\n",
      "    episode_reward_mean: -1.8389999999999886\n",
      "    episode_reward_min: -27.000000000000075\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -0.5999999999999744\n",
      "      - 12.900000000000032\n",
      "      - -18.000000000000036\n",
      "      - -24.300000000000026\n",
      "      - -8.399999999999977\n",
      "      - -10.79999999999997\n",
      "      - -27.000000000000075\n",
      "      - -10.499999999999988\n",
      "      - -7.499999999999977\n",
      "      - 8.100000000000014\n",
      "      - -16.49999999999998\n",
      "      - -10.499999999999973\n",
      "      - -25.5\n",
      "      - 1.2000000000000006\n",
      "      - 3.600000000000031\n",
      "      - 3.000000000000025\n",
      "      - 3.0000000000000187\n",
      "      - -4.499999999999986\n",
      "      - -5.399999999999993\n",
      "      - 11.700000000000019\n",
      "      - 4.200000000000014\n",
      "      - -13.499999999999988\n",
      "      - 11.100000000000021\n",
      "      - 6.000000000000027\n",
      "      - 6.000000000000016\n",
      "      - -11.999999999999984\n",
      "      - -10.499999999999988\n",
      "      - -6.299999999999981\n",
      "      - -11.399999999999979\n",
      "      - -5.999999999999982\n",
      "      - -8.999999999999986\n",
      "      - 4.500000000000019\n",
      "      - -14.09999999999999\n",
      "      - 10.200000000000026\n",
      "      - 0.6000000000000059\n",
      "      - -14.399999999999983\n",
      "      - 18.000000000000007\n",
      "      - -8.99999999999998\n",
      "      - -1.4999999999999833\n",
      "      - -9.899999999999975\n",
      "      - 5.999999999999947\n",
      "      - 5.9674487573602164e-15\n",
      "      - -7.499999999999972\n",
      "      - 8.999999999999966\n",
      "      - -7.499999999999993\n",
      "      - -2.3999999999999884\n",
      "      - 7.499999999999973\n",
      "      - 3.3\n",
      "      - -12.899999999999997\n",
      "      - 2.700000000000022\n",
      "      - -5.699999999999989\n",
      "      - 7.500000000000028\n",
      "      - -2.9999999999999782\n",
      "      - 1.5000000000000187\n",
      "      - 2.100000000000014\n",
      "      - 7.50000000000003\n",
      "      - -13.499999999999986\n",
      "      - 10.499999999999947\n",
      "      - -5.999999999999998\n",
      "      - -1.4999999999999867\n",
      "      - 1.200000000000022\n",
      "      - 10.499999999999975\n",
      "      - 5.700000000000012\n",
      "      - 3.600000000000024\n",
      "      - -2.999999999999985\n",
      "      - 7.800000000000011\n",
      "      - 13.500000000000016\n",
      "      - -16.49999999999998\n",
      "      - -11.69999999999998\n",
      "      - -3.9000000000000017\n",
      "      - -3.2999999999999954\n",
      "      - 5.700000000000028\n",
      "      - -10.49999999999998\n",
      "      - 6.900000000000027\n",
      "      - -12.299999999999972\n",
      "      - -2.999999999999979\n",
      "      - 6.00000000000003\n",
      "      - 2.700000000000021\n",
      "      - -1.1999999999999744\n",
      "      - 1.8290924330699454e-14\n",
      "      - -0.5999999999999935\n",
      "      - 23.999999999999936\n",
      "      - 2.099999999999989\n",
      "      - -8.99999999999999\n",
      "      - -12.29999999999998\n",
      "      - 10.500000000000007\n",
      "      - 8.100000000000001\n",
      "      - 6.000000000000023\n",
      "      - 5.4000000000000306\n",
      "      - -3.300000000000005\n",
      "      - -9.299999999999985\n",
      "      - -2.999999999999992\n",
      "      - -2.09999999999999\n",
      "      - 2.4000000000000186\n",
      "      - -4.499999999999977\n",
      "      - 2.70000000000003\n",
      "      - -7.199999999999983\n",
      "      - -2.6999999999999815\n",
      "      - -3.599999999999979\n",
      "      - -0.29999999999998683\n",
      "      policy_policy1_reward:\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - -8.0\n",
      "      - -16.5\n",
      "      - -5.0\n",
      "      - -3.0\n",
      "      - -17.0\n",
      "      - -0.5\n",
      "      - 2.5\n",
      "      - 17.0\n",
      "      - -6.5\n",
      "      - -0.5\n",
      "      - -15.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - 19.5\n",
      "      - 12.0\n",
      "      - -3.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - -0.5\n",
      "      - -4.0\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - 1.0\n",
      "      - 14.5\n",
      "      - -8.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - -5.5\n",
      "      - 28.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      - -1.0\n",
      "      - 10.5\n",
      "      - 10.0\n",
      "      - 2.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 4.5\n",
      "      - -4.0\n",
      "      - 10.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 7.0\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      - -9.0\n",
      "      - 20.5\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - -6.5\n",
      "      - -5.0\n",
      "      - -0.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - -0.5\n",
      "      - 7.0\n",
      "      - -4.5\n",
      "      - 7.0\n",
      "      - 16.0\n",
      "      - 5.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 34.0\n",
      "      - 11.0\n",
      "      - 1.0\n",
      "      - -4.5\n",
      "      - 20.5\n",
      "      - 17.0\n",
      "      - 10.5\n",
      "      - 11.0\n",
      "      - 4.5\n",
      "      - -7.0\n",
      "      - -4.0\n",
      "      - 3.5\n",
      "      - 8.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - -0.5\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      policy_policy2_reward:\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -3.3999999999999915\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999986\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000001\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -3.3999999999999893\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.299999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000043\n",
      "      - 0.9999999999999948\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000057\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999989\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 0.9999999999999948\n",
      "    policy_reward_mean:\n",
      "      policy1: 6.005\n",
      "      policy2: -7.843999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -17.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11364168492398961\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05073635994788006\n",
      "      mean_inference_ms: 1.196395814573412\n",
      "      mean_raw_obs_processing_ms: 0.22384471582509924\n",
      "  time_since_restore: 43.2422935962677\n",
      "  time_this_iter_s: 13.889430046081543\n",
      "  time_total_s: 43.2422935962677\n",
      "  timers:\n",
      "    learn_throughput: 579.639\n",
      "    learn_time_ms: 5175.638\n",
      "    synch_weights_time_ms: 3.545\n",
      "    training_iteration_time_ms: 10805.124\n",
      "  timestamp: 1658917092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 4\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 24000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.599999999999987\n",
      "  episode_reward_mean: -3.3479999999999883\n",
      "  episode_reward_min: -27.000000000000014\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 120\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.245635986328125\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018387729302048683\n",
      "          model: {}\n",
      "          policy_loss: -0.05564967170357704\n",
      "          total_loss: 6.773309230804443\n",
      "          vf_explained_var: 0.05877907946705818\n",
      "          vf_loss: 6.82068395614624\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2408335208892822\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02146780677139759\n",
      "          model: {}\n",
      "          policy_loss: -0.05698816478252411\n",
      "          total_loss: 1.7015472650527954\n",
      "          vf_explained_var: 0.3434005379676819\n",
      "          vf_loss: 1.7542415857315063\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 12000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.12380952380951\n",
      "    ram_util_percent: 60.31904761904762\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 30.5\n",
      "    policy2: -2.3000000000000043\n",
      "  policy_reward_mean:\n",
      "    policy1: 5.255\n",
      "    policy2: -8.602999999999986\n",
      "  policy_reward_min:\n",
      "    policy1: -17.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.11577183007453659\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.050593893461357294\n",
      "    mean_inference_ms: 1.212103586932021\n",
      "    mean_raw_obs_processing_ms: 0.2284652117926095\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 21.599999999999987\n",
      "    episode_reward_mean: -3.3479999999999883\n",
      "    episode_reward_min: -27.000000000000014\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 6.078471059822732e-15\n",
      "      - -22.500000000000004\n",
      "      - -10.499999999999979\n",
      "      - -19.500000000000014\n",
      "      - 3.3000000000000096\n",
      "      - -13.499999999999993\n",
      "      - -13.499999999999979\n",
      "      - -7.499999999999993\n",
      "      - -7.499999999999979\n",
      "      - -13.499999999999968\n",
      "      - 4.500000000000007\n",
      "      - -2.9999999999999973\n",
      "      - -11.999999999999979\n",
      "      - 7.500000000000021\n",
      "      - -16.19999999999999\n",
      "      - -6.89999999999999\n",
      "      - -2.6999999999999966\n",
      "      - -11.99999999999998\n",
      "      - 4.200000000000024\n",
      "      - -7.199999999999974\n",
      "      - 2.9999999999999982\n",
      "      - -27.000000000000014\n",
      "      - -1.5000000000000173\n",
      "      - -2.399999999999985\n",
      "      - -2.9999999999999933\n",
      "      - -5.399999999999981\n",
      "      - -8.999999999999977\n",
      "      - 1.500000000000019\n",
      "      - 3.0000000000000115\n",
      "      - -21.90000000000002\n",
      "      - -25.500000000000057\n",
      "      - 6.000000000000014\n",
      "      - -4.499999999999992\n",
      "      - -5.399999999999997\n",
      "      - -19.500000000000004\n",
      "      - 1.0297318553398327e-14\n",
      "      - 1.2628786905111156e-14\n",
      "      - -5.999999999999972\n",
      "      - 4.8000000000000185\n",
      "      - 1.5000000000000195\n",
      "      - -4.499999999999981\n",
      "      - -11.699999999999976\n",
      "      - 12.600000000000009\n",
      "      - 6.411537967210279e-15\n",
      "      - -3.2999999999999923\n",
      "      - 5.700000000000006\n",
      "      - -2.999999999999978\n",
      "      - -2.9999999999999813\n",
      "      - -12.899999999999979\n",
      "      - 3.600000000000019\n",
      "      - -9.899999999999993\n",
      "      - -3.899999999999985\n",
      "      - 12.300000000000022\n",
      "      - -1.5000000000000058\n",
      "      - 9.000000000000025\n",
      "      - -6.599999999999994\n",
      "      - -16.49999999999998\n",
      "      - 2.8171909249863347e-14\n",
      "      - -12.899999999999991\n",
      "      - -2.9999999999999933\n",
      "      - 4.500000000000028\n",
      "      - -18.299999999999983\n",
      "      - -5.9999999999999885\n",
      "      - -0.2999999999999997\n",
      "      - -8.99999999999999\n",
      "      - -8.999999999999988\n",
      "      - -8.099999999999985\n",
      "      - 5.999999999999997\n",
      "      - -14.399999999999975\n",
      "      - -6.299999999999978\n",
      "      - 10.200000000000026\n",
      "      - 12.000000000000032\n",
      "      - 21.599999999999987\n",
      "      - -8.699999999999974\n",
      "      - 5.10000000000001\n",
      "      - 2.9999999999999862\n",
      "      - -0.29999999999997684\n",
      "      - -1.4999999999999782\n",
      "      - -1.7999999999999763\n",
      "      - -11.999999999999975\n",
      "      - -0.2999999999999755\n",
      "      - 2.1000000000000107\n",
      "      - -10.799999999999985\n",
      "      - 10.200000000000006\n",
      "      - 1.5000000000000173\n",
      "      - -3.2999999999999776\n",
      "      - 12.90000000000003\n",
      "      - -5.69999999999998\n",
      "      - 7.500000000000021\n",
      "      - 2.1000000000000028\n",
      "      - -15.299999999999976\n",
      "      - -0.8999999999999915\n",
      "      - 4.8000000000000185\n",
      "      - -2.3999999999999897\n",
      "      - -11.999999999999982\n",
      "      - -1.19999999999999\n",
      "      - 7.743805596760467e-15\n",
      "      - 0.6000000000000166\n",
      "      - 7.500000000000014\n",
      "      - 10.500000000000005\n",
      "      policy_policy1_reward:\n",
      "      - 10.0\n",
      "      - -12.5\n",
      "      - -0.5\n",
      "      - -9.5\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - -3.5\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -3.5\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - -2.0\n",
      "      - 17.5\n",
      "      - -9.5\n",
      "      - 2.0\n",
      "      - 4.0\n",
      "      - -7.5\n",
      "      - 6.5\n",
      "      - -0.5\n",
      "      - 13.0\n",
      "      - -17.0\n",
      "      - 3.0\n",
      "      - 6.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - -13.0\n",
      "      - -15.5\n",
      "      - 16.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - -15.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - 21.5\n",
      "      - 4.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - 7.0\n",
      "      - 7.0\n",
      "      - -4.0\n",
      "      - 12.5\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - -1.0\n",
      "      - -6.5\n",
      "      - 10.0\n",
      "      - -4.0\n",
      "      - 1.5\n",
      "      - 9.0\n",
      "      - -10.5\n",
      "      - 4.0\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 1.5\n",
      "      - 18.0\n",
      "      - 22.0\n",
      "      - 30.5\n",
      "      - -2.0\n",
      "      - 14.0\n",
      "      - 13.0\n",
      "      - 7.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - -2.0\n",
      "      - 7.5\n",
      "      - 11.0\n",
      "      - -3.0\n",
      "      - 18.0\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 18.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - -7.5\n",
      "      - 8.0\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - -2.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 9.5\n",
      "      - 17.5\n",
      "      - 20.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999989\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -6.699999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.6\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 30.5\n",
      "      policy2: -2.3000000000000043\n",
      "    policy_reward_mean:\n",
      "      policy1: 5.255\n",
      "      policy2: -8.602999999999986\n",
      "    policy_reward_min:\n",
      "      policy1: -17.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.11577183007453659\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.050593893461357294\n",
      "      mean_inference_ms: 1.212103586932021\n",
      "      mean_raw_obs_processing_ms: 0.2284652117926095\n",
      "  time_since_restore: 43.557579040527344\n",
      "  time_this_iter_s: 13.897963047027588\n",
      "  time_total_s: 43.557579040527344\n",
      "  timers:\n",
      "    learn_throughput: 581.352\n",
      "    learn_time_ms: 5160.384\n",
      "    synch_weights_time_ms: 3.241\n",
      "    training_iteration_time_ms: 10885.438\n",
      "  timestamp: 1658917092\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 4\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 32000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_env_steps_sampled: 16000\n",
      "    num_env_steps_trained: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 20.099999999999966\n",
      "  episode_reward_mean: -0.27299999999998653\n",
      "  episode_reward_min: -17.999999999999986\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 160\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2698756456375122\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011310586705803871\n",
      "          model: {}\n",
      "          policy_loss: -0.03385556489229202\n",
      "          total_loss: 7.176877021789551\n",
      "          vf_explained_var: 0.11425112187862396\n",
      "          vf_loss: 7.208470344543457\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2730835676193237\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0117361880838871\n",
      "          model: {}\n",
      "          policy_loss: -0.036037225276231766\n",
      "          total_loss: 2.432779550552368\n",
      "          vf_explained_var: 0.28762397170066833\n",
      "          vf_loss: 2.4664692878723145\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_env_steps_sampled: 16000\n",
      "    num_env_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_env_steps_sampled: 16000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 16000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.711999999999996\n",
      "    ram_util_percent: 60.292\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: 7.600000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.175\n",
      "    policy2: -7.447999999999984\n",
      "  policy_reward_min:\n",
      "    policy1: -20.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.12440882425658403\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.054282971679587746\n",
      "    mean_inference_ms: 1.3081119435935344\n",
      "    mean_raw_obs_processing_ms: 0.2453742544365965\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 20.099999999999966\n",
      "    episode_reward_mean: -0.27299999999998653\n",
      "    episode_reward_min: -17.999999999999986\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -6.899999999999997\n",
      "      - -12.899999999999983\n",
      "      - 2.9999999999999916\n",
      "      - 1.5000000000000244\n",
      "      - 14.999999999999954\n",
      "      - 7.2000000000000295\n",
      "      - -0.2999999999999797\n",
      "      - 8.999999999999979\n",
      "      - -7.499999999999989\n",
      "      - 7.5000000000000195\n",
      "      - 6.600000000000026\n",
      "      - 3.3000000000000167\n",
      "      - 11.99999999999997\n",
      "      - 16.5\n",
      "      - -4.499999999999981\n",
      "      - -8.999999999999982\n",
      "      - -15.299999999999985\n",
      "      - -4.199999999999983\n",
      "      - -0.8999999999999844\n",
      "      - -10.499999999999975\n",
      "      - 4.200000000000002\n",
      "      - 3.3000000000000282\n",
      "      - 0.6000000000000184\n",
      "      - 7.500000000000034\n",
      "      - -6.899999999999972\n",
      "      - 6.900000000000029\n",
      "      - -0.8999999999999723\n",
      "      - 2.100000000000026\n",
      "      - -7.499999999999982\n",
      "      - -13.79999999999999\n",
      "      - -0.2999999999999782\n",
      "      - -1.7999999999999914\n",
      "      - -6.8999999999999915\n",
      "      - -0.2999999999999913\n",
      "      - -2.6999999999999775\n",
      "      - -12.29999999999998\n",
      "      - 7.500000000000027\n",
      "      - -3.8999999999999972\n",
      "      - -5.399999999999984\n",
      "      - 3.900000000000017\n",
      "      - 1.5000000000000182\n",
      "      - -2.999999999999978\n",
      "      - -1.499999999999992\n",
      "      - 5.400000000000016\n",
      "      - 0.6000000000000221\n",
      "      - 11.100000000000032\n",
      "      - 2.0999999999999757\n",
      "      - 0.6000000000000023\n",
      "      - 19.500000000000018\n",
      "      - -8.399999999999979\n",
      "      - 7.7999999999999705\n",
      "      - 3.3000000000000247\n",
      "      - -5.3999999999999755\n",
      "      - -2.099999999999996\n",
      "      - -8.999999999999977\n",
      "      - -7.499999999999977\n",
      "      - 6.900000000000015\n",
      "      - -8.999999999999996\n",
      "      - 1.2000000000000146\n",
      "      - 0.6000000000000113\n",
      "      - -5.999999999999972\n",
      "      - 6.000000000000005\n",
      "      - -17.999999999999986\n",
      "      - -1.5000000000000036\n",
      "      - -1.7999999999999745\n",
      "      - -2.099999999999978\n",
      "      - -8.699999999999982\n",
      "      - -3.8999999999999817\n",
      "      - 6.600000000000014\n",
      "      - -9.89999999999998\n",
      "      - -0.29999999999998306\n",
      "      - 0.6000000000000046\n",
      "      - 12.00000000000003\n",
      "      - -13.199999999999989\n",
      "      - 11.100000000000017\n",
      "      - 4.50000000000003\n",
      "      - -3.8999999999999813\n",
      "      - -8.999999999999975\n",
      "      - 19.799999999999926\n",
      "      - -6.2999999999999705\n",
      "      - 6.300000000000031\n",
      "      - -1.49999999999998\n",
      "      - 9.900000000000023\n",
      "      - 20.099999999999966\n",
      "      - 3.6000000000000227\n",
      "      - -4.499999999999973\n",
      "      - -8.399999999999983\n",
      "      - -4.199999999999983\n",
      "      - 3.600000000000026\n",
      "      - 6.00000000000003\n",
      "      - -3.6000000000000014\n",
      "      - -0.5999999999999898\n",
      "      - 6.000000000000028\n",
      "      - -7.7999999999999865\n",
      "      - 0.9000000000000165\n",
      "      - -12.899999999999977\n",
      "      - 0.899999999999964\n",
      "      - 1.800000000000018\n",
      "      - -4.199999999999978\n",
      "      - -12.299999999999983\n",
      "      policy_policy1_reward:\n",
      "      - 2.0\n",
      "      - -4.0\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 25.0\n",
      "      - 15.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 17.5\n",
      "      - 15.5\n",
      "      - 10.0\n",
      "      - 16.5\n",
      "      - 26.5\n",
      "      - 5.5\n",
      "      - 1.0\n",
      "      - -13.0\n",
      "      - 2.5\n",
      "      - 8.0\n",
      "      - -0.5\n",
      "      - 12.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 17.5\n",
      "      - 2.0\n",
      "      - 12.5\n",
      "      - 8.0\n",
      "      - 11.0\n",
      "      - 2.5\n",
      "      - -6.0\n",
      "      - 7.5\n",
      "      - 6.0\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - -4.5\n",
      "      - 12.0\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - 9.5\n",
      "      - 0.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 20.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 29.5\n",
      "      - 0.5\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      - 10.5\n",
      "      - -8.0\n",
      "      - 8.5\n",
      "      - 0.5\n",
      "      - 3.5\n",
      "      - -2.0\n",
      "      - 5.0\n",
      "      - 15.5\n",
      "      - -6.5\n",
      "      - 7.5\n",
      "      - 9.5\n",
      "      - 16.5\n",
      "      - -6.5\n",
      "      - 14.5\n",
      "      - 14.5\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 26.5\n",
      "      - 1.5\n",
      "      - 13.0\n",
      "      - 3.0\n",
      "      - 15.5\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 10.5\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 6.5\n",
      "      - -20.5\n",
      "      - 6.5\n",
      "      - 8.5\n",
      "      - 2.5\n",
      "      - -4.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.69999999999999\n",
      "      - -3.3999999999999932\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999983\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999895\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999996\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -5.5999999999999845\n",
      "      - 0.999999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000007\n",
      "      - -5.59999999999999\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -3.3999999999999972\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999987\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999983\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999897\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -5.599999999999987\n",
      "      - 7.600000000000005\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: 7.600000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.175\n",
      "      policy2: -7.447999999999984\n",
      "    policy_reward_min:\n",
      "      policy1: -20.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.12440882425658403\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.054282971679587746\n",
      "      mean_inference_ms: 1.3081119435935344\n",
      "      mean_raw_obs_processing_ms: 0.2453742544365965\n",
      "  time_since_restore: 58.793367862701416\n",
      "  time_this_iter_s: 17.39957094192505\n",
      "  time_total_s: 58.793367862701416\n",
      "  timers:\n",
      "    learn_throughput: 546.379\n",
      "    learn_time_ms: 7320.926\n",
      "    synch_weights_time_ms: 4.132\n",
      "    training_iteration_time_ms: 14690.81\n",
      "  timestamp: 1658917105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 24000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 19.499999999999925\n",
      "  episode_reward_mean: -2.58899999999999\n",
      "  episode_reward_min: -33.000000000000036\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 120\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2826536893844604\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01927920989692211\n",
      "          model: {}\n",
      "          policy_loss: -0.05118432268500328\n",
      "          total_loss: 6.520752906799316\n",
      "          vf_explained_var: 0.11647122353315353\n",
      "          vf_loss: 6.566153526306152\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2808589935302734\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019857851788401604\n",
      "          model: {}\n",
      "          policy_loss: -0.051244329661130905\n",
      "          total_loss: 2.1870081424713135\n",
      "          vf_explained_var: 0.335828959941864\n",
      "          vf_loss: 2.234280824661255\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 24000\n",
      "    num_env_steps_sampled: 12000\n",
      "    num_env_steps_trained: 12000\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 24000\n",
      "  num_agent_steps_trained: 24000\n",
      "  num_env_steps_sampled: 12000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 12000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.2423076923077\n",
      "    ram_util_percent: 60.30384615384615\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: -0.09999999999999432\n",
      "  policy_reward_mean:\n",
      "    policy1: 5.915\n",
      "    policy2: -8.503999999999984\n",
      "  policy_reward_min:\n",
      "    policy1: -23.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13552177446035424\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05860204124008158\n",
      "    mean_inference_ms: 1.433000186182224\n",
      "    mean_raw_obs_processing_ms: 0.2667972405002905\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 19.499999999999925\n",
      "    episode_reward_mean: -2.58899999999999\n",
      "    episode_reward_min: -33.000000000000036\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -7.499999999999995\n",
      "      - -17.999999999999993\n",
      "      - -6.0\n",
      "      - -11.999999999999977\n",
      "      - -11.09999999999998\n",
      "      - 19.499999999999925\n",
      "      - -15.900000000000016\n",
      "      - -7.799999999999979\n",
      "      - -33.000000000000036\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000002\n",
      "      - -11.999999999999979\n",
      "      - 5.700000000000003\n",
      "      - -20.999999999999986\n",
      "      - -0.2999999999999775\n",
      "      - -0.2999999999999944\n",
      "      - -0.8999999999999826\n",
      "      - -17.39999999999999\n",
      "      - 13.499999999999934\n",
      "      - -29.400000000000034\n",
      "      - 0.6000000000000069\n",
      "      - 10.500000000000034\n",
      "      - -11.399999999999975\n",
      "      - 2.100000000000023\n",
      "      - 4.500000000000018\n",
      "      - -5.999999999999993\n",
      "      - -16.499999999999993\n",
      "      - -13.499999999999982\n",
      "      - -18.0\n",
      "      - 6.600000000000026\n",
      "      - 2.7000000000000113\n",
      "      - 5.100000000000026\n",
      "      - 2.699999999999987\n",
      "      - -7.499999999999988\n",
      "      - -25.500000000000046\n",
      "      - 6.600000000000023\n",
      "      - -7.499999999999995\n",
      "      - -8.399999999999983\n",
      "      - 6.000000000000016\n",
      "      - -2.400000000000001\n",
      "      - 3.0000000000000187\n",
      "      - 9.00000000000002\n",
      "      - -0.599999999999972\n",
      "      - -8.99999999999998\n",
      "      - -7.499999999999991\n",
      "      - 6.6000000000000085\n",
      "      - -1.499999999999989\n",
      "      - -8.39999999999999\n",
      "      - -17.99999999999999\n",
      "      - -8.399999999999983\n",
      "      - 0.6000000000000167\n",
      "      - 4.800000000000004\n",
      "      - -9.299999999999983\n",
      "      - 1.2000000000000146\n",
      "      - 3.3000000000000034\n",
      "      - -4.499999999999973\n",
      "      - -10.499999999999993\n",
      "      - 9.900000000000006\n",
      "      - -9.299999999999988\n",
      "      - -16.499999999999975\n",
      "      - 2.373101715136272e-14\n",
      "      - -3.8999999999999884\n",
      "      - -2.0999999999999757\n",
      "      - -10.499999999999975\n",
      "      - -3.2999999999999923\n",
      "      - -4.799999999999989\n",
      "      - 5.100000000000005\n",
      "      - 17.999999999999993\n",
      "      - 14.70000000000003\n",
      "      - 9.90000000000002\n",
      "      - -13.499999999999979\n",
      "      - 4.500000000000021\n",
      "      - 3.600000000000009\n",
      "      - -0.8999999999999924\n",
      "      - 12.59999999999999\n",
      "      - -6.0\n",
      "      - 6.600000000000007\n",
      "      - 6.300000000000015\n",
      "      - 1.5000000000000178\n",
      "      - 2.100000000000028\n",
      "      - -2.3999999999999884\n",
      "      - -13.499999999999988\n",
      "      - -1.799999999999982\n",
      "      - -4.799999999999992\n",
      "      - 4.500000000000028\n",
      "      - 4.200000000000015\n",
      "      - 10.499999999999998\n",
      "      - -1.4999999999999862\n",
      "      - 5.400000000000025\n",
      "      - -7.199999999999976\n",
      "      - -0.29999999999998084\n",
      "      - 0.3000000000000077\n",
      "      - -1.4999999999999802\n",
      "      - -11.099999999999982\n",
      "      - 1.970645868709653e-15\n",
      "      - 3.6000000000000187\n",
      "      - 1.199999999999997\n",
      "      - 6.600000000000028\n",
      "      - 6.300000000000027\n",
      "      - 1.5000000000000164\n",
      "      policy_policy1_reward:\n",
      "      - 2.5\n",
      "      - -8.0\n",
      "      - 4.0\n",
      "      - -2.0\n",
      "      - -11.0\n",
      "      - 29.5\n",
      "      - -7.0\n",
      "      - 0.0\n",
      "      - -23.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - -2.0\n",
      "      - 13.5\n",
      "      - -11.0\n",
      "      - 7.5\n",
      "      - 7.5\n",
      "      - 8.0\n",
      "      - -8.5\n",
      "      - 23.5\n",
      "      - -20.5\n",
      "      - 9.5\n",
      "      - 20.5\n",
      "      - -2.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 4.0\n",
      "      - -6.5\n",
      "      - -3.5\n",
      "      - -8.0\n",
      "      - 15.5\n",
      "      - 10.5\n",
      "      - 14.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      - -15.5\n",
      "      - 15.5\n",
      "      - 2.5\n",
      "      - 0.5\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 13.0\n",
      "      - 19.0\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 15.5\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - -8.0\n",
      "      - 0.5\n",
      "      - 9.5\n",
      "      - 11.5\n",
      "      - -1.5\n",
      "      - 9.0\n",
      "      - 10.0\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 15.5\n",
      "      - -1.5\n",
      "      - -6.5\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - -0.5\n",
      "      - 4.5\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 28.0\n",
      "      - 17.0\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 14.5\n",
      "      - 12.5\n",
      "      - 8.0\n",
      "      - 21.5\n",
      "      - 4.0\n",
      "      - 10.0\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 6.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - -5.5\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999432\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999988\n",
      "      - -6.699999999999988\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000025\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999985\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.6\n",
      "      - -6.69999999999999\n",
      "      - -7.799999999999987\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: -0.09999999999999432\n",
      "    policy_reward_mean:\n",
      "      policy1: 5.915\n",
      "      policy2: -8.503999999999984\n",
      "    policy_reward_min:\n",
      "      policy1: -23.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13552177446035424\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05860204124008158\n",
      "      mean_inference_ms: 1.433000186182224\n",
      "      mean_raw_obs_processing_ms: 0.2667972405002905\n",
      "  time_since_restore: 48.78333568572998\n",
      "  time_this_iter_s: 17.575217723846436\n",
      "  time_total_s: 48.78333568572998\n",
      "  timers:\n",
      "    learn_throughput: 481.476\n",
      "    learn_time_ms: 8307.794\n",
      "    synch_weights_time_ms: 4.18\n",
      "    training_iteration_time_ms: 16253.943\n",
      "  timestamp: 1658917105\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 3\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 30000\n",
      "    num_env_steps_sampled: 15000\n",
      "    num_env_steps_trained: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.999999999999936\n",
      "  episode_reward_mean: 0.5520000000000089\n",
      "  episode_reward_min: -16.49999999999998\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 150\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.245719313621521\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012123588472604752\n",
      "          model: {}\n",
      "          policy_loss: -0.03945505991578102\n",
      "          total_loss: 6.732685089111328\n",
      "          vf_explained_var: 0.057131607085466385\n",
      "          vf_loss: 6.769715785980225\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2171440124511719\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012180752120912075\n",
      "          model: {}\n",
      "          policy_loss: -0.038172416388988495\n",
      "          total_loss: 2.431185007095337\n",
      "          vf_explained_var: 0.11617200821638107\n",
      "          vf_loss: 2.468139410018921\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 30000\n",
      "    num_env_steps_sampled: 15000\n",
      "    num_env_steps_trained: 15000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 30000\n",
      "  num_agent_steps_trained: 30000\n",
      "  num_env_steps_sampled: 15000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 15000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.22500000000001\n",
      "    ram_util_percent: 60.315\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 4.300000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.945\n",
      "    policy2: -7.392999999999986\n",
      "  policy_reward_min:\n",
      "    policy1: -9.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1247266459180989\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05554331796068063\n",
      "    mean_inference_ms: 1.3132740137038739\n",
      "    mean_raw_obs_processing_ms: 0.24509612292301888\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.999999999999936\n",
      "    episode_reward_mean: 0.5520000000000089\n",
      "    episode_reward_min: -16.49999999999998\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -8.999999999999986\n",
      "      - 4.500000000000019\n",
      "      - -14.09999999999999\n",
      "      - 10.200000000000026\n",
      "      - 0.6000000000000059\n",
      "      - -14.399999999999983\n",
      "      - 18.000000000000007\n",
      "      - -8.99999999999998\n",
      "      - -1.4999999999999833\n",
      "      - -9.899999999999975\n",
      "      - 5.999999999999947\n",
      "      - 5.9674487573602164e-15\n",
      "      - -7.499999999999972\n",
      "      - 8.999999999999966\n",
      "      - -7.499999999999993\n",
      "      - -2.3999999999999884\n",
      "      - 7.499999999999973\n",
      "      - 3.3\n",
      "      - -12.899999999999997\n",
      "      - 2.700000000000022\n",
      "      - -5.699999999999989\n",
      "      - 7.500000000000028\n",
      "      - -2.9999999999999782\n",
      "      - 1.5000000000000187\n",
      "      - 2.100000000000014\n",
      "      - 7.50000000000003\n",
      "      - -13.499999999999986\n",
      "      - 10.499999999999947\n",
      "      - -5.999999999999998\n",
      "      - -1.4999999999999867\n",
      "      - 1.200000000000022\n",
      "      - 10.499999999999975\n",
      "      - 5.700000000000012\n",
      "      - 3.600000000000024\n",
      "      - -2.999999999999985\n",
      "      - 7.800000000000011\n",
      "      - 13.500000000000016\n",
      "      - -16.49999999999998\n",
      "      - -11.69999999999998\n",
      "      - -3.9000000000000017\n",
      "      - -3.2999999999999954\n",
      "      - 5.700000000000028\n",
      "      - -10.49999999999998\n",
      "      - 6.900000000000027\n",
      "      - -12.299999999999972\n",
      "      - -2.999999999999979\n",
      "      - 6.00000000000003\n",
      "      - 2.700000000000021\n",
      "      - -1.1999999999999744\n",
      "      - 1.8290924330699454e-14\n",
      "      - -0.5999999999999935\n",
      "      - 23.999999999999936\n",
      "      - 2.099999999999989\n",
      "      - -8.99999999999999\n",
      "      - -12.29999999999998\n",
      "      - 10.500000000000007\n",
      "      - 8.100000000000001\n",
      "      - 6.000000000000023\n",
      "      - 5.4000000000000306\n",
      "      - -3.300000000000005\n",
      "      - -9.299999999999985\n",
      "      - -2.999999999999992\n",
      "      - -2.09999999999999\n",
      "      - 2.4000000000000186\n",
      "      - -4.499999999999977\n",
      "      - 2.70000000000003\n",
      "      - -7.199999999999983\n",
      "      - -2.6999999999999815\n",
      "      - -3.599999999999979\n",
      "      - -0.29999999999998683\n",
      "      - 8.999999999999925\n",
      "      - -2.399999999999989\n",
      "      - 11.700000000000019\n",
      "      - -1.1999999999999755\n",
      "      - -1.8000000000000291\n",
      "      - -7.499999999999977\n",
      "      - 1.8000000000000025\n",
      "      - 10.500000000000027\n",
      "      - -10.49999999999998\n",
      "      - 13.499999999999991\n",
      "      - -14.999999999999975\n",
      "      - 8.999999999999957\n",
      "      - -8.699999999999985\n",
      "      - 8.400000000000006\n",
      "      - -4.499999999999991\n",
      "      - 9.000000000000012\n",
      "      - 2.1000000000000023\n",
      "      - 2.4000000000000203\n",
      "      - -1.7999999999999967\n",
      "      - 3.300000000000023\n",
      "      - 8.10000000000003\n",
      "      - 0.9000000000000082\n",
      "      - 14.699999999999996\n",
      "      - 8.400000000000025\n",
      "      - 6.300000000000022\n",
      "      - -1.4999999999999871\n",
      "      - -7.7999999999999785\n",
      "      - 7.500000000000025\n",
      "      - 20.6999999999999\n",
      "      - -3.8999999999999795\n",
      "      policy_policy1_reward:\n",
      "      - 1.0\n",
      "      - 14.5\n",
      "      - -8.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - -5.5\n",
      "      - 28.0\n",
      "      - 1.0\n",
      "      - 3.0\n",
      "      - -1.0\n",
      "      - 10.5\n",
      "      - 10.0\n",
      "      - 2.5\n",
      "      - 19.0\n",
      "      - 2.5\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 4.5\n",
      "      - -4.0\n",
      "      - 10.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 7.0\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      - -9.0\n",
      "      - 20.5\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - -6.5\n",
      "      - -5.0\n",
      "      - -0.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - -0.5\n",
      "      - 7.0\n",
      "      - -4.5\n",
      "      - 7.0\n",
      "      - 16.0\n",
      "      - 5.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 34.0\n",
      "      - 11.0\n",
      "      - 1.0\n",
      "      - -4.5\n",
      "      - 20.5\n",
      "      - 17.0\n",
      "      - 10.5\n",
      "      - 11.0\n",
      "      - 4.5\n",
      "      - -7.0\n",
      "      - -4.0\n",
      "      - 3.5\n",
      "      - 8.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - -0.5\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - -4.5\n",
      "      - 19.5\n",
      "      - 5.5\n",
      "      - 6.0\n",
      "      - -3.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - -0.5\n",
      "      - 23.5\n",
      "      - -5.0\n",
      "      - 19.0\n",
      "      - -2.0\n",
      "      - 8.5\n",
      "      - 5.5\n",
      "      - 13.5\n",
      "      - 11.0\n",
      "      - 8.0\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999986\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000001\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -3.3999999999999893\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.299999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000043\n",
      "      - 0.9999999999999948\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000057\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - 2.10000000000001\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999986\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999995\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000331\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999991\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999895\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -7.79999999999999\n",
      "      - -0.1000000000000042\n",
      "      - 4.300000000000008\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 4.300000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.945\n",
      "      policy2: -7.392999999999986\n",
      "    policy_reward_min:\n",
      "      policy1: -9.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1247266459180989\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05554331796068063\n",
      "      mean_inference_ms: 1.3132740137038739\n",
      "      mean_raw_obs_processing_ms: 0.24509612292301888\n",
      "  time_since_restore: 56.55104970932007\n",
      "  time_this_iter_s: 13.308756113052368\n",
      "  time_total_s: 56.55104970932007\n",
      "  timers:\n",
      "    learn_throughput: 538.601\n",
      "    learn_time_ms: 5569.983\n",
      "    synch_weights_time_ms: 3.538\n",
      "    training_iteration_time_ms: 11304.639\n",
      "  timestamp: 1658917106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 5\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 30000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 30000\n",
      "    num_env_steps_sampled: 15000\n",
      "    num_env_steps_trained: 15000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.599999999999987\n",
      "  episode_reward_mean: -1.7069999999999872\n",
      "  episode_reward_min: -25.500000000000057\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 150\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2237616777420044\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016725990921258926\n",
      "          model: {}\n",
      "          policy_loss: -0.052370473742485046\n",
      "          total_loss: 6.456605911254883\n",
      "          vf_explained_var: 0.1525229811668396\n",
      "          vf_loss: 6.501450061798096\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2176802158355713\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018923189491033554\n",
      "          model: {}\n",
      "          policy_loss: -0.05508580803871155\n",
      "          total_loss: 2.5223641395568848\n",
      "          vf_explained_var: 0.2008708119392395\n",
      "          vf_loss: 2.571773052215576\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 30000\n",
      "    num_env_steps_sampled: 15000\n",
      "    num_env_steps_trained: 15000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 30000\n",
      "  num_agent_steps_trained: 30000\n",
      "  num_env_steps_sampled: 15000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 15000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.66842105263158\n",
      "    ram_util_percent: 60.35263157894736\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 30.5\n",
      "    policy2: -1.1999999999999977\n",
      "  policy_reward_mean:\n",
      "    policy1: 6.445\n",
      "    policy2: -8.151999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -15.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1271693502140225\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05532596666988424\n",
      "    mean_inference_ms: 1.332378617499365\n",
      "    mean_raw_obs_processing_ms: 0.2493219856100949\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 21.599999999999987\n",
      "    episode_reward_mean: -1.7069999999999872\n",
      "    episode_reward_min: -25.500000000000057\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -25.500000000000057\n",
      "      - 6.000000000000014\n",
      "      - -4.499999999999992\n",
      "      - -5.399999999999997\n",
      "      - -19.500000000000004\n",
      "      - 1.0297318553398327e-14\n",
      "      - 1.2628786905111156e-14\n",
      "      - -5.999999999999972\n",
      "      - 4.8000000000000185\n",
      "      - 1.5000000000000195\n",
      "      - -4.499999999999981\n",
      "      - -11.699999999999976\n",
      "      - 12.600000000000009\n",
      "      - 6.411537967210279e-15\n",
      "      - -3.2999999999999923\n",
      "      - 5.700000000000006\n",
      "      - -2.999999999999978\n",
      "      - -2.9999999999999813\n",
      "      - -12.899999999999979\n",
      "      - 3.600000000000019\n",
      "      - -9.899999999999993\n",
      "      - -3.899999999999985\n",
      "      - 12.300000000000022\n",
      "      - -1.5000000000000058\n",
      "      - 9.000000000000025\n",
      "      - -6.599999999999994\n",
      "      - -16.49999999999998\n",
      "      - 2.8171909249863347e-14\n",
      "      - -12.899999999999991\n",
      "      - -2.9999999999999933\n",
      "      - 4.500000000000028\n",
      "      - -18.299999999999983\n",
      "      - -5.9999999999999885\n",
      "      - -0.2999999999999997\n",
      "      - -8.99999999999999\n",
      "      - -8.999999999999988\n",
      "      - -8.099999999999985\n",
      "      - 5.999999999999997\n",
      "      - -14.399999999999975\n",
      "      - -6.299999999999978\n",
      "      - 10.200000000000026\n",
      "      - 12.000000000000032\n",
      "      - 21.599999999999987\n",
      "      - -8.699999999999974\n",
      "      - 5.10000000000001\n",
      "      - 2.9999999999999862\n",
      "      - -0.29999999999997684\n",
      "      - -1.4999999999999782\n",
      "      - -1.7999999999999763\n",
      "      - -11.999999999999975\n",
      "      - -0.2999999999999755\n",
      "      - 2.1000000000000107\n",
      "      - -10.799999999999985\n",
      "      - 10.200000000000006\n",
      "      - 1.5000000000000173\n",
      "      - -3.2999999999999776\n",
      "      - 12.90000000000003\n",
      "      - -5.69999999999998\n",
      "      - 7.500000000000021\n",
      "      - 2.1000000000000028\n",
      "      - -15.299999999999976\n",
      "      - -0.8999999999999915\n",
      "      - 4.8000000000000185\n",
      "      - -2.3999999999999897\n",
      "      - -11.999999999999982\n",
      "      - -1.19999999999999\n",
      "      - 7.743805596760467e-15\n",
      "      - 0.6000000000000166\n",
      "      - 7.500000000000014\n",
      "      - 10.500000000000005\n",
      "      - -8.999999999999982\n",
      "      - -2.3999999999999795\n",
      "      - -13.49999999999998\n",
      "      - -1.4999999999999991\n",
      "      - 16.499999999999986\n",
      "      - -5.999999999999979\n",
      "      - 13.20000000000003\n",
      "      - 2.7000000000000184\n",
      "      - -13.799999999999974\n",
      "      - 10.800000000000002\n",
      "      - 10.19999999999993\n",
      "      - -5.699999999999983\n",
      "      - -5.69999999999999\n",
      "      - 15.000000000000028\n",
      "      - -9.299999999999981\n",
      "      - 0.30000000000001914\n",
      "      - -10.19999999999998\n",
      "      - 1.500000000000019\n",
      "      - -4.499999999999979\n",
      "      - -14.99999999999998\n",
      "      - -13.200000000000005\n",
      "      - 2.9999999999999925\n",
      "      - -7.499999999999989\n",
      "      - -4.499999999999973\n",
      "      - 0.30000000000002536\n",
      "      - 6.599999999999996\n",
      "      - 6.30000000000002\n",
      "      - -10.199999999999982\n",
      "      - 2.70000000000003\n",
      "      - -4.199999999999983\n",
      "      policy_policy1_reward:\n",
      "      - -15.5\n",
      "      - 16.0\n",
      "      - 5.5\n",
      "      - 3.5\n",
      "      - -15.0\n",
      "      - 10.0\n",
      "      - 10.0\n",
      "      - 4.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - 21.5\n",
      "      - 4.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - 7.0\n",
      "      - 7.0\n",
      "      - -4.0\n",
      "      - 12.5\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - -1.0\n",
      "      - -6.5\n",
      "      - 10.0\n",
      "      - -4.0\n",
      "      - 1.5\n",
      "      - 9.0\n",
      "      - -10.5\n",
      "      - 4.0\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 1.5\n",
      "      - 18.0\n",
      "      - 22.0\n",
      "      - 30.5\n",
      "      - -2.0\n",
      "      - 14.0\n",
      "      - 13.0\n",
      "      - 7.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - -2.0\n",
      "      - 7.5\n",
      "      - 11.0\n",
      "      - -3.0\n",
      "      - 18.0\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 18.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - -7.5\n",
      "      - 8.0\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - -2.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 9.5\n",
      "      - 17.5\n",
      "      - 20.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -3.5\n",
      "      - 8.5\n",
      "      - 26.5\n",
      "      - 4.0\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      - -6.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - 25.0\n",
      "      - -1.5\n",
      "      - 7.0\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - -6.5\n",
      "      - 13.0\n",
      "      - -3.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - -9.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999989\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -6.699999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000002\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.6\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000035\n",
      "      - -2.3000000000000047\n",
      "      - -6.699999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -4.49999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.1999999999999977\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999987\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 30.5\n",
      "      policy2: -1.1999999999999977\n",
      "    policy_reward_mean:\n",
      "      policy1: 6.445\n",
      "      policy2: -8.151999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -15.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1271693502140225\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05532596666988424\n",
      "      mean_inference_ms: 1.332378617499365\n",
      "      mean_raw_obs_processing_ms: 0.2493219856100949\n",
      "  time_since_restore: 56.950748920440674\n",
      "  time_this_iter_s: 13.39316987991333\n",
      "  time_total_s: 56.950748920440674\n",
      "  timers:\n",
      "    learn_throughput: 540.662\n",
      "    learn_time_ms: 5548.755\n",
      "    synch_weights_time_ms: 3.177\n",
      "    training_iteration_time_ms: 11385.534\n",
      "  timestamp: 1658917106\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 15000\n",
      "  training_iteration: 5\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_env_steps_sampled: 18000\n",
      "    num_env_steps_trained: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-39\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.999999999999936\n",
      "  episode_reward_mean: 1.1130000000000086\n",
      "  episode_reward_min: -16.49999999999998\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 180\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2147157192230225\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011954664252698421\n",
      "          model: {}\n",
      "          policy_loss: -0.04047074168920517\n",
      "          total_loss: 6.785300254821777\n",
      "          vf_explained_var: 0.1677219122648239\n",
      "          vf_loss: 6.823379993438721\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.176808476448059\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012550078332424164\n",
      "          model: {}\n",
      "          policy_loss: -0.04062055051326752\n",
      "          total_loss: 2.7570269107818604\n",
      "          vf_explained_var: 0.17053455114364624\n",
      "          vf_loss: 2.7963924407958984\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_env_steps_sampled: 18000\n",
      "    num_env_steps_trained: 18000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 36000\n",
      "  num_env_steps_sampled: 18000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 18000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.82222222222222\n",
      "    ram_util_percent: 60.07222222222222\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 4.300000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.055\n",
      "    policy2: -6.941999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -10.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13166760400528393\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0584977797089925\n",
      "    mean_inference_ms: 1.3875186929254397\n",
      "    mean_raw_obs_processing_ms: 0.2586257197316241\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.999999999999936\n",
      "    episode_reward_mean: 1.1130000000000086\n",
      "    episode_reward_min: -16.49999999999998\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 1.200000000000022\n",
      "      - 10.499999999999975\n",
      "      - 5.700000000000012\n",
      "      - 3.600000000000024\n",
      "      - -2.999999999999985\n",
      "      - 7.800000000000011\n",
      "      - 13.500000000000016\n",
      "      - -16.49999999999998\n",
      "      - -11.69999999999998\n",
      "      - -3.9000000000000017\n",
      "      - -3.2999999999999954\n",
      "      - 5.700000000000028\n",
      "      - -10.49999999999998\n",
      "      - 6.900000000000027\n",
      "      - -12.299999999999972\n",
      "      - -2.999999999999979\n",
      "      - 6.00000000000003\n",
      "      - 2.700000000000021\n",
      "      - -1.1999999999999744\n",
      "      - 1.8290924330699454e-14\n",
      "      - -0.5999999999999935\n",
      "      - 23.999999999999936\n",
      "      - 2.099999999999989\n",
      "      - -8.99999999999999\n",
      "      - -12.29999999999998\n",
      "      - 10.500000000000007\n",
      "      - 8.100000000000001\n",
      "      - 6.000000000000023\n",
      "      - 5.4000000000000306\n",
      "      - -3.300000000000005\n",
      "      - -9.299999999999985\n",
      "      - -2.999999999999992\n",
      "      - -2.09999999999999\n",
      "      - 2.4000000000000186\n",
      "      - -4.499999999999977\n",
      "      - 2.70000000000003\n",
      "      - -7.199999999999983\n",
      "      - -2.6999999999999815\n",
      "      - -3.599999999999979\n",
      "      - -0.29999999999998683\n",
      "      - 8.999999999999925\n",
      "      - -2.399999999999989\n",
      "      - 11.700000000000019\n",
      "      - -1.1999999999999755\n",
      "      - -1.8000000000000291\n",
      "      - -7.499999999999977\n",
      "      - 1.8000000000000025\n",
      "      - 10.500000000000027\n",
      "      - -10.49999999999998\n",
      "      - 13.499999999999991\n",
      "      - -14.999999999999975\n",
      "      - 8.999999999999957\n",
      "      - -8.699999999999985\n",
      "      - 8.400000000000006\n",
      "      - -4.499999999999991\n",
      "      - 9.000000000000012\n",
      "      - 2.1000000000000023\n",
      "      - 2.4000000000000203\n",
      "      - -1.7999999999999967\n",
      "      - 3.300000000000023\n",
      "      - 8.10000000000003\n",
      "      - 0.9000000000000082\n",
      "      - 14.699999999999996\n",
      "      - 8.400000000000025\n",
      "      - 6.300000000000022\n",
      "      - -1.4999999999999871\n",
      "      - -7.7999999999999785\n",
      "      - 7.500000000000025\n",
      "      - 20.6999999999999\n",
      "      - -3.8999999999999795\n",
      "      - 4.80000000000002\n",
      "      - 9.000000000000032\n",
      "      - -1.499999999999978\n",
      "      - -4.499999999999979\n",
      "      - 14.399999999999983\n",
      "      - -9.89999999999999\n",
      "      - -3.899999999999994\n",
      "      - -12.299999999999981\n",
      "      - -6.299999999999997\n",
      "      - -13.499999999999991\n",
      "      - -0.8999999999999923\n",
      "      - 6.000000000000016\n",
      "      - 4.799999999999999\n",
      "      - -7.499999999999983\n",
      "      - 0.6000000000000255\n",
      "      - 10.499999999999996\n",
      "      - 3.0000000000000293\n",
      "      - -7.799999999999985\n",
      "      - 6.300000000000026\n",
      "      - 0.6000000000000273\n",
      "      - -6.899999999999979\n",
      "      - -1.799999999999982\n",
      "      - 2.699999999999996\n",
      "      - 10.79999999999996\n",
      "      - 7.799999999999958\n",
      "      - 3.6000000000000094\n",
      "      - 13.499999999999963\n",
      "      - -1.5000000000000202\n",
      "      - 3.5999999999999956\n",
      "      - 5.400000000000009\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - -6.5\n",
      "      - -5.0\n",
      "      - -0.5\n",
      "      - 4.5\n",
      "      - 13.5\n",
      "      - -0.5\n",
      "      - 7.0\n",
      "      - -4.5\n",
      "      - 7.0\n",
      "      - 16.0\n",
      "      - 5.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 34.0\n",
      "      - 11.0\n",
      "      - 1.0\n",
      "      - -4.5\n",
      "      - 20.5\n",
      "      - 17.0\n",
      "      - 10.5\n",
      "      - 11.0\n",
      "      - 4.5\n",
      "      - -7.0\n",
      "      - -4.0\n",
      "      - 3.5\n",
      "      - 8.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - -0.5\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - -4.5\n",
      "      - 19.5\n",
      "      - 5.5\n",
      "      - 6.0\n",
      "      - -3.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - -0.5\n",
      "      - 23.5\n",
      "      - -5.0\n",
      "      - 19.0\n",
      "      - -2.0\n",
      "      - 8.5\n",
      "      - 5.5\n",
      "      - 13.5\n",
      "      - 11.0\n",
      "      - 8.0\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 11.5\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 20.0\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - -10.0\n",
      "      - 1.5\n",
      "      - -3.5\n",
      "      - 8.0\n",
      "      - 10.5\n",
      "      - 11.5\n",
      "      - 2.5\n",
      "      - 9.5\n",
      "      - 20.5\n",
      "      - 13.0\n",
      "      - 0.0\n",
      "      - 13.0\n",
      "      - 9.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 12.0\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 8.5\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000004\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -3.3999999999999893\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.299999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000043\n",
      "      - 0.9999999999999948\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000057\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - 2.10000000000001\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999986\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999995\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000331\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999991\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999895\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -7.79999999999999\n",
      "      - -0.1000000000000042\n",
      "      - 4.300000000000008\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999985\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.2999999999999954\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999988\n",
      "      - -1.1999999999999909\n",
      "      - -6.699999999999984\n",
      "      - -3.400000000000003\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000331\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 4.300000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.055\n",
      "      policy2: -6.941999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -10.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13166760400528393\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0584977797089925\n",
      "      mean_inference_ms: 1.3875186929254397\n",
      "      mean_raw_obs_processing_ms: 0.2586257197316241\n",
      "  time_since_restore: 69.24620151519775\n",
      "  time_this_iter_s: 12.695151805877686\n",
      "  time_total_s: 69.24620151519775\n",
      "  timers:\n",
      "    learn_throughput: 509.626\n",
      "    learn_time_ms: 5886.674\n",
      "    synch_weights_time_ms: 3.693\n",
      "    training_iteration_time_ms: 11534.547\n",
      "  timestamp: 1658917119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 6\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 36000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_env_steps_sampled: 18000\n",
      "    num_env_steps_trained: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-39\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 21.599999999999987\n",
      "  episode_reward_mean: 0.09300000000001467\n",
      "  episode_reward_min: -18.299999999999983\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 180\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1833819150924683\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01807878352701664\n",
      "          model: {}\n",
      "          policy_loss: -0.055433738976716995\n",
      "          total_loss: 6.95738410949707\n",
      "          vf_explained_var: 0.09151872992515564\n",
      "          vf_loss: 7.0046820640563965\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1541551351547241\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019486304372549057\n",
      "          model: {}\n",
      "          policy_loss: -0.052715957164764404\n",
      "          total_loss: 2.3363165855407715\n",
      "          vf_explained_var: 0.21255145967006683\n",
      "          vf_loss: 2.3831865787506104\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 36000\n",
      "    num_env_steps_sampled: 18000\n",
      "    num_env_steps_trained: 18000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 36000\n",
      "  num_agent_steps_trained: 36000\n",
      "  num_env_steps_sampled: 18000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 18000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.694736842105264\n",
      "    ram_util_percent: 60.08947368421052\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 30.5\n",
      "    policy2: 1.000000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.97\n",
      "    policy2: -7.876999999999986\n",
      "  policy_reward_min:\n",
      "    policy1: -10.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.134552170318365\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05831943031728648\n",
      "    mean_inference_ms: 1.410926168397911\n",
      "    mean_raw_obs_processing_ms: 0.26289810588033513\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 21.599999999999987\n",
      "    episode_reward_mean: 0.09300000000001467\n",
      "    episode_reward_min: -18.299999999999983\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.500000000000028\n",
      "      - -18.299999999999983\n",
      "      - -5.9999999999999885\n",
      "      - -0.2999999999999997\n",
      "      - -8.99999999999999\n",
      "      - -8.999999999999988\n",
      "      - -8.099999999999985\n",
      "      - 5.999999999999997\n",
      "      - -14.399999999999975\n",
      "      - -6.299999999999978\n",
      "      - 10.200000000000026\n",
      "      - 12.000000000000032\n",
      "      - 21.599999999999987\n",
      "      - -8.699999999999974\n",
      "      - 5.10000000000001\n",
      "      - 2.9999999999999862\n",
      "      - -0.29999999999997684\n",
      "      - -1.4999999999999782\n",
      "      - -1.7999999999999763\n",
      "      - -11.999999999999975\n",
      "      - -0.2999999999999755\n",
      "      - 2.1000000000000107\n",
      "      - -10.799999999999985\n",
      "      - 10.200000000000006\n",
      "      - 1.5000000000000173\n",
      "      - -3.2999999999999776\n",
      "      - 12.90000000000003\n",
      "      - -5.69999999999998\n",
      "      - 7.500000000000021\n",
      "      - 2.1000000000000028\n",
      "      - -15.299999999999976\n",
      "      - -0.8999999999999915\n",
      "      - 4.8000000000000185\n",
      "      - -2.3999999999999897\n",
      "      - -11.999999999999982\n",
      "      - -1.19999999999999\n",
      "      - 7.743805596760467e-15\n",
      "      - 0.6000000000000166\n",
      "      - 7.500000000000014\n",
      "      - 10.500000000000005\n",
      "      - -8.999999999999982\n",
      "      - -2.3999999999999795\n",
      "      - -13.49999999999998\n",
      "      - -1.4999999999999991\n",
      "      - 16.499999999999986\n",
      "      - -5.999999999999979\n",
      "      - 13.20000000000003\n",
      "      - 2.7000000000000184\n",
      "      - -13.799999999999974\n",
      "      - 10.800000000000002\n",
      "      - 10.19999999999993\n",
      "      - -5.699999999999983\n",
      "      - -5.69999999999999\n",
      "      - 15.000000000000028\n",
      "      - -9.299999999999981\n",
      "      - 0.30000000000001914\n",
      "      - -10.19999999999998\n",
      "      - 1.500000000000019\n",
      "      - -4.499999999999979\n",
      "      - -14.99999999999998\n",
      "      - -13.200000000000005\n",
      "      - 2.9999999999999925\n",
      "      - -7.499999999999989\n",
      "      - -4.499999999999973\n",
      "      - 0.30000000000002536\n",
      "      - 6.599999999999996\n",
      "      - 6.30000000000002\n",
      "      - -10.199999999999982\n",
      "      - 2.70000000000003\n",
      "      - -4.199999999999983\n",
      "      - -2.9999999999999813\n",
      "      - 4.500000000000014\n",
      "      - 2.7000000000000157\n",
      "      - -16.49999999999999\n",
      "      - 15.600000000000025\n",
      "      - 4.500000000000025\n",
      "      - 8.400000000000025\n",
      "      - 2.100000000000028\n",
      "      - 17.100000000000023\n",
      "      - -5.9999999999999964\n",
      "      - 12.30000000000002\n",
      "      - 5.700000000000026\n",
      "      - -2.399999999999976\n",
      "      - 16.49999999999997\n",
      "      - 1.5000000000000244\n",
      "      - -3.899999999999985\n",
      "      - -6.299999999999985\n",
      "      - 3.899999999999984\n",
      "      - 5.100000000000023\n",
      "      - 1.800000000000014\n",
      "      - 8.100000000000012\n",
      "      - 16.500000000000014\n",
      "      - -5.699999999999983\n",
      "      - -1.7999999999999852\n",
      "      - -5.399999999999981\n",
      "      - -5.399999999999981\n",
      "      - -1.4999999999999734\n",
      "      - -1.4999999999999831\n",
      "      - 12.599999999999998\n",
      "      - 2.4000000000000132\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - -10.5\n",
      "      - 4.0\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 1.5\n",
      "      - 18.0\n",
      "      - 22.0\n",
      "      - 30.5\n",
      "      - -2.0\n",
      "      - 14.0\n",
      "      - 13.0\n",
      "      - 7.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - -2.0\n",
      "      - 7.5\n",
      "      - 11.0\n",
      "      - -3.0\n",
      "      - 18.0\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 18.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - -7.5\n",
      "      - 8.0\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - -2.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 9.5\n",
      "      - 17.5\n",
      "      - 20.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -3.5\n",
      "      - 8.5\n",
      "      - 26.5\n",
      "      - 4.0\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      - -6.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - 25.0\n",
      "      - -1.5\n",
      "      - 7.0\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - -6.5\n",
      "      - 13.0\n",
      "      - -3.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - -9.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 10.5\n",
      "      - -6.5\n",
      "      - 19.0\n",
      "      - 14.5\n",
      "      - 14.0\n",
      "      - 11.0\n",
      "      - 26.0\n",
      "      - -7.0\n",
      "      - 19.0\n",
      "      - 13.5\n",
      "      - 6.5\n",
      "      - 26.5\n",
      "      - 11.5\n",
      "      - -0.5\n",
      "      - 1.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 8.5\n",
      "      - 17.0\n",
      "      - 26.5\n",
      "      - 1.0\n",
      "      - 6.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 8.5\n",
      "      - 3.0\n",
      "      - 21.5\n",
      "      - 8.0\n",
      "      policy_policy2_reward:\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.6\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000035\n",
      "      - -2.3000000000000047\n",
      "      - -6.699999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -4.49999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.1999999999999977\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999985\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 1.000000000000008\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999897\n",
      "      - -7.799999999999987\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 30.5\n",
      "      policy2: 1.000000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.97\n",
      "      policy2: -7.876999999999986\n",
      "    policy_reward_min:\n",
      "      policy1: -10.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.134552170318365\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05831943031728648\n",
      "      mean_inference_ms: 1.410926168397911\n",
      "      mean_raw_obs_processing_ms: 0.26289810588033513\n",
      "  time_since_restore: 69.8666160106659\n",
      "  time_this_iter_s: 12.91586709022522\n",
      "  time_total_s: 69.8666160106659\n",
      "  timers:\n",
      "    learn_throughput: 509.519\n",
      "    learn_time_ms: 5887.902\n",
      "    synch_weights_time_ms: 3.339\n",
      "    training_iteration_time_ms: 11639.249\n",
      "  timestamp: 1658917119\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 6\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 40000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_env_steps_sampled: 20000\n",
      "    num_env_steps_trained: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.99999999999991\n",
      "  episode_reward_mean: 1.338000000000013\n",
      "  episode_reward_min: -17.999999999999986\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 200\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2533438205718994\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01136587094515562\n",
      "          model: {}\n",
      "          policy_loss: -0.03583327680826187\n",
      "          total_loss: 6.822192192077637\n",
      "          vf_explained_var: 0.1494927853345871\n",
      "          vf_loss: 6.855752468109131\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2331674098968506\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01223585195839405\n",
      "          model: {}\n",
      "          policy_loss: -0.03885067626833916\n",
      "          total_loss: 2.5632517337799072\n",
      "          vf_explained_var: 0.2022281289100647\n",
      "          vf_loss: 2.5996556282043457\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_env_steps_sampled: 20000\n",
      "    num_env_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 40000\n",
      "  num_env_steps_sampled: 20000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 20000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.871999999999986\n",
      "    ram_util_percent: 60.196\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 43.0\n",
      "    policy2: 7.600000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.335\n",
      "    policy2: -6.996999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -20.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.130522247711924\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05692460279197574\n",
      "    mean_inference_ms: 1.3712908765968064\n",
      "    mean_raw_obs_processing_ms: 0.25742358023057216\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.99999999999991\n",
      "    episode_reward_mean: 1.338000000000013\n",
      "    episode_reward_min: -17.999999999999986\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 1.5000000000000182\n",
      "      - -2.999999999999978\n",
      "      - -1.499999999999992\n",
      "      - 5.400000000000016\n",
      "      - 0.6000000000000221\n",
      "      - 11.100000000000032\n",
      "      - 2.0999999999999757\n",
      "      - 0.6000000000000023\n",
      "      - 19.500000000000018\n",
      "      - -8.399999999999979\n",
      "      - 7.7999999999999705\n",
      "      - 3.3000000000000247\n",
      "      - -5.3999999999999755\n",
      "      - -2.099999999999996\n",
      "      - -8.999999999999977\n",
      "      - -7.499999999999977\n",
      "      - 6.900000000000015\n",
      "      - -8.999999999999996\n",
      "      - 1.2000000000000146\n",
      "      - 0.6000000000000113\n",
      "      - -5.999999999999972\n",
      "      - 6.000000000000005\n",
      "      - -17.999999999999986\n",
      "      - -1.5000000000000036\n",
      "      - -1.7999999999999745\n",
      "      - -2.099999999999978\n",
      "      - -8.699999999999982\n",
      "      - -3.8999999999999817\n",
      "      - 6.600000000000014\n",
      "      - -9.89999999999998\n",
      "      - -0.29999999999998306\n",
      "      - 0.6000000000000046\n",
      "      - 12.00000000000003\n",
      "      - -13.199999999999989\n",
      "      - 11.100000000000017\n",
      "      - 4.50000000000003\n",
      "      - -3.8999999999999813\n",
      "      - -8.999999999999975\n",
      "      - 19.799999999999926\n",
      "      - -6.2999999999999705\n",
      "      - 6.300000000000031\n",
      "      - -1.49999999999998\n",
      "      - 9.900000000000023\n",
      "      - 20.099999999999966\n",
      "      - 3.6000000000000227\n",
      "      - -4.499999999999973\n",
      "      - -8.399999999999983\n",
      "      - -4.199999999999983\n",
      "      - 3.600000000000026\n",
      "      - 6.00000000000003\n",
      "      - -3.6000000000000014\n",
      "      - -0.5999999999999898\n",
      "      - 6.000000000000028\n",
      "      - -7.7999999999999865\n",
      "      - 0.9000000000000165\n",
      "      - -12.899999999999977\n",
      "      - 0.899999999999964\n",
      "      - 1.800000000000018\n",
      "      - -4.199999999999978\n",
      "      - -12.299999999999983\n",
      "      - 32.99999999999991\n",
      "      - 6.299999999999995\n",
      "      - 18.899999999999963\n",
      "      - 3.6000000000000085\n",
      "      - 3.900000000000025\n",
      "      - 3.3000000000000282\n",
      "      - -2.099999999999986\n",
      "      - 2.1000000000000183\n",
      "      - 1.5000000000000155\n",
      "      - -8.099999999999978\n",
      "      - 4.800000000000029\n",
      "      - 0.3000000000000129\n",
      "      - -15.299999999999978\n",
      "      - -1.1999999999999846\n",
      "      - -7.199999999999978\n",
      "      - 7.500000000000027\n",
      "      - 1.5000000000000258\n",
      "      - 11.400000000000007\n",
      "      - -4.4999999999999885\n",
      "      - 3.000000000000021\n",
      "      - -10.499999999999975\n",
      "      - -4.499999999999993\n",
      "      - 4.200000000000021\n",
      "      - 10.799999999999981\n",
      "      - 10.800000000000027\n",
      "      - -0.2999999999999702\n",
      "      - 18.000000000000007\n",
      "      - 5.7000000000000135\n",
      "      - 1.7999999999999972\n",
      "      - 5.700000000000026\n",
      "      - 7.200000000000014\n",
      "      - 0.9000000000000271\n",
      "      - 7.500000000000025\n",
      "      - 18.599999999999987\n",
      "      - -13.499999999999972\n",
      "      - -9.899999999999975\n",
      "      - 9.300000000000022\n",
      "      - 14.100000000000017\n",
      "      - -3.6000000000000276\n",
      "      - 9.000000000000027\n",
      "      policy_policy1_reward:\n",
      "      - 0.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 20.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 29.5\n",
      "      - 0.5\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      - 10.5\n",
      "      - -8.0\n",
      "      - 8.5\n",
      "      - 0.5\n",
      "      - 3.5\n",
      "      - -2.0\n",
      "      - 5.0\n",
      "      - 15.5\n",
      "      - -6.5\n",
      "      - 7.5\n",
      "      - 9.5\n",
      "      - 16.5\n",
      "      - -6.5\n",
      "      - 14.5\n",
      "      - 14.5\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 26.5\n",
      "      - 1.5\n",
      "      - 13.0\n",
      "      - 3.0\n",
      "      - 15.5\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 10.5\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 6.5\n",
      "      - -20.5\n",
      "      - 6.5\n",
      "      - 8.5\n",
      "      - 2.5\n",
      "      - -4.5\n",
      "      - 43.0\n",
      "      - 13.0\n",
      "      - 24.5\n",
      "      - 12.5\n",
      "      - 9.5\n",
      "      - 10.0\n",
      "      - 3.5\n",
      "      - 11.0\n",
      "      - 6.0\n",
      "      - -2.5\n",
      "      - 11.5\n",
      "      - 7.0\n",
      "      - -7.5\n",
      "      - 0.0\n",
      "      - -6.0\n",
      "      - 17.5\n",
      "      - 11.5\n",
      "      - 6.0\n",
      "      - 5.5\n",
      "      - 7.5\n",
      "      - -0.5\n",
      "      - 5.5\n",
      "      - 12.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - 7.5\n",
      "      - 28.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 8.0\n",
      "      - 15.0\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 27.5\n",
      "      - -3.5\n",
      "      - -1.0\n",
      "      - 16.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 19.0\n",
      "      policy_policy2_reward:\n",
      "      - 0.999999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000007\n",
      "      - -5.59999999999999\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -3.3999999999999972\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999987\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999983\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999897\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -5.599999999999987\n",
      "      - 7.600000000000005\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -6.699999999999984\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000004\n",
      "      - -5.599999999999991\n",
      "      - -6.69999999999999\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000042\n",
      "      - -1.199999999999996\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 43.0\n",
      "      policy2: 7.600000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.335\n",
      "      policy2: -6.996999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -20.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.130522247711924\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05692460279197574\n",
      "      mean_inference_ms: 1.3712908765968064\n",
      "      mean_raw_obs_processing_ms: 0.25742358023057216\n",
      "  time_since_restore: 76.01157188415527\n",
      "  time_this_iter_s: 17.218204021453857\n",
      "  time_total_s: 76.01157188415527\n",
      "  timers:\n",
      "    learn_throughput: 520.327\n",
      "    learn_time_ms: 7687.469\n",
      "    synch_weights_time_ms: 3.811\n",
      "    training_iteration_time_ms: 15195.17\n",
      "  timestamp: 1658917122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 32000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_env_steps_sampled: 16000\n",
      "    num_env_steps_trained: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-42\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.399999999999935\n",
      "  episode_reward_mean: -0.029999999999988914\n",
      "  episode_reward_min: -23.099999999999994\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 160\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2437326908111572\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020543571561574936\n",
      "          model: {}\n",
      "          policy_loss: -0.05002003535628319\n",
      "          total_loss: 6.145132541656494\n",
      "          vf_explained_var: 0.2256942093372345\n",
      "          vf_loss: 6.188989162445068\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2382687330245972\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01910250447690487\n",
      "          model: {}\n",
      "          policy_loss: -0.047617357224226\n",
      "          total_loss: 2.7126526832580566\n",
      "          vf_explained_var: 0.231859490275383\n",
      "          vf_loss: 2.7564494609832764\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 32000\n",
      "    num_env_steps_sampled: 16000\n",
      "    num_env_steps_trained: 16000\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 32000\n",
      "  num_agent_steps_trained: 32000\n",
      "  num_env_steps_sampled: 16000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 16000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.5625\n",
      "    ram_util_percent: 60.19583333333333\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: 2.0999999999999948\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.715\n",
      "    policy2: -7.744999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -19.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13987065159325368\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06055758257654839\n",
      "    mean_inference_ms: 1.4762631287601318\n",
      "    mean_raw_obs_processing_ms: 0.2758300407151302\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.399999999999935\n",
      "    episode_reward_mean: -0.029999999999988914\n",
      "    episode_reward_min: -23.099999999999994\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 3.0000000000000187\n",
      "      - 9.00000000000002\n",
      "      - -0.599999999999972\n",
      "      - -8.99999999999998\n",
      "      - -7.499999999999991\n",
      "      - 6.6000000000000085\n",
      "      - -1.499999999999989\n",
      "      - -8.39999999999999\n",
      "      - -17.99999999999999\n",
      "      - -8.399999999999983\n",
      "      - 0.6000000000000167\n",
      "      - 4.800000000000004\n",
      "      - -9.299999999999983\n",
      "      - 1.2000000000000146\n",
      "      - 3.3000000000000034\n",
      "      - -4.499999999999973\n",
      "      - -10.499999999999993\n",
      "      - 9.900000000000006\n",
      "      - -9.299999999999988\n",
      "      - -16.499999999999975\n",
      "      - 2.373101715136272e-14\n",
      "      - -3.8999999999999884\n",
      "      - -2.0999999999999757\n",
      "      - -10.499999999999975\n",
      "      - -3.2999999999999923\n",
      "      - -4.799999999999989\n",
      "      - 5.100000000000005\n",
      "      - 17.999999999999993\n",
      "      - 14.70000000000003\n",
      "      - 9.90000000000002\n",
      "      - -13.499999999999979\n",
      "      - 4.500000000000021\n",
      "      - 3.600000000000009\n",
      "      - -0.8999999999999924\n",
      "      - 12.59999999999999\n",
      "      - -6.0\n",
      "      - 6.600000000000007\n",
      "      - 6.300000000000015\n",
      "      - 1.5000000000000178\n",
      "      - 2.100000000000028\n",
      "      - -2.3999999999999884\n",
      "      - -13.499999999999988\n",
      "      - -1.799999999999982\n",
      "      - -4.799999999999992\n",
      "      - 4.500000000000028\n",
      "      - 4.200000000000015\n",
      "      - 10.499999999999998\n",
      "      - -1.4999999999999862\n",
      "      - 5.400000000000025\n",
      "      - -7.199999999999976\n",
      "      - -0.29999999999998084\n",
      "      - 0.3000000000000077\n",
      "      - -1.4999999999999802\n",
      "      - -11.099999999999982\n",
      "      - 1.970645868709653e-15\n",
      "      - 3.6000000000000187\n",
      "      - 1.199999999999997\n",
      "      - 6.600000000000028\n",
      "      - 6.300000000000027\n",
      "      - 1.5000000000000164\n",
      "      - 23.399999999999935\n",
      "      - 1.800000000000022\n",
      "      - 7.200000000000026\n",
      "      - 0.3000000000000209\n",
      "      - -0.2999999999999764\n",
      "      - 15.000000000000004\n",
      "      - -1.7999999999999783\n",
      "      - -0.8999999999999945\n",
      "      - -2.999999999999985\n",
      "      - 4.500000000000011\n",
      "      - -4.199999999999988\n",
      "      - -7.799999999999974\n",
      "      - -17.399999999999984\n",
      "      - 4.199999999999984\n",
      "      - 1.4999999999999498\n",
      "      - -8.999999999999991\n",
      "      - 3.0000000000000204\n",
      "      - 0.6000000000000197\n",
      "      - 5.700000000000022\n",
      "      - 6.0\n",
      "      - -8.999999999999979\n",
      "      - 7.799999999999994\n",
      "      - -0.2999999999999948\n",
      "      - 1.2000000000000175\n",
      "      - 3.0000000000000084\n",
      "      - -23.099999999999994\n",
      "      - -0.29999999999997284\n",
      "      - -4.799999999999975\n",
      "      - -2.999999999999985\n",
      "      - -3.2999999999999816\n",
      "      - -6.899999999999988\n",
      "      - -2.9999999999999742\n",
      "      - 3.900000000000016\n",
      "      - 7.799999999999967\n",
      "      - 1.2000000000000237\n",
      "      - -5.4\n",
      "      - 19.4999999999999\n",
      "      - 1.5000000000000053\n",
      "      - 4.5000000000000115\n",
      "      - 2.10000000000002\n",
      "      policy_policy1_reward:\n",
      "      - 13.0\n",
      "      - 19.0\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 2.5\n",
      "      - 15.5\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - -8.0\n",
      "      - 0.5\n",
      "      - 9.5\n",
      "      - 11.5\n",
      "      - -1.5\n",
      "      - 9.0\n",
      "      - 10.0\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 15.5\n",
      "      - -1.5\n",
      "      - -6.5\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - -0.5\n",
      "      - 4.5\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 28.0\n",
      "      - 17.0\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 14.5\n",
      "      - 12.5\n",
      "      - 8.0\n",
      "      - 21.5\n",
      "      - 4.0\n",
      "      - 10.0\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 6.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - -5.5\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 29.0\n",
      "      - 3.0\n",
      "      - 15.0\n",
      "      - 7.0\n",
      "      - 7.5\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 2.5\n",
      "      - 0.0\n",
      "      - -19.5\n",
      "      - 12.0\n",
      "      - 11.5\n",
      "      - 1.0\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - -17.5\n",
      "      - 7.5\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 4.5\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 4.0\n",
      "      - 14.5\n",
      "      - 9.0\n",
      "      - 3.5\n",
      "      - 29.5\n",
      "      - 11.5\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999988\n",
      "      - -6.699999999999988\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000025\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999985\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.6\n",
      "      - -6.69999999999999\n",
      "      - -7.799999999999987\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -1.200000000000003\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - 2.0999999999999948\n",
      "      - -7.799999999999988\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999973\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999993\n",
      "      - -7.799999999999982\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -7.79999999999999\n",
      "      - -2.29999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999637\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: 2.0999999999999948\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.715\n",
      "      policy2: -7.744999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -19.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13987065159325368\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06055758257654839\n",
      "      mean_inference_ms: 1.4762631287601318\n",
      "      mean_raw_obs_processing_ms: 0.2758300407151302\n",
      "  time_since_restore: 65.96104168891907\n",
      "  time_this_iter_s: 17.177706003189087\n",
      "  time_total_s: 65.96104168891907\n",
      "  timers:\n",
      "    learn_throughput: 469.154\n",
      "    learn_time_ms: 8525.984\n",
      "    synch_weights_time_ms: 3.796\n",
      "    training_iteration_time_ms: 16483.283\n",
      "  timestamp: 1658917122\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 4\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 42000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 42000\n",
      "    num_env_steps_sampled: 21000\n",
      "    num_env_steps_trained: 21000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 27.59999999999996\n",
      "  episode_reward_mean: 2.0850000000000044\n",
      "  episode_reward_min: -14.999999999999975\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 210\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1770386695861816\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013167980127036572\n",
      "          model: {}\n",
      "          policy_loss: -0.04606029763817787\n",
      "          total_loss: 7.035675525665283\n",
      "          vf_explained_var: 0.14874276518821716\n",
      "          vf_loss: 7.079102993011475\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1389542818069458\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011300456710159779\n",
      "          model: {}\n",
      "          policy_loss: -0.03998418152332306\n",
      "          total_loss: 2.798161506652832\n",
      "          vf_explained_var: 0.0871126726269722\n",
      "          vf_loss: 2.8370156288146973\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 42000\n",
      "    num_env_steps_sampled: 21000\n",
      "    num_env_steps_trained: 21000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 42000\n",
      "  num_agent_steps_trained: 42000\n",
      "  num_env_steps_sampled: 21000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 21000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.982352941176465\n",
      "    ram_util_percent: 60.04705882352941\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 36.5\n",
      "    policy2: 5.400000000000011\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.785\n",
      "    policy2: -6.699999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -10.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13416752748374705\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05965562427006534\n",
      "    mean_inference_ms: 1.415117267498357\n",
      "    mean_raw_obs_processing_ms: 0.2637912111273913\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 27.59999999999996\n",
      "    episode_reward_mean: 2.0850000000000044\n",
      "    episode_reward_min: -14.999999999999975\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -9.299999999999985\n",
      "      - -2.999999999999992\n",
      "      - -2.09999999999999\n",
      "      - 2.4000000000000186\n",
      "      - -4.499999999999977\n",
      "      - 2.70000000000003\n",
      "      - -7.199999999999983\n",
      "      - -2.6999999999999815\n",
      "      - -3.599999999999979\n",
      "      - -0.29999999999998683\n",
      "      - 8.999999999999925\n",
      "      - -2.399999999999989\n",
      "      - 11.700000000000019\n",
      "      - -1.1999999999999755\n",
      "      - -1.8000000000000291\n",
      "      - -7.499999999999977\n",
      "      - 1.8000000000000025\n",
      "      - 10.500000000000027\n",
      "      - -10.49999999999998\n",
      "      - 13.499999999999991\n",
      "      - -14.999999999999975\n",
      "      - 8.999999999999957\n",
      "      - -8.699999999999985\n",
      "      - 8.400000000000006\n",
      "      - -4.499999999999991\n",
      "      - 9.000000000000012\n",
      "      - 2.1000000000000023\n",
      "      - 2.4000000000000203\n",
      "      - -1.7999999999999967\n",
      "      - 3.300000000000023\n",
      "      - 8.10000000000003\n",
      "      - 0.9000000000000082\n",
      "      - 14.699999999999996\n",
      "      - 8.400000000000025\n",
      "      - 6.300000000000022\n",
      "      - -1.4999999999999871\n",
      "      - -7.7999999999999785\n",
      "      - 7.500000000000025\n",
      "      - 20.6999999999999\n",
      "      - -3.8999999999999795\n",
      "      - 4.80000000000002\n",
      "      - 9.000000000000032\n",
      "      - -1.499999999999978\n",
      "      - -4.499999999999979\n",
      "      - 14.399999999999983\n",
      "      - -9.89999999999999\n",
      "      - -3.899999999999994\n",
      "      - -12.299999999999981\n",
      "      - -6.299999999999997\n",
      "      - -13.499999999999991\n",
      "      - -0.8999999999999923\n",
      "      - 6.000000000000016\n",
      "      - 4.799999999999999\n",
      "      - -7.499999999999983\n",
      "      - 0.6000000000000255\n",
      "      - 10.499999999999996\n",
      "      - 3.0000000000000293\n",
      "      - -7.799999999999985\n",
      "      - 6.300000000000026\n",
      "      - 0.6000000000000273\n",
      "      - -6.899999999999979\n",
      "      - -1.799999999999982\n",
      "      - 2.699999999999996\n",
      "      - 10.79999999999996\n",
      "      - 7.799999999999958\n",
      "      - 3.6000000000000094\n",
      "      - 13.499999999999963\n",
      "      - -1.5000000000000202\n",
      "      - 3.5999999999999956\n",
      "      - 5.400000000000009\n",
      "      - -6.599999999999988\n",
      "      - -9.299999999999983\n",
      "      - -0.2999999999999826\n",
      "      - 9.599999999999962\n",
      "      - 14.100000000000025\n",
      "      - -3.600000000000012\n",
      "      - 3.6000000000000143\n",
      "      - 19.199999999999953\n",
      "      - 0.6000000000000058\n",
      "      - -10.499999999999979\n",
      "      - 2.1000000000000214\n",
      "      - -4.499999999999979\n",
      "      - 6.000000000000002\n",
      "      - 27.59999999999996\n",
      "      - 10.799999999999983\n",
      "      - 19.199999999999896\n",
      "      - 9.600000000000021\n",
      "      - -5.999999999999987\n",
      "      - 2.7727820040013285e-14\n",
      "      - 4.500000000000012\n",
      "      - 6.599999999999975\n",
      "      - -13.500000000000005\n",
      "      - 12.600000000000032\n",
      "      - 12.599999999999955\n",
      "      - 10.19999999999997\n",
      "      - -2.9999999999999876\n",
      "      - 3.5999999999999797\n",
      "      - 8.700000000000031\n",
      "      - -5.099999999999985\n",
      "      - 7.500000000000021\n",
      "      policy_policy1_reward:\n",
      "      - -7.0\n",
      "      - -4.0\n",
      "      - 3.5\n",
      "      - 8.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - -0.5\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 7.5\n",
      "      - 19.0\n",
      "      - -4.5\n",
      "      - 19.5\n",
      "      - 5.5\n",
      "      - 6.0\n",
      "      - -3.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - -0.5\n",
      "      - 23.5\n",
      "      - -5.0\n",
      "      - 19.0\n",
      "      - -2.0\n",
      "      - 8.5\n",
      "      - 5.5\n",
      "      - 13.5\n",
      "      - 11.0\n",
      "      - 8.0\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 11.5\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 20.0\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - -10.0\n",
      "      - 1.5\n",
      "      - -3.5\n",
      "      - 8.0\n",
      "      - 10.5\n",
      "      - 11.5\n",
      "      - 2.5\n",
      "      - 9.5\n",
      "      - 20.5\n",
      "      - 13.0\n",
      "      - 0.0\n",
      "      - 13.0\n",
      "      - 9.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 12.0\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 8.5\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 27.0\n",
      "      - 9.5\n",
      "      - -0.5\n",
      "      - 11.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - 36.5\n",
      "      - 17.5\n",
      "      - 27.0\n",
      "      - 13.0\n",
      "      - -1.5\n",
      "      - 4.5\n",
      "      - 14.5\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 16.5\n",
      "      - -10.5\n",
      "      - 17.5\n",
      "      policy_policy2_reward:\n",
      "      - -2.3000000000000043\n",
      "      - 0.9999999999999948\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000057\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - 2.10000000000001\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999986\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999995\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000331\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999991\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999895\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -7.79999999999999\n",
      "      - -0.1000000000000042\n",
      "      - 4.300000000000008\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999985\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.2999999999999954\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999988\n",
      "      - -1.1999999999999909\n",
      "      - -6.699999999999984\n",
      "      - -3.400000000000003\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -5.5999999999999925\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000047\n",
      "      - -3.4000000000000017\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999996\n",
      "      - -3.399999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -3.3999999999999826\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.79999999999999\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 36.5\n",
      "      policy2: 5.400000000000011\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.785\n",
      "      policy2: -6.699999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -10.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13416752748374705\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05965562427006534\n",
      "      mean_inference_ms: 1.415117267498357\n",
      "      mean_raw_obs_processing_ms: 0.2637912111273913\n",
      "  time_since_restore: 80.91998052597046\n",
      "  time_this_iter_s: 11.673779010772705\n",
      "  time_total_s: 80.91998052597046\n",
      "  timers:\n",
      "    learn_throughput: 515.499\n",
      "    learn_time_ms: 5819.6\n",
      "    synch_weights_time_ms: 3.653\n",
      "    training_iteration_time_ms: 11553.244\n",
      "  timestamp: 1658917130\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 7\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 42000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 42000\n",
      "    num_env_steps_sampled: 21000\n",
      "    num_env_steps_trained: 21000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-18-51\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 29.999999999999936\n",
      "  episode_reward_mean: 1.0110000000000092\n",
      "  episode_reward_min: -22.799999999999997\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 210\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1489176750183105\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01841074414551258\n",
      "          model: {}\n",
      "          policy_loss: -0.05802270025014877\n",
      "          total_loss: 6.7759833335876465\n",
      "          vf_explained_var: 0.016382412984967232\n",
      "          vf_loss: 6.825721740722656\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.120417833328247\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02074545808136463\n",
      "          model: {}\n",
      "          policy_loss: -0.05930214375257492\n",
      "          total_loss: 2.261990785598755\n",
      "          vf_explained_var: 0.25701653957366943\n",
      "          vf_loss: 2.3150691986083984\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 42000\n",
      "    num_env_steps_sampled: 21000\n",
      "    num_env_steps_trained: 21000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 42000\n",
      "  num_agent_steps_trained: 42000\n",
      "  num_env_steps_sampled: 21000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 21000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.23529411764706\n",
      "    ram_util_percent: 60.05294117647059\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 40.0\n",
      "    policy2: 1.000000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.69\n",
      "    policy2: -7.678999999999986\n",
      "  policy_reward_min:\n",
      "    policy1: -15.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1371031285427616\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.059372026575052514\n",
      "    mean_inference_ms: 1.4381952867378434\n",
      "    mean_raw_obs_processing_ms: 0.2678627391411467\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 29.999999999999936\n",
      "    episode_reward_mean: 1.0110000000000092\n",
      "    episode_reward_min: -22.799999999999997\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -15.299999999999976\n",
      "      - -0.8999999999999915\n",
      "      - 4.8000000000000185\n",
      "      - -2.3999999999999897\n",
      "      - -11.999999999999982\n",
      "      - -1.19999999999999\n",
      "      - 7.743805596760467e-15\n",
      "      - 0.6000000000000166\n",
      "      - 7.500000000000014\n",
      "      - 10.500000000000005\n",
      "      - -8.999999999999982\n",
      "      - -2.3999999999999795\n",
      "      - -13.49999999999998\n",
      "      - -1.4999999999999991\n",
      "      - 16.499999999999986\n",
      "      - -5.999999999999979\n",
      "      - 13.20000000000003\n",
      "      - 2.7000000000000184\n",
      "      - -13.799999999999974\n",
      "      - 10.800000000000002\n",
      "      - 10.19999999999993\n",
      "      - -5.699999999999983\n",
      "      - -5.69999999999999\n",
      "      - 15.000000000000028\n",
      "      - -9.299999999999981\n",
      "      - 0.30000000000001914\n",
      "      - -10.19999999999998\n",
      "      - 1.500000000000019\n",
      "      - -4.499999999999979\n",
      "      - -14.99999999999998\n",
      "      - -13.200000000000005\n",
      "      - 2.9999999999999925\n",
      "      - -7.499999999999989\n",
      "      - -4.499999999999973\n",
      "      - 0.30000000000002536\n",
      "      - 6.599999999999996\n",
      "      - 6.30000000000002\n",
      "      - -10.199999999999982\n",
      "      - 2.70000000000003\n",
      "      - -4.199999999999983\n",
      "      - -2.9999999999999813\n",
      "      - 4.500000000000014\n",
      "      - 2.7000000000000157\n",
      "      - -16.49999999999999\n",
      "      - 15.600000000000025\n",
      "      - 4.500000000000025\n",
      "      - 8.400000000000025\n",
      "      - 2.100000000000028\n",
      "      - 17.100000000000023\n",
      "      - -5.9999999999999964\n",
      "      - 12.30000000000002\n",
      "      - 5.700000000000026\n",
      "      - -2.399999999999976\n",
      "      - 16.49999999999997\n",
      "      - 1.5000000000000244\n",
      "      - -3.899999999999985\n",
      "      - -6.299999999999985\n",
      "      - 3.899999999999984\n",
      "      - 5.100000000000023\n",
      "      - 1.800000000000014\n",
      "      - 8.100000000000012\n",
      "      - 16.500000000000014\n",
      "      - -5.699999999999983\n",
      "      - -1.7999999999999852\n",
      "      - -5.399999999999981\n",
      "      - -5.399999999999981\n",
      "      - -1.4999999999999734\n",
      "      - -1.4999999999999831\n",
      "      - 12.599999999999998\n",
      "      - 2.4000000000000132\n",
      "      - -9.899999999999995\n",
      "      - 4.799999999999963\n",
      "      - 1.500000000000006\n",
      "      - 3.0000000000000164\n",
      "      - 7.800000000000027\n",
      "      - -22.799999999999997\n",
      "      - -13.799999999999972\n",
      "      - -16.799999999999983\n",
      "      - 18.29999999999994\n",
      "      - 13.799999999999978\n",
      "      - 24.599999999999945\n",
      "      - 29.999999999999936\n",
      "      - 4.2000000000000215\n",
      "      - 9.900000000000023\n",
      "      - 13.499999999999902\n",
      "      - -4.4999999999999964\n",
      "      - -10.499999999999991\n",
      "      - -0.2999999999999782\n",
      "      - 8.699999999999958\n",
      "      - -2.3999999999999826\n",
      "      - -10.799999999999994\n",
      "      - 3.599999999999994\n",
      "      - 10.800000000000004\n",
      "      - 2.1000000000000245\n",
      "      - 4.500000000000028\n",
      "      - 7.500000000000025\n",
      "      - 0.6000000000000117\n",
      "      - 7.80000000000002\n",
      "      - -2.999999999999981\n",
      "      - -7.499999999999979\n",
      "      policy_policy1_reward:\n",
      "      - -7.5\n",
      "      - 8.0\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - -2.0\n",
      "      - 5.5\n",
      "      - 10.0\n",
      "      - 9.5\n",
      "      - 17.5\n",
      "      - 20.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - -3.5\n",
      "      - 8.5\n",
      "      - 26.5\n",
      "      - 4.0\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      - -6.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 1.0\n",
      "      - 1.0\n",
      "      - 25.0\n",
      "      - -1.5\n",
      "      - 7.0\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 5.5\n",
      "      - -5.0\n",
      "      - -6.5\n",
      "      - 13.0\n",
      "      - -3.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - -9.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 10.5\n",
      "      - -6.5\n",
      "      - 19.0\n",
      "      - 14.5\n",
      "      - 14.0\n",
      "      - 11.0\n",
      "      - 26.0\n",
      "      - -7.0\n",
      "      - 19.0\n",
      "      - 13.5\n",
      "      - 6.5\n",
      "      - 26.5\n",
      "      - 11.5\n",
      "      - -0.5\n",
      "      - 1.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 8.5\n",
      "      - 17.0\n",
      "      - 26.5\n",
      "      - 1.0\n",
      "      - 6.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 8.5\n",
      "      - 3.0\n",
      "      - 21.5\n",
      "      - 8.0\n",
      "      - -1.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 7.5\n",
      "      - 14.5\n",
      "      - -15.0\n",
      "      - -6.0\n",
      "      - -14.5\n",
      "      - 25.0\n",
      "      - 20.5\n",
      "      - 28.0\n",
      "      - 40.0\n",
      "      - 12.0\n",
      "      - 15.5\n",
      "      - 23.5\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      - 6.5\n",
      "      - -3.0\n",
      "      - 12.5\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 9.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 2.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000035\n",
      "      - -2.3000000000000047\n",
      "      - -6.699999999999993\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -4.49999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.1999999999999977\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999985\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 1.000000000000008\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999897\n",
      "      - -7.799999999999987\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999984\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -2.3000000000000056\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999982\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 40.0\n",
      "      policy2: 1.000000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.69\n",
      "      policy2: -7.678999999999986\n",
      "    policy_reward_min:\n",
      "      policy1: -15.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1371031285427616\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059372026575052514\n",
      "      mean_inference_ms: 1.4381952867378434\n",
      "      mean_raw_obs_processing_ms: 0.2678627391411467\n",
      "  time_since_restore: 81.45852184295654\n",
      "  time_this_iter_s: 11.59190583229065\n",
      "  time_total_s: 81.45852184295654\n",
      "  timers:\n",
      "    learn_throughput: 515.142\n",
      "    learn_time_ms: 5823.639\n",
      "    synch_weights_time_ms: 3.33\n",
      "    training_iteration_time_ms: 11631.198\n",
      "  timestamp: 1658917131\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 21000\n",
      "  training_iteration: 7\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 40000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_env_steps_sampled: 20000\n",
      "    num_env_steps_trained: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-00\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.399999999999935\n",
      "  episode_reward_mean: 0.5610000000000079\n",
      "  episode_reward_min: -23.099999999999994\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 200\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1998289823532104\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015405802987515926\n",
      "          model: {}\n",
      "          policy_loss: -0.0443233996629715\n",
      "          total_loss: 6.75216817855835\n",
      "          vf_explained_var: 0.18040746450424194\n",
      "          vf_loss: 6.7895588874816895\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.2102311849594116\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020154906436800957\n",
      "          model: {}\n",
      "          policy_loss: -0.05268534645438194\n",
      "          total_loss: 1.9629422426223755\n",
      "          vf_explained_var: 0.34062403440475464\n",
      "          vf_loss: 2.0115966796875\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 40000\n",
      "    num_env_steps_sampled: 20000\n",
      "    num_env_steps_trained: 20000\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 40000\n",
      "  num_agent_steps_trained: 40000\n",
      "  num_env_steps_sampled: 20000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 20000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.208\n",
      "    ram_util_percent: 59.952\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 29.5\n",
      "    policy2: 2.0999999999999948\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.185\n",
      "    policy2: -7.623999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -19.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14271535987456796\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0617729953413377\n",
      "    mean_inference_ms: 1.5031030897522266\n",
      "    mean_raw_obs_processing_ms: 0.2817068114691493\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.399999999999935\n",
      "    episode_reward_mean: 0.5610000000000079\n",
      "    episode_reward_min: -23.099999999999994\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -2.3999999999999884\n",
      "      - -13.499999999999988\n",
      "      - -1.799999999999982\n",
      "      - -4.799999999999992\n",
      "      - 4.500000000000028\n",
      "      - 4.200000000000015\n",
      "      - 10.499999999999998\n",
      "      - -1.4999999999999862\n",
      "      - 5.400000000000025\n",
      "      - -7.199999999999976\n",
      "      - -0.29999999999998084\n",
      "      - 0.3000000000000077\n",
      "      - -1.4999999999999802\n",
      "      - -11.099999999999982\n",
      "      - 1.970645868709653e-15\n",
      "      - 3.6000000000000187\n",
      "      - 1.199999999999997\n",
      "      - 6.600000000000028\n",
      "      - 6.300000000000027\n",
      "      - 1.5000000000000164\n",
      "      - 23.399999999999935\n",
      "      - 1.800000000000022\n",
      "      - 7.200000000000026\n",
      "      - 0.3000000000000209\n",
      "      - -0.2999999999999764\n",
      "      - 15.000000000000004\n",
      "      - -1.7999999999999783\n",
      "      - -0.8999999999999945\n",
      "      - -2.999999999999985\n",
      "      - 4.500000000000011\n",
      "      - -4.199999999999988\n",
      "      - -7.799999999999974\n",
      "      - -17.399999999999984\n",
      "      - 4.199999999999984\n",
      "      - 1.4999999999999498\n",
      "      - -8.999999999999991\n",
      "      - 3.0000000000000204\n",
      "      - 0.6000000000000197\n",
      "      - 5.700000000000022\n",
      "      - 6.0\n",
      "      - -8.999999999999979\n",
      "      - 7.799999999999994\n",
      "      - -0.2999999999999948\n",
      "      - 1.2000000000000175\n",
      "      - 3.0000000000000084\n",
      "      - -23.099999999999994\n",
      "      - -0.29999999999997284\n",
      "      - -4.799999999999975\n",
      "      - -2.999999999999985\n",
      "      - -3.2999999999999816\n",
      "      - -6.899999999999988\n",
      "      - -2.9999999999999742\n",
      "      - 3.900000000000016\n",
      "      - 7.799999999999967\n",
      "      - 1.2000000000000237\n",
      "      - -5.4\n",
      "      - 19.4999999999999\n",
      "      - 1.5000000000000053\n",
      "      - 4.5000000000000115\n",
      "      - 2.10000000000002\n",
      "      - -1.4999999999999774\n",
      "      - -8.399999999999979\n",
      "      - 5.700000000000031\n",
      "      - -17.4\n",
      "      - -3.8999999999999813\n",
      "      - -2.0999999999999774\n",
      "      - 8.699999999999958\n",
      "      - 5.100000000000016\n",
      "      - -6.599999999999984\n",
      "      - -8.399999999999983\n",
      "      - 13.499999999999945\n",
      "      - 13.199999999999948\n",
      "      - 13.199999999999955\n",
      "      - 9.000000000000032\n",
      "      - -0.8999999999999833\n",
      "      - 9.600000000000026\n",
      "      - 8.400000000000002\n",
      "      - 3.600000000000017\n",
      "      - 5.099999999999975\n",
      "      - 6.3000000000000185\n",
      "      - 7.7999999999999545\n",
      "      - -1.7999999999999927\n",
      "      - -1.4999999999999871\n",
      "      - -11.39999999999998\n",
      "      - -7.499999999999984\n",
      "      - 3.6000000000000294\n",
      "      - -10.499999999999975\n",
      "      - -15.29999999999998\n",
      "      - 4.499999999999954\n",
      "      - -4.799999999999978\n",
      "      - 8.400000000000013\n",
      "      - 12.299999999999997\n",
      "      - 12.600000000000009\n",
      "      - -5.699999999999987\n",
      "      - 0.3000000000000076\n",
      "      - -0.8999999999999848\n",
      "      - -7.499999999999972\n",
      "      - 6.300000000000004\n",
      "      - -2.699999999999986\n",
      "      - -4.499999999999984\n",
      "      policy_policy1_reward:\n",
      "      - 6.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - -5.5\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 11.5\n",
      "      - 29.0\n",
      "      - 3.0\n",
      "      - 15.0\n",
      "      - 7.0\n",
      "      - 7.5\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 2.5\n",
      "      - 0.0\n",
      "      - -19.5\n",
      "      - 12.0\n",
      "      - 11.5\n",
      "      - 1.0\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - -17.5\n",
      "      - 7.5\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 4.5\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 4.0\n",
      "      - 14.5\n",
      "      - 9.0\n",
      "      - 3.5\n",
      "      - 29.5\n",
      "      - 11.5\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      - 8.5\n",
      "      - 0.5\n",
      "      - 13.5\n",
      "      - -8.5\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - 16.5\n",
      "      - 14.0\n",
      "      - -1.0\n",
      "      - 0.5\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 21.0\n",
      "      - 19.0\n",
      "      - 8.0\n",
      "      - 18.5\n",
      "      - 14.0\n",
      "      - 12.5\n",
      "      - 14.0\n",
      "      - 13.0\n",
      "      - 14.5\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - -2.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - -0.5\n",
      "      - -7.5\n",
      "      - 9.0\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 1.0\n",
      "      - 7.0\n",
      "      - 8.0\n",
      "      - 2.5\n",
      "      - 13.0\n",
      "      - 4.0\n",
      "      - 5.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.6\n",
      "      - -6.69999999999999\n",
      "      - -7.799999999999987\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -1.200000000000003\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - 2.0999999999999948\n",
      "      - -7.799999999999988\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999973\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999993\n",
      "      - -7.799999999999982\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -7.79999999999999\n",
      "      - -2.29999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999637\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -5.6\n",
      "      - -7.7999999999999865\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999993\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999995\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999982\n",
      "      - -6.699999999999987\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.5\n",
      "      policy2: 2.0999999999999948\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.185\n",
      "      policy2: -7.623999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -19.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14271535987456796\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0617729953413377\n",
      "      mean_inference_ms: 1.5031030897522266\n",
      "      mean_raw_obs_processing_ms: 0.2817068114691493\n",
      "  time_since_restore: 83.48143482208252\n",
      "  time_this_iter_s: 17.520393133163452\n",
      "  time_total_s: 83.48143482208252\n",
      "  timers:\n",
      "    learn_throughput: 471.665\n",
      "    learn_time_ms: 8480.59\n",
      "    synch_weights_time_ms: 3.669\n",
      "    training_iteration_time_ms: 16689.989\n",
      "  timestamp: 1658917140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 5\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 48000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-00\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.99999999999991\n",
      "  episode_reward_mean: 2.8080000000000105\n",
      "  episode_reward_min: -15.299999999999978\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 240\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2165471315383911\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0130231361836195\n",
      "          model: {}\n",
      "          policy_loss: -0.03955047205090523\n",
      "          total_loss: 6.581253528594971\n",
      "          vf_explained_var: 0.16812795400619507\n",
      "          vf_loss: 6.618199825286865\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.2016520500183105\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013423670083284378\n",
      "          model: {}\n",
      "          policy_loss: -0.0391361266374588\n",
      "          total_loss: 2.195582151412964\n",
      "          vf_explained_var: 0.31700897216796875\n",
      "          vf_loss: 2.2320332527160645\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 24000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.66\n",
      "    ram_util_percent: 59.952\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 43.0\n",
      "    policy2: 7.600000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 9.09\n",
      "    policy2: -6.281999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -20.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13494488754258113\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.058882325518962594\n",
      "    mean_inference_ms: 1.416049587382271\n",
      "    mean_raw_obs_processing_ms: 0.2663344245055217\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.99999999999991\n",
      "    episode_reward_mean: 2.8080000000000105\n",
      "    episode_reward_min: -15.299999999999978\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 6.300000000000031\n",
      "      - -1.49999999999998\n",
      "      - 9.900000000000023\n",
      "      - 20.099999999999966\n",
      "      - 3.6000000000000227\n",
      "      - -4.499999999999973\n",
      "      - -8.399999999999983\n",
      "      - -4.199999999999983\n",
      "      - 3.600000000000026\n",
      "      - 6.00000000000003\n",
      "      - -3.6000000000000014\n",
      "      - -0.5999999999999898\n",
      "      - 6.000000000000028\n",
      "      - -7.7999999999999865\n",
      "      - 0.9000000000000165\n",
      "      - -12.899999999999977\n",
      "      - 0.899999999999964\n",
      "      - 1.800000000000018\n",
      "      - -4.199999999999978\n",
      "      - -12.299999999999983\n",
      "      - 32.99999999999991\n",
      "      - 6.299999999999995\n",
      "      - 18.899999999999963\n",
      "      - 3.6000000000000085\n",
      "      - 3.900000000000025\n",
      "      - 3.3000000000000282\n",
      "      - -2.099999999999986\n",
      "      - 2.1000000000000183\n",
      "      - 1.5000000000000155\n",
      "      - -8.099999999999978\n",
      "      - 4.800000000000029\n",
      "      - 0.3000000000000129\n",
      "      - -15.299999999999978\n",
      "      - -1.1999999999999846\n",
      "      - -7.199999999999978\n",
      "      - 7.500000000000027\n",
      "      - 1.5000000000000258\n",
      "      - 11.400000000000007\n",
      "      - -4.4999999999999885\n",
      "      - 3.000000000000021\n",
      "      - -10.499999999999975\n",
      "      - -4.499999999999993\n",
      "      - 4.200000000000021\n",
      "      - 10.799999999999981\n",
      "      - 10.800000000000027\n",
      "      - -0.2999999999999702\n",
      "      - 18.000000000000007\n",
      "      - 5.7000000000000135\n",
      "      - 1.7999999999999972\n",
      "      - 5.700000000000026\n",
      "      - 7.200000000000014\n",
      "      - 0.9000000000000271\n",
      "      - 7.500000000000025\n",
      "      - 18.599999999999987\n",
      "      - -13.499999999999972\n",
      "      - -9.899999999999975\n",
      "      - 9.300000000000022\n",
      "      - 14.100000000000017\n",
      "      - -3.6000000000000276\n",
      "      - 9.000000000000027\n",
      "      - -4.799999999999985\n",
      "      - 10.500000000000028\n",
      "      - -4.199999999999983\n",
      "      - 17.699999999999953\n",
      "      - 9.900000000000015\n",
      "      - 0.3000000000000218\n",
      "      - 2.700000000000018\n",
      "      - -5.099999999999985\n",
      "      - 19.19999999999996\n",
      "      - -1.7999999999999876\n",
      "      - -0.2999999999999762\n",
      "      - 0.9000000000000098\n",
      "      - 1.2000000000000246\n",
      "      - 7.799999999999983\n",
      "      - 9.899999999999968\n",
      "      - 1.500000000000011\n",
      "      - 5.10000000000003\n",
      "      - -6.299999999999978\n",
      "      - 16.80000000000001\n",
      "      - -7.4999999999999805\n",
      "      - 4.800000000000015\n",
      "      - 8.699999999999998\n",
      "      - 3.9000000000000195\n",
      "      - -11.699999999999982\n",
      "      - 2.100000000000022\n",
      "      - 6.299999999999956\n",
      "      - 2.700000000000009\n",
      "      - -2.099999999999981\n",
      "      - -2.0999999999999877\n",
      "      - 14.400000000000011\n",
      "      - 4.200000000000022\n",
      "      - 8.999999999999915\n",
      "      - 2.4000000000000274\n",
      "      - 6.5999999999999766\n",
      "      - 1.2961853812498703e-14\n",
      "      - 7.800000000000017\n",
      "      - 1.5000000000000102\n",
      "      - 3.6000000000000276\n",
      "      - 8.10000000000003\n",
      "      - -5.999999999999977\n",
      "      policy_policy1_reward:\n",
      "      - 13.0\n",
      "      - 3.0\n",
      "      - 15.5\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 10.5\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 16.0\n",
      "      - -5.5\n",
      "      - 6.5\n",
      "      - -20.5\n",
      "      - 6.5\n",
      "      - 8.5\n",
      "      - 2.5\n",
      "      - -4.5\n",
      "      - 43.0\n",
      "      - 13.0\n",
      "      - 24.5\n",
      "      - 12.5\n",
      "      - 9.5\n",
      "      - 10.0\n",
      "      - 3.5\n",
      "      - 11.0\n",
      "      - 6.0\n",
      "      - -2.5\n",
      "      - 11.5\n",
      "      - 7.0\n",
      "      - -7.5\n",
      "      - 0.0\n",
      "      - -6.0\n",
      "      - 17.5\n",
      "      - 11.5\n",
      "      - 6.0\n",
      "      - 5.5\n",
      "      - 7.5\n",
      "      - -0.5\n",
      "      - 5.5\n",
      "      - 12.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - 7.5\n",
      "      - 28.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 8.0\n",
      "      - 15.0\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 27.5\n",
      "      - -3.5\n",
      "      - -1.0\n",
      "      - 16.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 19.0\n",
      "      - 3.0\n",
      "      - 15.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 15.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 0.5\n",
      "      - 27.0\n",
      "      - 6.0\n",
      "      - 7.5\n",
      "      - 6.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 15.5\n",
      "      - 11.5\n",
      "      - 8.5\n",
      "      - 1.5\n",
      "      - 23.5\n",
      "      - 2.5\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - -5.0\n",
      "      - 11.0\n",
      "      - 13.0\n",
      "      - 5.0\n",
      "      - -2.0\n",
      "      - 3.5\n",
      "      - 20.0\n",
      "      - 12.0\n",
      "      - 13.5\n",
      "      - 2.5\n",
      "      - 10.0\n",
      "      - 4.5\n",
      "      - 9.0\n",
      "      - 6.0\n",
      "      - 12.5\n",
      "      - 17.0\n",
      "      - 4.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999983\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999897\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000065\n",
      "      - -5.599999999999987\n",
      "      - 7.600000000000005\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -6.699999999999984\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000004\n",
      "      - -5.599999999999991\n",
      "      - -6.69999999999999\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000042\n",
      "      - -1.199999999999996\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -4.499999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999905\n",
      "      - -5.599999999999999\n",
      "      - -6.699999999999995\n",
      "      - -2.300000000000004\n",
      "      - -5.599999999999995\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999987\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999972\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -5.599999999999983\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -2.300000000000003\n",
      "      - -0.10000000000000175\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999984\n",
      "      - -4.5000000000000036\n",
      "      - -0.10000000000000464\n",
      "      - -3.4000000000000044\n",
      "      - -4.499999999999997\n",
      "      - -1.199999999999994\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 43.0\n",
      "      policy2: 7.600000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 9.09\n",
      "      policy2: -6.281999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -20.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13494488754258113\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.058882325518962594\n",
      "      mean_inference_ms: 1.416049587382271\n",
      "      mean_raw_obs_processing_ms: 0.2663344245055217\n",
      "  time_since_restore: 93.60101819038391\n",
      "  time_this_iter_s: 17.589446306228638\n",
      "  time_total_s: 93.60101819038391\n",
      "  timers:\n",
      "    learn_throughput: 513.497\n",
      "    learn_time_ms: 7789.73\n",
      "    synch_weights_time_ms: 3.742\n",
      "    training_iteration_time_ms: 15592.755\n",
      "  timestamp: 1658917140\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 48000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-06\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 27.59999999999996\n",
      "  episode_reward_mean: 4.713000000000003\n",
      "  episode_reward_min: -17.99999999999998\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 240\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.127983808517456\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.010410805232822895\n",
      "          model: {}\n",
      "          policy_loss: -0.03326042741537094\n",
      "          total_loss: 7.05066442489624\n",
      "          vf_explained_var: 0.14426949620246887\n",
      "          vf_loss: 7.08184289932251\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1186281442642212\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012280963361263275\n",
      "          model: {}\n",
      "          policy_loss: -0.04304998368024826\n",
      "          total_loss: 2.585232973098755\n",
      "          vf_explained_var: 0.21568875014781952\n",
      "          vf_loss: 2.6270546913146973\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 24000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 58.97826086956522\n",
      "    ram_util_percent: 60.10434782608695\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 36.5\n",
      "    policy2: 5.400000000000011\n",
      "  policy_reward_mean:\n",
      "    policy1: 11.545\n",
      "    policy2: -6.83199999999999\n",
      "  policy_reward_min:\n",
      "    policy1: -10.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.13736298577945916\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06112930122866574\n",
      "    mean_inference_ms: 1.4497947053770246\n",
      "    mean_raw_obs_processing_ms: 0.2705924376416336\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 27.59999999999996\n",
      "    episode_reward_mean: 4.713000000000003\n",
      "    episode_reward_min: -17.99999999999998\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 8.10000000000003\n",
      "      - 0.9000000000000082\n",
      "      - 14.699999999999996\n",
      "      - 8.400000000000025\n",
      "      - 6.300000000000022\n",
      "      - -1.4999999999999871\n",
      "      - -7.7999999999999785\n",
      "      - 7.500000000000025\n",
      "      - 20.6999999999999\n",
      "      - -3.8999999999999795\n",
      "      - 4.80000000000002\n",
      "      - 9.000000000000032\n",
      "      - -1.499999999999978\n",
      "      - -4.499999999999979\n",
      "      - 14.399999999999983\n",
      "      - -9.89999999999999\n",
      "      - -3.899999999999994\n",
      "      - -12.299999999999981\n",
      "      - -6.299999999999997\n",
      "      - -13.499999999999991\n",
      "      - -0.8999999999999923\n",
      "      - 6.000000000000016\n",
      "      - 4.799999999999999\n",
      "      - -7.499999999999983\n",
      "      - 0.6000000000000255\n",
      "      - 10.499999999999996\n",
      "      - 3.0000000000000293\n",
      "      - -7.799999999999985\n",
      "      - 6.300000000000026\n",
      "      - 0.6000000000000273\n",
      "      - -6.899999999999979\n",
      "      - -1.799999999999982\n",
      "      - 2.699999999999996\n",
      "      - 10.79999999999996\n",
      "      - 7.799999999999958\n",
      "      - 3.6000000000000094\n",
      "      - 13.499999999999963\n",
      "      - -1.5000000000000202\n",
      "      - 3.5999999999999956\n",
      "      - 5.400000000000009\n",
      "      - -6.599999999999988\n",
      "      - -9.299999999999983\n",
      "      - -0.2999999999999826\n",
      "      - 9.599999999999962\n",
      "      - 14.100000000000025\n",
      "      - -3.600000000000012\n",
      "      - 3.6000000000000143\n",
      "      - 19.199999999999953\n",
      "      - 0.6000000000000058\n",
      "      - -10.499999999999979\n",
      "      - 2.1000000000000214\n",
      "      - -4.499999999999979\n",
      "      - 6.000000000000002\n",
      "      - 27.59999999999996\n",
      "      - 10.799999999999983\n",
      "      - 19.199999999999896\n",
      "      - 9.600000000000021\n",
      "      - -5.999999999999987\n",
      "      - 2.7727820040013285e-14\n",
      "      - 4.500000000000012\n",
      "      - 6.599999999999975\n",
      "      - -13.500000000000005\n",
      "      - 12.600000000000032\n",
      "      - 12.599999999999955\n",
      "      - 10.19999999999997\n",
      "      - -2.9999999999999876\n",
      "      - 3.5999999999999797\n",
      "      - 8.700000000000031\n",
      "      - -5.099999999999985\n",
      "      - 7.500000000000021\n",
      "      - 6.600000000000023\n",
      "      - 10.80000000000003\n",
      "      - 3.6000000000000116\n",
      "      - 21.599999999999895\n",
      "      - 12.600000000000014\n",
      "      - 6.000000000000027\n",
      "      - 11.399999999999967\n",
      "      - -3.8999999999999915\n",
      "      - 16.499999999999957\n",
      "      - 0.6000000000000212\n",
      "      - 24.899999999999967\n",
      "      - 5.10000000000003\n",
      "      - 2.6999999999999833\n",
      "      - 12.90000000000001\n",
      "      - 5.4000000000000234\n",
      "      - 10.500000000000028\n",
      "      - 7.50000000000003\n",
      "      - 23.699999999999953\n",
      "      - 14.999999999999952\n",
      "      - -3.2999999999999883\n",
      "      - 11.400000000000022\n",
      "      - 12.000000000000005\n",
      "      - 17.699999999999996\n",
      "      - 16.19999999999994\n",
      "      - 4.200000000000016\n",
      "      - 0.9000000000000085\n",
      "      - 7.800000000000033\n",
      "      - 7.50000000000003\n",
      "      - 12.600000000000026\n",
      "      - -17.99999999999998\n",
      "      policy_policy1_reward:\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 11.5\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 20.0\n",
      "      - -1.0\n",
      "      - 5.0\n",
      "      - -10.0\n",
      "      - 1.5\n",
      "      - -3.5\n",
      "      - 8.0\n",
      "      - 10.5\n",
      "      - 11.5\n",
      "      - 2.5\n",
      "      - 9.5\n",
      "      - 20.5\n",
      "      - 13.0\n",
      "      - 0.0\n",
      "      - 13.0\n",
      "      - 9.5\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 12.0\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 8.5\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 27.0\n",
      "      - 9.5\n",
      "      - -0.5\n",
      "      - 11.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - 36.5\n",
      "      - 17.5\n",
      "      - 27.0\n",
      "      - 13.0\n",
      "      - -1.5\n",
      "      - 4.5\n",
      "      - 14.5\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 16.5\n",
      "      - -10.5\n",
      "      - 17.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 5.0\n",
      "      - 26.5\n",
      "      - 9.5\n",
      "      - 25.0\n",
      "      - 8.5\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - 11.0\n",
      "      - 20.5\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 24.0\n",
      "      - 12.0\n",
      "      - 6.5\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -7.79999999999999\n",
      "      - -0.1000000000000042\n",
      "      - 4.300000000000008\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999985\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.2999999999999954\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999988\n",
      "      - -1.1999999999999909\n",
      "      - -6.699999999999984\n",
      "      - -3.400000000000003\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -5.5999999999999925\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000047\n",
      "      - -3.4000000000000017\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999996\n",
      "      - -3.399999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -3.3999999999999826\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.79999999999999\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.09999999999999593\n",
      "      - -3.3999999999999995\n",
      "      - -2.299999999999998\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000002\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999995\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 36.5\n",
      "      policy2: 5.400000000000011\n",
      "    policy_reward_mean:\n",
      "      policy1: 11.545\n",
      "      policy2: -6.83199999999999\n",
      "    policy_reward_min:\n",
      "      policy1: -10.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.13736298577945916\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06112930122866574\n",
      "      mean_inference_ms: 1.4497947053770246\n",
      "      mean_raw_obs_processing_ms: 0.2705924376416336\n",
      "  time_since_restore: 96.76031041145325\n",
      "  time_this_iter_s: 15.840329885482788\n",
      "  time_total_s: 96.76031041145325\n",
      "  timers:\n",
      "    learn_throughput: 505.648\n",
      "    learn_time_ms: 5932.979\n",
      "    synch_weights_time_ms: 3.677\n",
      "    training_iteration_time_ms: 12088.17\n",
      "  timestamp: 1658917146\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 8\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 48000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-07\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 29.999999999999936\n",
      "  episode_reward_mean: 1.9410000000000074\n",
      "  episode_reward_min: -22.799999999999997\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 240\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1326675415039062\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016458706930279732\n",
      "          model: {}\n",
      "          policy_loss: -0.05323980748653412\n",
      "          total_loss: 7.244359493255615\n",
      "          vf_explained_var: 0.0754673182964325\n",
      "          vf_loss: 7.290192127227783\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0824979543685913\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018985502421855927\n",
      "          model: {}\n",
      "          policy_loss: -0.0546221062541008\n",
      "          total_loss: 3.228741407394409\n",
      "          vf_explained_var: 0.16639967262744904\n",
      "          vf_loss: 3.274819850921631\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 24000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 71.0391304347826\n",
      "    ram_util_percent: 60.091304347826096\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 40.0\n",
      "    policy2: 4.300000000000001\n",
      "  policy_reward_mean:\n",
      "    policy1: 9.125\n",
      "    policy2: -7.183999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -17.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14046763040537466\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06069503899409492\n",
      "    mean_inference_ms: 1.47194481477015\n",
      "    mean_raw_obs_processing_ms: 0.2745769018764014\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 29.999999999999936\n",
      "    episode_reward_mean: 1.9410000000000074\n",
      "    episode_reward_min: -22.799999999999997\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -13.200000000000005\n",
      "      - 2.9999999999999925\n",
      "      - -7.499999999999989\n",
      "      - -4.499999999999973\n",
      "      - 0.30000000000002536\n",
      "      - 6.599999999999996\n",
      "      - 6.30000000000002\n",
      "      - -10.199999999999982\n",
      "      - 2.70000000000003\n",
      "      - -4.199999999999983\n",
      "      - -2.9999999999999813\n",
      "      - 4.500000000000014\n",
      "      - 2.7000000000000157\n",
      "      - -16.49999999999999\n",
      "      - 15.600000000000025\n",
      "      - 4.500000000000025\n",
      "      - 8.400000000000025\n",
      "      - 2.100000000000028\n",
      "      - 17.100000000000023\n",
      "      - -5.9999999999999964\n",
      "      - 12.30000000000002\n",
      "      - 5.700000000000026\n",
      "      - -2.399999999999976\n",
      "      - 16.49999999999997\n",
      "      - 1.5000000000000244\n",
      "      - -3.899999999999985\n",
      "      - -6.299999999999985\n",
      "      - 3.899999999999984\n",
      "      - 5.100000000000023\n",
      "      - 1.800000000000014\n",
      "      - 8.100000000000012\n",
      "      - 16.500000000000014\n",
      "      - -5.699999999999983\n",
      "      - -1.7999999999999852\n",
      "      - -5.399999999999981\n",
      "      - -5.399999999999981\n",
      "      - -1.4999999999999734\n",
      "      - -1.4999999999999831\n",
      "      - 12.599999999999998\n",
      "      - 2.4000000000000132\n",
      "      - -9.899999999999995\n",
      "      - 4.799999999999963\n",
      "      - 1.500000000000006\n",
      "      - 3.0000000000000164\n",
      "      - 7.800000000000027\n",
      "      - -22.799999999999997\n",
      "      - -13.799999999999972\n",
      "      - -16.799999999999983\n",
      "      - 18.29999999999994\n",
      "      - 13.799999999999978\n",
      "      - 24.599999999999945\n",
      "      - 29.999999999999936\n",
      "      - 4.2000000000000215\n",
      "      - 9.900000000000023\n",
      "      - 13.499999999999902\n",
      "      - -4.4999999999999964\n",
      "      - -10.499999999999991\n",
      "      - -0.2999999999999782\n",
      "      - 8.699999999999958\n",
      "      - -2.3999999999999826\n",
      "      - -10.799999999999994\n",
      "      - 3.599999999999994\n",
      "      - 10.800000000000004\n",
      "      - 2.1000000000000245\n",
      "      - 4.500000000000028\n",
      "      - 7.500000000000025\n",
      "      - 0.6000000000000117\n",
      "      - 7.80000000000002\n",
      "      - -2.999999999999981\n",
      "      - -7.499999999999979\n",
      "      - -5.999999999999979\n",
      "      - -13.799999999999985\n",
      "      - 8.09999999999998\n",
      "      - -1.199999999999985\n",
      "      - -6.299999999999991\n",
      "      - 11.700000000000022\n",
      "      - 6.6000000000000245\n",
      "      - 6.6000000000000245\n",
      "      - -4.19999999999998\n",
      "      - 0.3000000000000147\n",
      "      - 1.7999999999999745\n",
      "      - 10.499999999999993\n",
      "      - 10.199999999999969\n",
      "      - 6.300000000000006\n",
      "      - -0.8999999999999868\n",
      "      - -7.499999999999972\n",
      "      - -17.399999999999984\n",
      "      - 7.500000000000003\n",
      "      - 1.5000000000000138\n",
      "      - -1.7999999999999872\n",
      "      - 14.700000000000022\n",
      "      - 7.200000000000008\n",
      "      - 23.399999999999956\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000021\n",
      "      - 1.500000000000019\n",
      "      - -8.699999999999983\n",
      "      - 1.500000000000012\n",
      "      - 12.299999999999926\n",
      "      - 4.800000000000013\n",
      "      policy_policy1_reward:\n",
      "      - -6.5\n",
      "      - 13.0\n",
      "      - -3.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - -9.0\n",
      "      - 10.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 10.5\n",
      "      - -6.5\n",
      "      - 19.0\n",
      "      - 14.5\n",
      "      - 14.0\n",
      "      - 11.0\n",
      "      - 26.0\n",
      "      - -7.0\n",
      "      - 19.0\n",
      "      - 13.5\n",
      "      - 6.5\n",
      "      - 26.5\n",
      "      - 11.5\n",
      "      - -0.5\n",
      "      - 1.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 8.5\n",
      "      - 17.0\n",
      "      - 26.5\n",
      "      - 1.0\n",
      "      - 6.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 8.5\n",
      "      - 3.0\n",
      "      - 21.5\n",
      "      - 8.0\n",
      "      - -1.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 7.5\n",
      "      - 14.5\n",
      "      - -15.0\n",
      "      - -6.0\n",
      "      - -14.5\n",
      "      - 25.0\n",
      "      - 20.5\n",
      "      - 28.0\n",
      "      - 40.0\n",
      "      - 12.0\n",
      "      - 15.5\n",
      "      - 23.5\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      - 6.5\n",
      "      - -3.0\n",
      "      - 12.5\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 9.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 2.5\n",
      "      - 4.0\n",
      "      - -17.0\n",
      "      - 17.0\n",
      "      - 5.5\n",
      "      - 1.5\n",
      "      - 14.0\n",
      "      - 15.5\n",
      "      - 15.5\n",
      "      - -8.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - 18.0\n",
      "      - 13.0\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -8.5\n",
      "      - 17.5\n",
      "      - 0.5\n",
      "      - 6.0\n",
      "      - 22.5\n",
      "      - 15.0\n",
      "      - 29.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - -2.0\n",
      "      - 0.5\n",
      "      - 19.0\n",
      "      - 6.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.699999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.1999999999999977\n",
      "      - -7.799999999999987\n",
      "      - -6.699999999999987\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999985\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 1.000000000000008\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999897\n",
      "      - -7.799999999999987\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999984\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -2.3000000000000056\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999982\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 3.200000000000001\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999988\n",
      "      - -2.2999999999999896\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 4.300000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999943\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 1.0000000000000093\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000042\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 40.0\n",
      "      policy2: 4.300000000000001\n",
      "    policy_reward_mean:\n",
      "      policy1: 9.125\n",
      "      policy2: -7.183999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -17.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14046763040537466\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06069503899409492\n",
      "      mean_inference_ms: 1.47194481477015\n",
      "      mean_raw_obs_processing_ms: 0.2745769018764014\n",
      "  time_since_restore: 97.3879508972168\n",
      "  time_this_iter_s: 15.929429054260254\n",
      "  time_total_s: 97.3879508972168\n",
      "  timers:\n",
      "    learn_throughput: 506.511\n",
      "    learn_time_ms: 5922.867\n",
      "    synch_weights_time_ms: 3.327\n",
      "    training_iteration_time_ms: 12167.49\n",
      "  timestamp: 1658917147\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 8\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 48000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.49999999999998\n",
      "  episode_reward_mean: 0.41100000000000575\n",
      "  episode_reward_min: -25.50000000000001\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 240\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1635500192642212\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015430976636707783\n",
      "          model: {}\n",
      "          policy_loss: -0.04806463047862053\n",
      "          total_loss: 7.075747966766357\n",
      "          vf_explained_var: 0.1588059514760971\n",
      "          vf_loss: 7.11686897277832\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.171951174736023\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019017191603779793\n",
      "          model: {}\n",
      "          policy_loss: -0.048073235899209976\n",
      "          total_loss: 2.7795393466949463\n",
      "          vf_explained_var: 0.09142162650823593\n",
      "          vf_loss: 2.8219075202941895\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 48000\n",
      "    num_env_steps_sampled: 24000\n",
      "    num_env_steps_trained: 24000\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 48000\n",
      "  num_agent_steps_trained: 48000\n",
      "  num_env_steps_sampled: 24000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 24000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.08333333333334\n",
      "    ram_util_percent: 59.986666666666665\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 3.199999999999999\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.87\n",
      "    policy2: -7.458999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -17.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1477078421554079\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06380044442221358\n",
      "    mean_inference_ms: 1.5530453912796771\n",
      "    mean_raw_obs_processing_ms: 0.2914213537931351\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 22.49999999999998\n",
      "    episode_reward_mean: 0.41100000000000575\n",
      "    episode_reward_min: -25.50000000000001\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -8.999999999999979\n",
      "      - 7.799999999999994\n",
      "      - -0.2999999999999948\n",
      "      - 1.2000000000000175\n",
      "      - 3.0000000000000084\n",
      "      - -23.099999999999994\n",
      "      - -0.29999999999997284\n",
      "      - -4.799999999999975\n",
      "      - -2.999999999999985\n",
      "      - -3.2999999999999816\n",
      "      - -6.899999999999988\n",
      "      - -2.9999999999999742\n",
      "      - 3.900000000000016\n",
      "      - 7.799999999999967\n",
      "      - 1.2000000000000237\n",
      "      - -5.4\n",
      "      - 19.4999999999999\n",
      "      - 1.5000000000000053\n",
      "      - 4.5000000000000115\n",
      "      - 2.10000000000002\n",
      "      - -1.4999999999999774\n",
      "      - -8.399999999999979\n",
      "      - 5.700000000000031\n",
      "      - -17.4\n",
      "      - -3.8999999999999813\n",
      "      - -2.0999999999999774\n",
      "      - 8.699999999999958\n",
      "      - 5.100000000000016\n",
      "      - -6.599999999999984\n",
      "      - -8.399999999999983\n",
      "      - 13.499999999999945\n",
      "      - 13.199999999999948\n",
      "      - 13.199999999999955\n",
      "      - 9.000000000000032\n",
      "      - -0.8999999999999833\n",
      "      - 9.600000000000026\n",
      "      - 8.400000000000002\n",
      "      - 3.600000000000017\n",
      "      - 5.099999999999975\n",
      "      - 6.3000000000000185\n",
      "      - 7.7999999999999545\n",
      "      - -1.7999999999999927\n",
      "      - -1.4999999999999871\n",
      "      - -11.39999999999998\n",
      "      - -7.499999999999984\n",
      "      - 3.6000000000000294\n",
      "      - -10.499999999999975\n",
      "      - -15.29999999999998\n",
      "      - 4.499999999999954\n",
      "      - -4.799999999999978\n",
      "      - 8.400000000000013\n",
      "      - 12.299999999999997\n",
      "      - 12.600000000000009\n",
      "      - -5.699999999999987\n",
      "      - 0.3000000000000076\n",
      "      - -0.8999999999999848\n",
      "      - -7.499999999999972\n",
      "      - 6.300000000000004\n",
      "      - -2.699999999999986\n",
      "      - -4.499999999999984\n",
      "      - 11.399999999999954\n",
      "      - 1.5000000000000093\n",
      "      - -4.200000000000015\n",
      "      - -8.399999999999983\n",
      "      - 0.6000000000000046\n",
      "      - 3.000000000000017\n",
      "      - -15.89999999999999\n",
      "      - 8.700000000000006\n",
      "      - 1.200000000000022\n",
      "      - -0.29999999999997373\n",
      "      - -25.50000000000001\n",
      "      - -8.399999999999974\n",
      "      - -7.199999999999992\n",
      "      - 8.700000000000012\n",
      "      - -0.29999999999997995\n",
      "      - 11.999999999999991\n",
      "      - -3.29999999999998\n",
      "      - 6.000000000000023\n",
      "      - -1.712519015484304e-14\n",
      "      - 1.200000000000002\n",
      "      - 2.9999999999999867\n",
      "      - -3.2999999999999887\n",
      "      - -4.799999999999978\n",
      "      - -5.399999999999992\n",
      "      - -7.499999999999992\n",
      "      - -12.899999999999983\n",
      "      - 13.200000000000031\n",
      "      - 8.099999999999996\n",
      "      - 14.09999999999992\n",
      "      - -10.499999999999975\n",
      "      - 1.2000000000000153\n",
      "      - 10.5\n",
      "      - 14.100000000000003\n",
      "      - 2.1000000000000045\n",
      "      - -8.399999999999977\n",
      "      - 22.49999999999998\n",
      "      - -12.299999999999974\n",
      "      - 8.99999999999998\n",
      "      - 8.400000000000013\n",
      "      - -8.099999999999975\n",
      "      policy_policy1_reward:\n",
      "      - 1.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - -17.5\n",
      "      - 7.5\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 4.5\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 4.0\n",
      "      - 14.5\n",
      "      - 9.0\n",
      "      - 3.5\n",
      "      - 29.5\n",
      "      - 11.5\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      - 8.5\n",
      "      - 0.5\n",
      "      - 13.5\n",
      "      - -8.5\n",
      "      - 5.0\n",
      "      - 3.5\n",
      "      - 16.5\n",
      "      - 14.0\n",
      "      - -1.0\n",
      "      - 0.5\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 21.0\n",
      "      - 19.0\n",
      "      - 8.0\n",
      "      - 18.5\n",
      "      - 14.0\n",
      "      - 12.5\n",
      "      - 14.0\n",
      "      - 13.0\n",
      "      - 14.5\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - -2.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - -0.5\n",
      "      - -7.5\n",
      "      - 9.0\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 1.0\n",
      "      - 7.0\n",
      "      - 8.0\n",
      "      - 2.5\n",
      "      - 13.0\n",
      "      - 4.0\n",
      "      - 5.5\n",
      "      - 17.0\n",
      "      - 11.5\n",
      "      - 2.5\n",
      "      - 0.5\n",
      "      - 4.0\n",
      "      - 13.0\n",
      "      - -7.0\n",
      "      - 16.5\n",
      "      - 9.0\n",
      "      - 2.0\n",
      "      - -15.5\n",
      "      - 0.5\n",
      "      - -6.0\n",
      "      - 11.0\n",
      "      - 7.5\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 16.0\n",
      "      - 10.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - -6.5\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 2.5\n",
      "      - -4.0\n",
      "      - 21.0\n",
      "      - 6.0\n",
      "      - 23.0\n",
      "      - -0.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 23.0\n",
      "      - 11.0\n",
      "      - -5.0\n",
      "      - 32.5\n",
      "      - -4.5\n",
      "      - 13.5\n",
      "      - 14.0\n",
      "      - -2.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999993\n",
      "      - -7.799999999999982\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -7.79999999999999\n",
      "      - -2.29999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999999637\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -5.6\n",
      "      - -7.7999999999999865\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999993\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999995\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999982\n",
      "      - -6.699999999999987\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999987\n",
      "      - -8.899999999999984\n",
      "      - -3.399999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.79999999999999\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -1.1999999999999982\n",
      "      - -2.2999999999999927\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999984\n",
      "      - 3.199999999999999\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999985\n",
      "      - 2.0999999999999943\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.500000000000003\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 3.199999999999999\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.87\n",
      "      policy2: -7.458999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -17.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1477078421554079\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06380044442221358\n",
      "      mean_inference_ms: 1.5530453912796771\n",
      "      mean_raw_obs_processing_ms: 0.2914213537931351\n",
      "  time_since_restore: 103.85770273208618\n",
      "  time_this_iter_s: 20.376267910003662\n",
      "  time_total_s: 103.85770273208618\n",
      "  timers:\n",
      "    learn_throughput: 460.694\n",
      "    learn_time_ms: 8682.553\n",
      "    synch_weights_time_ms: 3.788\n",
      "    training_iteration_time_ms: 17302.592\n",
      "  timestamp: 1658917160\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 6\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 56000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_env_steps_sampled: 28000\n",
      "    num_env_steps_trained: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-21\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.799999999999983\n",
      "  episode_reward_mean: 4.371000000000005\n",
      "  episode_reward_min: -16.49999999999998\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 280\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.185457468032837\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01295371726155281\n",
      "          model: {}\n",
      "          policy_loss: -0.039791643619537354\n",
      "          total_loss: 7.041825294494629\n",
      "          vf_explained_var: 0.16684100031852722\n",
      "          vf_loss: 7.079026222229004\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1620513200759888\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01215352676808834\n",
      "          model: {}\n",
      "          policy_loss: -0.03318491578102112\n",
      "          total_loss: 2.8663811683654785\n",
      "          vf_explained_var: 0.20944491028785706\n",
      "          vf_loss: 2.8971354961395264\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_env_steps_sampled: 28000\n",
      "    num_env_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 56000\n",
      "  num_env_steps_sampled: 28000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 28000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 40.10333333333333\n",
      "    ram_util_percent: 59.97333333333333\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 29.0\n",
      "    policy2: 1.0000000000000075\n",
      "  policy_reward_mean:\n",
      "    policy1: 10.95\n",
      "    policy2: -6.578999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -6.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14072825459117355\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06131167655390697\n",
      "    mean_inference_ms: 1.474595913071746\n",
      "    mean_raw_obs_processing_ms: 0.27755240425523575\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 22.799999999999983\n",
      "    episode_reward_mean: 4.371000000000005\n",
      "    episode_reward_min: -16.49999999999998\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -10.499999999999975\n",
      "      - -4.499999999999993\n",
      "      - 4.200000000000021\n",
      "      - 10.799999999999981\n",
      "      - 10.800000000000027\n",
      "      - -0.2999999999999702\n",
      "      - 18.000000000000007\n",
      "      - 5.7000000000000135\n",
      "      - 1.7999999999999972\n",
      "      - 5.700000000000026\n",
      "      - 7.200000000000014\n",
      "      - 0.9000000000000271\n",
      "      - 7.500000000000025\n",
      "      - 18.599999999999987\n",
      "      - -13.499999999999972\n",
      "      - -9.899999999999975\n",
      "      - 9.300000000000022\n",
      "      - 14.100000000000017\n",
      "      - -3.6000000000000276\n",
      "      - 9.000000000000027\n",
      "      - -4.799999999999985\n",
      "      - 10.500000000000028\n",
      "      - -4.199999999999983\n",
      "      - 17.699999999999953\n",
      "      - 9.900000000000015\n",
      "      - 0.3000000000000218\n",
      "      - 2.700000000000018\n",
      "      - -5.099999999999985\n",
      "      - 19.19999999999996\n",
      "      - -1.7999999999999876\n",
      "      - -0.2999999999999762\n",
      "      - 0.9000000000000098\n",
      "      - 1.2000000000000246\n",
      "      - 7.799999999999983\n",
      "      - 9.899999999999968\n",
      "      - 1.500000000000011\n",
      "      - 5.10000000000003\n",
      "      - -6.299999999999978\n",
      "      - 16.80000000000001\n",
      "      - -7.4999999999999805\n",
      "      - 4.800000000000015\n",
      "      - 8.699999999999998\n",
      "      - 3.9000000000000195\n",
      "      - -11.699999999999982\n",
      "      - 2.100000000000022\n",
      "      - 6.299999999999956\n",
      "      - 2.700000000000009\n",
      "      - -2.099999999999981\n",
      "      - -2.0999999999999877\n",
      "      - 14.400000000000011\n",
      "      - 4.200000000000022\n",
      "      - 8.999999999999915\n",
      "      - 2.4000000000000274\n",
      "      - 6.5999999999999766\n",
      "      - 1.2961853812498703e-14\n",
      "      - 7.800000000000017\n",
      "      - 1.5000000000000102\n",
      "      - 3.6000000000000276\n",
      "      - 8.10000000000003\n",
      "      - -5.999999999999977\n",
      "      - 15.000000000000018\n",
      "      - -13.499999999999993\n",
      "      - -16.49999999999998\n",
      "      - 13.199999999999948\n",
      "      - 2.373101715136272e-14\n",
      "      - 18.599999999999937\n",
      "      - 10.800000000000031\n",
      "      - 14.699999999999898\n",
      "      - -5.999999999999984\n",
      "      - 12.000000000000028\n",
      "      - 13.499999999999988\n",
      "      - 14.69999999999999\n",
      "      - 1.8000000000000167\n",
      "      - 14.100000000000025\n",
      "      - 3.000000000000023\n",
      "      - 1.529332216421153e-14\n",
      "      - -1.199999999999982\n",
      "      - -8.399999999999983\n",
      "      - -2.3999999999999986\n",
      "      - 12.3\n",
      "      - 4.5000000000000036\n",
      "      - -0.29999999999997795\n",
      "      - 7.499999999999936\n",
      "      - 4.199999999999971\n",
      "      - -5.699999999999976\n",
      "      - -5.999999999999987\n",
      "      - -2.3999999999999853\n",
      "      - 10.79999999999998\n",
      "      - 11.999999999999932\n",
      "      - 5.700000000000033\n",
      "      - 14.399999999999926\n",
      "      - -2.999999999999975\n",
      "      - 10.800000000000017\n",
      "      - 8.100000000000028\n",
      "      - 15.60000000000001\n",
      "      - 1.5000000000000187\n",
      "      - 20.099999999999923\n",
      "      - -3.5999999999999766\n",
      "      - 5.399999999999993\n",
      "      - 22.799999999999983\n",
      "      policy_policy1_reward:\n",
      "      - -0.5\n",
      "      - 5.5\n",
      "      - 12.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - 7.5\n",
      "      - 28.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 8.0\n",
      "      - 15.0\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 27.5\n",
      "      - -3.5\n",
      "      - -1.0\n",
      "      - 16.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 19.0\n",
      "      - 3.0\n",
      "      - 15.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 15.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 0.5\n",
      "      - 27.0\n",
      "      - 6.0\n",
      "      - 7.5\n",
      "      - 6.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 15.5\n",
      "      - 11.5\n",
      "      - 8.5\n",
      "      - 1.5\n",
      "      - 23.5\n",
      "      - 2.5\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - -5.0\n",
      "      - 11.0\n",
      "      - 13.0\n",
      "      - 5.0\n",
      "      - -2.0\n",
      "      - 3.5\n",
      "      - 20.0\n",
      "      - 12.0\n",
      "      - 13.5\n",
      "      - 2.5\n",
      "      - 10.0\n",
      "      - 4.5\n",
      "      - 9.0\n",
      "      - 6.0\n",
      "      - 12.5\n",
      "      - 17.0\n",
      "      - 4.0\n",
      "      - 25.0\n",
      "      - -3.5\n",
      "      - -6.5\n",
      "      - 21.0\n",
      "      - 10.0\n",
      "      - 27.5\n",
      "      - 17.5\n",
      "      - 22.5\n",
      "      - 4.0\n",
      "      - 22.0\n",
      "      - 23.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - 7.5\n",
      "      - 10.0\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 6.5\n",
      "      - 19.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 12.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - -1.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 17.5\n",
      "      - 17.0\n",
      "      - 24.5\n",
      "      - 0.5\n",
      "      - 29.0\n",
      "      - 2.0\n",
      "      - 11.0\n",
      "      - 24.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -4.499999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999905\n",
      "      - -5.599999999999999\n",
      "      - -6.699999999999995\n",
      "      - -2.300000000000004\n",
      "      - -5.599999999999995\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999987\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999972\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -5.599999999999983\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -2.300000000000003\n",
      "      - -0.10000000000000175\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999984\n",
      "      - -4.5000000000000036\n",
      "      - -0.10000000000000464\n",
      "      - -3.4000000000000044\n",
      "      - -4.499999999999997\n",
      "      - -1.199999999999994\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999993\n",
      "      - -3.3999999999999915\n",
      "      - -4.500000000000004\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999987\n",
      "      - -4.500000000000003\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999982\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999988\n",
      "      - -3.4000000000000052\n",
      "      - -6.699999999999987\n",
      "      - 1.0000000000000075\n",
      "      - -7.799999999999982\n",
      "      - -0.0999999999999962\n",
      "      - -4.500000000000001\n",
      "      - -6.699999999999994\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - 0.9999999999999946\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -1.200000000000002\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 29.0\n",
      "      policy2: 1.0000000000000075\n",
      "    policy_reward_mean:\n",
      "      policy1: 10.95\n",
      "      policy2: -6.578999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -6.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14072825459117355\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06131167655390697\n",
      "      mean_inference_ms: 1.474595913071746\n",
      "      mean_raw_obs_processing_ms: 0.27755240425523575\n",
      "  time_since_restore: 114.06865310668945\n",
      "  time_this_iter_s: 20.467634916305542\n",
      "  time_total_s: 114.06865310668945\n",
      "  timers:\n",
      "    learn_throughput: 495.98\n",
      "    learn_time_ms: 8064.841\n",
      "    synch_weights_time_ms: 3.819\n",
      "    training_iteration_time_ms: 16287.763\n",
      "  timestamp: 1658917161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 54000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 54000\n",
      "    num_env_steps_sampled: 27000\n",
      "    num_env_steps_trained: 27000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-21\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 27.59999999999996\n",
      "  episode_reward_mean: 5.654999999999998\n",
      "  episode_reward_min: -21.90000000000002\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 270\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1073260307312012\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013394907116889954\n",
      "          model: {}\n",
      "          policy_loss: -0.04426106810569763\n",
      "          total_loss: 6.495303630828857\n",
      "          vf_explained_var: 0.21691451966762543\n",
      "          vf_loss: 6.536886215209961\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0561548471450806\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013607633300125599\n",
      "          model: {}\n",
      "          policy_loss: -0.04444800317287445\n",
      "          total_loss: 2.3075430393218994\n",
      "          vf_explained_var: 0.2942819893360138\n",
      "          vf_loss: 2.350630044937134\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 54000\n",
      "    num_env_steps_sampled: 27000\n",
      "    num_env_steps_trained: 27000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 54000\n",
      "  num_agent_steps_trained: 54000\n",
      "  num_env_steps_sampled: 27000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 27000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.400000000000006\n",
      "    ram_util_percent: 59.866666666666646\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 36.5\n",
      "    policy2: 5.400000000000011\n",
      "  policy_reward_mean:\n",
      "    policy1: 12.465\n",
      "    policy2: -6.80999999999999\n",
      "  policy_reward_min:\n",
      "    policy1: -13.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14167323153115366\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0630347127629752\n",
      "    mean_inference_ms: 1.4938769394134845\n",
      "    mean_raw_obs_processing_ms: 0.2795715011707715\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 27.59999999999996\n",
      "    episode_reward_mean: 5.654999999999998\n",
      "    episode_reward_min: -21.90000000000002\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -6.899999999999979\n",
      "      - -1.799999999999982\n",
      "      - 2.699999999999996\n",
      "      - 10.79999999999996\n",
      "      - 7.799999999999958\n",
      "      - 3.6000000000000094\n",
      "      - 13.499999999999963\n",
      "      - -1.5000000000000202\n",
      "      - 3.5999999999999956\n",
      "      - 5.400000000000009\n",
      "      - -6.599999999999988\n",
      "      - -9.299999999999983\n",
      "      - -0.2999999999999826\n",
      "      - 9.599999999999962\n",
      "      - 14.100000000000025\n",
      "      - -3.600000000000012\n",
      "      - 3.6000000000000143\n",
      "      - 19.199999999999953\n",
      "      - 0.6000000000000058\n",
      "      - -10.499999999999979\n",
      "      - 2.1000000000000214\n",
      "      - -4.499999999999979\n",
      "      - 6.000000000000002\n",
      "      - 27.59999999999996\n",
      "      - 10.799999999999983\n",
      "      - 19.199999999999896\n",
      "      - 9.600000000000021\n",
      "      - -5.999999999999987\n",
      "      - 2.7727820040013285e-14\n",
      "      - 4.500000000000012\n",
      "      - 6.599999999999975\n",
      "      - -13.500000000000005\n",
      "      - 12.600000000000032\n",
      "      - 12.599999999999955\n",
      "      - 10.19999999999997\n",
      "      - -2.9999999999999876\n",
      "      - 3.5999999999999797\n",
      "      - 8.700000000000031\n",
      "      - -5.099999999999985\n",
      "      - 7.500000000000021\n",
      "      - 6.600000000000023\n",
      "      - 10.80000000000003\n",
      "      - 3.6000000000000116\n",
      "      - 21.599999999999895\n",
      "      - 12.600000000000014\n",
      "      - 6.000000000000027\n",
      "      - 11.399999999999967\n",
      "      - -3.8999999999999915\n",
      "      - 16.499999999999957\n",
      "      - 0.6000000000000212\n",
      "      - 24.899999999999967\n",
      "      - 5.10000000000003\n",
      "      - 2.6999999999999833\n",
      "      - 12.90000000000001\n",
      "      - 5.4000000000000234\n",
      "      - 10.500000000000028\n",
      "      - 7.50000000000003\n",
      "      - 23.699999999999953\n",
      "      - 14.999999999999952\n",
      "      - -3.2999999999999883\n",
      "      - 11.400000000000022\n",
      "      - 12.000000000000005\n",
      "      - 17.699999999999996\n",
      "      - 16.19999999999994\n",
      "      - 4.200000000000016\n",
      "      - 0.9000000000000085\n",
      "      - 7.800000000000033\n",
      "      - 7.50000000000003\n",
      "      - 12.600000000000026\n",
      "      - -17.99999999999998\n",
      "      - 5.400000000000017\n",
      "      - 12.599999999999948\n",
      "      - -3.2999999999999883\n",
      "      - -5.099999999999991\n",
      "      - 1.2000000000000308\n",
      "      - 10.80000000000003\n",
      "      - 13.500000000000009\n",
      "      - 1.5000000000000022\n",
      "      - -5.699999999999996\n",
      "      - -3.299999999999988\n",
      "      - 3.0000000000000187\n",
      "      - 6.000000000000025\n",
      "      - 17.999999999999915\n",
      "      - 17.09999999999996\n",
      "      - 0.30000000000002025\n",
      "      - 1.2000000000000148\n",
      "      - 5.100000000000028\n",
      "      - -12.89999999999998\n",
      "      - 2.099999999999979\n",
      "      - 0.5999999999999509\n",
      "      - 5.999999999999988\n",
      "      - 10.500000000000028\n",
      "      - 16.799999999999926\n",
      "      - 20.099999999999987\n",
      "      - 9.90000000000003\n",
      "      - -21.90000000000002\n",
      "      - 3.0000000000000275\n",
      "      - 12.599999999999971\n",
      "      - 10.500000000000025\n",
      "      - 3.9000000000000195\n",
      "      policy_policy1_reward:\n",
      "      - -3.5\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 12.0\n",
      "      - 14.5\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 8.5\n",
      "      - 12.5\n",
      "      - 5.5\n",
      "      - -1.0\n",
      "      - -1.5\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 7.0\n",
      "      - 27.0\n",
      "      - 9.5\n",
      "      - -0.5\n",
      "      - 11.0\n",
      "      - 5.5\n",
      "      - 10.5\n",
      "      - 36.5\n",
      "      - 17.5\n",
      "      - 27.0\n",
      "      - 13.0\n",
      "      - -1.5\n",
      "      - 4.5\n",
      "      - 14.5\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 16.5\n",
      "      - -10.5\n",
      "      - 17.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 5.0\n",
      "      - 26.5\n",
      "      - 9.5\n",
      "      - 25.0\n",
      "      - 8.5\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - 11.0\n",
      "      - 20.5\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 24.0\n",
      "      - 12.0\n",
      "      - 6.5\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 11.0\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 0.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 18.0\n",
      "      - 6.0\n",
      "      - 1.0\n",
      "      - -1.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 28.0\n",
      "      - 20.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 14.0\n",
      "      - -4.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 23.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - -13.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 9.5\n",
      "      policy_policy2_reward:\n",
      "      - -3.3999999999999937\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999988\n",
      "      - -1.1999999999999909\n",
      "      - -6.699999999999984\n",
      "      - -3.400000000000003\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000331\n",
      "      - -5.5999999999999925\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000047\n",
      "      - -3.4000000000000017\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999996\n",
      "      - -3.399999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -3.3999999999999826\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.79999999999999\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.09999999999999593\n",
      "      - -3.3999999999999995\n",
      "      - -2.299999999999998\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000002\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999995\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -3.4000000000000044\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999995\n",
      "      - -4.5\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4\n",
      "      - -6.699999999999983\n",
      "      - -2.300000000000003\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 36.5\n",
      "      policy2: 5.400000000000011\n",
      "    policy_reward_mean:\n",
      "      policy1: 12.465\n",
      "      policy2: -6.80999999999999\n",
      "    policy_reward_min:\n",
      "      policy1: -13.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14167323153115366\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0630347127629752\n",
      "      mean_inference_ms: 1.4938769394134845\n",
      "      mean_raw_obs_processing_ms: 0.2795715011707715\n",
      "  time_since_restore: 111.55292129516602\n",
      "  time_this_iter_s: 14.792610883712769\n",
      "  time_total_s: 111.55292129516602\n",
      "  timers:\n",
      "    learn_throughput: 490.171\n",
      "    learn_time_ms: 6120.319\n",
      "    synch_weights_time_ms: 3.677\n",
      "    training_iteration_time_ms: 12387.755\n",
      "  timestamp: 1658917161\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 9\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 54000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 54000\n",
      "    num_env_steps_sampled: 27000\n",
      "    num_env_steps_trained: 27000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-22\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 29.999999999999936\n",
      "  episode_reward_mean: 1.734000000000007\n",
      "  episode_reward_min: -22.799999999999997\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 270\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0898394584655762\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017939390614628792\n",
      "          model: {}\n",
      "          policy_loss: -0.05420557036995888\n",
      "          total_loss: 6.07111930847168\n",
      "          vf_explained_var: 0.17800672352313995\n",
      "          vf_loss: 6.117251873016357\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0476619005203247\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01646272838115692\n",
      "          model: {}\n",
      "          policy_loss: -0.049705620855093\n",
      "          total_loss: 2.1007349491119385\n",
      "          vf_explained_var: 0.21863681077957153\n",
      "          vf_loss: 2.1430323123931885\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 54000\n",
      "    num_env_steps_sampled: 27000\n",
      "    num_env_steps_trained: 27000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 54000\n",
      "  num_agent_steps_trained: 54000\n",
      "  num_env_steps_sampled: 27000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 27000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.652380952380945\n",
      "    ram_util_percent: 59.842857142857135\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 40.0\n",
      "    policy2: 4.300000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.94\n",
      "    policy2: -7.205999999999986\n",
      "  policy_reward_min:\n",
      "    policy1: -17.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14520346930912542\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0625705271290788\n",
      "    mean_inference_ms: 1.5183268943746382\n",
      "    mean_raw_obs_processing_ms: 0.2840964832880993\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 29.999999999999936\n",
      "    episode_reward_mean: 1.734000000000007\n",
      "    episode_reward_min: -22.799999999999997\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 8.100000000000012\n",
      "      - 16.500000000000014\n",
      "      - -5.699999999999983\n",
      "      - -1.7999999999999852\n",
      "      - -5.399999999999981\n",
      "      - -5.399999999999981\n",
      "      - -1.4999999999999734\n",
      "      - -1.4999999999999831\n",
      "      - 12.599999999999998\n",
      "      - 2.4000000000000132\n",
      "      - -9.899999999999995\n",
      "      - 4.799999999999963\n",
      "      - 1.500000000000006\n",
      "      - 3.0000000000000164\n",
      "      - 7.800000000000027\n",
      "      - -22.799999999999997\n",
      "      - -13.799999999999972\n",
      "      - -16.799999999999983\n",
      "      - 18.29999999999994\n",
      "      - 13.799999999999978\n",
      "      - 24.599999999999945\n",
      "      - 29.999999999999936\n",
      "      - 4.2000000000000215\n",
      "      - 9.900000000000023\n",
      "      - 13.499999999999902\n",
      "      - -4.4999999999999964\n",
      "      - -10.499999999999991\n",
      "      - -0.2999999999999782\n",
      "      - 8.699999999999958\n",
      "      - -2.3999999999999826\n",
      "      - -10.799999999999994\n",
      "      - 3.599999999999994\n",
      "      - 10.800000000000004\n",
      "      - 2.1000000000000245\n",
      "      - 4.500000000000028\n",
      "      - 7.500000000000025\n",
      "      - 0.6000000000000117\n",
      "      - 7.80000000000002\n",
      "      - -2.999999999999981\n",
      "      - -7.499999999999979\n",
      "      - -5.999999999999979\n",
      "      - -13.799999999999985\n",
      "      - 8.09999999999998\n",
      "      - -1.199999999999985\n",
      "      - -6.299999999999991\n",
      "      - 11.700000000000022\n",
      "      - 6.6000000000000245\n",
      "      - 6.6000000000000245\n",
      "      - -4.19999999999998\n",
      "      - 0.3000000000000147\n",
      "      - 1.7999999999999745\n",
      "      - 10.499999999999993\n",
      "      - 10.199999999999969\n",
      "      - 6.300000000000006\n",
      "      - -0.8999999999999868\n",
      "      - -7.499999999999972\n",
      "      - -17.399999999999984\n",
      "      - 7.500000000000003\n",
      "      - 1.5000000000000138\n",
      "      - -1.7999999999999872\n",
      "      - 14.700000000000022\n",
      "      - 7.200000000000008\n",
      "      - 23.399999999999956\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000021\n",
      "      - 1.500000000000019\n",
      "      - -8.699999999999983\n",
      "      - 1.500000000000012\n",
      "      - 12.299999999999926\n",
      "      - 4.800000000000013\n",
      "      - 8.700000000000001\n",
      "      - 8.40000000000002\n",
      "      - -4.4999999999999805\n",
      "      - -0.2999999999999817\n",
      "      - -1.7999999999999905\n",
      "      - 3.083644450896372e-14\n",
      "      - -3.89999999999999\n",
      "      - 4.200000000000024\n",
      "      - -1.1999999999999904\n",
      "      - 20.399999999999938\n",
      "      - 2.1000000000000223\n",
      "      - 4.5000000000000195\n",
      "      - -1.4999999999999738\n",
      "      - 5.400000000000027\n",
      "      - -13.79999999999998\n",
      "      - 6.000000000000014\n",
      "      - 1.5000000000000195\n",
      "      - 6.30000000000002\n",
      "      - 5.1000000000000245\n",
      "      - -5.099999999999978\n",
      "      - -11.699999999999983\n",
      "      - -5.999999999999991\n",
      "      - -0.8999999999999977\n",
      "      - 5.700000000000003\n",
      "      - 5.1000000000000245\n",
      "      - 0.3000000000000067\n",
      "      - -3.8999999999999866\n",
      "      - -7.499999999999979\n",
      "      - 3.0000000000000124\n",
      "      - -2.3999999999999835\n",
      "      policy_policy1_reward:\n",
      "      - 17.0\n",
      "      - 26.5\n",
      "      - 1.0\n",
      "      - 6.0\n",
      "      - 3.5\n",
      "      - 3.5\n",
      "      - 8.5\n",
      "      - 3.0\n",
      "      - 21.5\n",
      "      - 8.0\n",
      "      - -1.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 7.5\n",
      "      - 14.5\n",
      "      - -15.0\n",
      "      - -6.0\n",
      "      - -14.5\n",
      "      - 25.0\n",
      "      - 20.5\n",
      "      - 28.0\n",
      "      - 40.0\n",
      "      - 12.0\n",
      "      - 15.5\n",
      "      - 23.5\n",
      "      - 5.5\n",
      "      - -0.5\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      - 6.5\n",
      "      - -3.0\n",
      "      - 12.5\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 9.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 2.5\n",
      "      - 4.0\n",
      "      - -17.0\n",
      "      - 17.0\n",
      "      - 5.5\n",
      "      - 1.5\n",
      "      - 14.0\n",
      "      - 15.5\n",
      "      - 15.5\n",
      "      - -8.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - 18.0\n",
      "      - 13.0\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -8.5\n",
      "      - 17.5\n",
      "      - 0.5\n",
      "      - 6.0\n",
      "      - 22.5\n",
      "      - 15.0\n",
      "      - 29.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - -2.0\n",
      "      - 0.5\n",
      "      - 19.0\n",
      "      - 6.0\n",
      "      - 16.5\n",
      "      - 14.0\n",
      "      - 5.5\n",
      "      - 7.5\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - -5.5\n",
      "      - 26.0\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - 14.0\n",
      "      - 0.5\n",
      "      - -5.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 2.5\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999998\n",
      "      - -8.899999999999984\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -2.3000000000000056\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999982\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 3.200000000000001\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999988\n",
      "      - -2.2999999999999896\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 4.300000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999943\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 1.0000000000000093\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000042\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.7999999999999865\n",
      "      - 4.300000000000008\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -5.6\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999983\n",
      "      - -3.3999999999999986\n",
      "      - -6.699999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999997\n",
      "      - -3.4000000000000044\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 40.0\n",
      "      policy2: 4.300000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.94\n",
      "      policy2: -7.205999999999986\n",
      "    policy_reward_min:\n",
      "      policy1: -17.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14520346930912542\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0625705271290788\n",
      "      mean_inference_ms: 1.5183268943746382\n",
      "      mean_raw_obs_processing_ms: 0.2840964832880993\n",
      "  time_since_restore: 112.41456389427185\n",
      "  time_this_iter_s: 15.026612997055054\n",
      "  time_total_s: 112.41456389427185\n",
      "  timers:\n",
      "    learn_throughput: 493.223\n",
      "    learn_time_ms: 6082.442\n",
      "    synch_weights_time_ms: 3.287\n",
      "    training_iteration_time_ms: 12484.358\n",
      "  timestamp: 1658917162\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 27000\n",
      "  training_iteration: 9\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 60000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_env_steps_sampled: 30000\n",
      "    num_env_steps_trained: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-36\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 30.599999999999923\n",
      "  episode_reward_mean: 7.271999999999992\n",
      "  episode_reward_min: -21.90000000000002\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 300\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0620309114456177\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014522287994623184\n",
      "          model: {}\n",
      "          policy_loss: -0.040203794836997986\n",
      "          total_loss: 6.817282676696777\n",
      "          vf_explained_var: 0.20594194531440735\n",
      "          vf_loss: 6.854581832885742\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0061476230621338\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014284193515777588\n",
      "          model: {}\n",
      "          policy_loss: -0.04189135134220123\n",
      "          total_loss: 3.1010165214538574\n",
      "          vf_explained_var: 0.0863879844546318\n",
      "          vf_loss: 3.1414794921875\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_env_steps_sampled: 30000\n",
      "    num_env_steps_trained: 30000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 60000\n",
      "  num_env_steps_sampled: 30000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 30000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.07142857142858\n",
      "    ram_util_percent: 60.019047619047605\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 7.600000000000004\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.005\n",
      "    policy2: -6.732999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -13.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1457977101683138\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06484642249062496\n",
      "    mean_inference_ms: 1.5363820783712328\n",
      "    mean_raw_obs_processing_ms: 0.28802251362748593\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 30.599999999999923\n",
      "    episode_reward_mean: 7.271999999999992\n",
      "    episode_reward_min: -21.90000000000002\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 6.599999999999975\n",
      "      - -13.500000000000005\n",
      "      - 12.600000000000032\n",
      "      - 12.599999999999955\n",
      "      - 10.19999999999997\n",
      "      - -2.9999999999999876\n",
      "      - 3.5999999999999797\n",
      "      - 8.700000000000031\n",
      "      - -5.099999999999985\n",
      "      - 7.500000000000021\n",
      "      - 6.600000000000023\n",
      "      - 10.80000000000003\n",
      "      - 3.6000000000000116\n",
      "      - 21.599999999999895\n",
      "      - 12.600000000000014\n",
      "      - 6.000000000000027\n",
      "      - 11.399999999999967\n",
      "      - -3.8999999999999915\n",
      "      - 16.499999999999957\n",
      "      - 0.6000000000000212\n",
      "      - 24.899999999999967\n",
      "      - 5.10000000000003\n",
      "      - 2.6999999999999833\n",
      "      - 12.90000000000001\n",
      "      - 5.4000000000000234\n",
      "      - 10.500000000000028\n",
      "      - 7.50000000000003\n",
      "      - 23.699999999999953\n",
      "      - 14.999999999999952\n",
      "      - -3.2999999999999883\n",
      "      - 11.400000000000022\n",
      "      - 12.000000000000005\n",
      "      - 17.699999999999996\n",
      "      - 16.19999999999994\n",
      "      - 4.200000000000016\n",
      "      - 0.9000000000000085\n",
      "      - 7.800000000000033\n",
      "      - 7.50000000000003\n",
      "      - 12.600000000000026\n",
      "      - -17.99999999999998\n",
      "      - 5.400000000000017\n",
      "      - 12.599999999999948\n",
      "      - -3.2999999999999883\n",
      "      - -5.099999999999991\n",
      "      - 1.2000000000000308\n",
      "      - 10.80000000000003\n",
      "      - 13.500000000000009\n",
      "      - 1.5000000000000022\n",
      "      - -5.699999999999996\n",
      "      - -3.299999999999988\n",
      "      - 3.0000000000000187\n",
      "      - 6.000000000000025\n",
      "      - 17.999999999999915\n",
      "      - 17.09999999999996\n",
      "      - 0.30000000000002025\n",
      "      - 1.2000000000000148\n",
      "      - 5.100000000000028\n",
      "      - -12.89999999999998\n",
      "      - 2.099999999999979\n",
      "      - 0.5999999999999509\n",
      "      - 5.999999999999988\n",
      "      - 10.500000000000028\n",
      "      - 16.799999999999926\n",
      "      - 20.099999999999987\n",
      "      - 9.90000000000003\n",
      "      - -21.90000000000002\n",
      "      - 3.0000000000000275\n",
      "      - 12.599999999999971\n",
      "      - 10.500000000000025\n",
      "      - 3.9000000000000195\n",
      "      - 5.999999999999988\n",
      "      - 11.999999999999982\n",
      "      - 1.2000000000000086\n",
      "      - 9.299999999999992\n",
      "      - 18.59999999999995\n",
      "      - 15.299999999999915\n",
      "      - 17.999999999999943\n",
      "      - 7.799999999999983\n",
      "      - -16.199999999999985\n",
      "      - 30.599999999999923\n",
      "      - 5.700000000000017\n",
      "      - 15.899999999999972\n",
      "      - 1.500000000000027\n",
      "      - 9.00000000000001\n",
      "      - 28.199999999999932\n",
      "      - -10.499999999999984\n",
      "      - 16.20000000000003\n",
      "      - 18.29999999999996\n",
      "      - 5.999999999999972\n",
      "      - 18.299999999999912\n",
      "      - -3.8999999999999924\n",
      "      - 15.000000000000032\n",
      "      - 1.500000000000011\n",
      "      - 2.6999999999999997\n",
      "      - 1.8000000000000167\n",
      "      - 12.29999999999998\n",
      "      - 18.599999999999966\n",
      "      - 6.599999999999966\n",
      "      - 3.0000000000000218\n",
      "      - 16.199999999999967\n",
      "      policy_policy1_reward:\n",
      "      - 15.5\n",
      "      - -3.5\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 16.5\n",
      "      - -10.5\n",
      "      - 17.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 5.0\n",
      "      - 26.5\n",
      "      - 9.5\n",
      "      - 25.0\n",
      "      - 8.5\n",
      "      - 5.0\n",
      "      - 18.5\n",
      "      - 11.0\n",
      "      - 20.5\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 24.0\n",
      "      - 12.0\n",
      "      - 6.5\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 11.0\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 0.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 18.0\n",
      "      - 6.0\n",
      "      - 1.0\n",
      "      - -1.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 28.0\n",
      "      - 20.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 14.0\n",
      "      - -4.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 23.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - -13.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 16.5\n",
      "      - 9.0\n",
      "      - 10.5\n",
      "      - 27.5\n",
      "      - 22.0\n",
      "      - 28.0\n",
      "      - 14.5\n",
      "      - -9.5\n",
      "      - 34.0\n",
      "      - 13.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 30.5\n",
      "      - -0.5\n",
      "      - 24.0\n",
      "      - 25.0\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 7.5\n",
      "      - 24.0\n",
      "      policy_policy2_reward:\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.79999999999999\n",
      "      - 5.400000000000011\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.09999999999999593\n",
      "      - -3.3999999999999995\n",
      "      - -2.299999999999998\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000002\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999995\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -3.4000000000000044\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999995\n",
      "      - -4.5\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4\n",
      "      - -6.699999999999983\n",
      "      - -2.300000000000003\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -7.7999999999999865\n",
      "      - -1.199999999999999\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000044\n",
      "      - -7.799999999999981\n",
      "      - -0.09999999999999779\n",
      "      - -4.500000000000003\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999994\n",
      "      - -3.3999999999999897\n",
      "      - 7.600000000000004\n",
      "      - -4.500000000000001\n",
      "      - -7.799999999999981\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 7.600000000000004\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.005\n",
      "      policy2: -6.732999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -13.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1457977101683138\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06484642249062496\n",
      "      mean_inference_ms: 1.5363820783712328\n",
      "      mean_raw_obs_processing_ms: 0.28802251362748593\n",
      "  time_since_restore: 126.06367421150208\n",
      "  time_this_iter_s: 14.51075291633606\n",
      "  time_total_s: 126.06367421150208\n",
      "  timers:\n",
      "    learn_throughput: 474.428\n",
      "    learn_time_ms: 6323.401\n",
      "    synch_weights_time_ms: 4.274\n",
      "    training_iteration_time_ms: 12599.247\n",
      "  timestamp: 1658917176\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 10\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 60000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_env_steps_sampled: 30000\n",
      "    num_env_steps_trained: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-37\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.399999999999956\n",
      "  episode_reward_mean: 1.9200000000000101\n",
      "  episode_reward_min: -17.399999999999984\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 300\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0732980966567993\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018295474350452423\n",
      "          model: {}\n",
      "          policy_loss: -0.05435498431324959\n",
      "          total_loss: 6.705576419830322\n",
      "          vf_explained_var: 0.23446404933929443\n",
      "          vf_loss: 6.751698970794678\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0091174840927124\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018993105739355087\n",
      "          model: {}\n",
      "          policy_loss: -0.052728280425071716\n",
      "          total_loss: 3.0853779315948486\n",
      "          vf_explained_var: 0.21195852756500244\n",
      "          vf_loss: 3.129559278488159\n",
      "    num_agent_steps_sampled: 60000\n",
      "    num_agent_steps_trained: 60000\n",
      "    num_env_steps_sampled: 30000\n",
      "    num_env_steps_trained: 30000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 60000\n",
      "  num_agent_steps_trained: 60000\n",
      "  num_env_steps_sampled: 30000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 30000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 55.88181818181818\n",
      "    ram_util_percent: 60.04545454545453\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 4.300000000000008\n",
      "  policy_reward_mean:\n",
      "    policy1: 8.51\n",
      "    policy2: -6.589999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -17.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14988996453169157\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06443286985648618\n",
      "    mean_inference_ms: 1.5652405517338794\n",
      "    mean_raw_obs_processing_ms: 0.29343383752009117\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.399999999999956\n",
      "    episode_reward_mean: 1.9200000000000101\n",
      "    episode_reward_min: -17.399999999999984\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -10.799999999999994\n",
      "      - 3.599999999999994\n",
      "      - 10.800000000000004\n",
      "      - 2.1000000000000245\n",
      "      - 4.500000000000028\n",
      "      - 7.500000000000025\n",
      "      - 0.6000000000000117\n",
      "      - 7.80000000000002\n",
      "      - -2.999999999999981\n",
      "      - -7.499999999999979\n",
      "      - -5.999999999999979\n",
      "      - -13.799999999999985\n",
      "      - 8.09999999999998\n",
      "      - -1.199999999999985\n",
      "      - -6.299999999999991\n",
      "      - 11.700000000000022\n",
      "      - 6.6000000000000245\n",
      "      - 6.6000000000000245\n",
      "      - -4.19999999999998\n",
      "      - 0.3000000000000147\n",
      "      - 1.7999999999999745\n",
      "      - 10.499999999999993\n",
      "      - 10.199999999999969\n",
      "      - 6.300000000000006\n",
      "      - -0.8999999999999868\n",
      "      - -7.499999999999972\n",
      "      - -17.399999999999984\n",
      "      - 7.500000000000003\n",
      "      - 1.5000000000000138\n",
      "      - -1.7999999999999872\n",
      "      - 14.700000000000022\n",
      "      - 7.200000000000008\n",
      "      - 23.399999999999956\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000021\n",
      "      - 1.500000000000019\n",
      "      - -8.699999999999983\n",
      "      - 1.500000000000012\n",
      "      - 12.299999999999926\n",
      "      - 4.800000000000013\n",
      "      - 8.700000000000001\n",
      "      - 8.40000000000002\n",
      "      - -4.4999999999999805\n",
      "      - -0.2999999999999817\n",
      "      - -1.7999999999999905\n",
      "      - 3.083644450896372e-14\n",
      "      - -3.89999999999999\n",
      "      - 4.200000000000024\n",
      "      - -1.1999999999999904\n",
      "      - 20.399999999999938\n",
      "      - 2.1000000000000223\n",
      "      - 4.5000000000000195\n",
      "      - -1.4999999999999738\n",
      "      - 5.400000000000027\n",
      "      - -13.79999999999998\n",
      "      - 6.000000000000014\n",
      "      - 1.5000000000000195\n",
      "      - 6.30000000000002\n",
      "      - 5.1000000000000245\n",
      "      - -5.099999999999978\n",
      "      - -11.699999999999983\n",
      "      - -5.999999999999991\n",
      "      - -0.8999999999999977\n",
      "      - 5.700000000000003\n",
      "      - 5.1000000000000245\n",
      "      - 0.3000000000000067\n",
      "      - -3.8999999999999866\n",
      "      - -7.499999999999979\n",
      "      - 3.0000000000000124\n",
      "      - -2.3999999999999835\n",
      "      - 22.499999999999936\n",
      "      - 15.300000000000015\n",
      "      - -2.699999999999985\n",
      "      - -1.499999999999989\n",
      "      - -5.099999999999987\n",
      "      - 1.7999999999999883\n",
      "      - 1.500000000000014\n",
      "      - -1.4999999999999747\n",
      "      - -5.3999999999999755\n",
      "      - 9.300000000000027\n",
      "      - -13.499999999999986\n",
      "      - 16.800000000000026\n",
      "      - -9.599999999999985\n",
      "      - -8.99999999999998\n",
      "      - 23.099999999999923\n",
      "      - 9.300000000000024\n",
      "      - 0.9000000000000067\n",
      "      - 5.100000000000017\n",
      "      - 0.900000000000028\n",
      "      - 9.000000000000021\n",
      "      - 3.0000000000000204\n",
      "      - 3.6000000000000028\n",
      "      - 9.29999999999997\n",
      "      - -1.7999999999999827\n",
      "      - 1.8000000000000114\n",
      "      - -3.299999999999975\n",
      "      - 1.5000000000000289\n",
      "      - 10.199999999999996\n",
      "      - -1.4999999999999818\n",
      "      - 6.000000000000002\n",
      "      policy_policy1_reward:\n",
      "      - -3.0\n",
      "      - 12.5\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 9.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 2.5\n",
      "      - 4.0\n",
      "      - -17.0\n",
      "      - 17.0\n",
      "      - 5.5\n",
      "      - 1.5\n",
      "      - 14.0\n",
      "      - 15.5\n",
      "      - 15.5\n",
      "      - -8.5\n",
      "      - 7.0\n",
      "      - 8.5\n",
      "      - 20.5\n",
      "      - 18.0\n",
      "      - 13.0\n",
      "      - 2.5\n",
      "      - 2.5\n",
      "      - -8.5\n",
      "      - 17.5\n",
      "      - 0.5\n",
      "      - 6.0\n",
      "      - 22.5\n",
      "      - 15.0\n",
      "      - 29.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - -2.0\n",
      "      - 0.5\n",
      "      - 19.0\n",
      "      - 6.0\n",
      "      - 16.5\n",
      "      - 14.0\n",
      "      - 5.5\n",
      "      - 7.5\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - -5.5\n",
      "      - 26.0\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - 14.0\n",
      "      - 0.5\n",
      "      - -5.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 2.5\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 32.5\n",
      "      - 22.0\n",
      "      - 4.0\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - -3.5\n",
      "      - 23.5\n",
      "      - -9.5\n",
      "      - -10.0\n",
      "      - 32.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 14.0\n",
      "      - 6.5\n",
      "      - 19.0\n",
      "      - 13.0\n",
      "      - 1.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - 4.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 3.200000000000001\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999988\n",
      "      - -2.2999999999999896\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 4.300000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999943\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 1.0000000000000093\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000042\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.7999999999999865\n",
      "      - 4.300000000000008\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -5.6\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999983\n",
      "      - -3.3999999999999986\n",
      "      - -6.699999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999997\n",
      "      - -3.4000000000000044\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999986\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000364\n",
      "      - 0.9999999999999976\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999998563\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 3.1999999999999984\n",
      "      - 0.9999999999999979\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 4.300000000000008\n",
      "    policy_reward_mean:\n",
      "      policy1: 8.51\n",
      "      policy2: -6.589999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -17.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14988996453169157\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06443286985648618\n",
      "      mean_inference_ms: 1.5652405517338794\n",
      "      mean_raw_obs_processing_ms: 0.29343383752009117\n",
      "  time_since_restore: 127.2973906993866\n",
      "  time_this_iter_s: 14.882826805114746\n",
      "  time_total_s: 127.2973906993866\n",
      "  timers:\n",
      "    learn_throughput: 475.636\n",
      "    learn_time_ms: 6307.343\n",
      "    synch_weights_time_ms: 3.608\n",
      "    training_iteration_time_ms: 12723.351\n",
      "  timestamp: 1658917177\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 10\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 56000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_env_steps_sampled: 28000\n",
      "    num_env_steps_trained: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.799999999999926\n",
      "  episode_reward_mean: 0.36300000000000776\n",
      "  episode_reward_min: -25.50000000000001\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 280\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1476136445999146\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017885420471429825\n",
      "          model: {}\n",
      "          policy_loss: -0.04955006390810013\n",
      "          total_loss: 6.292756080627441\n",
      "          vf_explained_var: 0.29451802372932434\n",
      "          vf_loss: 6.334258556365967\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.1350269317626953\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.02123565785586834\n",
      "          model: {}\n",
      "          policy_loss: -0.0497857965528965\n",
      "          total_loss: 3.001063108444214\n",
      "          vf_explained_var: 0.1592864990234375\n",
      "          vf_loss: 3.044478178024292\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 56000\n",
      "    num_env_steps_sampled: 28000\n",
      "    num_env_steps_trained: 28000\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 56000\n",
      "  num_agent_steps_trained: 56000\n",
      "  num_env_steps_sampled: 28000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 28000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.67241379310343\n",
      "    ram_util_percent: 59.91724137931035\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 6.500000000000014\n",
      "  policy_reward_mean:\n",
      "    policy1: 7.36\n",
      "    policy2: -6.996999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -15.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1524318536238593\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06578411308408719\n",
      "    mean_inference_ms: 1.6050486361202059\n",
      "    mean_raw_obs_processing_ms: 0.30068862603142493\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 22.799999999999926\n",
      "    episode_reward_mean: 0.36300000000000776\n",
      "    episode_reward_min: -25.50000000000001\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 7.7999999999999545\n",
      "      - -1.7999999999999927\n",
      "      - -1.4999999999999871\n",
      "      - -11.39999999999998\n",
      "      - -7.499999999999984\n",
      "      - 3.6000000000000294\n",
      "      - -10.499999999999975\n",
      "      - -15.29999999999998\n",
      "      - 4.499999999999954\n",
      "      - -4.799999999999978\n",
      "      - 8.400000000000013\n",
      "      - 12.299999999999997\n",
      "      - 12.600000000000009\n",
      "      - -5.699999999999987\n",
      "      - 0.3000000000000076\n",
      "      - -0.8999999999999848\n",
      "      - -7.499999999999972\n",
      "      - 6.300000000000004\n",
      "      - -2.699999999999986\n",
      "      - -4.499999999999984\n",
      "      - 11.399999999999954\n",
      "      - 1.5000000000000093\n",
      "      - -4.200000000000015\n",
      "      - -8.399999999999983\n",
      "      - 0.6000000000000046\n",
      "      - 3.000000000000017\n",
      "      - -15.89999999999999\n",
      "      - 8.700000000000006\n",
      "      - 1.200000000000022\n",
      "      - -0.29999999999997373\n",
      "      - -25.50000000000001\n",
      "      - -8.399999999999974\n",
      "      - -7.199999999999992\n",
      "      - 8.700000000000012\n",
      "      - -0.29999999999997995\n",
      "      - 11.999999999999991\n",
      "      - -3.29999999999998\n",
      "      - 6.000000000000023\n",
      "      - -1.712519015484304e-14\n",
      "      - 1.200000000000002\n",
      "      - 2.9999999999999867\n",
      "      - -3.2999999999999887\n",
      "      - -4.799999999999978\n",
      "      - -5.399999999999992\n",
      "      - -7.499999999999992\n",
      "      - -12.899999999999983\n",
      "      - 13.200000000000031\n",
      "      - 8.099999999999996\n",
      "      - 14.09999999999992\n",
      "      - -10.499999999999975\n",
      "      - 1.2000000000000153\n",
      "      - 10.5\n",
      "      - 14.100000000000003\n",
      "      - 2.1000000000000045\n",
      "      - -8.399999999999977\n",
      "      - 22.49999999999998\n",
      "      - -12.299999999999974\n",
      "      - 8.99999999999998\n",
      "      - 8.400000000000013\n",
      "      - -8.099999999999975\n",
      "      - 6.600000000000033\n",
      "      - 22.799999999999926\n",
      "      - 10.500000000000016\n",
      "      - -2.3999999999999764\n",
      "      - 4.800000000000015\n",
      "      - 10.199999999999992\n",
      "      - -3.899999999999983\n",
      "      - 11.400000000000032\n",
      "      - -5.999999999999986\n",
      "      - -6.299999999999978\n",
      "      - -4.499999999999972\n",
      "      - -4.500000000000011\n",
      "      - 12.599999999999932\n",
      "      - -2.999999999999986\n",
      "      - 6.0000000000000195\n",
      "      - 4.500000000000023\n",
      "      - 12.599999999999957\n",
      "      - 5.399999999999974\n",
      "      - -8.399999999999975\n",
      "      - 5.100000000000017\n",
      "      - -9.900000000000013\n",
      "      - 0.30000000000002025\n",
      "      - 2.100000000000024\n",
      "      - -7.4999999999999805\n",
      "      - -2.3999999999999817\n",
      "      - -24.0\n",
      "      - 4.50000000000002\n",
      "      - -9.599999999999987\n",
      "      - 7.2000000000000295\n",
      "      - 2.7000000000000264\n",
      "      - 1.174060848541103e-14\n",
      "      - -5.699999999999987\n",
      "      - -2.399999999999973\n",
      "      - -5.399999999999984\n",
      "      - 5.999999999999979\n",
      "      - -4.499999999999979\n",
      "      - 3.000000000000017\n",
      "      - 4.200000000000024\n",
      "      - 5.1\n",
      "      - 3.6000000000000294\n",
      "      policy_policy1_reward:\n",
      "      - 14.5\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - -2.5\n",
      "      - 2.5\n",
      "      - 7.0\n",
      "      - -0.5\n",
      "      - -7.5\n",
      "      - 9.0\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 1.0\n",
      "      - 7.0\n",
      "      - 8.0\n",
      "      - 2.5\n",
      "      - 13.0\n",
      "      - 4.0\n",
      "      - 5.5\n",
      "      - 17.0\n",
      "      - 11.5\n",
      "      - 2.5\n",
      "      - 0.5\n",
      "      - 4.0\n",
      "      - 13.0\n",
      "      - -7.0\n",
      "      - 16.5\n",
      "      - 9.0\n",
      "      - 2.0\n",
      "      - -15.5\n",
      "      - 0.5\n",
      "      - -6.0\n",
      "      - 11.0\n",
      "      - 7.5\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 16.0\n",
      "      - 10.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - -6.5\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 2.5\n",
      "      - -4.0\n",
      "      - 21.0\n",
      "      - 6.0\n",
      "      - 23.0\n",
      "      - -0.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 23.0\n",
      "      - 11.0\n",
      "      - -5.0\n",
      "      - 32.5\n",
      "      - -4.5\n",
      "      - 13.5\n",
      "      - 14.0\n",
      "      - -2.5\n",
      "      - 15.5\n",
      "      - 24.0\n",
      "      - 15.0\n",
      "      - 6.5\n",
      "      - 11.5\n",
      "      - 18.0\n",
      "      - 5.0\n",
      "      - 17.0\n",
      "      - 4.0\n",
      "      - 1.5\n",
      "      - 5.5\n",
      "      - 5.5\n",
      "      - 21.5\n",
      "      - 1.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 21.5\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 14.0\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 11.0\n",
      "      - 2.5\n",
      "      - 1.0\n",
      "      - -14.0\n",
      "      - 14.5\n",
      "      - -4.0\n",
      "      - 15.0\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - -10.0\n",
      "      - 6.5\n",
      "      - 3.5\n",
      "      - 10.5\n",
      "      - 5.5\n",
      "      - -3.5\n",
      "      - 12.0\n",
      "      - 14.0\n",
      "      - 7.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999995\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999982\n",
      "      - -6.699999999999987\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999987\n",
      "      - -8.899999999999984\n",
      "      - -3.399999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.79999999999999\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -1.1999999999999982\n",
      "      - -2.2999999999999927\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999984\n",
      "      - 3.199999999999999\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999985\n",
      "      - 2.0999999999999943\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.500000000000003\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999999\n",
      "      - -8.899999999999986\n",
      "      - -1.199999999999989\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.5\n",
      "      - -4.499999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.09999999999999509\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -7.7999999999999865\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000006\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -4.4999999999999885\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000014\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 6.500000000000014\n",
      "    policy_reward_mean:\n",
      "      policy1: 7.36\n",
      "      policy2: -6.996999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -15.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1524318536238593\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06578411308408719\n",
      "      mean_inference_ms: 1.6050486361202059\n",
      "      mean_raw_obs_processing_ms: 0.30068862603142493\n",
      "  time_since_restore: 124.09174060821533\n",
      "  time_this_iter_s: 20.23403787612915\n",
      "  time_total_s: 124.09174060821533\n",
      "  timers:\n",
      "    learn_throughput: 446.687\n",
      "    learn_time_ms: 8954.809\n",
      "    synch_weights_time_ms: 3.769\n",
      "    training_iteration_time_ms: 17720.287\n",
      "  timestamp: 1658917181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 7\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 64000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_env_steps_sampled: 32000\n",
      "    num_env_steps_trained: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-41\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 22.799999999999983\n",
      "  episode_reward_mean: 6.092999999999997\n",
      "  episode_reward_min: -16.49999999999998\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 320\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1280633211135864\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013104433193802834\n",
      "          model: {}\n",
      "          policy_loss: -0.0387432835996151\n",
      "          total_loss: 7.065526485443115\n",
      "          vf_explained_var: 0.18689700961112976\n",
      "          vf_loss: 7.101648807525635\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.1073933839797974\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01337507925927639\n",
      "          model: {}\n",
      "          policy_loss: -0.03586779162287712\n",
      "          total_loss: 3.109609842300415\n",
      "          vf_explained_var: 0.18135717511177063\n",
      "          vf_loss: 3.1428024768829346\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_env_steps_sampled: 32000\n",
      "    num_env_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_env_steps_sampled: 32000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 32000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.141379310344824\n",
      "    ram_util_percent: 59.920689655172424\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 30.0\n",
      "    policy2: 3.2000000000000073\n",
      "  policy_reward_mean:\n",
      "    policy1: 12.265\n",
      "    policy2: -6.171999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -6.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14626176563203008\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06359985891752175\n",
      "    mean_inference_ms: 1.53199397109762\n",
      "    mean_raw_obs_processing_ms: 0.28813550045938313\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 22.799999999999983\n",
      "    episode_reward_mean: 6.092999999999997\n",
      "    episode_reward_min: -16.49999999999998\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.800000000000015\n",
      "      - 8.699999999999998\n",
      "      - 3.9000000000000195\n",
      "      - -11.699999999999982\n",
      "      - 2.100000000000022\n",
      "      - 6.299999999999956\n",
      "      - 2.700000000000009\n",
      "      - -2.099999999999981\n",
      "      - -2.0999999999999877\n",
      "      - 14.400000000000011\n",
      "      - 4.200000000000022\n",
      "      - 8.999999999999915\n",
      "      - 2.4000000000000274\n",
      "      - 6.5999999999999766\n",
      "      - 1.2961853812498703e-14\n",
      "      - 7.800000000000017\n",
      "      - 1.5000000000000102\n",
      "      - 3.6000000000000276\n",
      "      - 8.10000000000003\n",
      "      - -5.999999999999977\n",
      "      - 15.000000000000018\n",
      "      - -13.499999999999993\n",
      "      - -16.49999999999998\n",
      "      - 13.199999999999948\n",
      "      - 2.373101715136272e-14\n",
      "      - 18.599999999999937\n",
      "      - 10.800000000000031\n",
      "      - 14.699999999999898\n",
      "      - -5.999999999999984\n",
      "      - 12.000000000000028\n",
      "      - 13.499999999999988\n",
      "      - 14.69999999999999\n",
      "      - 1.8000000000000167\n",
      "      - 14.100000000000025\n",
      "      - 3.000000000000023\n",
      "      - 1.529332216421153e-14\n",
      "      - -1.199999999999982\n",
      "      - -8.399999999999983\n",
      "      - -2.3999999999999986\n",
      "      - 12.3\n",
      "      - 4.5000000000000036\n",
      "      - -0.29999999999997795\n",
      "      - 7.499999999999936\n",
      "      - 4.199999999999971\n",
      "      - -5.699999999999976\n",
      "      - -5.999999999999987\n",
      "      - -2.3999999999999853\n",
      "      - 10.79999999999998\n",
      "      - 11.999999999999932\n",
      "      - 5.700000000000033\n",
      "      - 14.399999999999926\n",
      "      - -2.999999999999975\n",
      "      - 10.800000000000017\n",
      "      - 8.100000000000028\n",
      "      - 15.60000000000001\n",
      "      - 1.5000000000000187\n",
      "      - 20.099999999999923\n",
      "      - -3.5999999999999766\n",
      "      - 5.399999999999993\n",
      "      - 22.799999999999983\n",
      "      - -6.899999999999988\n",
      "      - 11.999999999999968\n",
      "      - 1.5000000000000169\n",
      "      - 7.499999999999941\n",
      "      - 7.200000000000031\n",
      "      - 18.299999999999926\n",
      "      - -9.299999999999999\n",
      "      - 17.399999999999913\n",
      "      - 7.500000000000025\n",
      "      - 9.900000000000029\n",
      "      - -6.299999999999994\n",
      "      - 13.799999999999912\n",
      "      - 4.2000000000000135\n",
      "      - 22.19999999999994\n",
      "      - 14.999999999999988\n",
      "      - 6.600000000000017\n",
      "      - 16.49999999999998\n",
      "      - 17.10000000000002\n",
      "      - 16.199999999999953\n",
      "      - -13.199999999999976\n",
      "      - -5.399999999999989\n",
      "      - 4.199999999999973\n",
      "      - 15.900000000000007\n",
      "      - 0.900000000000028\n",
      "      - 19.499999999999993\n",
      "      - -4.199999999999987\n",
      "      - 3.300000000000032\n",
      "      - 19.199999999999918\n",
      "      - 6.900000000000002\n",
      "      - 6.900000000000027\n",
      "      - 5.100000000000021\n",
      "      - 2.700000000000023\n",
      "      - 6.600000000000026\n",
      "      - 3.000000000000033\n",
      "      - 18.299999999999976\n",
      "      - 20.09999999999989\n",
      "      - 4.500000000000009\n",
      "      - 5.100000000000017\n",
      "      - 18.299999999999976\n",
      "      - 18.899999999999967\n",
      "      policy_policy1_reward:\n",
      "      - 11.5\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - -5.0\n",
      "      - 11.0\n",
      "      - 13.0\n",
      "      - 5.0\n",
      "      - -2.0\n",
      "      - 3.5\n",
      "      - 20.0\n",
      "      - 12.0\n",
      "      - 13.5\n",
      "      - 2.5\n",
      "      - 10.0\n",
      "      - 4.5\n",
      "      - 9.0\n",
      "      - 6.0\n",
      "      - 12.5\n",
      "      - 17.0\n",
      "      - 4.0\n",
      "      - 25.0\n",
      "      - -3.5\n",
      "      - -6.5\n",
      "      - 21.0\n",
      "      - 10.0\n",
      "      - 27.5\n",
      "      - 17.5\n",
      "      - 22.5\n",
      "      - 4.0\n",
      "      - 22.0\n",
      "      - 23.5\n",
      "      - 22.5\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - 7.5\n",
      "      - 10.0\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 6.5\n",
      "      - 19.0\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 12.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - -1.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 17.5\n",
      "      - 17.0\n",
      "      - 24.5\n",
      "      - 0.5\n",
      "      - 29.0\n",
      "      - 2.0\n",
      "      - 11.0\n",
      "      - 24.0\n",
      "      - 2.0\n",
      "      - 22.0\n",
      "      - 11.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 25.0\n",
      "      - -1.5\n",
      "      - 23.0\n",
      "      - 17.5\n",
      "      - 15.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 30.0\n",
      "      - 19.5\n",
      "      - 10.0\n",
      "      - 26.5\n",
      "      - 26.0\n",
      "      - 24.0\n",
      "      - -6.5\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 16.0\n",
      "      - 6.5\n",
      "      - 29.5\n",
      "      - -3.0\n",
      "      - 10.0\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 3.0\n",
      "      - 10.5\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 19.5\n",
      "      - 29.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 25.0\n",
      "      - 24.5\n",
      "      policy_policy2_reward:\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000004\n",
      "      - -5.599999999999983\n",
      "      - -6.699999999999984\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -2.300000000000003\n",
      "      - -0.10000000000000175\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999984\n",
      "      - -4.5000000000000036\n",
      "      - -0.10000000000000464\n",
      "      - -3.4000000000000044\n",
      "      - -4.499999999999997\n",
      "      - -1.199999999999994\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999993\n",
      "      - -3.3999999999999915\n",
      "      - -4.500000000000004\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999987\n",
      "      - -4.500000000000003\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999982\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999988\n",
      "      - -3.4000000000000052\n",
      "      - -6.699999999999987\n",
      "      - 1.0000000000000075\n",
      "      - -7.799999999999982\n",
      "      - -0.0999999999999962\n",
      "      - -4.500000000000001\n",
      "      - -6.699999999999994\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - 0.9999999999999946\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -1.200000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999986\n",
      "      - -6.69999999999999\n",
      "      - -7.799999999999981\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999986\n",
      "      - -2.300000000000007\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -3.400000000000006\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - 3.2000000000000073\n",
      "      - -0.09999999999999232\n",
      "      - -5.599999999999994\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999992\n",
      "      - -0.10000000000000675\n",
      "      - 2.0999999999999974\n",
      "      - -7.799999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.200000000000004\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999924\n",
      "      - -6.699999999999984\n",
      "      - -5.599999999999984\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 30.0\n",
      "      policy2: 3.2000000000000073\n",
      "    policy_reward_mean:\n",
      "      policy1: 12.265\n",
      "      policy2: -6.171999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -6.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14626176563203008\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06359985891752175\n",
      "      mean_inference_ms: 1.53199397109762\n",
      "      mean_raw_obs_processing_ms: 0.28813550045938313\n",
      "  time_since_restore: 134.2980272769928\n",
      "  time_this_iter_s: 20.229374170303345\n",
      "  time_total_s: 134.2980272769928\n",
      "  timers:\n",
      "    learn_throughput: 478.443\n",
      "    learn_time_ms: 8360.457\n",
      "    synch_weights_time_ms: 3.716\n",
      "    training_iteration_time_ms: 16779.496\n",
      "  timestamp: 1658917181\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 66000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 66000\n",
      "    num_env_steps_sampled: 33000\n",
      "    num_env_steps_trained: 33000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-52\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 30.599999999999923\n",
      "  episode_reward_mean: 7.784999999999989\n",
      "  episode_reward_min: -21.90000000000002\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 330\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0099689960479736\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.0132649140432477\n",
      "          model: {}\n",
      "          policy_loss: -0.0439159981906414\n",
      "          total_loss: 7.349052429199219\n",
      "          vf_explained_var: 0.2634908854961395\n",
      "          vf_loss: 7.390315532684326\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9487521648406982\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014884631149470806\n",
      "          model: {}\n",
      "          policy_loss: -0.04756339266896248\n",
      "          total_loss: 2.741011619567871\n",
      "          vf_explained_var: 0.10835278034210205\n",
      "          vf_loss: 2.7870867252349854\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 66000\n",
      "    num_env_steps_sampled: 33000\n",
      "    num_env_steps_trained: 33000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 66000\n",
      "  num_agent_steps_trained: 66000\n",
      "  num_env_steps_sampled: 33000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 33000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.62727272727273\n",
      "    ram_util_percent: 59.85454545454545\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 7.600000000000004\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.32\n",
      "    policy2: -6.534999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -13.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.14920308993098033\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06626765557805257\n",
      "    mean_inference_ms: 1.571649810440297\n",
      "    mean_raw_obs_processing_ms: 0.29479992841434355\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 30.599999999999923\n",
      "    episode_reward_mean: 7.784999999999989\n",
      "    episode_reward_min: -21.90000000000002\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 11.400000000000022\n",
      "      - 12.000000000000005\n",
      "      - 17.699999999999996\n",
      "      - 16.19999999999994\n",
      "      - 4.200000000000016\n",
      "      - 0.9000000000000085\n",
      "      - 7.800000000000033\n",
      "      - 7.50000000000003\n",
      "      - 12.600000000000026\n",
      "      - -17.99999999999998\n",
      "      - 5.400000000000017\n",
      "      - 12.599999999999948\n",
      "      - -3.2999999999999883\n",
      "      - -5.099999999999991\n",
      "      - 1.2000000000000308\n",
      "      - 10.80000000000003\n",
      "      - 13.500000000000009\n",
      "      - 1.5000000000000022\n",
      "      - -5.699999999999996\n",
      "      - -3.299999999999988\n",
      "      - 3.0000000000000187\n",
      "      - 6.000000000000025\n",
      "      - 17.999999999999915\n",
      "      - 17.09999999999996\n",
      "      - 0.30000000000002025\n",
      "      - 1.2000000000000148\n",
      "      - 5.100000000000028\n",
      "      - -12.89999999999998\n",
      "      - 2.099999999999979\n",
      "      - 0.5999999999999509\n",
      "      - 5.999999999999988\n",
      "      - 10.500000000000028\n",
      "      - 16.799999999999926\n",
      "      - 20.099999999999987\n",
      "      - 9.90000000000003\n",
      "      - -21.90000000000002\n",
      "      - 3.0000000000000275\n",
      "      - 12.599999999999971\n",
      "      - 10.500000000000025\n",
      "      - 3.9000000000000195\n",
      "      - 5.999999999999988\n",
      "      - 11.999999999999982\n",
      "      - 1.2000000000000086\n",
      "      - 9.299999999999992\n",
      "      - 18.59999999999995\n",
      "      - 15.299999999999915\n",
      "      - 17.999999999999943\n",
      "      - 7.799999999999983\n",
      "      - -16.199999999999985\n",
      "      - 30.599999999999923\n",
      "      - 5.700000000000017\n",
      "      - 15.899999999999972\n",
      "      - 1.500000000000027\n",
      "      - 9.00000000000001\n",
      "      - 28.199999999999932\n",
      "      - -10.499999999999984\n",
      "      - 16.20000000000003\n",
      "      - 18.29999999999996\n",
      "      - 5.999999999999972\n",
      "      - 18.299999999999912\n",
      "      - -3.8999999999999924\n",
      "      - 15.000000000000032\n",
      "      - 1.500000000000011\n",
      "      - 2.6999999999999997\n",
      "      - 1.8000000000000167\n",
      "      - 12.29999999999998\n",
      "      - 18.599999999999966\n",
      "      - 6.599999999999966\n",
      "      - 3.0000000000000218\n",
      "      - 16.199999999999967\n",
      "      - 16.19999999999999\n",
      "      - 11.10000000000002\n",
      "      - 14.70000000000002\n",
      "      - 5.400000000000027\n",
      "      - 10.199999999999973\n",
      "      - 12.89999999999998\n",
      "      - 24.899999999999913\n",
      "      - -9.299999999999978\n",
      "      - 12.60000000000003\n",
      "      - 12.89999999999996\n",
      "      - 19.19999999999994\n",
      "      - -9.6\n",
      "      - 14.09999999999993\n",
      "      - 11.399999999999913\n",
      "      - 13.199999999999955\n",
      "      - 8.099999999999957\n",
      "      - -9.299999999999972\n",
      "      - 8.399999999999999\n",
      "      - 16.799999999999912\n",
      "      - 11.399999999999945\n",
      "      - 12.000000000000034\n",
      "      - 18.899999999999956\n",
      "      - 14.399999999999936\n",
      "      - 14.99999999999991\n",
      "      - -1.4999999999999853\n",
      "      - 0.30000000000000493\n",
      "      - 7.799999999999942\n",
      "      - 14.099999999999978\n",
      "      - 7.199999999999971\n",
      "      - -1.8000000000000007\n",
      "      policy_policy1_reward:\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 24.0\n",
      "      - 12.0\n",
      "      - 6.5\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 11.0\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 0.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 18.0\n",
      "      - 6.0\n",
      "      - 1.0\n",
      "      - -1.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 28.0\n",
      "      - 20.5\n",
      "      - 7.0\n",
      "      - 3.5\n",
      "      - 14.0\n",
      "      - -4.0\n",
      "      - 11.0\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 23.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - -13.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 16.5\n",
      "      - 9.0\n",
      "      - 10.5\n",
      "      - 27.5\n",
      "      - 22.0\n",
      "      - 28.0\n",
      "      - 14.5\n",
      "      - -9.5\n",
      "      - 34.0\n",
      "      - 13.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 30.5\n",
      "      - -0.5\n",
      "      - 24.0\n",
      "      - 25.0\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 7.5\n",
      "      - 24.0\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 12.5\n",
      "      - 18.5\n",
      "      - 30.5\n",
      "      - -1.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 21.5\n",
      "      - -4.0\n",
      "      - 23.0\n",
      "      - 17.0\n",
      "      - 21.0\n",
      "      - 17.0\n",
      "      - -1.5\n",
      "      - 8.5\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 25.0\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 6.0\n",
      "      policy_policy2_reward:\n",
      "      - -5.5999999999999925\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999995\n",
      "      - -4.500000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -3.4000000000000044\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999995\n",
      "      - -4.5\n",
      "      - -6.6999999999999815\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4\n",
      "      - -6.699999999999983\n",
      "      - -2.300000000000003\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -7.7999999999999865\n",
      "      - -1.199999999999999\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000044\n",
      "      - -7.799999999999981\n",
      "      - -0.09999999999999779\n",
      "      - -4.500000000000003\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999994\n",
      "      - -3.3999999999999897\n",
      "      - 7.600000000000004\n",
      "      - -4.500000000000001\n",
      "      - -7.799999999999981\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999984\n",
      "      - -2.2999999999999976\n",
      "      - -5.599999999999998\n",
      "      - -2.299999999999984\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999987\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999988\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000431\n",
      "      - -6.699999999999993\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999979\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -3.399999999999994\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999986\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 7.600000000000004\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.32\n",
      "      policy2: -6.534999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -13.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.14920308993098033\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06626765557805257\n",
      "      mean_inference_ms: 1.571649810440297\n",
      "      mean_raw_obs_processing_ms: 0.29479992841434355\n",
      "  time_since_restore: 141.23441410064697\n",
      "  time_this_iter_s: 15.170739889144897\n",
      "  time_total_s: 141.23441410064697\n",
      "  timers:\n",
      "    learn_throughput: 454.253\n",
      "    learn_time_ms: 6604.243\n",
      "    synch_weights_time_ms: 4.355\n",
      "    training_iteration_time_ms: 13332.296\n",
      "  timestamp: 1658917192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 11\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 66000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 66000\n",
      "    num_env_steps_sampled: 33000\n",
      "    num_env_steps_trained: 33000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-19-52\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.399999999999956\n",
      "  episode_reward_mean: 3.7680000000000042\n",
      "  episode_reward_min: -16.49999999999998\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 330\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.043629765510559\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019383687525987625\n",
      "          model: {}\n",
      "          policy_loss: -0.05511296167969704\n",
      "          total_loss: 6.472012042999268\n",
      "          vf_explained_var: 0.26160743832588196\n",
      "          vf_loss: 6.518401622772217\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9619395136833191\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017916196957230568\n",
      "          model: {}\n",
      "          policy_loss: -0.052171315997838974\n",
      "          total_loss: 2.85982608795166\n",
      "          vf_explained_var: 0.1696033924818039\n",
      "          vf_loss: 2.9039347171783447\n",
      "    num_agent_steps_sampled: 66000\n",
      "    num_agent_steps_trained: 66000\n",
      "    num_env_steps_sampled: 33000\n",
      "    num_env_steps_trained: 33000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 66000\n",
      "  num_agent_steps_trained: 66000\n",
      "  num_env_steps_sampled: 33000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 33000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.33809523809524\n",
      "    ram_util_percent: 59.847619047619055\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 6.500000000000021\n",
      "  policy_reward_mean:\n",
      "    policy1: 10.105\n",
      "    policy2: -6.336999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -10.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15345289887751232\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06590788521699797\n",
      "    mean_inference_ms: 1.6015998085242427\n",
      "    mean_raw_obs_processing_ms: 0.30077697193405906\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.399999999999956\n",
      "    episode_reward_mean: 3.7680000000000042\n",
      "    episode_reward_min: -16.49999999999998\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 14.700000000000022\n",
      "      - 7.200000000000008\n",
      "      - 23.399999999999956\n",
      "      - -16.49999999999998\n",
      "      - 6.000000000000021\n",
      "      - 1.500000000000019\n",
      "      - -8.699999999999983\n",
      "      - 1.500000000000012\n",
      "      - 12.299999999999926\n",
      "      - 4.800000000000013\n",
      "      - 8.700000000000001\n",
      "      - 8.40000000000002\n",
      "      - -4.4999999999999805\n",
      "      - -0.2999999999999817\n",
      "      - -1.7999999999999905\n",
      "      - 3.083644450896372e-14\n",
      "      - -3.89999999999999\n",
      "      - 4.200000000000024\n",
      "      - -1.1999999999999904\n",
      "      - 20.399999999999938\n",
      "      - 2.1000000000000223\n",
      "      - 4.5000000000000195\n",
      "      - -1.4999999999999738\n",
      "      - 5.400000000000027\n",
      "      - -13.79999999999998\n",
      "      - 6.000000000000014\n",
      "      - 1.5000000000000195\n",
      "      - 6.30000000000002\n",
      "      - 5.1000000000000245\n",
      "      - -5.099999999999978\n",
      "      - -11.699999999999983\n",
      "      - -5.999999999999991\n",
      "      - -0.8999999999999977\n",
      "      - 5.700000000000003\n",
      "      - 5.1000000000000245\n",
      "      - 0.3000000000000067\n",
      "      - -3.8999999999999866\n",
      "      - -7.499999999999979\n",
      "      - 3.0000000000000124\n",
      "      - -2.3999999999999835\n",
      "      - 22.499999999999936\n",
      "      - 15.300000000000015\n",
      "      - -2.699999999999985\n",
      "      - -1.499999999999989\n",
      "      - -5.099999999999987\n",
      "      - 1.7999999999999883\n",
      "      - 1.500000000000014\n",
      "      - -1.4999999999999747\n",
      "      - -5.3999999999999755\n",
      "      - 9.300000000000027\n",
      "      - -13.499999999999986\n",
      "      - 16.800000000000026\n",
      "      - -9.599999999999985\n",
      "      - -8.99999999999998\n",
      "      - 23.099999999999923\n",
      "      - 9.300000000000024\n",
      "      - 0.9000000000000067\n",
      "      - 5.100000000000017\n",
      "      - 0.900000000000028\n",
      "      - 9.000000000000021\n",
      "      - 3.0000000000000204\n",
      "      - 3.6000000000000028\n",
      "      - 9.29999999999997\n",
      "      - -1.7999999999999827\n",
      "      - 1.8000000000000114\n",
      "      - -3.299999999999975\n",
      "      - 1.5000000000000289\n",
      "      - 10.199999999999996\n",
      "      - -1.4999999999999818\n",
      "      - 6.000000000000002\n",
      "      - 6.0000000000000195\n",
      "      - -8.99999999999999\n",
      "      - 18.599999999999937\n",
      "      - 15.600000000000003\n",
      "      - -4.199999999999983\n",
      "      - 6.00000000000003\n",
      "      - 13.20000000000001\n",
      "      - 20.099999999999902\n",
      "      - 14.699999999999921\n",
      "      - 3.000000000000024\n",
      "      - 16.799999999999947\n",
      "      - 9.00000000000002\n",
      "      - 3.300000000000025\n",
      "      - 10.800000000000027\n",
      "      - 3.3000000000000247\n",
      "      - 2.6999999999999607\n",
      "      - 19.499999999999893\n",
      "      - 9.299999999999976\n",
      "      - 12.000000000000007\n",
      "      - 0.3000000000000298\n",
      "      - 1.2000000000000188\n",
      "      - -0.9000000000000024\n",
      "      - -5.999999999999972\n",
      "      - 14.999999999999961\n",
      "      - 7.500000000000034\n",
      "      - -4.199999999999994\n",
      "      - 5.699999999999969\n",
      "      - 15.299999999999937\n",
      "      - 10.499999999999925\n",
      "      - -2.699999999999972\n",
      "      policy_policy1_reward:\n",
      "      - 22.5\n",
      "      - 15.0\n",
      "      - 29.0\n",
      "      - -6.5\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - -2.0\n",
      "      - 0.5\n",
      "      - 19.0\n",
      "      - 6.0\n",
      "      - 16.5\n",
      "      - 14.0\n",
      "      - 5.5\n",
      "      - 7.5\n",
      "      - 6.0\n",
      "      - 10.0\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - -5.5\n",
      "      - 26.0\n",
      "      - 11.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 16.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - 14.0\n",
      "      - 0.5\n",
      "      - -5.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 2.5\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 32.5\n",
      "      - 22.0\n",
      "      - 4.0\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - -3.5\n",
      "      - 23.5\n",
      "      - -9.5\n",
      "      - -10.0\n",
      "      - 32.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 14.0\n",
      "      - 6.5\n",
      "      - 19.0\n",
      "      - 13.0\n",
      "      - 1.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - 4.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 2.5\n",
      "      - 16.0\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 22.5\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 8.0\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - -1.0\n",
      "      - -0.5\n",
      "      - 29.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - -3.0\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 1.0000000000000093\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000042\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999985\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.7999999999999865\n",
      "      - 4.300000000000008\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999996\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.899999999999986\n",
      "      - -5.6\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999983\n",
      "      - -3.3999999999999986\n",
      "      - -6.699999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999997\n",
      "      - -3.4000000000000044\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999986\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000364\n",
      "      - 0.9999999999999976\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999998563\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 3.1999999999999984\n",
      "      - 0.9999999999999979\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - 1.000000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - 4.299999999999999\n",
      "      - 3.200000000000003\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000021\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000022\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - 1.0000000000000129\n",
      "      - -6.699999999999994\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 6.500000000000021\n",
      "    policy_reward_mean:\n",
      "      policy1: 10.105\n",
      "      policy2: -6.336999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -10.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15345289887751232\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06590788521699797\n",
      "      mean_inference_ms: 1.6015998085242427\n",
      "      mean_raw_obs_processing_ms: 0.30077697193405906\n",
      "  time_since_restore: 142.12525057792664\n",
      "  time_this_iter_s: 14.827859878540039\n",
      "  time_total_s: 142.12525057792664\n",
      "  timers:\n",
      "    learn_throughput: 456.78\n",
      "    learn_time_ms: 6567.716\n",
      "    synch_weights_time_ms: 3.669\n",
      "    training_iteration_time_ms: 13397.303\n",
      "  timestamp: 1658917192\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 33000\n",
      "  training_iteration: 11\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 64000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_env_steps_sampled: 32000\n",
      "    num_env_steps_trained: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-02\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 24.89999999999998\n",
      "  episode_reward_mean: 2.6520000000000072\n",
      "  episode_reward_min: -24.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 320\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.109828233718872\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015722697600722313\n",
      "          model: {}\n",
      "          policy_loss: -0.04246313497424126\n",
      "          total_loss: 6.388411521911621\n",
      "          vf_explained_var: 0.1524168998003006\n",
      "          vf_loss: 6.423799514770508\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.097143292427063\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017671091482043266\n",
      "          model: {}\n",
      "          policy_loss: -0.04679924249649048\n",
      "          total_loss: 2.3351237773895264\n",
      "          vf_explained_var: 0.2243797481060028\n",
      "          vf_loss: 2.3739709854125977\n",
      "    num_agent_steps_sampled: 64000\n",
      "    num_agent_steps_trained: 64000\n",
      "    num_env_steps_sampled: 32000\n",
      "    num_env_steps_trained: 32000\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 64000\n",
      "  num_agent_steps_trained: 64000\n",
      "  num_env_steps_sampled: 32000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 32000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.65\n",
      "    ram_util_percent: 59.733333333333334\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 6.500000000000014\n",
      "  policy_reward_mean:\n",
      "    policy1: 9.605\n",
      "    policy2: -6.952999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -14.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15700258110075088\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06764310631926686\n",
      "    mean_inference_ms: 1.6578399416384577\n",
      "    mean_raw_obs_processing_ms: 0.3094672143519579\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 24.89999999999998\n",
      "    episode_reward_mean: 2.6520000000000072\n",
      "    episode_reward_min: -24.0\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 2.9999999999999867\n",
      "      - -3.2999999999999887\n",
      "      - -4.799999999999978\n",
      "      - -5.399999999999992\n",
      "      - -7.499999999999992\n",
      "      - -12.899999999999983\n",
      "      - 13.200000000000031\n",
      "      - 8.099999999999996\n",
      "      - 14.09999999999992\n",
      "      - -10.499999999999975\n",
      "      - 1.2000000000000153\n",
      "      - 10.5\n",
      "      - 14.100000000000003\n",
      "      - 2.1000000000000045\n",
      "      - -8.399999999999977\n",
      "      - 22.49999999999998\n",
      "      - -12.299999999999974\n",
      "      - 8.99999999999998\n",
      "      - 8.400000000000013\n",
      "      - -8.099999999999975\n",
      "      - 6.600000000000033\n",
      "      - 22.799999999999926\n",
      "      - 10.500000000000016\n",
      "      - -2.3999999999999764\n",
      "      - 4.800000000000015\n",
      "      - 10.199999999999992\n",
      "      - -3.899999999999983\n",
      "      - 11.400000000000032\n",
      "      - -5.999999999999986\n",
      "      - -6.299999999999978\n",
      "      - -4.499999999999972\n",
      "      - -4.500000000000011\n",
      "      - 12.599999999999932\n",
      "      - -2.999999999999986\n",
      "      - 6.0000000000000195\n",
      "      - 4.500000000000023\n",
      "      - 12.599999999999957\n",
      "      - 5.399999999999974\n",
      "      - -8.399999999999975\n",
      "      - 5.100000000000017\n",
      "      - -9.900000000000013\n",
      "      - 0.30000000000002025\n",
      "      - 2.100000000000024\n",
      "      - -7.4999999999999805\n",
      "      - -2.3999999999999817\n",
      "      - -24.0\n",
      "      - 4.50000000000002\n",
      "      - -9.599999999999987\n",
      "      - 7.2000000000000295\n",
      "      - 2.7000000000000264\n",
      "      - 1.174060848541103e-14\n",
      "      - -5.699999999999987\n",
      "      - -2.399999999999973\n",
      "      - -5.399999999999984\n",
      "      - 5.999999999999979\n",
      "      - -4.499999999999979\n",
      "      - 3.000000000000017\n",
      "      - 4.200000000000024\n",
      "      - 5.1\n",
      "      - 3.6000000000000294\n",
      "      - 1.840194663316197e-14\n",
      "      - -1.4999999999999747\n",
      "      - -0.8999999999999762\n",
      "      - 24.89999999999998\n",
      "      - -9.299999999999972\n",
      "      - -1.7999999999999834\n",
      "      - 20.69999999999994\n",
      "      - -2.9999999999999916\n",
      "      - 16.499999999999982\n",
      "      - 3.600000000000017\n",
      "      - 6.300000000000031\n",
      "      - -1.4999999999999893\n",
      "      - -3.5999999999999805\n",
      "      - -0.5999999999999838\n",
      "      - 12.300000000000027\n",
      "      - 4.799999999999973\n",
      "      - 9.300000000000008\n",
      "      - 8.100000000000014\n",
      "      - 9.600000000000016\n",
      "      - -3.900000000000002\n",
      "      - -1.4999999999999907\n",
      "      - 8.40000000000002\n",
      "      - 21.59999999999995\n",
      "      - 20.999999999999922\n",
      "      - 4.800000000000029\n",
      "      - 8.10000000000002\n",
      "      - -2.3999999999999795\n",
      "      - 0.6000000000000091\n",
      "      - 2.806088694740083e-14\n",
      "      - -1.49999999999998\n",
      "      - 4.500000000000018\n",
      "      - 10.500000000000032\n",
      "      - 4.500000000000023\n",
      "      - 8.70000000000002\n",
      "      - 1.1296519275560968e-14\n",
      "      - 8.700000000000017\n",
      "      - 6.30000000000002\n",
      "      - 11.399999999999936\n",
      "      - -4.199999999999978\n",
      "      - -8.099999999999982\n",
      "      policy_policy1_reward:\n",
      "      - 7.5\n",
      "      - -6.5\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 2.5\n",
      "      - -4.0\n",
      "      - 21.0\n",
      "      - 6.0\n",
      "      - 23.0\n",
      "      - -0.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 23.0\n",
      "      - 11.0\n",
      "      - -5.0\n",
      "      - 32.5\n",
      "      - -4.5\n",
      "      - 13.5\n",
      "      - 14.0\n",
      "      - -2.5\n",
      "      - 15.5\n",
      "      - 24.0\n",
      "      - 15.0\n",
      "      - 6.5\n",
      "      - 11.5\n",
      "      - 18.0\n",
      "      - 5.0\n",
      "      - 17.0\n",
      "      - 4.0\n",
      "      - 1.5\n",
      "      - 5.5\n",
      "      - 5.5\n",
      "      - 21.5\n",
      "      - 1.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 21.5\n",
      "      - 5.5\n",
      "      - 0.5\n",
      "      - 14.0\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 11.0\n",
      "      - 2.5\n",
      "      - 1.0\n",
      "      - -14.0\n",
      "      - 14.5\n",
      "      - -4.0\n",
      "      - 15.0\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - -10.0\n",
      "      - 6.5\n",
      "      - 3.5\n",
      "      - 10.5\n",
      "      - 5.5\n",
      "      - -3.5\n",
      "      - 12.0\n",
      "      - 14.0\n",
      "      - 7.0\n",
      "      - 4.5\n",
      "      - 8.5\n",
      "      - 8.0\n",
      "      - 30.5\n",
      "      - -1.5\n",
      "      - 6.0\n",
      "      - 28.5\n",
      "      - 1.5\n",
      "      - 26.5\n",
      "      - 12.5\n",
      "      - 13.0\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 30.5\n",
      "      - 31.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - 9.5\n",
      "      - 10.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 4.5\n",
      "      - 16.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 2.5\n",
      "      - -2.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999984\n",
      "      - 3.199999999999999\n",
      "      - -7.799999999999989\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999985\n",
      "      - 2.0999999999999943\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.500000000000003\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999999\n",
      "      - -8.899999999999986\n",
      "      - -1.199999999999989\n",
      "      - -4.5000000000000036\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999984\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.5\n",
      "      - -4.499999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -0.09999999999999509\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -7.7999999999999865\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000006\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -4.4999999999999885\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000014\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -4.5000000000000036\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999991\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999996\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.4\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999988\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000055\n",
      "      - -5.59999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999989\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 6.500000000000014\n",
      "    policy_reward_mean:\n",
      "      policy1: 9.605\n",
      "      policy2: -6.952999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -14.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15700258110075088\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06764310631926686\n",
      "      mean_inference_ms: 1.6578399416384577\n",
      "      mean_raw_obs_processing_ms: 0.3094672143519579\n",
      "  time_since_restore: 144.59592151641846\n",
      "  time_this_iter_s: 20.504180908203125\n",
      "  time_total_s: 144.59592151641846\n",
      "  timers:\n",
      "    learn_throughput: 445.907\n",
      "    learn_time_ms: 8970.477\n",
      "    synch_weights_time_ms: 3.691\n",
      "    training_iteration_time_ms: 18067.365\n",
      "  timestamp: 1658917202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 8\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 72000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-02\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 26.99999999999995\n",
      "  episode_reward_mean: 8.53199999999999\n",
      "  episode_reward_min: -14.399999999999975\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 360\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.095049262046814\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012627086602151394\n",
      "          model: {}\n",
      "          policy_loss: -0.03492411598563194\n",
      "          total_loss: 7.0667009353637695\n",
      "          vf_explained_var: 0.17639513313770294\n",
      "          vf_loss: 7.099099159240723\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0779457092285156\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014032215811312199\n",
      "          model: {}\n",
      "          policy_loss: -0.03613104671239853\n",
      "          total_loss: 3.7217233180999756\n",
      "          vf_explained_var: 0.15414442121982574\n",
      "          vf_loss: 3.7550477981567383\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 36000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.403333333333336\n",
      "    ram_util_percent: 59.74666666666667\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 31.5\n",
      "    policy2: 7.6000000000000085\n",
      "  policy_reward_mean:\n",
      "    policy1: 13.78\n",
      "    policy2: -5.24799999999999\n",
      "  policy_reward_min:\n",
      "    policy1: -6.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1516623989320258\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06582198533062651\n",
      "    mean_inference_ms: 1.5895988671414147\n",
      "    mean_raw_obs_processing_ms: 0.29836473449759415\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 26.99999999999995\n",
      "    episode_reward_mean: 8.53199999999999\n",
      "    episode_reward_min: -14.399999999999975\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.5000000000000036\n",
      "      - -0.29999999999997795\n",
      "      - 7.499999999999936\n",
      "      - 4.199999999999971\n",
      "      - -5.699999999999976\n",
      "      - -5.999999999999987\n",
      "      - -2.3999999999999853\n",
      "      - 10.79999999999998\n",
      "      - 11.999999999999932\n",
      "      - 5.700000000000033\n",
      "      - 14.399999999999926\n",
      "      - -2.999999999999975\n",
      "      - 10.800000000000017\n",
      "      - 8.100000000000028\n",
      "      - 15.60000000000001\n",
      "      - 1.5000000000000187\n",
      "      - 20.099999999999923\n",
      "      - -3.5999999999999766\n",
      "      - 5.399999999999993\n",
      "      - 22.799999999999983\n",
      "      - -6.899999999999988\n",
      "      - 11.999999999999968\n",
      "      - 1.5000000000000169\n",
      "      - 7.499999999999941\n",
      "      - 7.200000000000031\n",
      "      - 18.299999999999926\n",
      "      - -9.299999999999999\n",
      "      - 17.399999999999913\n",
      "      - 7.500000000000025\n",
      "      - 9.900000000000029\n",
      "      - -6.299999999999994\n",
      "      - 13.799999999999912\n",
      "      - 4.2000000000000135\n",
      "      - 22.19999999999994\n",
      "      - 14.999999999999988\n",
      "      - 6.600000000000017\n",
      "      - 16.49999999999998\n",
      "      - 17.10000000000002\n",
      "      - 16.199999999999953\n",
      "      - -13.199999999999976\n",
      "      - -5.399999999999989\n",
      "      - 4.199999999999973\n",
      "      - 15.900000000000007\n",
      "      - 0.900000000000028\n",
      "      - 19.499999999999993\n",
      "      - -4.199999999999987\n",
      "      - 3.300000000000032\n",
      "      - 19.199999999999918\n",
      "      - 6.900000000000002\n",
      "      - 6.900000000000027\n",
      "      - 5.100000000000021\n",
      "      - 2.700000000000023\n",
      "      - 6.600000000000026\n",
      "      - 3.000000000000033\n",
      "      - 18.299999999999976\n",
      "      - 20.09999999999989\n",
      "      - 4.500000000000009\n",
      "      - 5.100000000000017\n",
      "      - 18.299999999999976\n",
      "      - 18.899999999999967\n",
      "      - 11.40000000000003\n",
      "      - 14.699999999999934\n",
      "      - 6.600000000000032\n",
      "      - 9.300000000000002\n",
      "      - 6.300000000000017\n",
      "      - 3.6000000000000036\n",
      "      - 4.200000000000021\n",
      "      - 7.199999999999999\n",
      "      - 23.699999999999914\n",
      "      - 3.600000000000025\n",
      "      - 26.99999999999995\n",
      "      - 10.499999999999938\n",
      "      - -3.299999999999983\n",
      "      - 8.700000000000022\n",
      "      - 6.600000000000023\n",
      "      - 23.99999999999994\n",
      "      - 15.899999999999975\n",
      "      - 8.399999999999977\n",
      "      - 22.199999999999946\n",
      "      - 10.199999999999925\n",
      "      - 21.599999999999916\n",
      "      - 11.099999999999968\n",
      "      - -1.4999999999999787\n",
      "      - 11.699999999999967\n",
      "      - 9.000000000000005\n",
      "      - 23.399999999999913\n",
      "      - 14.699999999999992\n",
      "      - 8.099999999999975\n",
      "      - 14.10000000000002\n",
      "      - 1.1999999999999924\n",
      "      - -14.399999999999975\n",
      "      - 3.6000000000000316\n",
      "      - 10.499999999999925\n",
      "      - 24.299999999999933\n",
      "      - 9.599999999999998\n",
      "      - 1.5000000000000218\n",
      "      - 9.600000000000032\n",
      "      - 15.600000000000007\n",
      "      - 6.600000000000001\n",
      "      - 2.6999999999999513\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - 7.5\n",
      "      - 12.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - -1.5\n",
      "      - 1.0\n",
      "      - 17.5\n",
      "      - 11.0\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 1.5\n",
      "      - 17.5\n",
      "      - 17.0\n",
      "      - 24.5\n",
      "      - 0.5\n",
      "      - 29.0\n",
      "      - 2.0\n",
      "      - 11.0\n",
      "      - 24.0\n",
      "      - 2.0\n",
      "      - 22.0\n",
      "      - 11.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 25.0\n",
      "      - -1.5\n",
      "      - 23.0\n",
      "      - 17.5\n",
      "      - 15.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 30.0\n",
      "      - 19.5\n",
      "      - 10.0\n",
      "      - 26.5\n",
      "      - 26.0\n",
      "      - 24.0\n",
      "      - -6.5\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 16.0\n",
      "      - 6.5\n",
      "      - 29.5\n",
      "      - -3.0\n",
      "      - 10.0\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 3.0\n",
      "      - 10.5\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 19.5\n",
      "      - 29.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 25.0\n",
      "      - 24.5\n",
      "      - 17.0\n",
      "      - 22.5\n",
      "      - 15.5\n",
      "      - 5.0\n",
      "      - 7.5\n",
      "      - 12.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      - 15.0\n",
      "      - 4.5\n",
      "      - 11.0\n",
      "      - 15.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 14.0\n",
      "      - 24.5\n",
      "      - 18.0\n",
      "      - 30.5\n",
      "      - 20.0\n",
      "      - 3.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 0.5\n",
      "      - 17.5\n",
      "      - -2.0\n",
      "      - -5.5\n",
      "      - 12.5\n",
      "      - 15.0\n",
      "      - 31.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 18.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 10.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.500000000000003\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999982\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999988\n",
      "      - -3.4000000000000052\n",
      "      - -6.699999999999987\n",
      "      - 1.0000000000000075\n",
      "      - -7.799999999999982\n",
      "      - -0.0999999999999962\n",
      "      - -4.500000000000001\n",
      "      - -6.699999999999994\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - 0.9999999999999946\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -5.599999999999982\n",
      "      - -1.200000000000002\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999986\n",
      "      - -6.69999999999999\n",
      "      - -7.799999999999981\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999986\n",
      "      - -2.300000000000007\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -3.400000000000006\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - 3.2000000000000073\n",
      "      - -0.09999999999999232\n",
      "      - -5.599999999999994\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999992\n",
      "      - -0.10000000000000675\n",
      "      - 2.0999999999999974\n",
      "      - -7.799999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.200000000000004\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999924\n",
      "      - -6.699999999999984\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999987\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - 4.3000000000000025\n",
      "      - -1.2000000000000013\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 3.199999999999994\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999995\n",
      "      - -4.499999999999982\n",
      "      - -7.799999999999981\n",
      "      - -2.300000000000002\n",
      "      - -8.89999999999998\n",
      "      - 0.9999999999999957\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999994\n",
      "      - -2.2999999999999994\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -4.500000000000003\n",
      "      - 3.200000000000008\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998915\n",
      "      - -2.299999999999989\n",
      "      - 7.600000000000005\n",
      "      - -3.3999999999999853\n",
      "      - 3.200000000000001\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999991\n",
      "      - -4.499999999999994\n",
      "      - -8.89999999999998\n",
      "      - 7.6000000000000085\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 31.5\n",
      "      policy2: 7.6000000000000085\n",
      "    policy_reward_mean:\n",
      "      policy1: 13.78\n",
      "      policy2: -5.24799999999999\n",
      "    policy_reward_min:\n",
      "      policy1: -6.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1516623989320258\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06582198533062651\n",
      "      mean_inference_ms: 1.5895988671414147\n",
      "      mean_raw_obs_processing_ms: 0.29836473449759415\n",
      "  time_since_restore: 154.94989919662476\n",
      "  time_this_iter_s: 20.651871919631958\n",
      "  time_total_s: 154.94989919662476\n",
      "  timers:\n",
      "    learn_throughput: 474.112\n",
      "    learn_time_ms: 8436.816\n",
      "    synch_weights_time_ms: 3.659\n",
      "    training_iteration_time_ms: 17208.896\n",
      "  timestamp: 1658917202\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 72000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-09\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 33.899999999999906\n",
      "  episode_reward_mean: 10.826999999999975\n",
      "  episode_reward_min: -21.90000000000002\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 360\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9821093082427979\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012020330876111984\n",
      "          model: {}\n",
      "          policy_loss: -0.03810083493590355\n",
      "          total_loss: 7.084563732147217\n",
      "          vf_explained_var: 0.3033592700958252\n",
      "          vf_loss: 7.120259761810303\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9038862586021423\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01351723913103342\n",
      "          model: {}\n",
      "          policy_loss: -0.03925925865769386\n",
      "          total_loss: 2.6291584968566895\n",
      "          vf_explained_var: 0.16150957345962524\n",
      "          vf_loss: 2.6670658588409424\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 36000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.6576923076923\n",
      "    ram_util_percent: 59.696153846153834\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 7.600000000000004\n",
      "  policy_reward_mean:\n",
      "    policy1: 17.175\n",
      "    policy2: -6.347999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -13.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15294356504617823\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06780537442530235\n",
      "    mean_inference_ms: 1.6157734152002972\n",
      "    mean_raw_obs_processing_ms: 0.3022585563682134\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 33.899999999999906\n",
      "    episode_reward_mean: 10.826999999999975\n",
      "    episode_reward_min: -21.90000000000002\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 5.999999999999988\n",
      "      - 10.500000000000028\n",
      "      - 16.799999999999926\n",
      "      - 20.099999999999987\n",
      "      - 9.90000000000003\n",
      "      - -21.90000000000002\n",
      "      - 3.0000000000000275\n",
      "      - 12.599999999999971\n",
      "      - 10.500000000000025\n",
      "      - 3.9000000000000195\n",
      "      - 5.999999999999988\n",
      "      - 11.999999999999982\n",
      "      - 1.2000000000000086\n",
      "      - 9.299999999999992\n",
      "      - 18.59999999999995\n",
      "      - 15.299999999999915\n",
      "      - 17.999999999999943\n",
      "      - 7.799999999999983\n",
      "      - -16.199999999999985\n",
      "      - 30.599999999999923\n",
      "      - 5.700000000000017\n",
      "      - 15.899999999999972\n",
      "      - 1.500000000000027\n",
      "      - 9.00000000000001\n",
      "      - 28.199999999999932\n",
      "      - -10.499999999999984\n",
      "      - 16.20000000000003\n",
      "      - 18.29999999999996\n",
      "      - 5.999999999999972\n",
      "      - 18.299999999999912\n",
      "      - -3.8999999999999924\n",
      "      - 15.000000000000032\n",
      "      - 1.500000000000011\n",
      "      - 2.6999999999999997\n",
      "      - 1.8000000000000167\n",
      "      - 12.29999999999998\n",
      "      - 18.599999999999966\n",
      "      - 6.599999999999966\n",
      "      - 3.0000000000000218\n",
      "      - 16.199999999999967\n",
      "      - 16.19999999999999\n",
      "      - 11.10000000000002\n",
      "      - 14.70000000000002\n",
      "      - 5.400000000000027\n",
      "      - 10.199999999999973\n",
      "      - 12.89999999999998\n",
      "      - 24.899999999999913\n",
      "      - -9.299999999999978\n",
      "      - 12.60000000000003\n",
      "      - 12.89999999999996\n",
      "      - 19.19999999999994\n",
      "      - -9.6\n",
      "      - 14.09999999999993\n",
      "      - 11.399999999999913\n",
      "      - 13.199999999999955\n",
      "      - 8.099999999999957\n",
      "      - -9.299999999999972\n",
      "      - 8.399999999999999\n",
      "      - 16.799999999999912\n",
      "      - 11.399999999999945\n",
      "      - 12.000000000000034\n",
      "      - 18.899999999999956\n",
      "      - 14.399999999999936\n",
      "      - 14.99999999999991\n",
      "      - -1.4999999999999853\n",
      "      - 0.30000000000000493\n",
      "      - 7.799999999999942\n",
      "      - 14.099999999999978\n",
      "      - 7.199999999999971\n",
      "      - -1.8000000000000007\n",
      "      - 10.500000000000027\n",
      "      - 23.09999999999991\n",
      "      - 8.699999999999989\n",
      "      - 5.400000000000018\n",
      "      - 18.59999999999991\n",
      "      - 23.999999999999908\n",
      "      - 5.099999999999946\n",
      "      - 18.599999999999962\n",
      "      - 9.899999999999983\n",
      "      - 7.799999999999942\n",
      "      - 20.09999999999997\n",
      "      - 11.699999999999934\n",
      "      - 12.599999999999932\n",
      "      - 9.899999999999926\n",
      "      - 19.79999999999996\n",
      "      - 1.2000000000000095\n",
      "      - 14.399999999999904\n",
      "      - 11.099999999999982\n",
      "      - 6.60000000000003\n",
      "      - 23.99999999999998\n",
      "      - 10.800000000000024\n",
      "      - 33.899999999999906\n",
      "      - 22.199999999999914\n",
      "      - 20.099999999999902\n",
      "      - 20.399999999999977\n",
      "      - 24.89999999999994\n",
      "      - 2.906008766956347e-14\n",
      "      - 24.59999999999991\n",
      "      - 5.999999999999957\n",
      "      - 18.59999999999992\n",
      "      policy_policy1_reward:\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 23.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - -13.0\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 9.5\n",
      "      - 16.0\n",
      "      - 16.5\n",
      "      - 9.0\n",
      "      - 10.5\n",
      "      - 27.5\n",
      "      - 22.0\n",
      "      - 28.0\n",
      "      - 14.5\n",
      "      - -9.5\n",
      "      - 34.0\n",
      "      - 13.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 30.5\n",
      "      - -0.5\n",
      "      - 24.0\n",
      "      - 25.0\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 7.5\n",
      "      - 24.0\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 12.5\n",
      "      - 18.5\n",
      "      - 30.5\n",
      "      - -1.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 21.5\n",
      "      - -4.0\n",
      "      - 23.0\n",
      "      - 17.0\n",
      "      - 21.0\n",
      "      - 17.0\n",
      "      - -1.5\n",
      "      - 8.5\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 25.0\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 32.0\n",
      "      - 16.5\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 28.5\n",
      "      - 14.0\n",
      "      - 22.0\n",
      "      - 15.5\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - 19.5\n",
      "      - 21.5\n",
      "      - 15.5\n",
      "      - 26.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 34.0\n",
      "      - 17.5\n",
      "      - 39.5\n",
      "      - 30.0\n",
      "      - 29.0\n",
      "      - 26.0\n",
      "      - 30.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000035\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999985\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -7.7999999999999865\n",
      "      - -1.199999999999999\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000044\n",
      "      - -7.799999999999981\n",
      "      - -0.09999999999999779\n",
      "      - -4.500000000000003\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999994\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999994\n",
      "      - -3.3999999999999897\n",
      "      - 7.600000000000004\n",
      "      - -4.500000000000001\n",
      "      - -7.799999999999981\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999984\n",
      "      - -2.2999999999999976\n",
      "      - -5.599999999999998\n",
      "      - -2.299999999999984\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999987\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999988\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000431\n",
      "      - -6.699999999999993\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999979\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -3.399999999999994\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999997\n",
      "      - -3.400000000000005\n",
      "      - -4.5\n",
      "      - -8.899999999999984\n",
      "      - -3.4000000000000044\n",
      "      - -5.599999999999982\n",
      "      - -6.69999999999999\n",
      "      - -3.399999999999991\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999988\n",
      "      - -3.400000000000002\n",
      "      - -3.3999999999999893\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 7.600000000000004\n",
      "    policy_reward_mean:\n",
      "      policy1: 17.175\n",
      "      policy2: -6.347999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -13.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15294356504617823\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06780537442530235\n",
      "      mean_inference_ms: 1.6157734152002972\n",
      "      mean_raw_obs_processing_ms: 0.3022585563682134\n",
      "  time_since_restore: 158.44395518302917\n",
      "  time_this_iter_s: 17.209541082382202\n",
      "  time_total_s: 158.44395518302917\n",
      "  timers:\n",
      "    learn_throughput: 446.587\n",
      "    learn_time_ms: 6717.619\n",
      "    synch_weights_time_ms: 4.385\n",
      "    training_iteration_time_ms: 14022.75\n",
      "  timestamp: 1658917209\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 12\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 72000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-10\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.099999999999923\n",
      "  episode_reward_mean: 4.412999999999999\n",
      "  episode_reward_min: -13.499999999999986\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 360\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0045912265777588\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018174076452851295\n",
      "          model: {}\n",
      "          policy_loss: -0.051466166973114014\n",
      "          total_loss: 6.555517673492432\n",
      "          vf_explained_var: 0.28402137756347656\n",
      "          vf_loss: 6.598805904388428\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9418887495994568\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017888108268380165\n",
      "          model: {}\n",
      "          policy_loss: -0.05232316255569458\n",
      "          total_loss: 2.805900812149048\n",
      "          vf_explained_var: 0.16572806239128113\n",
      "          vf_loss: 2.8501741886138916\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 36000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.71199999999999\n",
      "    ram_util_percent: 59.663999999999994\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 32.5\n",
      "    policy2: 12.000000000000007\n",
      "  policy_reward_mean:\n",
      "    policy1: 10.475\n",
      "    policy2: -6.061999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -10.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1571755766165819\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06738285589264802\n",
      "    mean_inference_ms: 1.6447828671256604\n",
      "    mean_raw_obs_processing_ms: 0.3082171281996295\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.099999999999923\n",
      "    episode_reward_mean: 4.412999999999999\n",
      "    episode_reward_min: -13.499999999999986\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -11.699999999999983\n",
      "      - -5.999999999999991\n",
      "      - -0.8999999999999977\n",
      "      - 5.700000000000003\n",
      "      - 5.1000000000000245\n",
      "      - 0.3000000000000067\n",
      "      - -3.8999999999999866\n",
      "      - -7.499999999999979\n",
      "      - 3.0000000000000124\n",
      "      - -2.3999999999999835\n",
      "      - 22.499999999999936\n",
      "      - 15.300000000000015\n",
      "      - -2.699999999999985\n",
      "      - -1.499999999999989\n",
      "      - -5.099999999999987\n",
      "      - 1.7999999999999883\n",
      "      - 1.500000000000014\n",
      "      - -1.4999999999999747\n",
      "      - -5.3999999999999755\n",
      "      - 9.300000000000027\n",
      "      - -13.499999999999986\n",
      "      - 16.800000000000026\n",
      "      - -9.599999999999985\n",
      "      - -8.99999999999998\n",
      "      - 23.099999999999923\n",
      "      - 9.300000000000024\n",
      "      - 0.9000000000000067\n",
      "      - 5.100000000000017\n",
      "      - 0.900000000000028\n",
      "      - 9.000000000000021\n",
      "      - 3.0000000000000204\n",
      "      - 3.6000000000000028\n",
      "      - 9.29999999999997\n",
      "      - -1.7999999999999827\n",
      "      - 1.8000000000000114\n",
      "      - -3.299999999999975\n",
      "      - 1.5000000000000289\n",
      "      - 10.199999999999996\n",
      "      - -1.4999999999999818\n",
      "      - 6.000000000000002\n",
      "      - 6.0000000000000195\n",
      "      - -8.99999999999999\n",
      "      - 18.599999999999937\n",
      "      - 15.600000000000003\n",
      "      - -4.199999999999983\n",
      "      - 6.00000000000003\n",
      "      - 13.20000000000001\n",
      "      - 20.099999999999902\n",
      "      - 14.699999999999921\n",
      "      - 3.000000000000024\n",
      "      - 16.799999999999947\n",
      "      - 9.00000000000002\n",
      "      - 3.300000000000025\n",
      "      - 10.800000000000027\n",
      "      - 3.3000000000000247\n",
      "      - 2.6999999999999607\n",
      "      - 19.499999999999893\n",
      "      - 9.299999999999976\n",
      "      - 12.000000000000007\n",
      "      - 0.3000000000000298\n",
      "      - 1.2000000000000188\n",
      "      - -0.9000000000000024\n",
      "      - -5.999999999999972\n",
      "      - 14.999999999999961\n",
      "      - 7.500000000000034\n",
      "      - -4.199999999999994\n",
      "      - 5.699999999999969\n",
      "      - 15.299999999999937\n",
      "      - 10.499999999999925\n",
      "      - -2.699999999999972\n",
      "      - 8.699999999999987\n",
      "      - -3.899999999999979\n",
      "      - 6.299999999999974\n",
      "      - 9.899999999999956\n",
      "      - -12.299999999999976\n",
      "      - -9.899999999999977\n",
      "      - 7.200000000000015\n",
      "      - 7.500000000000027\n",
      "      - 14.099999999999923\n",
      "      - -3.9000000000000066\n",
      "      - 17.69999999999991\n",
      "      - -6.5999999999999766\n",
      "      - -5.9999999999999805\n",
      "      - 6.900000000000003\n",
      "      - 13.49999999999993\n",
      "      - -2.099999999999974\n",
      "      - 6.000000000000025\n",
      "      - 8.100000000000014\n",
      "      - 10.50000000000002\n",
      "      - 21.599999999999927\n",
      "      - 4.499999999999989\n",
      "      - 9.000000000000028\n",
      "      - 6.60000000000003\n",
      "      - -1.1999999999999869\n",
      "      - 17.700000000000024\n",
      "      - 13.499999999999972\n",
      "      - 10.499999999999936\n",
      "      - 5.700000000000008\n",
      "      - -5.9999999999999885\n",
      "      - -2.400000000000012\n",
      "      policy_policy1_reward:\n",
      "      - -5.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 7.0\n",
      "      - 5.0\n",
      "      - 2.5\n",
      "      - 7.5\n",
      "      - 1.0\n",
      "      - 32.5\n",
      "      - 22.0\n",
      "      - 4.0\n",
      "      - 3.0\n",
      "      - 0.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 3.0\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - -3.5\n",
      "      - 23.5\n",
      "      - -9.5\n",
      "      - -10.0\n",
      "      - 32.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 14.0\n",
      "      - 6.5\n",
      "      - 19.0\n",
      "      - 13.0\n",
      "      - 1.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - 4.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 2.5\n",
      "      - 16.0\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 22.5\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 8.0\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - -1.0\n",
      "      - -0.5\n",
      "      - 29.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - -3.0\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      - 16.5\n",
      "      - 5.0\n",
      "      - 13.0\n",
      "      - 15.5\n",
      "      - -10.0\n",
      "      - -1.0\n",
      "      - 15.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - -0.5\n",
      "      - 25.5\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 30.5\n",
      "      - 14.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 5.5\n",
      "      - 25.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 6.5\n",
      "      policy_policy2_reward:\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999983\n",
      "      - -3.3999999999999986\n",
      "      - -6.699999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999997\n",
      "      - -3.4000000000000044\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -6.699999999999994\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999986\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -0.10000000000000364\n",
      "      - 0.9999999999999976\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999998563\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 3.1999999999999984\n",
      "      - 0.9999999999999979\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - 1.000000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - 4.299999999999999\n",
      "      - 3.200000000000003\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000021\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000022\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - 1.0000000000000129\n",
      "      - -6.699999999999994\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000003\n",
      "      - -3.3999999999999853\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999984\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999996\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000064\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.799999999999981\n",
      "      - 12.000000000000007\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 32.5\n",
      "      policy2: 12.000000000000007\n",
      "    policy_reward_mean:\n",
      "      policy1: 10.475\n",
      "      policy2: -6.061999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -10.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1571755766165819\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06738285589264802\n",
      "      mean_inference_ms: 1.6447828671256604\n",
      "      mean_raw_obs_processing_ms: 0.3082171281996295\n",
      "  time_since_restore: 159.53329253196716\n",
      "  time_this_iter_s: 17.408041954040527\n",
      "  time_total_s: 159.53329253196716\n",
      "  timers:\n",
      "    learn_throughput: 448.933\n",
      "    learn_time_ms: 6682.513\n",
      "    synch_weights_time_ms: 3.559\n",
      "    training_iteration_time_ms: 14102.579\n",
      "  timestamp: 1658917210\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 12\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 72000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 24.89999999999998\n",
      "  episode_reward_mean: 3.4740000000000055\n",
      "  episode_reward_min: -24.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 360\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0835849046707153\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018344493582844734\n",
      "          model: {}\n",
      "          policy_loss: -0.05145629867911339\n",
      "          total_loss: 6.334017276763916\n",
      "          vf_explained_var: 0.17794126272201538\n",
      "          vf_loss: 6.377219200134277\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0555083751678467\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016802776604890823\n",
      "          model: {}\n",
      "          policy_loss: -0.04442597180604935\n",
      "          total_loss: 2.3497397899627686\n",
      "          vf_explained_var: 0.25315314531326294\n",
      "          vf_loss: 2.3866043090820312\n",
      "    num_agent_steps_sampled: 72000\n",
      "    num_agent_steps_trained: 72000\n",
      "    num_env_steps_sampled: 36000\n",
      "    num_env_steps_trained: 36000\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 72000\n",
      "  num_agent_steps_trained: 72000\n",
      "  num_env_steps_sampled: 36000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 36000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.58285714285715\n",
      "    ram_util_percent: 60.03428571428571\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 33.5\n",
      "    policy2: 6.500000000000014\n",
      "  policy_reward_mean:\n",
      "    policy1: 10.735\n",
      "    policy2: -7.260999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -14.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16162325123957028\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06946490434926465\n",
      "    mean_inference_ms: 1.7132053313888702\n",
      "    mean_raw_obs_processing_ms: 0.31851354173925567\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 24.89999999999998\n",
      "    episode_reward_mean: 3.4740000000000055\n",
      "    episode_reward_min: -24.0\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -9.900000000000013\n",
      "      - 0.30000000000002025\n",
      "      - 2.100000000000024\n",
      "      - -7.4999999999999805\n",
      "      - -2.3999999999999817\n",
      "      - -24.0\n",
      "      - 4.50000000000002\n",
      "      - -9.599999999999987\n",
      "      - 7.2000000000000295\n",
      "      - 2.7000000000000264\n",
      "      - 1.174060848541103e-14\n",
      "      - -5.699999999999987\n",
      "      - -2.399999999999973\n",
      "      - -5.399999999999984\n",
      "      - 5.999999999999979\n",
      "      - -4.499999999999979\n",
      "      - 3.000000000000017\n",
      "      - 4.200000000000024\n",
      "      - 5.1\n",
      "      - 3.6000000000000294\n",
      "      - 1.840194663316197e-14\n",
      "      - -1.4999999999999747\n",
      "      - -0.8999999999999762\n",
      "      - 24.89999999999998\n",
      "      - -9.299999999999972\n",
      "      - -1.7999999999999834\n",
      "      - 20.69999999999994\n",
      "      - -2.9999999999999916\n",
      "      - 16.499999999999982\n",
      "      - 3.600000000000017\n",
      "      - 6.300000000000031\n",
      "      - -1.4999999999999893\n",
      "      - -3.5999999999999805\n",
      "      - -0.5999999999999838\n",
      "      - 12.300000000000027\n",
      "      - 4.799999999999973\n",
      "      - 9.300000000000008\n",
      "      - 8.100000000000014\n",
      "      - 9.600000000000016\n",
      "      - -3.900000000000002\n",
      "      - -1.4999999999999907\n",
      "      - 8.40000000000002\n",
      "      - 21.59999999999995\n",
      "      - 20.999999999999922\n",
      "      - 4.800000000000029\n",
      "      - 8.10000000000002\n",
      "      - -2.3999999999999795\n",
      "      - 0.6000000000000091\n",
      "      - 2.806088694740083e-14\n",
      "      - -1.49999999999998\n",
      "      - 4.500000000000018\n",
      "      - 10.500000000000032\n",
      "      - 4.500000000000023\n",
      "      - 8.70000000000002\n",
      "      - 1.1296519275560968e-14\n",
      "      - 8.700000000000017\n",
      "      - 6.30000000000002\n",
      "      - 11.399999999999936\n",
      "      - -4.199999999999978\n",
      "      - -8.099999999999982\n",
      "      - 11.100000000000014\n",
      "      - 11.099999999999985\n",
      "      - -4.500000000000002\n",
      "      - -2.9999999999999853\n",
      "      - 12.000000000000034\n",
      "      - -2.3999999999999826\n",
      "      - -6.899999999999992\n",
      "      - -14.999999999999982\n",
      "      - 1.5000000000000147\n",
      "      - 17.099999999999923\n",
      "      - -3.2999999999999927\n",
      "      - -8.99999999999999\n",
      "      - 9.000000000000002\n",
      "      - 1.2000000000000148\n",
      "      - 11.69999999999995\n",
      "      - 12.599999999999925\n",
      "      - 2.7283730830163222e-14\n",
      "      - 20.1\n",
      "      - 1.80000000000001\n",
      "      - 7.800000000000026\n",
      "      - 23.09999999999991\n",
      "      - 3.6000000000000125\n",
      "      - -6.299999999999999\n",
      "      - 6.600000000000023\n",
      "      - 24.599999999999916\n",
      "      - 17.70000000000001\n",
      "      - 1.2000000000000086\n",
      "      - 11.100000000000028\n",
      "      - -1.799999999999982\n",
      "      - 4.5000000000000115\n",
      "      - 4.2000000000000135\n",
      "      - 10.499999999999991\n",
      "      - 13.799999999999969\n",
      "      - 2.1000000000000254\n",
      "      - -13.79999999999998\n",
      "      - 5.100000000000026\n",
      "      - -0.2999999999999975\n",
      "      - -7.799999999999995\n",
      "      - 7.199999999999989\n",
      "      - 10.500000000000023\n",
      "      policy_policy1_reward:\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 11.0\n",
      "      - 2.5\n",
      "      - 1.0\n",
      "      - -14.0\n",
      "      - 14.5\n",
      "      - -4.0\n",
      "      - 15.0\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - -10.0\n",
      "      - 6.5\n",
      "      - 3.5\n",
      "      - 10.5\n",
      "      - 5.5\n",
      "      - -3.5\n",
      "      - 12.0\n",
      "      - 14.0\n",
      "      - 7.0\n",
      "      - 4.5\n",
      "      - 8.5\n",
      "      - 8.0\n",
      "      - 30.5\n",
      "      - -1.5\n",
      "      - 6.0\n",
      "      - 28.5\n",
      "      - 1.5\n",
      "      - 26.5\n",
      "      - 12.5\n",
      "      - 13.0\n",
      "      - 8.5\n",
      "      - 2.0\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 30.5\n",
      "      - 31.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - 9.5\n",
      "      - 10.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 4.5\n",
      "      - 16.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 2.5\n",
      "      - -2.5\n",
      "      - 20.0\n",
      "      - 20.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 22.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - -5.0\n",
      "      - 11.5\n",
      "      - 26.0\n",
      "      - 4.5\n",
      "      - 1.0\n",
      "      - 8.0\n",
      "      - 3.5\n",
      "      - 14.0\n",
      "      - 21.5\n",
      "      - 10.0\n",
      "      - 29.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 32.0\n",
      "      - 12.5\n",
      "      - 1.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 25.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 6.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 14.0\n",
      "      - 7.5\n",
      "      - 0.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.899999999999986\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -7.7999999999999865\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000006\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -4.4999999999999885\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000014\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -4.5000000000000036\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999982\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999991\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999996\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.4\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999988\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000055\n",
      "      - -5.59999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999989\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000013\n",
      "      - -2.300000000000001\n",
      "      - -2.3000000000000043\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999993\n",
      "      - -1.1999999999999948\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.5\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999984\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 33.5\n",
      "      policy2: 6.500000000000014\n",
      "    policy_reward_mean:\n",
      "      policy1: 10.735\n",
      "      policy2: -7.260999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -14.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16162325123957028\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06946490434926465\n",
      "      mean_inference_ms: 1.7132053313888702\n",
      "      mean_raw_obs_processing_ms: 0.31851354173925567\n",
      "  time_since_restore: 168.01573872566223\n",
      "  time_this_iter_s: 23.419817209243774\n",
      "  time_total_s: 168.01573872566223\n",
      "  timers:\n",
      "    learn_throughput: 432.141\n",
      "    learn_time_ms: 9256.23\n",
      "    synch_weights_time_ms: 3.818\n",
      "    training_iteration_time_ms: 18660.97\n",
      "  timestamp: 1658917226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 9\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 80000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_env_steps_sampled: 40000\n",
      "    num_env_steps_trained: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-26\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.09999999999989\n",
      "  episode_reward_mean: 9.857999999999986\n",
      "  episode_reward_min: -14.399999999999975\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 400\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0580378770828247\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012908995151519775\n",
      "          model: {}\n",
      "          policy_loss: -0.03538643568754196\n",
      "          total_loss: 6.90431022644043\n",
      "          vf_explained_var: 0.2320118546485901\n",
      "          vf_loss: 6.93711519241333\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0464762449264526\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012956216000020504\n",
      "          model: {}\n",
      "          policy_loss: -0.033716242760419846\n",
      "          total_loss: 3.115715503692627\n",
      "          vf_explained_var: 0.11610870808362961\n",
      "          vf_loss: 3.1468403339385986\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_env_steps_sampled: 40000\n",
      "    num_env_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 80000\n",
      "  num_env_steps_sampled: 40000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 40000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.47714285714286\n",
      "    ram_util_percent: 60.03428571428571\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 41.0\n",
      "    policy2: 7.60000000000001\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.435\n",
      "    policy2: -4.57699999999999\n",
      "  policy_reward_min:\n",
      "    policy1: -5.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15696567103601297\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06798386850111685\n",
      "    mean_inference_ms: 1.6482497929554631\n",
      "    mean_raw_obs_processing_ms: 0.3082744130017768\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.09999999999989\n",
      "    episode_reward_mean: 9.857999999999986\n",
      "    episode_reward_min: -14.399999999999975\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -5.399999999999989\n",
      "      - 4.199999999999973\n",
      "      - 15.900000000000007\n",
      "      - 0.900000000000028\n",
      "      - 19.499999999999993\n",
      "      - -4.199999999999987\n",
      "      - 3.300000000000032\n",
      "      - 19.199999999999918\n",
      "      - 6.900000000000002\n",
      "      - 6.900000000000027\n",
      "      - 5.100000000000021\n",
      "      - 2.700000000000023\n",
      "      - 6.600000000000026\n",
      "      - 3.000000000000033\n",
      "      - 18.299999999999976\n",
      "      - 20.09999999999989\n",
      "      - 4.500000000000009\n",
      "      - 5.100000000000017\n",
      "      - 18.299999999999976\n",
      "      - 18.899999999999967\n",
      "      - 11.40000000000003\n",
      "      - 14.699999999999934\n",
      "      - 6.600000000000032\n",
      "      - 9.300000000000002\n",
      "      - 6.300000000000017\n",
      "      - 3.6000000000000036\n",
      "      - 4.200000000000021\n",
      "      - 7.199999999999999\n",
      "      - 23.699999999999914\n",
      "      - 3.600000000000025\n",
      "      - 26.99999999999995\n",
      "      - 10.499999999999938\n",
      "      - -3.299999999999983\n",
      "      - 8.700000000000022\n",
      "      - 6.600000000000023\n",
      "      - 23.99999999999994\n",
      "      - 15.899999999999975\n",
      "      - 8.399999999999977\n",
      "      - 22.199999999999946\n",
      "      - 10.199999999999925\n",
      "      - 21.599999999999916\n",
      "      - 11.099999999999968\n",
      "      - -1.4999999999999787\n",
      "      - 11.699999999999967\n",
      "      - 9.000000000000005\n",
      "      - 23.399999999999913\n",
      "      - 14.699999999999992\n",
      "      - 8.099999999999975\n",
      "      - 14.10000000000002\n",
      "      - 1.1999999999999924\n",
      "      - -14.399999999999975\n",
      "      - 3.6000000000000316\n",
      "      - 10.499999999999925\n",
      "      - 24.299999999999933\n",
      "      - 9.599999999999998\n",
      "      - 1.5000000000000218\n",
      "      - 9.600000000000032\n",
      "      - 15.600000000000007\n",
      "      - 6.600000000000001\n",
      "      - 2.6999999999999513\n",
      "      - 8.09999999999997\n",
      "      - 16.499999999999964\n",
      "      - -11.399999999999983\n",
      "      - 2.3999999999999755\n",
      "      - 19.49999999999995\n",
      "      - 0.3000000000000207\n",
      "      - 12.000000000000012\n",
      "      - 15.00000000000003\n",
      "      - 18.59999999999995\n",
      "      - 4.800000000000013\n",
      "      - 18.899999999999984\n",
      "      - 5.999999999999973\n",
      "      - 9.599999999999998\n",
      "      - 6.899999999999958\n",
      "      - 14.699999999999944\n",
      "      - 6.3000000000000185\n",
      "      - 7.500000000000027\n",
      "      - 18.599999999999905\n",
      "      - -3.2999999999999825\n",
      "      - 17.099999999999966\n",
      "      - 13.800000000000027\n",
      "      - 32.09999999999989\n",
      "      - 6.600000000000026\n",
      "      - -0.30000000000001015\n",
      "      - 5.099999999999971\n",
      "      - 15.9\n",
      "      - 1.200000000000017\n",
      "      - 12.899999999999995\n",
      "      - 13.499999999999917\n",
      "      - 15.900000000000015\n",
      "      - 13.499999999999975\n",
      "      - 30.599999999999937\n",
      "      - 6.00000000000003\n",
      "      - -2.067790383364354e-14\n",
      "      - 7.499999999999931\n",
      "      - 0.8999999999999956\n",
      "      - 15.300000000000008\n",
      "      - 8.700000000000026\n",
      "      - 9.29999999999994\n",
      "      - 15.599999999999925\n",
      "      policy_policy1_reward:\n",
      "      - 3.5\n",
      "      - 1.0\n",
      "      - 16.0\n",
      "      - 6.5\n",
      "      - 29.5\n",
      "      - -3.0\n",
      "      - 10.0\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 3.0\n",
      "      - 10.5\n",
      "      - 15.5\n",
      "      - 13.0\n",
      "      - 19.5\n",
      "      - 29.0\n",
      "      - 14.5\n",
      "      - 8.5\n",
      "      - 25.0\n",
      "      - 24.5\n",
      "      - 17.0\n",
      "      - 22.5\n",
      "      - 15.5\n",
      "      - 5.0\n",
      "      - 7.5\n",
      "      - 12.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      - 15.0\n",
      "      - 4.5\n",
      "      - 11.0\n",
      "      - 15.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 14.0\n",
      "      - 24.5\n",
      "      - 18.0\n",
      "      - 30.5\n",
      "      - 20.0\n",
      "      - 3.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 0.5\n",
      "      - 17.5\n",
      "      - -2.0\n",
      "      - -5.5\n",
      "      - 12.5\n",
      "      - 15.0\n",
      "      - 31.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 18.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 10.5\n",
      "      - 0.5\n",
      "      - 21.0\n",
      "      - -2.5\n",
      "      - 8.0\n",
      "      - 24.0\n",
      "      - 7.0\n",
      "      - 16.5\n",
      "      - 19.5\n",
      "      - 22.0\n",
      "      - 11.5\n",
      "      - 24.5\n",
      "      - 10.5\n",
      "      - 13.0\n",
      "      - 12.5\n",
      "      - 17.0\n",
      "      - 13.0\n",
      "      - 6.5\n",
      "      - 27.5\n",
      "      - -1.0\n",
      "      - 20.5\n",
      "      - 20.5\n",
      "      - 41.0\n",
      "      - 15.5\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - 16.0\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 16.0\n",
      "      - 18.0\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 16.5\n",
      "      - 16.0\n",
      "      - 13.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.899999999999986\n",
      "      - 3.2000000000000073\n",
      "      - -0.09999999999999232\n",
      "      - -5.599999999999994\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999992\n",
      "      - -0.10000000000000675\n",
      "      - 2.0999999999999974\n",
      "      - -7.799999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.200000000000004\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999924\n",
      "      - -6.699999999999984\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999987\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - 4.3000000000000025\n",
      "      - -1.2000000000000013\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 3.199999999999994\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999995\n",
      "      - -4.499999999999982\n",
      "      - -7.799999999999981\n",
      "      - -2.300000000000002\n",
      "      - -8.89999999999998\n",
      "      - 0.9999999999999957\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999994\n",
      "      - -2.2999999999999994\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -4.500000000000003\n",
      "      - 3.200000000000008\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998915\n",
      "      - -2.299999999999989\n",
      "      - 7.600000000000005\n",
      "      - -3.3999999999999853\n",
      "      - 3.200000000000001\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999991\n",
      "      - -4.499999999999994\n",
      "      - -8.89999999999998\n",
      "      - 7.6000000000000085\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - 7.60000000000001\n",
      "      - -4.499999999999982\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999989\n",
      "      - -4.499999999999998\n",
      "      - -6.699999999999988\n",
      "      - -4.499999999999984\n",
      "      - -4.499999999999989\n",
      "      - -3.3999999999999977\n",
      "      - -6.6999999999999895\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999998\n",
      "      - -3.400000000000001\n",
      "      - -5.599999999999995\n",
      "      - -2.2999999999999976\n",
      "      - -6.6999999999999815\n",
      "      - 0.9999999999999959\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -3.4000000000000044\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000375\n",
      "      - -7.7999999999999865\n",
      "      - -0.09999999999999454\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998965\n",
      "      - -4.500000000000002\n",
      "      - 2.1000000000000054\n",
      "      - 0.9999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999998\n",
      "      - -0.10000000000000409\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - 2.099999999999996\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 41.0\n",
      "      policy2: 7.60000000000001\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.435\n",
      "      policy2: -4.57699999999999\n",
      "    policy_reward_min:\n",
      "      policy1: -5.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15696567103601297\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06798386850111685\n",
      "      mean_inference_ms: 1.6482497929554631\n",
      "      mean_raw_obs_processing_ms: 0.3082744130017768\n",
      "  time_since_restore: 178.41967916488647\n",
      "  time_this_iter_s: 23.46977996826172\n",
      "  time_total_s: 178.41967916488647\n",
      "  timers:\n",
      "    learn_throughput: 457.298\n",
      "    learn_time_ms: 8747.034\n",
      "    synch_weights_time_ms: 3.705\n",
      "    training_iteration_time_ms: 17833.841\n",
      "  timestamp: 1658917226\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 78000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 78000\n",
      "    num_agent_steps_trained: 78000\n",
      "    num_env_steps_sampled: 39000\n",
      "    num_env_steps_trained: 39000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-27\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 33.899999999999906\n",
      "  episode_reward_mean: 12.620999999999963\n",
      "  episode_reward_min: -9.6\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 390\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.935742199420929\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012122118845582008\n",
      "          model: {}\n",
      "          policy_loss: -0.03914063051342964\n",
      "          total_loss: 6.822906017303467\n",
      "          vf_explained_var: 0.2679924964904785\n",
      "          vf_loss: 6.859622001647949\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8861216306686401\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01402964349836111\n",
      "          model: {}\n",
      "          policy_loss: -0.04221044480800629\n",
      "          total_loss: 3.037410259246826\n",
      "          vf_explained_var: 0.09990940243005753\n",
      "          vf_loss: 3.0782175064086914\n",
      "    num_agent_steps_sampled: 78000\n",
      "    num_agent_steps_trained: 78000\n",
      "    num_env_steps_sampled: 39000\n",
      "    num_env_steps_trained: 39000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 78000\n",
      "  num_agent_steps_trained: 78000\n",
      "  num_env_steps_sampled: 39000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 39000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.75\n",
      "    ram_util_percent: 60.087500000000006\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 7.600000000000004\n",
      "  policy_reward_mean:\n",
      "    policy1: 18.65\n",
      "    policy2: -6.028999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -4.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.15708206315283196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0694420776239339\n",
      "    mean_inference_ms: 1.6646496394755739\n",
      "    mean_raw_obs_processing_ms: 0.3102955268502503\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 33.899999999999906\n",
      "    episode_reward_mean: 12.620999999999963\n",
      "    episode_reward_min: -9.6\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -3.8999999999999924\n",
      "      - 15.000000000000032\n",
      "      - 1.500000000000011\n",
      "      - 2.6999999999999997\n",
      "      - 1.8000000000000167\n",
      "      - 12.29999999999998\n",
      "      - 18.599999999999966\n",
      "      - 6.599999999999966\n",
      "      - 3.0000000000000218\n",
      "      - 16.199999999999967\n",
      "      - 16.19999999999999\n",
      "      - 11.10000000000002\n",
      "      - 14.70000000000002\n",
      "      - 5.400000000000027\n",
      "      - 10.199999999999973\n",
      "      - 12.89999999999998\n",
      "      - 24.899999999999913\n",
      "      - -9.299999999999978\n",
      "      - 12.60000000000003\n",
      "      - 12.89999999999996\n",
      "      - 19.19999999999994\n",
      "      - -9.6\n",
      "      - 14.09999999999993\n",
      "      - 11.399999999999913\n",
      "      - 13.199999999999955\n",
      "      - 8.099999999999957\n",
      "      - -9.299999999999972\n",
      "      - 8.399999999999999\n",
      "      - 16.799999999999912\n",
      "      - 11.399999999999945\n",
      "      - 12.000000000000034\n",
      "      - 18.899999999999956\n",
      "      - 14.399999999999936\n",
      "      - 14.99999999999991\n",
      "      - -1.4999999999999853\n",
      "      - 0.30000000000000493\n",
      "      - 7.799999999999942\n",
      "      - 14.099999999999978\n",
      "      - 7.199999999999971\n",
      "      - -1.8000000000000007\n",
      "      - 10.500000000000027\n",
      "      - 23.09999999999991\n",
      "      - 8.699999999999989\n",
      "      - 5.400000000000018\n",
      "      - 18.59999999999991\n",
      "      - 23.999999999999908\n",
      "      - 5.099999999999946\n",
      "      - 18.599999999999962\n",
      "      - 9.899999999999983\n",
      "      - 7.799999999999942\n",
      "      - 20.09999999999997\n",
      "      - 11.699999999999934\n",
      "      - 12.599999999999932\n",
      "      - 9.899999999999926\n",
      "      - 19.79999999999996\n",
      "      - 1.2000000000000095\n",
      "      - 14.399999999999904\n",
      "      - 11.099999999999982\n",
      "      - 6.60000000000003\n",
      "      - 23.99999999999998\n",
      "      - 10.800000000000024\n",
      "      - 33.899999999999906\n",
      "      - 22.199999999999914\n",
      "      - 20.099999999999902\n",
      "      - 20.399999999999977\n",
      "      - 24.89999999999994\n",
      "      - 2.906008766956347e-14\n",
      "      - 24.59999999999991\n",
      "      - 5.999999999999957\n",
      "      - 18.59999999999992\n",
      "      - 13.19999999999992\n",
      "      - 14.999999999999964\n",
      "      - 14.699999999999944\n",
      "      - 17.699999999999907\n",
      "      - 18.299999999999933\n",
      "      - 15.599999999999914\n",
      "      - 4.200000000000003\n",
      "      - 14.699999999999916\n",
      "      - 0.29999999999999427\n",
      "      - 17.099999999999923\n",
      "      - 11.399999999999942\n",
      "      - 14.400000000000018\n",
      "      - 8.699999999999962\n",
      "      - 25.799999999999926\n",
      "      - 22.19999999999994\n",
      "      - 16.199999999999925\n",
      "      - 8.999999999999986\n",
      "      - 15.599999999999918\n",
      "      - 12.600000000000009\n",
      "      - 12.900000000000023\n",
      "      - 28.199999999999918\n",
      "      - 19.1999999999999\n",
      "      - 1.5000000000000138\n",
      "      - 17.699999999999953\n",
      "      - 17.69999999999995\n",
      "      - 23.699999999999932\n",
      "      - 12.299999999999958\n",
      "      - 18.59999999999995\n",
      "      - 19.799999999999976\n",
      "      - 23.699999999999918\n",
      "      policy_policy1_reward:\n",
      "      - 5.0\n",
      "      - 25.0\n",
      "      - 6.0\n",
      "      - 10.5\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 22.0\n",
      "      - -1.0\n",
      "      - 7.5\n",
      "      - 24.0\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 12.5\n",
      "      - 18.5\n",
      "      - 30.5\n",
      "      - -1.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 21.5\n",
      "      - -4.0\n",
      "      - 23.0\n",
      "      - 17.0\n",
      "      - 21.0\n",
      "      - 17.0\n",
      "      - -1.5\n",
      "      - 8.5\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 25.0\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 32.0\n",
      "      - 16.5\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 28.5\n",
      "      - 14.0\n",
      "      - 22.0\n",
      "      - 15.5\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - 19.5\n",
      "      - 21.5\n",
      "      - 15.5\n",
      "      - 26.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 34.0\n",
      "      - 17.5\n",
      "      - 39.5\n",
      "      - 30.0\n",
      "      - 29.0\n",
      "      - 26.0\n",
      "      - 30.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 1.5\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      - 32.5\n",
      "      - 30.0\n",
      "      - 18.5\n",
      "      - 19.0\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 18.5\n",
      "      - 36.0\n",
      "      - 27.0\n",
      "      - 11.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 26.5\n",
      "      - 31.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999994\n",
      "      - -3.3999999999999897\n",
      "      - 7.600000000000004\n",
      "      - -4.500000000000001\n",
      "      - -7.799999999999981\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999984\n",
      "      - -2.2999999999999976\n",
      "      - -5.599999999999998\n",
      "      - -2.299999999999984\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999987\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999988\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000431\n",
      "      - -6.699999999999993\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999979\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -3.399999999999994\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999997\n",
      "      - -3.400000000000005\n",
      "      - -4.5\n",
      "      - -8.899999999999984\n",
      "      - -3.4000000000000044\n",
      "      - -5.599999999999982\n",
      "      - -6.69999999999999\n",
      "      - -3.399999999999991\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999988\n",
      "      - -3.400000000000002\n",
      "      - -3.3999999999999893\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.7999999999999865\n",
      "      - 1.0000000000000062\n",
      "      - -7.7999999999999865\n",
      "      - -7.7999999999999865\n",
      "      - -6.69999999999999\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999986\n",
      "      - -2.300000000000001\n",
      "      - -1.200000000000003\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999986\n",
      "      - -0.10000000000000331\n",
      "      - -2.3000000000000007\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000026\n",
      "      - -3.4000000000000012\n",
      "      - -5.5999999999999845\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999989\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999986\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 7.600000000000004\n",
      "    policy_reward_mean:\n",
      "      policy1: 18.65\n",
      "      policy2: -6.028999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -4.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.15708206315283196\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0694420776239339\n",
      "      mean_inference_ms: 1.6646496394755739\n",
      "      mean_raw_obs_processing_ms: 0.3102955268502503\n",
      "  time_since_restore: 175.684814453125\n",
      "  time_this_iter_s: 17.240859270095825\n",
      "  time_total_s: 175.684814453125\n",
      "  timers:\n",
      "    learn_throughput: 421.662\n",
      "    learn_time_ms: 7114.695\n",
      "    synch_weights_time_ms: 4.541\n",
      "    training_iteration_time_ms: 14624.579\n",
      "  timestamp: 1658917227\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 13\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 78000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 78000\n",
      "    num_agent_steps_trained: 78000\n",
      "    num_env_steps_sampled: 39000\n",
      "    num_env_steps_trained: 39000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-28\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.699999999999896\n",
      "  episode_reward_mean: 6.5309999999999935\n",
      "  episode_reward_min: -12.299999999999976\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 390\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9473790526390076\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016611367464065552\n",
      "          model: {}\n",
      "          policy_loss: -0.05206800997257233\n",
      "          total_loss: 6.376032829284668\n",
      "          vf_explained_var: 0.23823031783103943\n",
      "          vf_loss: 6.420625686645508\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8891525268554688\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016724249348044395\n",
      "          model: {}\n",
      "          policy_loss: -0.046536996960639954\n",
      "          total_loss: 3.0628886222839355\n",
      "          vf_explained_var: 0.033402420580387115\n",
      "          vf_loss: 3.1018998622894287\n",
      "    num_agent_steps_sampled: 78000\n",
      "    num_agent_steps_trained: 78000\n",
      "    num_env_steps_sampled: 39000\n",
      "    num_env_steps_trained: 39000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 78000\n",
      "  num_agent_steps_trained: 78000\n",
      "  num_env_steps_sampled: 39000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 39000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 63.48076923076922\n",
      "    ram_util_percent: 60.07692307692308\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 31.5\n",
      "    policy2: 12.000000000000007\n",
      "  policy_reward_mean:\n",
      "    policy1: 12.175\n",
      "    policy2: -5.643999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -10.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16140673786228196\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06909849813090675\n",
      "    mean_inference_ms: 1.6950750558168017\n",
      "    mean_raw_obs_processing_ms: 0.31669192849340805\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.699999999999896\n",
      "    episode_reward_mean: 6.5309999999999935\n",
      "    episode_reward_min: -12.299999999999976\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 3.0000000000000204\n",
      "      - 3.6000000000000028\n",
      "      - 9.29999999999997\n",
      "      - -1.7999999999999827\n",
      "      - 1.8000000000000114\n",
      "      - -3.299999999999975\n",
      "      - 1.5000000000000289\n",
      "      - 10.199999999999996\n",
      "      - -1.4999999999999818\n",
      "      - 6.000000000000002\n",
      "      - 6.0000000000000195\n",
      "      - -8.99999999999999\n",
      "      - 18.599999999999937\n",
      "      - 15.600000000000003\n",
      "      - -4.199999999999983\n",
      "      - 6.00000000000003\n",
      "      - 13.20000000000001\n",
      "      - 20.099999999999902\n",
      "      - 14.699999999999921\n",
      "      - 3.000000000000024\n",
      "      - 16.799999999999947\n",
      "      - 9.00000000000002\n",
      "      - 3.300000000000025\n",
      "      - 10.800000000000027\n",
      "      - 3.3000000000000247\n",
      "      - 2.6999999999999607\n",
      "      - 19.499999999999893\n",
      "      - 9.299999999999976\n",
      "      - 12.000000000000007\n",
      "      - 0.3000000000000298\n",
      "      - 1.2000000000000188\n",
      "      - -0.9000000000000024\n",
      "      - -5.999999999999972\n",
      "      - 14.999999999999961\n",
      "      - 7.500000000000034\n",
      "      - -4.199999999999994\n",
      "      - 5.699999999999969\n",
      "      - 15.299999999999937\n",
      "      - 10.499999999999925\n",
      "      - -2.699999999999972\n",
      "      - 8.699999999999987\n",
      "      - -3.899999999999979\n",
      "      - 6.299999999999974\n",
      "      - 9.899999999999956\n",
      "      - -12.299999999999976\n",
      "      - -9.899999999999977\n",
      "      - 7.200000000000015\n",
      "      - 7.500000000000027\n",
      "      - 14.099999999999923\n",
      "      - -3.9000000000000066\n",
      "      - 17.69999999999991\n",
      "      - -6.5999999999999766\n",
      "      - -5.9999999999999805\n",
      "      - 6.900000000000003\n",
      "      - 13.49999999999993\n",
      "      - -2.099999999999974\n",
      "      - 6.000000000000025\n",
      "      - 8.100000000000014\n",
      "      - 10.50000000000002\n",
      "      - 21.599999999999927\n",
      "      - 4.499999999999989\n",
      "      - 9.000000000000028\n",
      "      - 6.60000000000003\n",
      "      - -1.1999999999999869\n",
      "      - 17.700000000000024\n",
      "      - 13.499999999999972\n",
      "      - 10.499999999999936\n",
      "      - 5.700000000000008\n",
      "      - -5.9999999999999885\n",
      "      - -2.400000000000012\n",
      "      - -2.3999999999999804\n",
      "      - 17.699999999999932\n",
      "      - 11.699999999999925\n",
      "      - 16.799999999999958\n",
      "      - -0.3000000000000226\n",
      "      - 11.999999999999982\n",
      "      - 8.700000000000028\n",
      "      - 10.19999999999998\n",
      "      - 11.10000000000003\n",
      "      - 9.600000000000014\n",
      "      - 6.60000000000003\n",
      "      - 8.400000000000029\n",
      "      - 14.700000000000028\n",
      "      - 8.099999999999952\n",
      "      - -9.599999999999984\n",
      "      - 23.699999999999896\n",
      "      - 11.100000000000032\n",
      "      - 9.000000000000005\n",
      "      - 14.999999999999947\n",
      "      - 11.099999999999957\n",
      "      - 21.899999999999928\n",
      "      - 1.5000000000000262\n",
      "      - -2.999999999999992\n",
      "      - 6.600000000000005\n",
      "      - 10.800000000000004\n",
      "      - 3.6000000000000205\n",
      "      - 6.000000000000027\n",
      "      - 11.10000000000001\n",
      "      - 3.9000000000000017\n",
      "      - 5.100000000000016\n",
      "      policy_policy1_reward:\n",
      "      - 13.0\n",
      "      - 1.5\n",
      "      - 16.0\n",
      "      - 6.0\n",
      "      - 8.5\n",
      "      - 4.5\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - -2.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 2.5\n",
      "      - 16.0\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 22.5\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 8.0\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - -1.0\n",
      "      - -0.5\n",
      "      - 29.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 7.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - -3.0\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      - 16.5\n",
      "      - 5.0\n",
      "      - 13.0\n",
      "      - 15.5\n",
      "      - -10.0\n",
      "      - -1.0\n",
      "      - 15.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - -0.5\n",
      "      - 25.5\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 30.5\n",
      "      - 14.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 5.5\n",
      "      - 25.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 6.5\n",
      "      - 6.5\n",
      "      - 25.5\n",
      "      - 19.5\n",
      "      - 18.0\n",
      "      - 2.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 18.0\n",
      "      - 20.0\n",
      "      - 7.5\n",
      "      - 15.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 17.0\n",
      "      - -4.0\n",
      "      - 31.5\n",
      "      - 14.5\n",
      "      - 19.0\n",
      "      - 25.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 6.0\n",
      "      - 1.5\n",
      "      - 4.5\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999991\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 3.1999999999999984\n",
      "      - 0.9999999999999979\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000017\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999895\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - 1.000000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - 4.299999999999999\n",
      "      - 3.200000000000003\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000021\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000022\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - 1.0000000000000129\n",
      "      - -6.699999999999994\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000003\n",
      "      - -3.3999999999999853\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999984\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999996\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000064\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.799999999999981\n",
      "      - 12.000000000000007\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999987\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000048\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000047\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - 2.1000000000000085\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000286\n",
      "      - 8.700000000000019\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.0999999999999956\n",
      "      - -5.599999999999999\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000003\n",
      "      - 2.100000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.4000000000000035\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 31.5\n",
      "      policy2: 12.000000000000007\n",
      "    policy_reward_mean:\n",
      "      policy1: 12.175\n",
      "      policy2: -5.643999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -10.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16140673786228196\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06909849813090675\n",
      "      mean_inference_ms: 1.6950750558168017\n",
      "      mean_raw_obs_processing_ms: 0.31669192849340805\n",
      "  time_since_restore: 177.24098443984985\n",
      "  time_this_iter_s: 17.70769190788269\n",
      "  time_total_s: 177.24098443984985\n",
      "  timers:\n",
      "    learn_throughput: 425.542\n",
      "    learn_time_ms: 7049.837\n",
      "    synch_weights_time_ms: 3.66\n",
      "    training_iteration_time_ms: 14750.412\n",
      "  timestamp: 1658917228\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 39000\n",
      "  training_iteration: 13\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 84000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_env_steps_sampled: 42000\n",
      "    num_env_steps_trained: 42000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-43\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 33.899999999999906\n",
      "  episode_reward_mean: 14.855999999999952\n",
      "  episode_reward_min: -12.000000000000012\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 420\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.910982072353363\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01317764911800623\n",
      "          model: {}\n",
      "          policy_loss: -0.040567703545093536\n",
      "          total_loss: 7.112209796905518\n",
      "          vf_explained_var: 0.2697121798992157\n",
      "          vf_loss: 7.150142192840576\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8484559655189514\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012227688916027546\n",
      "          model: {}\n",
      "          policy_loss: -0.038126781582832336\n",
      "          total_loss: 2.474949359893799\n",
      "          vf_explained_var: 0.20196424424648285\n",
      "          vf_loss: 2.5118536949157715\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_env_steps_sampled: 42000\n",
      "    num_env_steps_trained: 42000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 84000\n",
      "  num_env_steps_sampled: 42000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 42000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.44347826086957\n",
      "    ram_util_percent: 60.25652173913044\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 2.099999999999997\n",
      "  policy_reward_mean:\n",
      "    policy1: 21.545\n",
      "    policy2: -6.6889999999999885\n",
      "  policy_reward_min:\n",
      "    policy1: -2.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16046058908078006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07081714587414842\n",
      "    mean_inference_ms: 1.7046527009877395\n",
      "    mean_raw_obs_processing_ms: 0.3168598068140407\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 33.899999999999906\n",
      "    episode_reward_mean: 14.855999999999952\n",
      "    episode_reward_min: -12.000000000000012\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 12.000000000000034\n",
      "      - 18.899999999999956\n",
      "      - 14.399999999999936\n",
      "      - 14.99999999999991\n",
      "      - -1.4999999999999853\n",
      "      - 0.30000000000000493\n",
      "      - 7.799999999999942\n",
      "      - 14.099999999999978\n",
      "      - 7.199999999999971\n",
      "      - -1.8000000000000007\n",
      "      - 10.500000000000027\n",
      "      - 23.09999999999991\n",
      "      - 8.699999999999989\n",
      "      - 5.400000000000018\n",
      "      - 18.59999999999991\n",
      "      - 23.999999999999908\n",
      "      - 5.099999999999946\n",
      "      - 18.599999999999962\n",
      "      - 9.899999999999983\n",
      "      - 7.799999999999942\n",
      "      - 20.09999999999997\n",
      "      - 11.699999999999934\n",
      "      - 12.599999999999932\n",
      "      - 9.899999999999926\n",
      "      - 19.79999999999996\n",
      "      - 1.2000000000000095\n",
      "      - 14.399999999999904\n",
      "      - 11.099999999999982\n",
      "      - 6.60000000000003\n",
      "      - 23.99999999999998\n",
      "      - 10.800000000000024\n",
      "      - 33.899999999999906\n",
      "      - 22.199999999999914\n",
      "      - 20.099999999999902\n",
      "      - 20.399999999999977\n",
      "      - 24.89999999999994\n",
      "      - 2.906008766956347e-14\n",
      "      - 24.59999999999991\n",
      "      - 5.999999999999957\n",
      "      - 18.59999999999992\n",
      "      - 13.19999999999992\n",
      "      - 14.999999999999964\n",
      "      - 14.699999999999944\n",
      "      - 17.699999999999907\n",
      "      - 18.299999999999933\n",
      "      - 15.599999999999914\n",
      "      - 4.200000000000003\n",
      "      - 14.699999999999916\n",
      "      - 0.29999999999999427\n",
      "      - 17.099999999999923\n",
      "      - 11.399999999999942\n",
      "      - 14.400000000000018\n",
      "      - 8.699999999999962\n",
      "      - 25.799999999999926\n",
      "      - 22.19999999999994\n",
      "      - 16.199999999999925\n",
      "      - 8.999999999999986\n",
      "      - 15.599999999999918\n",
      "      - 12.600000000000009\n",
      "      - 12.900000000000023\n",
      "      - 28.199999999999918\n",
      "      - 19.1999999999999\n",
      "      - 1.5000000000000138\n",
      "      - 17.699999999999953\n",
      "      - 17.69999999999995\n",
      "      - 23.699999999999932\n",
      "      - 12.299999999999958\n",
      "      - 18.59999999999995\n",
      "      - 19.799999999999976\n",
      "      - 23.699999999999918\n",
      "      - 28.499999999999886\n",
      "      - 20.999999999999936\n",
      "      - 17.999999999999893\n",
      "      - 3.299999999999966\n",
      "      - 17.99999999999993\n",
      "      - 17.999999999999986\n",
      "      - 7.200000000000024\n",
      "      - 16.499999999999957\n",
      "      - 24.599999999999916\n",
      "      - 19.49999999999993\n",
      "      - -12.000000000000012\n",
      "      - 14.099999999999902\n",
      "      - 19.19999999999994\n",
      "      - 20.99999999999999\n",
      "      - 26.69999999999991\n",
      "      - 22.79999999999996\n",
      "      - 8.999999999999964\n",
      "      - 5.1\n",
      "      - 14.999999999999961\n",
      "      - 17.0999999999999\n",
      "      - 14.69999999999993\n",
      "      - 20.099999999999934\n",
      "      - 13.199999999999905\n",
      "      - 18.89999999999995\n",
      "      - 23.9999999999999\n",
      "      - 17.999999999999922\n",
      "      - 25.199999999999896\n",
      "      - 18.599999999999973\n",
      "      - 11.700000000000031\n",
      "      - 15.599999999999948\n",
      "      policy_policy1_reward:\n",
      "      - 22.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 25.0\n",
      "      - -2.5\n",
      "      - 7.0\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 32.0\n",
      "      - 16.5\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 28.5\n",
      "      - 14.0\n",
      "      - 22.0\n",
      "      - 15.5\n",
      "      - 14.5\n",
      "      - 23.5\n",
      "      - 19.5\n",
      "      - 21.5\n",
      "      - 15.5\n",
      "      - 26.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 10.0\n",
      "      - 34.0\n",
      "      - 17.5\n",
      "      - 39.5\n",
      "      - 30.0\n",
      "      - 29.0\n",
      "      - 26.0\n",
      "      - 30.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 1.5\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      - 32.5\n",
      "      - 30.0\n",
      "      - 18.5\n",
      "      - 19.0\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 18.5\n",
      "      - 36.0\n",
      "      - 27.0\n",
      "      - 11.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 26.5\n",
      "      - 31.5\n",
      "      - 38.5\n",
      "      - 31.0\n",
      "      - 28.0\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 29.5\n",
      "      - -2.0\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 31.0\n",
      "      - 34.5\n",
      "      - 29.5\n",
      "      - 19.0\n",
      "      - 14.0\n",
      "      - 25.0\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 27.5\n",
      "      - 19.5\n",
      "      - 24.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999979\n",
      "      - -6.6999999999999895\n",
      "      - -6.699999999999993\n",
      "      - -3.399999999999994\n",
      "      - -7.799999999999989\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999997\n",
      "      - -3.400000000000005\n",
      "      - -4.5\n",
      "      - -8.899999999999984\n",
      "      - -3.4000000000000044\n",
      "      - -5.599999999999982\n",
      "      - -6.69999999999999\n",
      "      - -3.399999999999991\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999988\n",
      "      - -3.400000000000002\n",
      "      - -3.3999999999999893\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.7999999999999865\n",
      "      - 1.0000000000000062\n",
      "      - -7.7999999999999865\n",
      "      - -7.7999999999999865\n",
      "      - -6.69999999999999\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999986\n",
      "      - -2.300000000000001\n",
      "      - -1.200000000000003\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999986\n",
      "      - -0.10000000000000331\n",
      "      - -2.3000000000000007\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000026\n",
      "      - -3.4000000000000012\n",
      "      - -5.5999999999999845\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999989\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - 0.9999999999999961\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000034\n",
      "      - -3.400000000000005\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 2.099999999999997\n",
      "    policy_reward_mean:\n",
      "      policy1: 21.545\n",
      "      policy2: -6.6889999999999885\n",
      "    policy_reward_min:\n",
      "      policy1: -2.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16046058908078006\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07081714587414842\n",
      "      mean_inference_ms: 1.7046527009877395\n",
      "      mean_raw_obs_processing_ms: 0.3168598068140407\n",
      "  time_since_restore: 191.35981917381287\n",
      "  time_this_iter_s: 15.675004720687866\n",
      "  time_total_s: 191.35981917381287\n",
      "  timers:\n",
      "    learn_throughput: 408.068\n",
      "    learn_time_ms: 7351.708\n",
      "    synch_weights_time_ms: 5.111\n",
      "    training_iteration_time_ms: 14802.744\n",
      "  timestamp: 1658917243\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 42000\n",
      "  training_iteration: 14\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 84000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_env_steps_sampled: 42000\n",
      "    num_env_steps_trained: 42000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-44\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.699999999999896\n",
      "  episode_reward_mean: 6.914999999999993\n",
      "  episode_reward_min: -12.299999999999976\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 420\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9345654249191284\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019567547366023064\n",
      "          model: {}\n",
      "          policy_loss: -0.061114534735679626\n",
      "          total_loss: 6.284510612487793\n",
      "          vf_explained_var: 0.13540118932724\n",
      "          vf_loss: 6.336820602416992\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8688465356826782\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017059223726391792\n",
      "          model: {}\n",
      "          policy_loss: -0.04691340774297714\n",
      "          total_loss: 3.0165960788726807\n",
      "          vf_explained_var: 0.03801082447171211\n",
      "          vf_loss: 3.055832862854004\n",
      "    num_agent_steps_sampled: 84000\n",
      "    num_agent_steps_trained: 84000\n",
      "    num_env_steps_sampled: 42000\n",
      "    num_env_steps_trained: 42000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 84000\n",
      "  num_agent_steps_trained: 84000\n",
      "  num_env_steps_sampled: 42000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 42000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.99565217391305\n",
      "    ram_util_percent: 60.20869565217393\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 31.5\n",
      "    policy2: 14.20000000000001\n",
      "  policy_reward_mean:\n",
      "    policy1: 12.185\n",
      "    policy2: -5.26999999999999\n",
      "  policy_reward_min:\n",
      "    policy1: -10.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16499260834614993\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07055437497514506\n",
      "    mean_inference_ms: 1.7382672039891793\n",
      "    mean_raw_obs_processing_ms: 0.3238230730353075\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.699999999999896\n",
      "    episode_reward_mean: 6.914999999999993\n",
      "    episode_reward_min: -12.299999999999976\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 1.2000000000000188\n",
      "      - -0.9000000000000024\n",
      "      - -5.999999999999972\n",
      "      - 14.999999999999961\n",
      "      - 7.500000000000034\n",
      "      - -4.199999999999994\n",
      "      - 5.699999999999969\n",
      "      - 15.299999999999937\n",
      "      - 10.499999999999925\n",
      "      - -2.699999999999972\n",
      "      - 8.699999999999987\n",
      "      - -3.899999999999979\n",
      "      - 6.299999999999974\n",
      "      - 9.899999999999956\n",
      "      - -12.299999999999976\n",
      "      - -9.899999999999977\n",
      "      - 7.200000000000015\n",
      "      - 7.500000000000027\n",
      "      - 14.099999999999923\n",
      "      - -3.9000000000000066\n",
      "      - 17.69999999999991\n",
      "      - -6.5999999999999766\n",
      "      - -5.9999999999999805\n",
      "      - 6.900000000000003\n",
      "      - 13.49999999999993\n",
      "      - -2.099999999999974\n",
      "      - 6.000000000000025\n",
      "      - 8.100000000000014\n",
      "      - 10.50000000000002\n",
      "      - 21.599999999999927\n",
      "      - 4.499999999999989\n",
      "      - 9.000000000000028\n",
      "      - 6.60000000000003\n",
      "      - -1.1999999999999869\n",
      "      - 17.700000000000024\n",
      "      - 13.499999999999972\n",
      "      - 10.499999999999936\n",
      "      - 5.700000000000008\n",
      "      - -5.9999999999999885\n",
      "      - -2.400000000000012\n",
      "      - -2.3999999999999804\n",
      "      - 17.699999999999932\n",
      "      - 11.699999999999925\n",
      "      - 16.799999999999958\n",
      "      - -0.3000000000000226\n",
      "      - 11.999999999999982\n",
      "      - 8.700000000000028\n",
      "      - 10.19999999999998\n",
      "      - 11.10000000000003\n",
      "      - 9.600000000000014\n",
      "      - 6.60000000000003\n",
      "      - 8.400000000000029\n",
      "      - 14.700000000000028\n",
      "      - 8.099999999999952\n",
      "      - -9.599999999999984\n",
      "      - 23.699999999999896\n",
      "      - 11.100000000000032\n",
      "      - 9.000000000000005\n",
      "      - 14.999999999999947\n",
      "      - 11.099999999999957\n",
      "      - 21.899999999999928\n",
      "      - 1.5000000000000262\n",
      "      - -2.999999999999992\n",
      "      - 6.600000000000005\n",
      "      - 10.800000000000004\n",
      "      - 3.6000000000000205\n",
      "      - 6.000000000000027\n",
      "      - 11.10000000000001\n",
      "      - 3.9000000000000017\n",
      "      - 5.100000000000016\n",
      "      - -7.499999999999975\n",
      "      - 8.70000000000003\n",
      "      - 14.399999999999961\n",
      "      - 8.999999999999984\n",
      "      - 4.200000000000031\n",
      "      - 8.699999999999944\n",
      "      - 5.10000000000003\n",
      "      - 11.09999999999999\n",
      "      - 9.000000000000021\n",
      "      - -5.999999999999982\n",
      "      - -1.7999999999999874\n",
      "      - 6.300000000000004\n",
      "      - -1.7999999999999838\n",
      "      - -0.8999999999999702\n",
      "      - 6.9000000000000306\n",
      "      - 19.799999999999933\n",
      "      - 11.70000000000001\n",
      "      - 21.299999999999933\n",
      "      - -2.399999999999971\n",
      "      - 17.4\n",
      "      - 4.50000000000003\n",
      "      - 3.300000000000021\n",
      "      - 6.9\n",
      "      - 11.699999999999989\n",
      "      - 5.700000000000022\n",
      "      - 19.19999999999994\n",
      "      - 7.500000000000016\n",
      "      - 13.799999999999972\n",
      "      - 18.599999999999966\n",
      "      - 13.799999999999924\n",
      "      policy_policy1_reward:\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - -3.0\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 9.5\n",
      "      - 4.0\n",
      "      - 16.5\n",
      "      - 5.0\n",
      "      - 13.0\n",
      "      - 15.5\n",
      "      - -10.0\n",
      "      - -1.0\n",
      "      - 15.0\n",
      "      - 17.5\n",
      "      - 17.5\n",
      "      - -0.5\n",
      "      - 25.5\n",
      "      - -1.0\n",
      "      - 4.0\n",
      "      - 7.0\n",
      "      - 23.5\n",
      "      - 3.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 30.5\n",
      "      - 14.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 5.5\n",
      "      - 25.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 6.5\n",
      "      - 6.5\n",
      "      - 25.5\n",
      "      - 19.5\n",
      "      - 18.0\n",
      "      - 2.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 18.0\n",
      "      - 20.0\n",
      "      - 7.5\n",
      "      - 15.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 17.0\n",
      "      - -4.0\n",
      "      - 31.5\n",
      "      - 14.5\n",
      "      - 19.0\n",
      "      - 25.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 6.0\n",
      "      - 1.5\n",
      "      - 4.5\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 2.5\n",
      "      - 16.5\n",
      "      - 20.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 11.0\n",
      "      - 14.0\n",
      "      - 9.0\n",
      "      - 13.5\n",
      "      - -1.5\n",
      "      - 6.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 26.5\n",
      "      - 19.5\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 14.5\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - 6.500000000000021\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000022\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999994\n",
      "      - 1.0000000000000129\n",
      "      - -6.699999999999994\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000003\n",
      "      - -3.3999999999999853\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999984\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999996\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000064\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.799999999999981\n",
      "      - 12.000000000000007\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999987\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000048\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000047\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - 2.1000000000000085\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000286\n",
      "      - 8.700000000000019\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.0999999999999956\n",
      "      - -5.599999999999999\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000003\n",
      "      - 2.100000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.4000000000000035\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -2.2999999999999887\n",
      "      - -8.899999999999983\n",
      "      - 2.1000000000000036\n",
      "      - -4.499999999999999\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000553\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999983\n",
      "      - 4.300000000000008\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000011\n",
      "      - -0.1000000000000015\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 14.20000000000001\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999985\n",
      "      - -3.3999999999999955\n",
      "      - -1.2000000000000035\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 31.5\n",
      "      policy2: 14.20000000000001\n",
      "    policy_reward_mean:\n",
      "      policy1: 12.185\n",
      "      policy2: -5.26999999999999\n",
      "    policy_reward_min:\n",
      "      policy1: -10.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16499260834614993\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07055437497514506\n",
      "      mean_inference_ms: 1.7382672039891793\n",
      "      mean_raw_obs_processing_ms: 0.3238230730353075\n",
      "  time_since_restore: 193.31203436851501\n",
      "  time_this_iter_s: 16.07104992866516\n",
      "  time_total_s: 193.31203436851501\n",
      "  timers:\n",
      "    learn_throughput: 408.78\n",
      "    learn_time_ms: 7338.906\n",
      "    synch_weights_time_ms: 3.975\n",
      "    training_iteration_time_ms: 14967.098\n",
      "  timestamp: 1658917244\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 42000\n",
      "  training_iteration: 14\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 80000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_env_steps_sampled: 40000\n",
      "    num_env_steps_trained: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 24.599999999999916\n",
      "  episode_reward_mean: 5.898000000000001\n",
      "  episode_reward_min: -14.999999999999982\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 400\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0488072633743286\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01778813637793064\n",
      "          model: {}\n",
      "          policy_loss: -0.05030328407883644\n",
      "          total_loss: 6.541411399841309\n",
      "          vf_explained_var: 0.3040623366832733\n",
      "          vf_loss: 6.583710670471191\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0213696956634521\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016730662435293198\n",
      "          model: {}\n",
      "          policy_loss: -0.0426497682929039\n",
      "          total_loss: 2.949213981628418\n",
      "          vf_explained_var: 0.18553395569324493\n",
      "          vf_loss: 2.984334707260132\n",
      "    num_agent_steps_sampled: 80000\n",
      "    num_agent_steps_trained: 80000\n",
      "    num_env_steps_sampled: 40000\n",
      "    num_env_steps_trained: 40000\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 80000\n",
      "  num_agent_steps_trained: 80000\n",
      "  num_env_steps_sampled: 40000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 40000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.53823529411764\n",
      "    ram_util_percent: 60.9264705882353\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 33.5\n",
      "    policy2: 6.500000000000003\n",
      "  policy_reward_mean:\n",
      "    policy1: 12.95\n",
      "    policy2: -7.051999999999985\n",
      "  policy_reward_min:\n",
      "    policy1: -9.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1659160257698332\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07114286861417407\n",
      "    mean_inference_ms: 1.7634556348637622\n",
      "    mean_raw_obs_processing_ms: 0.32696154219929385\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 24.599999999999916\n",
      "    episode_reward_mean: 5.898000000000001\n",
      "    episode_reward_min: -14.999999999999982\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -1.4999999999999907\n",
      "      - 8.40000000000002\n",
      "      - 21.59999999999995\n",
      "      - 20.999999999999922\n",
      "      - 4.800000000000029\n",
      "      - 8.10000000000002\n",
      "      - -2.3999999999999795\n",
      "      - 0.6000000000000091\n",
      "      - 2.806088694740083e-14\n",
      "      - -1.49999999999998\n",
      "      - 4.500000000000018\n",
      "      - 10.500000000000032\n",
      "      - 4.500000000000023\n",
      "      - 8.70000000000002\n",
      "      - 1.1296519275560968e-14\n",
      "      - 8.700000000000017\n",
      "      - 6.30000000000002\n",
      "      - 11.399999999999936\n",
      "      - -4.199999999999978\n",
      "      - -8.099999999999982\n",
      "      - 11.100000000000014\n",
      "      - 11.099999999999985\n",
      "      - -4.500000000000002\n",
      "      - -2.9999999999999853\n",
      "      - 12.000000000000034\n",
      "      - -2.3999999999999826\n",
      "      - -6.899999999999992\n",
      "      - -14.999999999999982\n",
      "      - 1.5000000000000147\n",
      "      - 17.099999999999923\n",
      "      - -3.2999999999999927\n",
      "      - -8.99999999999999\n",
      "      - 9.000000000000002\n",
      "      - 1.2000000000000148\n",
      "      - 11.69999999999995\n",
      "      - 12.599999999999925\n",
      "      - 2.7283730830163222e-14\n",
      "      - 20.1\n",
      "      - 1.80000000000001\n",
      "      - 7.800000000000026\n",
      "      - 23.09999999999991\n",
      "      - 3.6000000000000125\n",
      "      - -6.299999999999999\n",
      "      - 6.600000000000023\n",
      "      - 24.599999999999916\n",
      "      - 17.70000000000001\n",
      "      - 1.2000000000000086\n",
      "      - 11.100000000000028\n",
      "      - -1.799999999999982\n",
      "      - 4.5000000000000115\n",
      "      - 4.2000000000000135\n",
      "      - 10.499999999999991\n",
      "      - 13.799999999999969\n",
      "      - 2.1000000000000254\n",
      "      - -13.79999999999998\n",
      "      - 5.100000000000026\n",
      "      - -0.2999999999999975\n",
      "      - -7.799999999999995\n",
      "      - 7.199999999999989\n",
      "      - 10.500000000000023\n",
      "      - 6.300000000000027\n",
      "      - 2.3842039453825237e-14\n",
      "      - -7.499999999999991\n",
      "      - 14.399999999999975\n",
      "      - 2.100000000000011\n",
      "      - 10.500000000000023\n",
      "      - 1.500000000000013\n",
      "      - 15.60000000000001\n",
      "      - 5.700000000000006\n",
      "      - 11.100000000000026\n",
      "      - 7.1999999999999655\n",
      "      - 22.79999999999992\n",
      "      - 3.000000000000012\n",
      "      - 11.699999999999994\n",
      "      - 1.5000000000000209\n",
      "      - 11.100000000000021\n",
      "      - -3.599999999999996\n",
      "      - 4.5000000000000195\n",
      "      - 4.800000000000026\n",
      "      - 7.500000000000021\n",
      "      - 22.799999999999905\n",
      "      - -1.7999999999999847\n",
      "      - 5.100000000000019\n",
      "      - 20.399999999999974\n",
      "      - 7.800000000000011\n",
      "      - 7.1999999999999496\n",
      "      - 20.099999999999973\n",
      "      - -0.2999999999999782\n",
      "      - 9.599999999999977\n",
      "      - 4.500000000000012\n",
      "      - -0.8999999999999759\n",
      "      - 14.099999999999975\n",
      "      - 3.600000000000026\n",
      "      - 2.858824288409778e-15\n",
      "      - 7.499999999999991\n",
      "      - -2.3999999999999764\n",
      "      - 9.600000000000003\n",
      "      - 20.69999999999994\n",
      "      - 8.699999999999982\n",
      "      - 13.19999999999999\n",
      "      policy_policy1_reward:\n",
      "      - 3.0\n",
      "      - 14.0\n",
      "      - 30.5\n",
      "      - 31.0\n",
      "      - 11.5\n",
      "      - 11.5\n",
      "      - 6.5\n",
      "      - 9.5\n",
      "      - 10.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 4.5\n",
      "      - 16.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 2.5\n",
      "      - -2.5\n",
      "      - 20.0\n",
      "      - 20.0\n",
      "      - 5.5\n",
      "      - 7.0\n",
      "      - 22.0\n",
      "      - 1.0\n",
      "      - 2.0\n",
      "      - -5.0\n",
      "      - 11.5\n",
      "      - 26.0\n",
      "      - 4.5\n",
      "      - 1.0\n",
      "      - 8.0\n",
      "      - 3.5\n",
      "      - 14.0\n",
      "      - 21.5\n",
      "      - 10.0\n",
      "      - 29.0\n",
      "      - 8.5\n",
      "      - 9.0\n",
      "      - 32.0\n",
      "      - 12.5\n",
      "      - 1.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 25.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 6.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 14.0\n",
      "      - 7.5\n",
      "      - 0.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 13.0\n",
      "      - 10.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 11.0\n",
      "      - 20.5\n",
      "      - 11.5\n",
      "      - 24.5\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 15.0\n",
      "      - 24.0\n",
      "      - 7.5\n",
      "      - 19.5\n",
      "      - 11.5\n",
      "      - 20.0\n",
      "      - -9.0\n",
      "      - 14.5\n",
      "      - 6.0\n",
      "      - 1.0\n",
      "      - 29.5\n",
      "      - 6.0\n",
      "      - 14.0\n",
      "      - 26.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 29.0\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 16.5\n",
      "      - 21.0\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999996\n",
      "      - -5.599999999999987\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.4\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999988\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000055\n",
      "      - -5.59999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999989\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999937\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000013\n",
      "      - -2.300000000000001\n",
      "      - -2.3000000000000043\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999993\n",
      "      - -1.1999999999999948\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.5\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999984\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - 3.200000000000011\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -1.1999999999999913\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - 5.399999999999996\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000042\n",
      "      - 6.500000000000003\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.69999999999999\n",
      "      - -2.3000000000000047\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -3.399999999999983\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - 2.100000000000001\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 33.5\n",
      "      policy2: 6.500000000000003\n",
      "    policy_reward_mean:\n",
      "      policy1: 12.95\n",
      "      policy2: -7.051999999999985\n",
      "    policy_reward_min:\n",
      "      policy1: -9.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1659160257698332\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07114286861417407\n",
      "      mean_inference_ms: 1.7634556348637622\n",
      "      mean_raw_obs_processing_ms: 0.32696154219929385\n",
      "  time_since_restore: 191.61249566078186\n",
      "  time_this_iter_s: 23.59675693511963\n",
      "  time_total_s: 191.61249566078186\n",
      "  timers:\n",
      "    learn_throughput: 417.915\n",
      "    learn_time_ms: 9571.332\n",
      "    synch_weights_time_ms: 3.987\n",
      "    training_iteration_time_ms: 19153.337\n",
      "  timestamp: 1658917250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 10\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 88000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_env_steps_sampled: 44000\n",
      "    num_env_steps_trained: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-20-50\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.09999999999989\n",
      "  episode_reward_mean: 10.67399999999998\n",
      "  episode_reward_min: -14.399999999999975\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 440\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0151617527008057\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013276380486786366\n",
      "          model: {}\n",
      "          policy_loss: -0.03917940333485603\n",
      "          total_loss: 6.810563087463379\n",
      "          vf_explained_var: 0.24620239436626434\n",
      "          vf_loss: 6.8470869064331055\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 1.0133777856826782\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012858168222010136\n",
      "          model: {}\n",
      "          policy_loss: -0.03622094914317131\n",
      "          total_loss: 3.320061206817627\n",
      "          vf_explained_var: 0.06838181614875793\n",
      "          vf_loss: 3.353710651397705\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_env_steps_sampled: 44000\n",
      "    num_env_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 88000\n",
      "  num_env_steps_sampled: 44000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 44000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.932352941176475\n",
      "    ram_util_percent: 60.98235294117647\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 41.0\n",
      "    policy2: 16.39999999999999\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.8\n",
      "    policy2: -4.1259999999999915\n",
      "  policy_reward_min:\n",
      "    policy1: -5.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16179768579443082\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06990573657695567\n",
      "    mean_inference_ms: 1.7010773310456897\n",
      "    mean_raw_obs_processing_ms: 0.3170746768642792\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.09999999999989\n",
      "    episode_reward_mean: 10.67399999999998\n",
      "    episode_reward_min: -14.399999999999975\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 21.599999999999916\n",
      "      - 11.099999999999968\n",
      "      - -1.4999999999999787\n",
      "      - 11.699999999999967\n",
      "      - 9.000000000000005\n",
      "      - 23.399999999999913\n",
      "      - 14.699999999999992\n",
      "      - 8.099999999999975\n",
      "      - 14.10000000000002\n",
      "      - 1.1999999999999924\n",
      "      - -14.399999999999975\n",
      "      - 3.6000000000000316\n",
      "      - 10.499999999999925\n",
      "      - 24.299999999999933\n",
      "      - 9.599999999999998\n",
      "      - 1.5000000000000218\n",
      "      - 9.600000000000032\n",
      "      - 15.600000000000007\n",
      "      - 6.600000000000001\n",
      "      - 2.6999999999999513\n",
      "      - 8.09999999999997\n",
      "      - 16.499999999999964\n",
      "      - -11.399999999999983\n",
      "      - 2.3999999999999755\n",
      "      - 19.49999999999995\n",
      "      - 0.3000000000000207\n",
      "      - 12.000000000000012\n",
      "      - 15.00000000000003\n",
      "      - 18.59999999999995\n",
      "      - 4.800000000000013\n",
      "      - 18.899999999999984\n",
      "      - 5.999999999999973\n",
      "      - 9.599999999999998\n",
      "      - 6.899999999999958\n",
      "      - 14.699999999999944\n",
      "      - 6.3000000000000185\n",
      "      - 7.500000000000027\n",
      "      - 18.599999999999905\n",
      "      - -3.2999999999999825\n",
      "      - 17.099999999999966\n",
      "      - 13.800000000000027\n",
      "      - 32.09999999999989\n",
      "      - 6.600000000000026\n",
      "      - -0.30000000000001015\n",
      "      - 5.099999999999971\n",
      "      - 15.9\n",
      "      - 1.200000000000017\n",
      "      - 12.899999999999995\n",
      "      - 13.499999999999917\n",
      "      - 15.900000000000015\n",
      "      - 13.499999999999975\n",
      "      - 30.599999999999937\n",
      "      - 6.00000000000003\n",
      "      - -2.067790383364354e-14\n",
      "      - 7.499999999999931\n",
      "      - 0.8999999999999956\n",
      "      - 15.300000000000008\n",
      "      - 8.700000000000026\n",
      "      - 9.29999999999994\n",
      "      - 15.599999999999925\n",
      "      - -2.100000000000012\n",
      "      - 18.599999999999902\n",
      "      - 12.600000000000028\n",
      "      - 11.10000000000003\n",
      "      - 9.899999999999942\n",
      "      - 15.900000000000004\n",
      "      - 20.69999999999994\n",
      "      - 24.599999999999902\n",
      "      - 8.69999999999999\n",
      "      - 9.0\n",
      "      - 14.999999999999927\n",
      "      - 13.199999999999946\n",
      "      - 8.100000000000007\n",
      "      - 19.499999999999922\n",
      "      - 12.599999999999934\n",
      "      - -5.699999999999987\n",
      "      - -7.19999999999998\n",
      "      - 10.199999999999942\n",
      "      - 1.5000000000000138\n",
      "      - 9.300000000000031\n",
      "      - 15.00000000000003\n",
      "      - 8.999999999999979\n",
      "      - 11.699999999999948\n",
      "      - 25.499999999999922\n",
      "      - 8.700000000000014\n",
      "      - 9.000000000000028\n",
      "      - 4.800000000000024\n",
      "      - 17.099999999999923\n",
      "      - 10.800000000000013\n",
      "      - 29.099999999999895\n",
      "      - -0.29999999999997795\n",
      "      - 12.299999999999983\n",
      "      - 11.399999999999949\n",
      "      - 25.79999999999992\n",
      "      - 16.79999999999996\n",
      "      - 11.39999999999997\n",
      "      - 9.899999999999972\n",
      "      - 14.699999999999937\n",
      "      - 8.99999999999999\n",
      "      - 15.000000000000004\n",
      "      policy_policy1_reward:\n",
      "      - 30.5\n",
      "      - 20.0\n",
      "      - 3.0\n",
      "      - 8.5\n",
      "      - 19.0\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 0.5\n",
      "      - 17.5\n",
      "      - -2.0\n",
      "      - -5.5\n",
      "      - 12.5\n",
      "      - 15.0\n",
      "      - 31.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 18.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 10.5\n",
      "      - 0.5\n",
      "      - 21.0\n",
      "      - -2.5\n",
      "      - 8.0\n",
      "      - 24.0\n",
      "      - 7.0\n",
      "      - 16.5\n",
      "      - 19.5\n",
      "      - 22.0\n",
      "      - 11.5\n",
      "      - 24.5\n",
      "      - 10.5\n",
      "      - 13.0\n",
      "      - 12.5\n",
      "      - 17.0\n",
      "      - 13.0\n",
      "      - 6.5\n",
      "      - 27.5\n",
      "      - -1.0\n",
      "      - 20.5\n",
      "      - 20.5\n",
      "      - 41.0\n",
      "      - 15.5\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - 16.0\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 16.0\n",
      "      - 18.0\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 16.5\n",
      "      - 16.0\n",
      "      - 13.5\n",
      "      - 3.5\n",
      "      - 27.5\n",
      "      - 16.0\n",
      "      - 20.0\n",
      "      - 15.5\n",
      "      - -0.5\n",
      "      - 28.5\n",
      "      - 22.5\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 19.5\n",
      "      - 21.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - -4.5\n",
      "      - -0.5\n",
      "      - 18.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 19.5\n",
      "      - 30.0\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 38.0\n",
      "      - 7.5\n",
      "      - 13.5\n",
      "      - 11.5\n",
      "      - 27.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 15.5\n",
      "      - 17.0\n",
      "      - 8.0\n",
      "      - 25.0\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -4.500000000000003\n",
      "      - 3.200000000000008\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998915\n",
      "      - -2.299999999999989\n",
      "      - 7.600000000000005\n",
      "      - -3.3999999999999853\n",
      "      - 3.200000000000001\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -6.6999999999999815\n",
      "      - -3.399999999999991\n",
      "      - -4.499999999999994\n",
      "      - -8.89999999999998\n",
      "      - 7.6000000000000085\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - 7.60000000000001\n",
      "      - -4.499999999999982\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999989\n",
      "      - -4.499999999999998\n",
      "      - -6.699999999999988\n",
      "      - -4.499999999999984\n",
      "      - -4.499999999999989\n",
      "      - -3.3999999999999977\n",
      "      - -6.6999999999999895\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999998\n",
      "      - -3.400000000000001\n",
      "      - -5.599999999999995\n",
      "      - -2.2999999999999976\n",
      "      - -6.6999999999999815\n",
      "      - 0.9999999999999959\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -3.4000000000000044\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000375\n",
      "      - -7.7999999999999865\n",
      "      - -0.09999999999999454\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998965\n",
      "      - -4.500000000000002\n",
      "      - 2.1000000000000054\n",
      "      - 0.9999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999998\n",
      "      - -0.10000000000000409\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999982\n",
      "      - -8.899999999999986\n",
      "      - -3.3999999999999893\n",
      "      - -8.89999999999998\n",
      "      - -5.5999999999999845\n",
      "      - 16.39999999999999\n",
      "      - -7.79999999999999\n",
      "      - 2.0999999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -4.499999999999995\n",
      "      - -4.4999999999999964\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - 6.500000000000012\n",
      "      - -3.3999999999999986\n",
      "      - -1.199999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999982\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.7999999999999865\n",
      "      - -4.5000000000000036\n",
      "      - -1.2000000000000033\n",
      "      - -3.400000000000004\n",
      "      - 4.300000000000009\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000008\n",
      "      - -0.09999999999999987\n",
      "      - -1.2000000000000026\n",
      "      - -1.1999999999999946\n",
      "      - -5.599999999999997\n",
      "      - -5.599999999999988\n",
      "      - -2.300000000000004\n",
      "      - 0.9999999999999992\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 41.0\n",
      "      policy2: 16.39999999999999\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.8\n",
      "      policy2: -4.1259999999999915\n",
      "    policy_reward_min:\n",
      "      policy1: -5.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16179768579443082\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06990573657695567\n",
      "      mean_inference_ms: 1.7010773310456897\n",
      "      mean_raw_obs_processing_ms: 0.3170746768642792\n",
      "  time_since_restore: 202.10628628730774\n",
      "  time_this_iter_s: 23.686607122421265\n",
      "  time_total_s: 202.10628628730774\n",
      "  timers:\n",
      "    learn_throughput: 421.758\n",
      "    learn_time_ms: 9484.101\n",
      "    synch_weights_time_ms: 3.97\n",
      "    training_iteration_time_ms: 19153.924\n",
      "  timestamp: 1658917250\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 90000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 90000\n",
      "    num_env_steps_sampled: 45000\n",
      "    num_env_steps_trained: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-02\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 33.899999999999906\n",
      "  episode_reward_mean: 16.277999999999945\n",
      "  episode_reward_min: -12.000000000000012\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 450\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.886432409286499\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012800653465092182\n",
      "          model: {}\n",
      "          policy_loss: -0.03865716606378555\n",
      "          total_loss: 6.952341079711914\n",
      "          vf_explained_var: 0.2358694076538086\n",
      "          vf_loss: 6.988437175750732\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8101575970649719\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015001444146037102\n",
      "          model: {}\n",
      "          policy_loss: -0.04354936257004738\n",
      "          total_loss: 2.698042392730713\n",
      "          vf_explained_var: 0.1229035034775734\n",
      "          vf_loss: 2.740091562271118\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 90000\n",
      "    num_env_steps_sampled: 45000\n",
      "    num_env_steps_trained: 45000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 90000\n",
      "  num_agent_steps_trained: 90000\n",
      "  num_env_steps_sampled: 45000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 45000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.17407407407408\n",
      "    ram_util_percent: 62.714814814814815\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 3.2000000000000153\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.78\n",
      "    policy2: -6.501999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -2.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1643339806296132\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07238299957644875\n",
      "    mean_inference_ms: 1.746176786798136\n",
      "    mean_raw_obs_processing_ms: 0.32402766017624207\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 33.899999999999906\n",
      "    episode_reward_mean: 16.277999999999945\n",
      "    episode_reward_min: -12.000000000000012\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 10.800000000000024\n",
      "      - 33.899999999999906\n",
      "      - 22.199999999999914\n",
      "      - 20.099999999999902\n",
      "      - 20.399999999999977\n",
      "      - 24.89999999999994\n",
      "      - 2.906008766956347e-14\n",
      "      - 24.59999999999991\n",
      "      - 5.999999999999957\n",
      "      - 18.59999999999992\n",
      "      - 13.19999999999992\n",
      "      - 14.999999999999964\n",
      "      - 14.699999999999944\n",
      "      - 17.699999999999907\n",
      "      - 18.299999999999933\n",
      "      - 15.599999999999914\n",
      "      - 4.200000000000003\n",
      "      - 14.699999999999916\n",
      "      - 0.29999999999999427\n",
      "      - 17.099999999999923\n",
      "      - 11.399999999999942\n",
      "      - 14.400000000000018\n",
      "      - 8.699999999999962\n",
      "      - 25.799999999999926\n",
      "      - 22.19999999999994\n",
      "      - 16.199999999999925\n",
      "      - 8.999999999999986\n",
      "      - 15.599999999999918\n",
      "      - 12.600000000000009\n",
      "      - 12.900000000000023\n",
      "      - 28.199999999999918\n",
      "      - 19.1999999999999\n",
      "      - 1.5000000000000138\n",
      "      - 17.699999999999953\n",
      "      - 17.69999999999995\n",
      "      - 23.699999999999932\n",
      "      - 12.299999999999958\n",
      "      - 18.59999999999995\n",
      "      - 19.799999999999976\n",
      "      - 23.699999999999918\n",
      "      - 28.499999999999886\n",
      "      - 20.999999999999936\n",
      "      - 17.999999999999893\n",
      "      - 3.299999999999966\n",
      "      - 17.99999999999993\n",
      "      - 17.999999999999986\n",
      "      - 7.200000000000024\n",
      "      - 16.499999999999957\n",
      "      - 24.599999999999916\n",
      "      - 19.49999999999993\n",
      "      - -12.000000000000012\n",
      "      - 14.099999999999902\n",
      "      - 19.19999999999994\n",
      "      - 20.99999999999999\n",
      "      - 26.69999999999991\n",
      "      - 22.79999999999996\n",
      "      - 8.999999999999964\n",
      "      - 5.1\n",
      "      - 14.999999999999961\n",
      "      - 17.0999999999999\n",
      "      - 14.69999999999993\n",
      "      - 20.099999999999934\n",
      "      - 13.199999999999905\n",
      "      - 18.89999999999995\n",
      "      - 23.9999999999999\n",
      "      - 17.999999999999922\n",
      "      - 25.199999999999896\n",
      "      - 18.599999999999973\n",
      "      - 11.700000000000031\n",
      "      - 15.599999999999948\n",
      "      - 28.499999999999922\n",
      "      - 17.699999999999918\n",
      "      - 15.299999999999923\n",
      "      - 19.499999999999922\n",
      "      - 13.800000000000006\n",
      "      - 12.599999999999934\n",
      "      - 15.60000000000001\n",
      "      - 10.20000000000003\n",
      "      - 11.700000000000003\n",
      "      - 11.999999999999925\n",
      "      - 15.899999999999912\n",
      "      - 17.09999999999996\n",
      "      - 22.49999999999995\n",
      "      - 22.49999999999995\n",
      "      - 18.00000000000002\n",
      "      - 13.199999999999987\n",
      "      - 13.499999999999956\n",
      "      - 27.599999999999895\n",
      "      - 9.299999999999946\n",
      "      - 15.299999999999944\n",
      "      - 10.2\n",
      "      - 21.299999999999912\n",
      "      - 20.999999999999893\n",
      "      - 6.30000000000002\n",
      "      - 7.200000000000022\n",
      "      - 18.599999999999902\n",
      "      - 22.199999999999896\n",
      "      - 19.199999999999932\n",
      "      - 6.899999999999954\n",
      "      - 26.999999999999936\n",
      "      policy_policy1_reward:\n",
      "      - 17.5\n",
      "      - 39.5\n",
      "      - 30.0\n",
      "      - 29.0\n",
      "      - 26.0\n",
      "      - 30.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 1.5\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 14.5\n",
      "      - 11.0\n",
      "      - 32.5\n",
      "      - 30.0\n",
      "      - 18.5\n",
      "      - 19.0\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 18.5\n",
      "      - 36.0\n",
      "      - 27.0\n",
      "      - 11.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 26.5\n",
      "      - 31.5\n",
      "      - 38.5\n",
      "      - 31.0\n",
      "      - 28.0\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 29.5\n",
      "      - -2.0\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 31.0\n",
      "      - 34.5\n",
      "      - 29.5\n",
      "      - 19.0\n",
      "      - 14.0\n",
      "      - 25.0\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 27.5\n",
      "      - 19.5\n",
      "      - 24.5\n",
      "      - 38.5\n",
      "      - 20.0\n",
      "      - 16.5\n",
      "      - 24.0\n",
      "      - 20.5\n",
      "      - 16.0\n",
      "      - 24.5\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 22.0\n",
      "      - 21.5\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 27.0\n",
      "      - 22.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 36.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 18.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 13.0\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      policy_policy2_reward:\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -7.7999999999999865\n",
      "      - 1.0000000000000062\n",
      "      - -7.7999999999999865\n",
      "      - -7.7999999999999865\n",
      "      - -6.69999999999999\n",
      "      - -3.400000000000004\n",
      "      - -7.799999999999986\n",
      "      - -2.300000000000001\n",
      "      - -1.200000000000003\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999986\n",
      "      - -0.10000000000000331\n",
      "      - -2.3000000000000007\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -2.300000000000004\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000026\n",
      "      - -3.4000000000000012\n",
      "      - -5.5999999999999845\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999989\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - 0.9999999999999961\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000034\n",
      "      - -3.400000000000005\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -1.1999999999999946\n",
      "      - -4.499999999999982\n",
      "      - -6.699999999999994\n",
      "      - -3.400000000000005\n",
      "      - -8.899999999999984\n",
      "      - 3.2000000000000153\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -1.1999999999999953\n",
      "      - -4.49999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000002\n",
      "      - -7.799999999999989\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 3.2000000000000153\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.78\n",
      "      policy2: -6.501999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -2.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1643339806296132\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07238299957644875\n",
      "      mean_inference_ms: 1.746176786798136\n",
      "      mean_raw_obs_processing_ms: 0.32402766017624207\n",
      "  time_since_restore: 210.27718210220337\n",
      "  time_this_iter_s: 18.917362928390503\n",
      "  time_total_s: 210.27718210220337\n",
      "  timers:\n",
      "    learn_throughput: 407.067\n",
      "    learn_time_ms: 7369.802\n",
      "    synch_weights_time_ms: 5.215\n",
      "    training_iteration_time_ms: 15363.176\n",
      "  timestamp: 1658917262\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 15\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 90000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 90000\n",
      "    num_env_steps_sampled: 45000\n",
      "    num_env_steps_trained: 45000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 23.699999999999896\n",
      "  episode_reward_mean: 8.22599999999999\n",
      "  episode_reward_min: -16.499999999999986\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 450\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9072506427764893\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01710844598710537\n",
      "          model: {}\n",
      "          policy_loss: -0.051543232053518295\n",
      "          total_loss: 6.973539352416992\n",
      "          vf_explained_var: 0.12423116713762283\n",
      "          vf_loss: 7.017384052276611\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8592402935028076\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013886228203773499\n",
      "          model: {}\n",
      "          policy_loss: -0.038665883243083954\n",
      "          total_loss: 2.6644842624664307\n",
      "          vf_explained_var: 0.09828411787748337\n",
      "          vf_loss: 2.696901321411133\n",
      "    num_agent_steps_sampled: 90000\n",
      "    num_agent_steps_trained: 90000\n",
      "    num_env_steps_sampled: 45000\n",
      "    num_env_steps_trained: 45000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 90000\n",
      "  num_agent_steps_trained: 90000\n",
      "  num_env_steps_sampled: 45000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 45000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.33703703703704\n",
      "    ram_util_percent: 62.57407407407407\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 31.5\n",
      "    policy2: 22.99999999999996\n",
      "  policy_reward_mean:\n",
      "    policy1: 13.265\n",
      "    policy2: -5.038999999999991\n",
      "  policy_reward_min:\n",
      "    policy1: -14.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16882744548110065\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07212242557192598\n",
      "    mean_inference_ms: 1.7806406949206792\n",
      "    mean_raw_obs_processing_ms: 0.3318779192080364\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 23.699999999999896\n",
      "    episode_reward_mean: 8.22599999999999\n",
      "    episode_reward_min: -16.499999999999986\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.499999999999989\n",
      "      - 9.000000000000028\n",
      "      - 6.60000000000003\n",
      "      - -1.1999999999999869\n",
      "      - 17.700000000000024\n",
      "      - 13.499999999999972\n",
      "      - 10.499999999999936\n",
      "      - 5.700000000000008\n",
      "      - -5.9999999999999885\n",
      "      - -2.400000000000012\n",
      "      - -2.3999999999999804\n",
      "      - 17.699999999999932\n",
      "      - 11.699999999999925\n",
      "      - 16.799999999999958\n",
      "      - -0.3000000000000226\n",
      "      - 11.999999999999982\n",
      "      - 8.700000000000028\n",
      "      - 10.19999999999998\n",
      "      - 11.10000000000003\n",
      "      - 9.600000000000014\n",
      "      - 6.60000000000003\n",
      "      - 8.400000000000029\n",
      "      - 14.700000000000028\n",
      "      - 8.099999999999952\n",
      "      - -9.599999999999984\n",
      "      - 23.699999999999896\n",
      "      - 11.100000000000032\n",
      "      - 9.000000000000005\n",
      "      - 14.999999999999947\n",
      "      - 11.099999999999957\n",
      "      - 21.899999999999928\n",
      "      - 1.5000000000000262\n",
      "      - -2.999999999999992\n",
      "      - 6.600000000000005\n",
      "      - 10.800000000000004\n",
      "      - 3.6000000000000205\n",
      "      - 6.000000000000027\n",
      "      - 11.10000000000001\n",
      "      - 3.9000000000000017\n",
      "      - 5.100000000000016\n",
      "      - -7.499999999999975\n",
      "      - 8.70000000000003\n",
      "      - 14.399999999999961\n",
      "      - 8.999999999999984\n",
      "      - 4.200000000000031\n",
      "      - 8.699999999999944\n",
      "      - 5.10000000000003\n",
      "      - 11.09999999999999\n",
      "      - 9.000000000000021\n",
      "      - -5.999999999999982\n",
      "      - -1.7999999999999874\n",
      "      - 6.300000000000004\n",
      "      - -1.7999999999999838\n",
      "      - -0.8999999999999702\n",
      "      - 6.9000000000000306\n",
      "      - 19.799999999999933\n",
      "      - 11.70000000000001\n",
      "      - 21.299999999999933\n",
      "      - -2.399999999999971\n",
      "      - 17.4\n",
      "      - 4.50000000000003\n",
      "      - 3.300000000000021\n",
      "      - 6.9\n",
      "      - 11.699999999999989\n",
      "      - 5.700000000000022\n",
      "      - 19.19999999999994\n",
      "      - 7.500000000000016\n",
      "      - 13.799999999999972\n",
      "      - 18.599999999999966\n",
      "      - 13.799999999999924\n",
      "      - 9.299999999999946\n",
      "      - 9.000000000000021\n",
      "      - 14.699999999999969\n",
      "      - 15.299999999999901\n",
      "      - 8.69999999999994\n",
      "      - 11.99999999999997\n",
      "      - 3.300000000000029\n",
      "      - 4.199999999999958\n",
      "      - 15.59999999999991\n",
      "      - 19.79999999999995\n",
      "      - 10.499999999999961\n",
      "      - 17.69999999999998\n",
      "      - 0.3000000000000085\n",
      "      - 22.199999999999967\n",
      "      - 6.300000000000026\n",
      "      - 15.899999999999945\n",
      "      - 12.299999999999939\n",
      "      - 2.4000000000000132\n",
      "      - -16.499999999999986\n",
      "      - 7.500000000000007\n",
      "      - -3.5999999999999908\n",
      "      - 3.0000000000000284\n",
      "      - -9.59999999999999\n",
      "      - 20.699999999999974\n",
      "      - 15.900000000000007\n",
      "      - 6.000000000000018\n",
      "      - 4.199999999999944\n",
      "      - 13.499999999999973\n",
      "      - 22.79999999999989\n",
      "      - 2.400000000000024\n",
      "      policy_policy1_reward:\n",
      "      - 14.5\n",
      "      - 8.0\n",
      "      - 15.5\n",
      "      - 5.5\n",
      "      - 25.5\n",
      "      - 1.5\n",
      "      - 20.5\n",
      "      - 8.0\n",
      "      - 4.0\n",
      "      - 6.5\n",
      "      - 6.5\n",
      "      - 25.5\n",
      "      - 19.5\n",
      "      - 18.0\n",
      "      - 2.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 18.0\n",
      "      - 20.0\n",
      "      - 7.5\n",
      "      - 15.5\n",
      "      - 8.5\n",
      "      - 6.0\n",
      "      - 17.0\n",
      "      - -4.0\n",
      "      - 31.5\n",
      "      - 14.5\n",
      "      - 19.0\n",
      "      - 25.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 6.0\n",
      "      - 1.5\n",
      "      - 4.5\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 2.5\n",
      "      - 16.5\n",
      "      - 20.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 11.0\n",
      "      - 14.0\n",
      "      - 9.0\n",
      "      - 13.5\n",
      "      - -1.5\n",
      "      - 6.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 26.5\n",
      "      - 19.5\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 14.5\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      - 16.0\n",
      "      - -14.0\n",
      "      - 22.5\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 20.5\n",
      "      - 25.5\n",
      "      - 7.0\n",
      "      - 24.5\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 19.0\n",
      "      - 8.0\n",
      "      - -6.5\n",
      "      - 12.0\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - -4.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 23.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000064\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.799999999999981\n",
      "      - 12.000000000000007\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999987\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000048\n",
      "      - -2.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000047\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999986\n",
      "      - 2.1000000000000085\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000286\n",
      "      - 8.700000000000019\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 2.0999999999999956\n",
      "      - -5.599999999999999\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000003\n",
      "      - 2.100000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.4000000000000035\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -2.2999999999999887\n",
      "      - -8.899999999999983\n",
      "      - 2.1000000000000036\n",
      "      - -4.499999999999999\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000553\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999983\n",
      "      - 4.300000000000008\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000011\n",
      "      - -0.1000000000000015\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 14.20000000000001\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999985\n",
      "      - -3.3999999999999955\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999994\n",
      "      - 22.99999999999996\n",
      "      - -7.799999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999994\n",
      "      - -4.5000000000000036\n",
      "      - -6.699999999999993\n",
      "      - -7.799999999999981\n",
      "      - -3.3999999999999844\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -6.6999999999999895\n",
      "      - -2.299999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999999831\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999997\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 31.5\n",
      "      policy2: 22.99999999999996\n",
      "    policy_reward_mean:\n",
      "      policy1: 13.265\n",
      "      policy2: -5.038999999999991\n",
      "    policy_reward_min:\n",
      "      policy1: -14.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16882744548110065\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07212242557192598\n",
      "      mean_inference_ms: 1.7806406949206792\n",
      "      mean_raw_obs_processing_ms: 0.3318779192080364\n",
      "  time_since_restore: 211.8434612751007\n",
      "  time_this_iter_s: 18.531426906585693\n",
      "  time_total_s: 211.8434612751007\n",
      "  timers:\n",
      "    learn_throughput: 407.705\n",
      "    learn_time_ms: 7358.266\n",
      "    synch_weights_time_ms: 4.025\n",
      "    training_iteration_time_ms: 15480.732\n",
      "  timestamp: 1658917263\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 45000\n",
      "  training_iteration: 15\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 88000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_env_steps_sampled: 44000\n",
      "    num_env_steps_trained: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-13\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 24.599999999999916\n",
      "  episode_reward_mean: 7.136999999999995\n",
      "  episode_reward_min: -14.999999999999982\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 440\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.01151442527771\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017482062801718712\n",
      "          model: {}\n",
      "          policy_loss: -0.04562337324023247\n",
      "          total_loss: 6.778234004974365\n",
      "          vf_explained_var: 0.2396658957004547\n",
      "          vf_loss: 6.815989971160889\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 1.0166174173355103\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01781453937292099\n",
      "          model: {}\n",
      "          policy_loss: -0.04691119119524956\n",
      "          total_loss: 2.797971248626709\n",
      "          vf_explained_var: 0.18222960829734802\n",
      "          vf_loss: 2.8368661403656006\n",
      "    num_agent_steps_sampled: 88000\n",
      "    num_agent_steps_trained: 88000\n",
      "    num_env_steps_sampled: 44000\n",
      "    num_env_steps_trained: 44000\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 88000\n",
      "  num_agent_steps_trained: 88000\n",
      "  num_env_steps_sampled: 44000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 44000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.425\n",
      "    ram_util_percent: 59.96249999999999\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 34.0\n",
      "    policy2: 6.500000000000003\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.09\n",
      "    policy2: -6.952999999999987\n",
      "  policy_reward_min:\n",
      "    policy1: -9.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17025661161314004\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07290018868643915\n",
      "    mean_inference_ms: 1.8104318239748003\n",
      "    mean_raw_obs_processing_ms: 0.3354249006707575\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 24.599999999999916\n",
      "    episode_reward_mean: 7.136999999999995\n",
      "    episode_reward_min: -14.999999999999982\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 23.09999999999991\n",
      "      - 3.6000000000000125\n",
      "      - -6.299999999999999\n",
      "      - 6.600000000000023\n",
      "      - 24.599999999999916\n",
      "      - 17.70000000000001\n",
      "      - 1.2000000000000086\n",
      "      - 11.100000000000028\n",
      "      - -1.799999999999982\n",
      "      - 4.5000000000000115\n",
      "      - 4.2000000000000135\n",
      "      - 10.499999999999991\n",
      "      - 13.799999999999969\n",
      "      - 2.1000000000000254\n",
      "      - -13.79999999999998\n",
      "      - 5.100000000000026\n",
      "      - -0.2999999999999975\n",
      "      - -7.799999999999995\n",
      "      - 7.199999999999989\n",
      "      - 10.500000000000023\n",
      "      - 6.300000000000027\n",
      "      - 2.3842039453825237e-14\n",
      "      - -7.499999999999991\n",
      "      - 14.399999999999975\n",
      "      - 2.100000000000011\n",
      "      - 10.500000000000023\n",
      "      - 1.500000000000013\n",
      "      - 15.60000000000001\n",
      "      - 5.700000000000006\n",
      "      - 11.100000000000026\n",
      "      - 7.1999999999999655\n",
      "      - 22.79999999999992\n",
      "      - 3.000000000000012\n",
      "      - 11.699999999999994\n",
      "      - 1.5000000000000209\n",
      "      - 11.100000000000021\n",
      "      - -3.599999999999996\n",
      "      - 4.5000000000000195\n",
      "      - 4.800000000000026\n",
      "      - 7.500000000000021\n",
      "      - 22.799999999999905\n",
      "      - -1.7999999999999847\n",
      "      - 5.100000000000019\n",
      "      - 20.399999999999974\n",
      "      - 7.800000000000011\n",
      "      - 7.1999999999999496\n",
      "      - 20.099999999999973\n",
      "      - -0.2999999999999782\n",
      "      - 9.599999999999977\n",
      "      - 4.500000000000012\n",
      "      - -0.8999999999999759\n",
      "      - 14.099999999999975\n",
      "      - 3.600000000000026\n",
      "      - 2.858824288409778e-15\n",
      "      - 7.499999999999991\n",
      "      - -2.3999999999999764\n",
      "      - 9.600000000000003\n",
      "      - 20.69999999999994\n",
      "      - 8.699999999999982\n",
      "      - 13.19999999999999\n",
      "      - 14.099999999999994\n",
      "      - 8.69999999999993\n",
      "      - 16.199999999999996\n",
      "      - 15.300000000000004\n",
      "      - 5.699999999999985\n",
      "      - 15.299999999999962\n",
      "      - 5.699999999999978\n",
      "      - 5.100000000000027\n",
      "      - -1.4999999999999862\n",
      "      - 13.200000000000008\n",
      "      - 21.599999999999994\n",
      "      - 4.800000000000024\n",
      "      - 12.000000000000027\n",
      "      - 2.7000000000000273\n",
      "      - 4.499999999999968\n",
      "      - 21.899999999999952\n",
      "      - 16.499999999999993\n",
      "      - 16.499999999999893\n",
      "      - 6.900000000000029\n",
      "      - 3.600000000000015\n",
      "      - 23.99999999999989\n",
      "      - 3.300000000000022\n",
      "      - 4.199999999999976\n",
      "      - -14.999999999999982\n",
      "      - 4.200000000000024\n",
      "      - 14.099999999999948\n",
      "      - 12.599999999999921\n",
      "      - 2.700000000000014\n",
      "      - -3.899999999999985\n",
      "      - 16.799999999999955\n",
      "      - 11.999999999999961\n",
      "      - 9.900000000000022\n",
      "      - -13.500000000000005\n",
      "      - 1.499999999999996\n",
      "      - -5.399999999999986\n",
      "      - 13.19999999999994\n",
      "      - -4.19999999999999\n",
      "      - 6.899999999999954\n",
      "      - 8.999999999999963\n",
      "      - -2.9999999999999725\n",
      "      policy_policy1_reward:\n",
      "      - 32.0\n",
      "      - 12.5\n",
      "      - 1.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 25.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 6.0\n",
      "      - 14.5\n",
      "      - 12.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 11.0\n",
      "      - -6.0\n",
      "      - 14.0\n",
      "      - 7.5\n",
      "      - 0.0\n",
      "      - 15.0\n",
      "      - 20.5\n",
      "      - 13.0\n",
      "      - 10.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 11.0\n",
      "      - 20.5\n",
      "      - 11.5\n",
      "      - 24.5\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 15.0\n",
      "      - 24.0\n",
      "      - 7.5\n",
      "      - 19.5\n",
      "      - 11.5\n",
      "      - 20.0\n",
      "      - -9.0\n",
      "      - 14.5\n",
      "      - 6.0\n",
      "      - 1.0\n",
      "      - 29.5\n",
      "      - 6.0\n",
      "      - 14.0\n",
      "      - 26.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 29.0\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 16.5\n",
      "      - 21.0\n",
      "      - 23.0\n",
      "      - 16.5\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 13.5\n",
      "      - 11.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 8.5\n",
      "      - 21.0\n",
      "      - 30.5\n",
      "      - 11.5\n",
      "      - 22.0\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 27.5\n",
      "      - 21.0\n",
      "      - 26.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 34.0\n",
      "      - 4.5\n",
      "      - 12.0\n",
      "      - -5.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 5.0\n",
      "      - 5.0\n",
      "      - 23.5\n",
      "      - 22.0\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - 11.5\n",
      "      - 3.5\n",
      "      - 15.5\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999985\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -4.5\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -7.79999999999999\n",
      "      - -8.899999999999984\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999986\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - 3.200000000000011\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -1.1999999999999913\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - 5.399999999999996\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000042\n",
      "      - 6.500000000000003\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.69999999999999\n",
      "      - -2.3000000000000047\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -3.399999999999983\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - 2.100000000000001\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -6.699999999999985\n",
      "      - -7.799999999999986\n",
      "      - 4.300000000000001\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000001\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -3.399999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000026\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999923\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.2999999999999927\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.300000000000004\n",
      "      - -6.6999999999999815\n",
      "      - -5.59999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 34.0\n",
      "      policy2: 6.500000000000003\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.09\n",
      "      policy2: -6.952999999999987\n",
      "    policy_reward_min:\n",
      "      policy1: -9.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17025661161314004\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07290018868643915\n",
      "      mean_inference_ms: 1.8104318239748003\n",
      "      mean_raw_obs_processing_ms: 0.3354249006707575\n",
      "  time_since_restore: 213.84676361083984\n",
      "  time_this_iter_s: 22.234267950057983\n",
      "  time_total_s: 213.84676361083984\n",
      "  timers:\n",
      "    learn_throughput: 411.373\n",
      "    learn_time_ms: 9723.546\n",
      "    synch_weights_time_ms: 3.915\n",
      "    training_iteration_time_ms: 19878.536\n",
      "  timestamp: 1658917273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 11\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 96000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-13\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.099999999999916\n",
      "  episode_reward_mean: 12.809999999999969\n",
      "  episode_reward_min: -7.19999999999998\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 480\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9776099324226379\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.024204928427934647\n",
      "          model: {}\n",
      "          policy_loss: -0.04806619510054588\n",
      "          total_loss: 7.264639377593994\n",
      "          vf_explained_var: 0.2293543815612793\n",
      "          vf_loss: 7.307864665985107\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9823102951049805\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011406797915697098\n",
      "          model: {}\n",
      "          policy_loss: -0.028226150199770927\n",
      "          total_loss: 4.3230814933776855\n",
      "          vf_explained_var: 0.07253017276525497\n",
      "          vf_loss: 4.349026203155518\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 48000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.184375\n",
      "    ram_util_percent: 59.959374999999994\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 41.0\n",
      "    policy2: 51.59999999999997\n",
      "  policy_reward_mean:\n",
      "    policy1: 15.66\n",
      "    policy2: -2.8499999999999925\n",
      "  policy_reward_min:\n",
      "    policy1: -39.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.16660980323616006\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07178802347902175\n",
      "    mean_inference_ms: 1.7498326497975347\n",
      "    mean_raw_obs_processing_ms: 0.3257381010743689\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.099999999999916\n",
      "    episode_reward_mean: 12.809999999999969\n",
      "    episode_reward_min: -7.19999999999998\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 13.800000000000027\n",
      "      - 32.09999999999989\n",
      "      - 6.600000000000026\n",
      "      - -0.30000000000001015\n",
      "      - 5.099999999999971\n",
      "      - 15.9\n",
      "      - 1.200000000000017\n",
      "      - 12.899999999999995\n",
      "      - 13.499999999999917\n",
      "      - 15.900000000000015\n",
      "      - 13.499999999999975\n",
      "      - 30.599999999999937\n",
      "      - 6.00000000000003\n",
      "      - -2.067790383364354e-14\n",
      "      - 7.499999999999931\n",
      "      - 0.8999999999999956\n",
      "      - 15.300000000000008\n",
      "      - 8.700000000000026\n",
      "      - 9.29999999999994\n",
      "      - 15.599999999999925\n",
      "      - -2.100000000000012\n",
      "      - 18.599999999999902\n",
      "      - 12.600000000000028\n",
      "      - 11.10000000000003\n",
      "      - 9.899999999999942\n",
      "      - 15.900000000000004\n",
      "      - 20.69999999999994\n",
      "      - 24.599999999999902\n",
      "      - 8.69999999999999\n",
      "      - 9.0\n",
      "      - 14.999999999999927\n",
      "      - 13.199999999999946\n",
      "      - 8.100000000000007\n",
      "      - 19.499999999999922\n",
      "      - 12.599999999999934\n",
      "      - -5.699999999999987\n",
      "      - -7.19999999999998\n",
      "      - 10.199999999999942\n",
      "      - 1.5000000000000138\n",
      "      - 9.300000000000031\n",
      "      - 15.00000000000003\n",
      "      - 8.999999999999979\n",
      "      - 11.699999999999948\n",
      "      - 25.499999999999922\n",
      "      - 8.700000000000014\n",
      "      - 9.000000000000028\n",
      "      - 4.800000000000024\n",
      "      - 17.099999999999923\n",
      "      - 10.800000000000013\n",
      "      - 29.099999999999895\n",
      "      - -0.29999999999997795\n",
      "      - 12.299999999999983\n",
      "      - 11.399999999999949\n",
      "      - 25.79999999999992\n",
      "      - 16.79999999999996\n",
      "      - 11.39999999999997\n",
      "      - 9.899999999999972\n",
      "      - 14.699999999999937\n",
      "      - 8.99999999999999\n",
      "      - 15.000000000000004\n",
      "      - 24.89999999999992\n",
      "      - 11.700000000000005\n",
      "      - 16.799999999999898\n",
      "      - -1.199999999999969\n",
      "      - 18.899999999999906\n",
      "      - 11.999999999999913\n",
      "      - 9.600000000000021\n",
      "      - 3.899999999999943\n",
      "      - 20.699999999999918\n",
      "      - 17.099999999999977\n",
      "      - -0.9000000000000181\n",
      "      - 16.799999999999926\n",
      "      - 9.599999999999955\n",
      "      - 4.499999999999989\n",
      "      - 25.799999999999947\n",
      "      - 18.29999999999991\n",
      "      - 10.799999999999992\n",
      "      - 16.499999999999996\n",
      "      - 8.400000000000027\n",
      "      - 16.199999999999953\n",
      "      - 13.19999999999996\n",
      "      - 20.69999999999994\n",
      "      - 32.099999999999916\n",
      "      - 10.799999999999935\n",
      "      - 23.399999999999906\n",
      "      - 6.899999999999963\n",
      "      - 10.200000000000024\n",
      "      - 20.09999999999998\n",
      "      - 22.1999999999999\n",
      "      - 10.200000000000026\n",
      "      - 8.999999999999986\n",
      "      - 9.900000000000022\n",
      "      - 1.5000000000000187\n",
      "      - 26.999999999999922\n",
      "      - 23.099999999999902\n",
      "      - 14.399999999999912\n",
      "      - 25.199999999999907\n",
      "      - 1.8000000000000114\n",
      "      - 29.9999999999999\n",
      "      - 12.600000000000014\n",
      "      policy_policy1_reward:\n",
      "      - 20.5\n",
      "      - 41.0\n",
      "      - 15.5\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - 16.0\n",
      "      - 9.0\n",
      "      - 13.0\n",
      "      - 23.5\n",
      "      - 16.0\n",
      "      - 18.0\n",
      "      - 28.5\n",
      "      - 5.0\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 16.5\n",
      "      - 16.0\n",
      "      - 13.5\n",
      "      - 3.5\n",
      "      - 27.5\n",
      "      - 16.0\n",
      "      - 20.0\n",
      "      - 15.5\n",
      "      - -0.5\n",
      "      - 28.5\n",
      "      - 22.5\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 19.5\n",
      "      - 21.0\n",
      "      - 11.5\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - -4.5\n",
      "      - -0.5\n",
      "      - 18.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 19.5\n",
      "      - 30.0\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 38.0\n",
      "      - 7.5\n",
      "      - 13.5\n",
      "      - 11.5\n",
      "      - 27.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 15.5\n",
      "      - 17.0\n",
      "      - 8.0\n",
      "      - 25.0\n",
      "      - 19.5\n",
      "      - 19.5\n",
      "      - 23.5\n",
      "      - 5.5\n",
      "      - 19.0\n",
      "      - 16.5\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - 23.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 13.0\n",
      "      - -7.5\n",
      "      - 27.0\n",
      "      - 14.0\n",
      "      - 17.5\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 18.5\n",
      "      - 21.0\n",
      "      - 28.5\n",
      "      - 30.0\n",
      "      - 12.0\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - -4.0\n",
      "      - 29.0\n",
      "      - 24.5\n",
      "      - 12.5\n",
      "      - 13.5\n",
      "      - 15.5\n",
      "      - 11.5\n",
      "      - 31.5\n",
      "      - 32.0\n",
      "      - 20.0\n",
      "      - 33.0\n",
      "      - 3.0\n",
      "      - 29.0\n",
      "      - -39.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999983\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000375\n",
      "      - -7.7999999999999865\n",
      "      - -0.09999999999999454\n",
      "      - -9.99999999999998\n",
      "      - -0.09999999999998965\n",
      "      - -4.500000000000002\n",
      "      - 2.1000000000000054\n",
      "      - 0.9999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999998\n",
      "      - -0.10000000000000409\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999982\n",
      "      - -8.899999999999986\n",
      "      - -3.3999999999999893\n",
      "      - -8.89999999999998\n",
      "      - -5.5999999999999845\n",
      "      - 16.39999999999999\n",
      "      - -7.79999999999999\n",
      "      - 2.0999999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -4.499999999999995\n",
      "      - -4.4999999999999964\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000004\n",
      "      - 6.500000000000012\n",
      "      - -3.3999999999999986\n",
      "      - -1.199999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.7999999999999865\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999982\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.7999999999999865\n",
      "      - -4.5000000000000036\n",
      "      - -1.2000000000000033\n",
      "      - -3.400000000000004\n",
      "      - 4.300000000000009\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000008\n",
      "      - -0.09999999999999987\n",
      "      - -1.2000000000000026\n",
      "      - -1.1999999999999946\n",
      "      - -5.599999999999997\n",
      "      - -5.599999999999988\n",
      "      - -2.300000000000004\n",
      "      - 0.9999999999999992\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000014\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -0.1000000000000012\n",
      "      - -4.499999999999999\n",
      "      - 2.1000000000000094\n",
      "      - -0.09999999999999853\n",
      "      - -2.299999999999988\n",
      "      - 13.09999999999999\n",
      "      - -8.899999999999986\n",
      "      - 9.800000000000002\n",
      "      - -3.399999999999989\n",
      "      - 11.999999999999998\n",
      "      - -1.2000000000000022\n",
      "      - 4.299999999999999\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -2.299999999999992\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999997\n",
      "      - -1.2000000000000017\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999982\n",
      "      - 14.199999999999996\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -2.300000000000003\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.4999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999988\n",
      "      - -1.2000000000000046\n",
      "      - 0.9999999999999948\n",
      "      - 51.59999999999997\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 41.0\n",
      "      policy2: 51.59999999999997\n",
      "    policy_reward_mean:\n",
      "      policy1: 15.66\n",
      "      policy2: -2.8499999999999925\n",
      "    policy_reward_min:\n",
      "      policy1: -39.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.16660980323616006\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07178802347902175\n",
      "      mean_inference_ms: 1.7498326497975347\n",
      "      mean_raw_obs_processing_ms: 0.3257381010743689\n",
      "  time_since_restore: 224.3916232585907\n",
      "  time_this_iter_s: 22.28533697128296\n",
      "  time_total_s: 224.3916232585907\n",
      "  timers:\n",
      "    learn_throughput: 412.279\n",
      "    learn_time_ms: 9702.162\n",
      "    synch_weights_time_ms: 3.948\n",
      "    training_iteration_time_ms: 19932.17\n",
      "  timestamp: 1658917273\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 96000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-22\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 30.89999999999995\n",
      "  episode_reward_mean: 16.733999999999945\n",
      "  episode_reward_min: -12.000000000000012\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 480\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8608449101448059\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01436468493193388\n",
      "          model: {}\n",
      "          policy_loss: -0.04181068390607834\n",
      "          total_loss: 7.118545055389404\n",
      "          vf_explained_var: 0.1673678457736969\n",
      "          vf_loss: 7.157482147216797\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7743738889694214\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01639396883547306\n",
      "          model: {}\n",
      "          policy_loss: -0.041871290653944016\n",
      "          total_loss: 3.633251905441284\n",
      "          vf_explained_var: 0.04642912372946739\n",
      "          vf_loss: 3.6734838485717773\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 48000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 56.743333333333325\n",
      "    ram_util_percent: 59.81333333333332\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 38.5\n",
      "    policy2: 13.100000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.95\n",
      "    policy2: -6.215999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -2.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1685458297877319\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07410106298878491\n",
      "    mean_inference_ms: 1.7885881629667781\n",
      "    mean_raw_obs_processing_ms: 0.33180838811645813\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 30.89999999999995\n",
      "    episode_reward_mean: 16.733999999999945\n",
      "    episode_reward_min: -12.000000000000012\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 28.199999999999918\n",
      "      - 19.1999999999999\n",
      "      - 1.5000000000000138\n",
      "      - 17.699999999999953\n",
      "      - 17.69999999999995\n",
      "      - 23.699999999999932\n",
      "      - 12.299999999999958\n",
      "      - 18.59999999999995\n",
      "      - 19.799999999999976\n",
      "      - 23.699999999999918\n",
      "      - 28.499999999999886\n",
      "      - 20.999999999999936\n",
      "      - 17.999999999999893\n",
      "      - 3.299999999999966\n",
      "      - 17.99999999999993\n",
      "      - 17.999999999999986\n",
      "      - 7.200000000000024\n",
      "      - 16.499999999999957\n",
      "      - 24.599999999999916\n",
      "      - 19.49999999999993\n",
      "      - -12.000000000000012\n",
      "      - 14.099999999999902\n",
      "      - 19.19999999999994\n",
      "      - 20.99999999999999\n",
      "      - 26.69999999999991\n",
      "      - 22.79999999999996\n",
      "      - 8.999999999999964\n",
      "      - 5.1\n",
      "      - 14.999999999999961\n",
      "      - 17.0999999999999\n",
      "      - 14.69999999999993\n",
      "      - 20.099999999999934\n",
      "      - 13.199999999999905\n",
      "      - 18.89999999999995\n",
      "      - 23.9999999999999\n",
      "      - 17.999999999999922\n",
      "      - 25.199999999999896\n",
      "      - 18.599999999999973\n",
      "      - 11.700000000000031\n",
      "      - 15.599999999999948\n",
      "      - 28.499999999999922\n",
      "      - 17.699999999999918\n",
      "      - 15.299999999999923\n",
      "      - 19.499999999999922\n",
      "      - 13.800000000000006\n",
      "      - 12.599999999999934\n",
      "      - 15.60000000000001\n",
      "      - 10.20000000000003\n",
      "      - 11.700000000000003\n",
      "      - 11.999999999999925\n",
      "      - 15.899999999999912\n",
      "      - 17.09999999999996\n",
      "      - 22.49999999999995\n",
      "      - 22.49999999999995\n",
      "      - 18.00000000000002\n",
      "      - 13.199999999999987\n",
      "      - 13.499999999999956\n",
      "      - 27.599999999999895\n",
      "      - 9.299999999999946\n",
      "      - 15.299999999999944\n",
      "      - 10.2\n",
      "      - 21.299999999999912\n",
      "      - 20.999999999999893\n",
      "      - 6.30000000000002\n",
      "      - 7.200000000000022\n",
      "      - 18.599999999999902\n",
      "      - 22.199999999999896\n",
      "      - 19.199999999999932\n",
      "      - 6.899999999999954\n",
      "      - 26.999999999999936\n",
      "      - 16.49999999999992\n",
      "      - 19.499999999999982\n",
      "      - 1.8000000000000127\n",
      "      - 30.89999999999995\n",
      "      - 9.599999999999968\n",
      "      - 7.799999999999953\n",
      "      - 18.599999999999895\n",
      "      - 14.100000000000005\n",
      "      - 9.299999999999986\n",
      "      - 19.199999999999918\n",
      "      - 23.699999999999896\n",
      "      - 13.200000000000003\n",
      "      - 17.999999999999908\n",
      "      - 15.899999999999936\n",
      "      - 20.099999999999923\n",
      "      - 20.099999999999945\n",
      "      - 23.09999999999994\n",
      "      - 16.799999999999905\n",
      "      - 25.499999999999908\n",
      "      - 10.799999999999988\n",
      "      - 24.599999999999913\n",
      "      - 8.100000000000025\n",
      "      - 13.799999999999992\n",
      "      - 18.599999999999902\n",
      "      - 16.799999999999976\n",
      "      - 26.3999999999999\n",
      "      - 2.100000000000011\n",
      "      - 12.899999999999935\n",
      "      - 19.49999999999992\n",
      "      - 29.399999999999906\n",
      "      policy_policy1_reward:\n",
      "      - 36.0\n",
      "      - 27.0\n",
      "      - 11.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 26.5\n",
      "      - 31.5\n",
      "      - 38.5\n",
      "      - 31.0\n",
      "      - 28.0\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 29.5\n",
      "      - -2.0\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 31.0\n",
      "      - 34.5\n",
      "      - 29.5\n",
      "      - 19.0\n",
      "      - 14.0\n",
      "      - 25.0\n",
      "      - 26.0\n",
      "      - 17.0\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 27.5\n",
      "      - 19.5\n",
      "      - 24.5\n",
      "      - 38.5\n",
      "      - 20.0\n",
      "      - 16.5\n",
      "      - 24.0\n",
      "      - 20.5\n",
      "      - 16.0\n",
      "      - 24.5\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 22.0\n",
      "      - 21.5\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 27.0\n",
      "      - 22.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 36.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 18.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 13.0\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      - 26.5\n",
      "      - 29.5\n",
      "      - 8.5\n",
      "      - 36.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 17.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 31.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 21.5\n",
      "      - 7.0\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 23.5\n",
      "      - 35.5\n",
      "      - 12.0\n",
      "      - 33.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 23.5\n",
      "      - 32.0\n",
      "      - 0.0\n",
      "      - 18.5\n",
      "      - 24.0\n",
      "      - 35.0\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -7.79999999999999\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999989\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - 0.9999999999999961\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000034\n",
      "      - -3.400000000000005\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -1.1999999999999946\n",
      "      - -4.499999999999982\n",
      "      - -6.699999999999994\n",
      "      - -3.400000000000005\n",
      "      - -8.899999999999984\n",
      "      - 3.2000000000000153\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -1.1999999999999953\n",
      "      - -4.49999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000002\n",
      "      - -7.799999999999989\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999985\n",
      "      - -5.599999999999984\n",
      "      - -3.399999999999995\n",
      "      - -1.2000000000000028\n",
      "      - -8.89999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -6.6999999999999895\n",
      "      - 3.2\n",
      "      - -7.799999999999989\n",
      "      - 3.2000000000000064\n",
      "      - -4.499999999999984\n",
      "      - -5.599999999999995\n",
      "      - 13.100000000000005\n",
      "      - 2.1\n",
      "      - -3.4000000000000044\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -1.199999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.5\n",
      "      policy2: 13.100000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.95\n",
      "      policy2: -6.215999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -2.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1685458297877319\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07410106298878491\n",
      "      mean_inference_ms: 1.7885881629667781\n",
      "      mean_raw_obs_processing_ms: 0.33180838811645813\n",
      "  time_since_restore: 230.6143980026245\n",
      "  time_this_iter_s: 20.337215900421143\n",
      "  time_total_s: 230.6143980026245\n",
      "  timers:\n",
      "    learn_throughput: 394.249\n",
      "    learn_time_ms: 7609.414\n",
      "    synch_weights_time_ms: 8.597\n",
      "    training_iteration_time_ms: 16119.407\n",
      "  timestamp: 1658917282\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 16\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 96000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-23\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 26.999999999999922\n",
      "  episode_reward_mean: 9.254999999999985\n",
      "  episode_reward_min: -16.499999999999986\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 480\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8977789878845215\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01803889311850071\n",
      "          model: {}\n",
      "          policy_loss: -0.05165165290236473\n",
      "          total_loss: 6.63762092590332\n",
      "          vf_explained_var: 0.20885007083415985\n",
      "          vf_loss: 6.681155204772949\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8402391076087952\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018205691128969193\n",
      "          model: {}\n",
      "          policy_loss: -0.054078832268714905\n",
      "          total_loss: 3.584033966064453\n",
      "          vf_explained_var: 0.07023043185472488\n",
      "          vf_loss: 3.629920482635498\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 48000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 62.162068965517236\n",
      "    ram_util_percent: 60.18275862068964\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 37.0\n",
      "    policy2: 22.99999999999996\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.36\n",
      "    policy2: -5.104999999999991\n",
      "  policy_reward_min:\n",
      "    policy1: -14.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1727470944237951\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07372354167864587\n",
      "    mean_inference_ms: 1.821402250001642\n",
      "    mean_raw_obs_processing_ms: 0.3400404648165052\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 26.999999999999922\n",
      "    episode_reward_mean: 9.254999999999985\n",
      "    episode_reward_min: -16.499999999999986\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 21.899999999999928\n",
      "      - 1.5000000000000262\n",
      "      - -2.999999999999992\n",
      "      - 6.600000000000005\n",
      "      - 10.800000000000004\n",
      "      - 3.6000000000000205\n",
      "      - 6.000000000000027\n",
      "      - 11.10000000000001\n",
      "      - 3.9000000000000017\n",
      "      - 5.100000000000016\n",
      "      - -7.499999999999975\n",
      "      - 8.70000000000003\n",
      "      - 14.399999999999961\n",
      "      - 8.999999999999984\n",
      "      - 4.200000000000031\n",
      "      - 8.699999999999944\n",
      "      - 5.10000000000003\n",
      "      - 11.09999999999999\n",
      "      - 9.000000000000021\n",
      "      - -5.999999999999982\n",
      "      - -1.7999999999999874\n",
      "      - 6.300000000000004\n",
      "      - -1.7999999999999838\n",
      "      - -0.8999999999999702\n",
      "      - 6.9000000000000306\n",
      "      - 19.799999999999933\n",
      "      - 11.70000000000001\n",
      "      - 21.299999999999933\n",
      "      - -2.399999999999971\n",
      "      - 17.4\n",
      "      - 4.50000000000003\n",
      "      - 3.300000000000021\n",
      "      - 6.9\n",
      "      - 11.699999999999989\n",
      "      - 5.700000000000022\n",
      "      - 19.19999999999994\n",
      "      - 7.500000000000016\n",
      "      - 13.799999999999972\n",
      "      - 18.599999999999966\n",
      "      - 13.799999999999924\n",
      "      - 9.299999999999946\n",
      "      - 9.000000000000021\n",
      "      - 14.699999999999969\n",
      "      - 15.299999999999901\n",
      "      - 8.69999999999994\n",
      "      - 11.99999999999997\n",
      "      - 3.300000000000029\n",
      "      - 4.199999999999958\n",
      "      - 15.59999999999991\n",
      "      - 19.79999999999995\n",
      "      - 10.499999999999961\n",
      "      - 17.69999999999998\n",
      "      - 0.3000000000000085\n",
      "      - 22.199999999999967\n",
      "      - 6.300000000000026\n",
      "      - 15.899999999999945\n",
      "      - 12.299999999999939\n",
      "      - 2.4000000000000132\n",
      "      - -16.499999999999986\n",
      "      - 7.500000000000007\n",
      "      - -3.5999999999999908\n",
      "      - 3.0000000000000284\n",
      "      - -9.59999999999999\n",
      "      - 20.699999999999974\n",
      "      - 15.900000000000007\n",
      "      - 6.000000000000018\n",
      "      - 4.199999999999944\n",
      "      - 13.499999999999973\n",
      "      - 22.79999999999989\n",
      "      - 2.400000000000024\n",
      "      - 26.699999999999903\n",
      "      - 6.600000000000028\n",
      "      - 16.499999999999986\n",
      "      - 10.200000000000033\n",
      "      - 3.0000000000000187\n",
      "      - 5.100000000000001\n",
      "      - 10.499999999999991\n",
      "      - 14.699999999999934\n",
      "      - 2.0999999999999863\n",
      "      - 26.999999999999922\n",
      "      - 14.099999999999968\n",
      "      - 7.2000000000000135\n",
      "      - 0.6000000000000233\n",
      "      - 9.599999999999959\n",
      "      - 5.10000000000003\n",
      "      - 7.500000000000021\n",
      "      - 24.599999999999902\n",
      "      - 7.1999999999999815\n",
      "      - 26.099999999999913\n",
      "      - 12.000000000000005\n",
      "      - 12.599999999999905\n",
      "      - 10.199999999999998\n",
      "      - 5.099999999999998\n",
      "      - 19.49999999999998\n",
      "      - -5.699999999999982\n",
      "      - 16.199999999999935\n",
      "      - 5.400000000000016\n",
      "      - 17.399999999999935\n",
      "      - 21.29999999999997\n",
      "      - 15.59999999999994\n",
      "      policy_policy1_reward:\n",
      "      - 27.5\n",
      "      - 6.0\n",
      "      - 1.5\n",
      "      - 4.5\n",
      "      - 17.5\n",
      "      - 12.5\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 14.0\n",
      "      - 2.5\n",
      "      - 16.5\n",
      "      - 20.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 11.0\n",
      "      - 14.0\n",
      "      - 9.0\n",
      "      - 13.5\n",
      "      - -1.5\n",
      "      - 6.0\n",
      "      - 13.0\n",
      "      - 6.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 26.5\n",
      "      - 19.5\n",
      "      - 17.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 14.5\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      - 16.0\n",
      "      - -14.0\n",
      "      - 22.5\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 20.5\n",
      "      - 25.5\n",
      "      - 7.0\n",
      "      - 24.5\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 19.0\n",
      "      - 8.0\n",
      "      - -6.5\n",
      "      - 12.0\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - -4.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 23.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      - 34.5\n",
      "      - 15.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - -1.5\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 37.0\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 9.5\n",
      "      - 18.5\n",
      "      - 8.5\n",
      "      - 6.5\n",
      "      - 33.5\n",
      "      - 15.0\n",
      "      - 29.5\n",
      "      - 16.5\n",
      "      - 21.5\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 29.5\n",
      "      - 1.0\n",
      "      - 24.0\n",
      "      - 11.0\n",
      "      - 12.0\n",
      "      - 22.5\n",
      "      - 13.5\n",
      "      policy_policy2_reward:\n",
      "      - -5.599999999999999\n",
      "      - -4.500000000000003\n",
      "      - -4.500000000000003\n",
      "      - 2.100000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -3.4000000000000035\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -2.2999999999999887\n",
      "      - -8.899999999999983\n",
      "      - 2.1000000000000036\n",
      "      - -4.499999999999999\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999992\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000553\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999983\n",
      "      - 4.300000000000008\n",
      "      - -8.89999999999998\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000011\n",
      "      - -0.1000000000000015\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 14.20000000000001\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999985\n",
      "      - -3.3999999999999955\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999994\n",
      "      - 22.99999999999996\n",
      "      - -7.799999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999994\n",
      "      - -4.5000000000000036\n",
      "      - -6.699999999999993\n",
      "      - -7.799999999999981\n",
      "      - -3.3999999999999844\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -6.6999999999999895\n",
      "      - -2.299999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999999831\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999997\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999983\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - 11.999999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000001\n",
      "      - 0.9999999999999954\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -3.3999999999999857\n",
      "      - -4.500000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999987\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - 5.4\n",
      "      - -1.2000000000000053\n",
      "      - 2.1000000000000014\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 37.0\n",
      "      policy2: 22.99999999999996\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.36\n",
      "      policy2: -5.104999999999991\n",
      "    policy_reward_min:\n",
      "      policy1: -14.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1727470944237951\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07372354167864587\n",
      "      mean_inference_ms: 1.821402250001642\n",
      "      mean_raw_obs_processing_ms: 0.3400404648165052\n",
      "  time_since_restore: 232.2071042060852\n",
      "  time_this_iter_s: 20.363642930984497\n",
      "  time_total_s: 232.2071042060852\n",
      "  timers:\n",
      "    learn_throughput: 395.596\n",
      "    learn_time_ms: 7583.501\n",
      "    synch_weights_time_ms: 4.872\n",
      "    training_iteration_time_ms: 16222.439\n",
      "  timestamp: 1658917283\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 16\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 96000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-39\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 27.59999999999991\n",
      "  episode_reward_mean: 8.081999999999987\n",
      "  episode_reward_min: -14.999999999999982\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 480\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9861927032470703\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01796719990670681\n",
      "          model: {}\n",
      "          policy_loss: -0.04694729670882225\n",
      "          total_loss: 6.709425926208496\n",
      "          vf_explained_var: 0.12637372314929962\n",
      "          vf_loss: 6.748288154602051\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9731193780899048\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019033467397093773\n",
      "          model: {}\n",
      "          policy_loss: -0.05006161704659462\n",
      "          total_loss: 2.463352918624878\n",
      "          vf_explained_var: 0.15300334990024567\n",
      "          vf_loss: 2.504849672317505\n",
      "    num_agent_steps_sampled: 96000\n",
      "    num_agent_steps_trained: 96000\n",
      "    num_env_steps_sampled: 48000\n",
      "    num_env_steps_trained: 48000\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 96000\n",
      "  num_agent_steps_trained: 96000\n",
      "  num_env_steps_sampled: 48000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 48000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 60.73947368421052\n",
      "    ram_util_percent: 62.81052631578949\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 36.5\n",
      "    policy2: 4.300000000000001\n",
      "  policy_reward_mean:\n",
      "    policy1: 14.705\n",
      "    policy2: -6.622999999999988\n",
      "  policy_reward_min:\n",
      "    policy1: -7.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17594490737236052\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07528088575297408\n",
      "    mean_inference_ms: 1.8714931276531923\n",
      "    mean_raw_obs_processing_ms: 0.346575455482428\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 27.59999999999991\n",
      "    episode_reward_mean: 8.081999999999987\n",
      "    episode_reward_min: -14.999999999999982\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 22.799999999999905\n",
      "      - -1.7999999999999847\n",
      "      - 5.100000000000019\n",
      "      - 20.399999999999974\n",
      "      - 7.800000000000011\n",
      "      - 7.1999999999999496\n",
      "      - 20.099999999999973\n",
      "      - -0.2999999999999782\n",
      "      - 9.599999999999977\n",
      "      - 4.500000000000012\n",
      "      - -0.8999999999999759\n",
      "      - 14.099999999999975\n",
      "      - 3.600000000000026\n",
      "      - 2.858824288409778e-15\n",
      "      - 7.499999999999991\n",
      "      - -2.3999999999999764\n",
      "      - 9.600000000000003\n",
      "      - 20.69999999999994\n",
      "      - 8.699999999999982\n",
      "      - 13.19999999999999\n",
      "      - 14.099999999999994\n",
      "      - 8.69999999999993\n",
      "      - 16.199999999999996\n",
      "      - 15.300000000000004\n",
      "      - 5.699999999999985\n",
      "      - 15.299999999999962\n",
      "      - 5.699999999999978\n",
      "      - 5.100000000000027\n",
      "      - -1.4999999999999862\n",
      "      - 13.200000000000008\n",
      "      - 21.599999999999994\n",
      "      - 4.800000000000024\n",
      "      - 12.000000000000027\n",
      "      - 2.7000000000000273\n",
      "      - 4.499999999999968\n",
      "      - 21.899999999999952\n",
      "      - 16.499999999999993\n",
      "      - 16.499999999999893\n",
      "      - 6.900000000000029\n",
      "      - 3.600000000000015\n",
      "      - 23.99999999999989\n",
      "      - 3.300000000000022\n",
      "      - 4.199999999999976\n",
      "      - -14.999999999999982\n",
      "      - 4.200000000000024\n",
      "      - 14.099999999999948\n",
      "      - 12.599999999999921\n",
      "      - 2.700000000000014\n",
      "      - -3.899999999999985\n",
      "      - 16.799999999999955\n",
      "      - 11.999999999999961\n",
      "      - 9.900000000000022\n",
      "      - -13.500000000000005\n",
      "      - 1.499999999999996\n",
      "      - -5.399999999999986\n",
      "      - 13.19999999999994\n",
      "      - -4.19999999999999\n",
      "      - 6.899999999999954\n",
      "      - 8.999999999999963\n",
      "      - -2.9999999999999725\n",
      "      - 19.499999999999915\n",
      "      - -5.399999999999977\n",
      "      - 13.800000000000022\n",
      "      - 0.9000000000000173\n",
      "      - 14.100000000000016\n",
      "      - 18.59999999999998\n",
      "      - 3.0000000000000107\n",
      "      - 18.00000000000002\n",
      "      - -8.69999999999998\n",
      "      - 4.200000000000031\n",
      "      - 16.199999999999953\n",
      "      - 1.2000000000000148\n",
      "      - 3.0000000000000173\n",
      "      - 15.299999999999969\n",
      "      - 5.7000000000000295\n",
      "      - 4.500000000000032\n",
      "      - 7.800000000000011\n",
      "      - 9.00000000000003\n",
      "      - -7.799999999999995\n",
      "      - 5.079270337660091e-15\n",
      "      - -6.899999999999981\n",
      "      - 12.899999999999995\n",
      "      - 1.1999999999999633\n",
      "      - 7.800000000000033\n",
      "      - 18.299999999999912\n",
      "      - 14.099999999999941\n",
      "      - -6.899999999999996\n",
      "      - 6.59999999999998\n",
      "      - 15.59999999999993\n",
      "      - 1.200000000000003\n",
      "      - 27.59999999999991\n",
      "      - 22.499999999999893\n",
      "      - 3.300000000000032\n",
      "      - 12.60000000000002\n",
      "      - 10.499999999999961\n",
      "      - 1.2000000000000235\n",
      "      - 14.39999999999996\n",
      "      - 15.599999999999914\n",
      "      - 18.8999999999999\n",
      "      - 17.099999999999994\n",
      "      policy_policy1_reward:\n",
      "      - 29.5\n",
      "      - 6.0\n",
      "      - 14.0\n",
      "      - 26.0\n",
      "      - 14.5\n",
      "      - 9.5\n",
      "      - 29.0\n",
      "      - 7.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 8.0\n",
      "      - 12.0\n",
      "      - 12.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 16.5\n",
      "      - 21.0\n",
      "      - 23.0\n",
      "      - 16.5\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 13.5\n",
      "      - 11.0\n",
      "      - 13.5\n",
      "      - 8.5\n",
      "      - 8.5\n",
      "      - 21.0\n",
      "      - 30.5\n",
      "      - 11.5\n",
      "      - 22.0\n",
      "      - 10.5\n",
      "      - 14.5\n",
      "      - 27.5\n",
      "      - 21.0\n",
      "      - 26.5\n",
      "      - 12.5\n",
      "      - 7.0\n",
      "      - 34.0\n",
      "      - 4.5\n",
      "      - 12.0\n",
      "      - -5.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 5.0\n",
      "      - 5.0\n",
      "      - 23.5\n",
      "      - 22.0\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - 11.5\n",
      "      - 3.5\n",
      "      - 15.5\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 24.0\n",
      "      - -2.0\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 22.0\n",
      "      - 13.0\n",
      "      - 28.0\n",
      "      - -7.5\n",
      "      - 12.0\n",
      "      - 24.0\n",
      "      - 3.5\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 19.0\n",
      "      - -5.5\n",
      "      - 4.5\n",
      "      - 2.0\n",
      "      - 18.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 25.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 9.0\n",
      "      - 36.5\n",
      "      - 32.5\n",
      "      - 10.0\n",
      "      - 16.0\n",
      "      - 9.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 24.5\n",
      "      - 15.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.699999999999988\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.69999999999999\n",
      "      - -2.3000000000000047\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -3.399999999999983\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - 2.100000000000001\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999983\n",
      "      - -6.699999999999985\n",
      "      - -7.799999999999986\n",
      "      - 4.300000000000001\n",
      "      - -7.799999999999981\n",
      "      - -3.400000000000001\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999988\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -4.500000000000002\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999998\n",
      "      - -3.399999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000026\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999923\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.2999999999999927\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.300000000000004\n",
      "      - -6.6999999999999815\n",
      "      - -5.59999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000003\n",
      "      - -3.400000000000003\n",
      "      - -6.699999999999991\n",
      "      - -5.599999999999993\n",
      "      - -3.4000000000000057\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.200000000000002\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999984\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000028\n",
      "      - -7.799999999999987\n",
      "      - -4.499999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -4.500000000000003\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 1.0\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999987\n",
      "      - 2.100000000000002\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 36.5\n",
      "      policy2: 4.300000000000001\n",
      "    policy_reward_mean:\n",
      "      policy1: 14.705\n",
      "      policy2: -6.622999999999988\n",
      "    policy_reward_min:\n",
      "      policy1: -7.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17594490737236052\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07528088575297408\n",
      "      mean_inference_ms: 1.8714931276531923\n",
      "      mean_raw_obs_processing_ms: 0.346575455482428\n",
      "  time_since_restore: 239.95789885520935\n",
      "  time_this_iter_s: 26.111135244369507\n",
      "  time_total_s: 239.95789885520935\n",
      "  timers:\n",
      "    learn_throughput: 397.827\n",
      "    learn_time_ms: 10054.616\n",
      "    synch_weights_time_ms: 4.036\n",
      "    training_iteration_time_ms: 20866.296\n",
      "  timestamp: 1658917299\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 12\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 104000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_env_steps_sampled: 52000\n",
      "    num_env_steps_trained: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-40\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.099999999999916\n",
      "  episode_reward_mean: 13.778999999999966\n",
      "  episode_reward_min: -2.3999999999999955\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 520\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9499492645263672\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01275540515780449\n",
      "          model: {}\n",
      "          policy_loss: -0.034422293305397034\n",
      "          total_loss: 6.697046279907227\n",
      "          vf_explained_var: 0.2761092185974121\n",
      "          vf_loss: 6.727641582489014\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9447128176689148\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014554927125573158\n",
      "          model: {}\n",
      "          policy_loss: -0.03571627661585808\n",
      "          total_loss: 3.0464046001434326\n",
      "          vf_explained_var: 0.08019266277551651\n",
      "          vf_loss: 3.079209804534912\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_env_steps_sampled: 52000\n",
      "    num_env_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 104000\n",
      "  num_agent_steps_trained: 104000\n",
      "  num_env_steps_sampled: 52000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 52000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.58157894736842\n",
      "    ram_util_percent: 62.83157894736843\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 38.0\n",
      "    policy2: 51.59999999999997\n",
      "  policy_reward_mean:\n",
      "    policy1: 16.585\n",
      "    policy2: -2.805999999999994\n",
      "  policy_reward_min:\n",
      "    policy1: -39.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17251824921766962\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07405897719677366\n",
      "    mean_inference_ms: 1.8105753291287205\n",
      "    mean_raw_obs_processing_ms: 0.337599433274287\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.099999999999916\n",
      "    episode_reward_mean: 13.778999999999966\n",
      "    episode_reward_min: -2.3999999999999955\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 15.00000000000003\n",
      "      - 8.999999999999979\n",
      "      - 11.699999999999948\n",
      "      - 25.499999999999922\n",
      "      - 8.700000000000014\n",
      "      - 9.000000000000028\n",
      "      - 4.800000000000024\n",
      "      - 17.099999999999923\n",
      "      - 10.800000000000013\n",
      "      - 29.099999999999895\n",
      "      - -0.29999999999997795\n",
      "      - 12.299999999999983\n",
      "      - 11.399999999999949\n",
      "      - 25.79999999999992\n",
      "      - 16.79999999999996\n",
      "      - 11.39999999999997\n",
      "      - 9.899999999999972\n",
      "      - 14.699999999999937\n",
      "      - 8.99999999999999\n",
      "      - 15.000000000000004\n",
      "      - 24.89999999999992\n",
      "      - 11.700000000000005\n",
      "      - 16.799999999999898\n",
      "      - -1.199999999999969\n",
      "      - 18.899999999999906\n",
      "      - 11.999999999999913\n",
      "      - 9.600000000000021\n",
      "      - 3.899999999999943\n",
      "      - 20.699999999999918\n",
      "      - 17.099999999999977\n",
      "      - -0.9000000000000181\n",
      "      - 16.799999999999926\n",
      "      - 9.599999999999955\n",
      "      - 4.499999999999989\n",
      "      - 25.799999999999947\n",
      "      - 18.29999999999991\n",
      "      - 10.799999999999992\n",
      "      - 16.499999999999996\n",
      "      - 8.400000000000027\n",
      "      - 16.199999999999953\n",
      "      - 13.19999999999996\n",
      "      - 20.69999999999994\n",
      "      - 32.099999999999916\n",
      "      - 10.799999999999935\n",
      "      - 23.399999999999906\n",
      "      - 6.899999999999963\n",
      "      - 10.200000000000024\n",
      "      - 20.09999999999998\n",
      "      - 22.1999999999999\n",
      "      - 10.200000000000026\n",
      "      - 8.999999999999986\n",
      "      - 9.900000000000022\n",
      "      - 1.5000000000000187\n",
      "      - 26.999999999999922\n",
      "      - 23.099999999999902\n",
      "      - 14.399999999999912\n",
      "      - 25.199999999999907\n",
      "      - 1.8000000000000114\n",
      "      - 29.9999999999999\n",
      "      - 12.600000000000014\n",
      "      - 16.19999999999991\n",
      "      - 11.69999999999995\n",
      "      - 9.899999999999963\n",
      "      - 18.899999999999913\n",
      "      - -2.3999999999999955\n",
      "      - 15.299999999999912\n",
      "      - 15.599999999999914\n",
      "      - 14.099999999999982\n",
      "      - 8.99999999999996\n",
      "      - 6.2999999999999705\n",
      "      - 17.399999999999952\n",
      "      - 12.899999999999947\n",
      "      - 14.69999999999992\n",
      "      - 21.299999999999912\n",
      "      - 23.999999999999968\n",
      "      - 7.799999999999953\n",
      "      - 15.899999999999972\n",
      "      - 18.59999999999996\n",
      "      - 16.499999999999897\n",
      "      - 15.3\n",
      "      - 6.300000000000022\n",
      "      - 15.299999999999962\n",
      "      - 3.300000000000032\n",
      "      - 10.800000000000031\n",
      "      - 15.5999999999999\n",
      "      - 5.400000000000004\n",
      "      - 13.50000000000003\n",
      "      - 17.39999999999992\n",
      "      - 16.19999999999999\n",
      "      - 20.999999999999922\n",
      "      - 6.000000000000014\n",
      "      - 17.099999999999945\n",
      "      - 6.900000000000016\n",
      "      - -0.9000000000000163\n",
      "      - 10.500000000000025\n",
      "      - 28.499999999999908\n",
      "      - 14.400000000000025\n",
      "      - 11.999999999999998\n",
      "      - 12.299999999999931\n",
      "      - 15.899999999999993\n",
      "      policy_policy1_reward:\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 19.5\n",
      "      - 30.0\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 6.0\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 38.0\n",
      "      - 7.5\n",
      "      - 13.5\n",
      "      - 11.5\n",
      "      - 27.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 15.5\n",
      "      - 17.0\n",
      "      - 8.0\n",
      "      - 25.0\n",
      "      - 19.5\n",
      "      - 19.5\n",
      "      - 23.5\n",
      "      - 5.5\n",
      "      - 19.0\n",
      "      - 16.5\n",
      "      - 7.5\n",
      "      - 4.0\n",
      "      - 23.0\n",
      "      - 4.0\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 13.0\n",
      "      - -7.5\n",
      "      - 27.0\n",
      "      - 14.0\n",
      "      - 17.5\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 18.5\n",
      "      - 21.0\n",
      "      - 28.5\n",
      "      - 30.0\n",
      "      - 12.0\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - -4.0\n",
      "      - 29.0\n",
      "      - 24.5\n",
      "      - 12.5\n",
      "      - 13.5\n",
      "      - 15.5\n",
      "      - 11.5\n",
      "      - 31.5\n",
      "      - 32.0\n",
      "      - 20.0\n",
      "      - 33.0\n",
      "      - 3.0\n",
      "      - 29.0\n",
      "      - -39.0\n",
      "      - 24.0\n",
      "      - 14.0\n",
      "      - 10.0\n",
      "      - 24.5\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 13.0\n",
      "      - 23.0\n",
      "      - 18.5\n",
      "      - 22.5\n",
      "      - 22.5\n",
      "      - 34.0\n",
      "      - 3.5\n",
      "      - 21.5\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 22.0\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 5.5\n",
      "      - 18.0\n",
      "      - 23.0\n",
      "      - 18.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 12.5\n",
      "      - 2.5\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999982\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999991\n",
      "      - -7.7999999999999865\n",
      "      - -4.5000000000000036\n",
      "      - -1.2000000000000033\n",
      "      - -3.400000000000004\n",
      "      - 4.300000000000009\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000008\n",
      "      - -0.09999999999999987\n",
      "      - -1.2000000000000026\n",
      "      - -1.1999999999999946\n",
      "      - -5.599999999999997\n",
      "      - -5.599999999999988\n",
      "      - -2.300000000000004\n",
      "      - 0.9999999999999992\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000014\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999815\n",
      "      - -0.1000000000000012\n",
      "      - -4.499999999999999\n",
      "      - 2.1000000000000094\n",
      "      - -0.09999999999999853\n",
      "      - -2.299999999999988\n",
      "      - 13.09999999999999\n",
      "      - -8.899999999999986\n",
      "      - 9.800000000000002\n",
      "      - -3.399999999999989\n",
      "      - 11.999999999999998\n",
      "      - -1.2000000000000022\n",
      "      - 4.299999999999999\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -2.299999999999992\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999997\n",
      "      - -1.2000000000000017\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999982\n",
      "      - 14.199999999999996\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -2.300000000000003\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.4999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999988\n",
      "      - -1.2000000000000046\n",
      "      - 0.9999999999999948\n",
      "      - 51.59999999999997\n",
      "      - -7.7999999999999865\n",
      "      - -2.3000000000000043\n",
      "      - -0.09999999999999765\n",
      "      - -5.599999999999991\n",
      "      - -3.400000000000005\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999986\n",
      "      - 2.0999999999999943\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999995\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000042\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000004\n",
      "      - -5.599999999999983\n",
      "      - -3.400000000000001\n",
      "      - -4.5000000000000036\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999986\n",
      "      - -1.2000000000000042\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - -3.400000000000003\n",
      "      - -0.10000000000000464\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999998\n",
      "      - -2.300000000000003\n",
      "      - 0.9999999999999952\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999853\n",
      "      - -5.599999999999998\n",
      "      - -3.3999999999999964\n",
      "      - -4.500000000000002\n",
      "      - 0.9999999999999974\n",
      "      - -0.10000000000000009\n",
      "      - -4.499999999999993\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.0\n",
      "      policy2: 51.59999999999997\n",
      "    policy_reward_mean:\n",
      "      policy1: 16.585\n",
      "      policy2: -2.805999999999994\n",
      "    policy_reward_min:\n",
      "      policy1: -39.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17251824921766962\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07405897719677366\n",
      "      mean_inference_ms: 1.8105753291287205\n",
      "      mean_raw_obs_processing_ms: 0.337599433274287\n",
      "  time_since_restore: 250.92399907112122\n",
      "  time_this_iter_s: 26.532375812530518\n",
      "  time_total_s: 250.92399907112122\n",
      "  timers:\n",
      "    learn_throughput: 398.544\n",
      "    learn_time_ms: 10036.535\n",
      "    synch_weights_time_ms: 10.925\n",
      "    training_iteration_time_ms: 20942.571\n",
      "  timestamp: 1658917300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 102000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 102000\n",
      "    num_agent_steps_trained: 102000\n",
      "    num_env_steps_sampled: 51000\n",
      "    num_env_steps_trained: 51000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-40\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 31.19999999999993\n",
      "  episode_reward_mean: 17.570999999999948\n",
      "  episode_reward_min: 1.8000000000000127\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 510\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8518694639205933\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011985564604401588\n",
      "          model: {}\n",
      "          policy_loss: -0.03768381103873253\n",
      "          total_loss: 7.258021354675293\n",
      "          vf_explained_var: 0.1420954465866089\n",
      "          vf_loss: 7.293307781219482\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7019802927970886\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013143147341907024\n",
      "          model: {}\n",
      "          policy_loss: -0.04051697626709938\n",
      "          total_loss: 3.309051275253296\n",
      "          vf_explained_var: 0.06396634131669998\n",
      "          vf_loss: 3.3482537269592285\n",
      "    num_agent_steps_sampled: 102000\n",
      "    num_agent_steps_trained: 102000\n",
      "    num_env_steps_sampled: 51000\n",
      "    num_env_steps_trained: 51000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 102000\n",
      "  num_agent_steps_trained: 102000\n",
      "  num_env_steps_sampled: 51000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 51000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.644000000000005\n",
      "    ram_util_percent: 62.571999999999996\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 40.0\n",
      "    policy2: 13.100000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.72\n",
      "    policy2: -5.14899999999999\n",
      "  policy_reward_min:\n",
      "    policy1: 0.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1728268183610494\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07589170678737962\n",
      "    mean_inference_ms: 1.8311637979216568\n",
      "    mean_raw_obs_processing_ms: 0.3400006014624004\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 31.19999999999993\n",
      "    episode_reward_mean: 17.570999999999948\n",
      "    episode_reward_min: 1.8000000000000127\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 14.69999999999993\n",
      "      - 20.099999999999934\n",
      "      - 13.199999999999905\n",
      "      - 18.89999999999995\n",
      "      - 23.9999999999999\n",
      "      - 17.999999999999922\n",
      "      - 25.199999999999896\n",
      "      - 18.599999999999973\n",
      "      - 11.700000000000031\n",
      "      - 15.599999999999948\n",
      "      - 28.499999999999922\n",
      "      - 17.699999999999918\n",
      "      - 15.299999999999923\n",
      "      - 19.499999999999922\n",
      "      - 13.800000000000006\n",
      "      - 12.599999999999934\n",
      "      - 15.60000000000001\n",
      "      - 10.20000000000003\n",
      "      - 11.700000000000003\n",
      "      - 11.999999999999925\n",
      "      - 15.899999999999912\n",
      "      - 17.09999999999996\n",
      "      - 22.49999999999995\n",
      "      - 22.49999999999995\n",
      "      - 18.00000000000002\n",
      "      - 13.199999999999987\n",
      "      - 13.499999999999956\n",
      "      - 27.599999999999895\n",
      "      - 9.299999999999946\n",
      "      - 15.299999999999944\n",
      "      - 10.2\n",
      "      - 21.299999999999912\n",
      "      - 20.999999999999893\n",
      "      - 6.30000000000002\n",
      "      - 7.200000000000022\n",
      "      - 18.599999999999902\n",
      "      - 22.199999999999896\n",
      "      - 19.199999999999932\n",
      "      - 6.899999999999954\n",
      "      - 26.999999999999936\n",
      "      - 16.49999999999992\n",
      "      - 19.499999999999982\n",
      "      - 1.8000000000000127\n",
      "      - 30.89999999999995\n",
      "      - 9.599999999999968\n",
      "      - 7.799999999999953\n",
      "      - 18.599999999999895\n",
      "      - 14.100000000000005\n",
      "      - 9.299999999999986\n",
      "      - 19.199999999999918\n",
      "      - 23.699999999999896\n",
      "      - 13.200000000000003\n",
      "      - 17.999999999999908\n",
      "      - 15.899999999999936\n",
      "      - 20.099999999999923\n",
      "      - 20.099999999999945\n",
      "      - 23.09999999999994\n",
      "      - 16.799999999999905\n",
      "      - 25.499999999999908\n",
      "      - 10.799999999999988\n",
      "      - 24.599999999999913\n",
      "      - 8.100000000000025\n",
      "      - 13.799999999999992\n",
      "      - 18.599999999999902\n",
      "      - 16.799999999999976\n",
      "      - 26.3999999999999\n",
      "      - 2.100000000000011\n",
      "      - 12.899999999999935\n",
      "      - 19.49999999999992\n",
      "      - 29.399999999999906\n",
      "      - 8.399999999999956\n",
      "      - 25.199999999999932\n",
      "      - 16.79999999999996\n",
      "      - 31.19999999999993\n",
      "      - 12.29999999999997\n",
      "      - 13.499999999999945\n",
      "      - 13.799999999999962\n",
      "      - 27.899999999999938\n",
      "      - 11.099999999999925\n",
      "      - 20.700000000000017\n",
      "      - 18.599999999999973\n",
      "      - 26.69999999999991\n",
      "      - 26.39999999999993\n",
      "      - 15.899999999999997\n",
      "      - 6.600000000000019\n",
      "      - 13.799999999999924\n",
      "      - 23.09999999999998\n",
      "      - 12.600000000000014\n",
      "      - 21.299999999999905\n",
      "      - 24.299999999999923\n",
      "      - 25.4999999999999\n",
      "      - 23.999999999999893\n",
      "      - 29.999999999999915\n",
      "      - 20.699999999999896\n",
      "      - 15.89999999999993\n",
      "      - 14.699999999999923\n",
      "      - 24.899999999999903\n",
      "      - 21.000000000000004\n",
      "      - 15.59999999999996\n",
      "      - 16.199999999999967\n",
      "      policy_policy1_reward:\n",
      "      - 17.0\n",
      "      - 23.5\n",
      "      - 21.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 27.5\n",
      "      - 19.5\n",
      "      - 24.5\n",
      "      - 38.5\n",
      "      - 20.0\n",
      "      - 16.5\n",
      "      - 24.0\n",
      "      - 20.5\n",
      "      - 16.0\n",
      "      - 24.5\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 22.0\n",
      "      - 21.5\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 27.0\n",
      "      - 22.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 36.5\n",
      "      - 16.0\n",
      "      - 22.0\n",
      "      - 18.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 13.0\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      - 26.5\n",
      "      - 29.5\n",
      "      - 8.5\n",
      "      - 36.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 17.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 31.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 21.5\n",
      "      - 7.0\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 23.5\n",
      "      - 35.5\n",
      "      - 12.0\n",
      "      - 33.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 23.5\n",
      "      - 32.0\n",
      "      - 0.0\n",
      "      - 18.5\n",
      "      - 24.0\n",
      "      - 35.0\n",
      "      - 8.5\n",
      "      - 33.0\n",
      "      - 18.0\n",
      "      - 39.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 20.5\n",
      "      - 33.5\n",
      "      - 20.0\n",
      "      - 28.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 20.5\n",
      "      - 26.5\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 25.5\n",
      "      - 30.0\n",
      "      - 34.0\n",
      "      - 40.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 17.0\n",
      "      - 30.5\n",
      "      - 25.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      policy_policy2_reward:\n",
      "      - -2.3000000000000034\n",
      "      - -3.400000000000005\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000003\n",
      "      - -1.1999999999999946\n",
      "      - -4.499999999999982\n",
      "      - -6.699999999999994\n",
      "      - -3.400000000000005\n",
      "      - -8.899999999999984\n",
      "      - 3.2000000000000153\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -4.499999999999985\n",
      "      - -4.499999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -1.1999999999999953\n",
      "      - -4.49999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000002\n",
      "      - -7.799999999999989\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999985\n",
      "      - -5.599999999999984\n",
      "      - -3.399999999999995\n",
      "      - -1.2000000000000028\n",
      "      - -8.89999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -6.6999999999999895\n",
      "      - 3.2\n",
      "      - -7.799999999999989\n",
      "      - 3.2000000000000064\n",
      "      - -4.499999999999984\n",
      "      - -5.599999999999995\n",
      "      - 13.100000000000005\n",
      "      - 2.1\n",
      "      - -3.4000000000000044\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -1.199999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999998\n",
      "      - -0.10000000000000153\n",
      "      - -7.799999999999986\n",
      "      - -1.2000000000000035\n",
      "      - -7.799999999999984\n",
      "      - -6.699999999999983\n",
      "      - -4.500000000000002\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - 10.899999999999997\n",
      "      - -0.09999999999999254\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -1.200000000000004\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999988\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000052\n",
      "      - -2.3000000000000025\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 40.0\n",
      "      policy2: 13.100000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.72\n",
      "      policy2: -5.14899999999999\n",
      "    policy_reward_min:\n",
      "      policy1: 0.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1728268183610494\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07589170678737962\n",
      "      mean_inference_ms: 1.8311637979216568\n",
      "      mean_raw_obs_processing_ms: 0.3400006014624004\n",
      "  time_since_restore: 247.91934514045715\n",
      "  time_this_iter_s: 17.30494713783264\n",
      "  time_total_s: 247.91934514045715\n",
      "  timers:\n",
      "    learn_throughput: 377.426\n",
      "    learn_time_ms: 7948.568\n",
      "    synch_weights_time_ms: 8.945\n",
      "    training_iteration_time_ms: 16681.933\n",
      "  timestamp: 1658917300\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51000\n",
      "  training_iteration: 17\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 102000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 102000\n",
      "    num_agent_steps_trained: 102000\n",
      "    num_env_steps_sampled: 51000\n",
      "    num_env_steps_trained: 51000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-41\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.2999999999999\n",
      "  episode_reward_mean: 10.676999999999982\n",
      "  episode_reward_min: -16.499999999999986\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 510\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8804399371147156\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01933870278298855\n",
      "          model: {}\n",
      "          policy_loss: -0.05920534208416939\n",
      "          total_loss: 6.737570762634277\n",
      "          vf_explained_var: 0.2089720219373703\n",
      "          vf_loss: 6.788073539733887\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8037095069885254\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01502184383571148\n",
      "          model: {}\n",
      "          policy_loss: -0.04205735772848129\n",
      "          total_loss: 3.123079776763916\n",
      "          vf_explained_var: 0.0681413859128952\n",
      "          vf_loss: 3.1583774089813232\n",
      "    num_agent_steps_sampled: 102000\n",
      "    num_agent_steps_trained: 102000\n",
      "    num_env_steps_sampled: 51000\n",
      "    num_env_steps_trained: 51000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 102000\n",
      "  num_agent_steps_trained: 102000\n",
      "  num_env_steps_sampled: 51000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 51000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 64.396\n",
      "    ram_util_percent: 62.495999999999995\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 22.999999999999993\n",
      "  policy_reward_mean:\n",
      "    policy1: 15.65\n",
      "    policy2: -4.972999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -15.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1767443726944412\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07530252538284074\n",
      "    mean_inference_ms: 1.862300692881612\n",
      "    mean_raw_obs_processing_ms: 0.34829074537065735\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.2999999999999\n",
      "    episode_reward_mean: 10.676999999999982\n",
      "    episode_reward_min: -16.499999999999986\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 4.50000000000003\n",
      "      - 3.300000000000021\n",
      "      - 6.9\n",
      "      - 11.699999999999989\n",
      "      - 5.700000000000022\n",
      "      - 19.19999999999994\n",
      "      - 7.500000000000016\n",
      "      - 13.799999999999972\n",
      "      - 18.599999999999966\n",
      "      - 13.799999999999924\n",
      "      - 9.299999999999946\n",
      "      - 9.000000000000021\n",
      "      - 14.699999999999969\n",
      "      - 15.299999999999901\n",
      "      - 8.69999999999994\n",
      "      - 11.99999999999997\n",
      "      - 3.300000000000029\n",
      "      - 4.199999999999958\n",
      "      - 15.59999999999991\n",
      "      - 19.79999999999995\n",
      "      - 10.499999999999961\n",
      "      - 17.69999999999998\n",
      "      - 0.3000000000000085\n",
      "      - 22.199999999999967\n",
      "      - 6.300000000000026\n",
      "      - 15.899999999999945\n",
      "      - 12.299999999999939\n",
      "      - 2.4000000000000132\n",
      "      - -16.499999999999986\n",
      "      - 7.500000000000007\n",
      "      - -3.5999999999999908\n",
      "      - 3.0000000000000284\n",
      "      - -9.59999999999999\n",
      "      - 20.699999999999974\n",
      "      - 15.900000000000007\n",
      "      - 6.000000000000018\n",
      "      - 4.199999999999944\n",
      "      - 13.499999999999973\n",
      "      - 22.79999999999989\n",
      "      - 2.400000000000024\n",
      "      - 26.699999999999903\n",
      "      - 6.600000000000028\n",
      "      - 16.499999999999986\n",
      "      - 10.200000000000033\n",
      "      - 3.0000000000000187\n",
      "      - 5.100000000000001\n",
      "      - 10.499999999999991\n",
      "      - 14.699999999999934\n",
      "      - 2.0999999999999863\n",
      "      - 26.999999999999922\n",
      "      - 14.099999999999968\n",
      "      - 7.2000000000000135\n",
      "      - 0.6000000000000233\n",
      "      - 9.599999999999959\n",
      "      - 5.10000000000003\n",
      "      - 7.500000000000021\n",
      "      - 24.599999999999902\n",
      "      - 7.1999999999999815\n",
      "      - 26.099999999999913\n",
      "      - 12.000000000000005\n",
      "      - 12.599999999999905\n",
      "      - 10.199999999999998\n",
      "      - 5.099999999999998\n",
      "      - 19.49999999999998\n",
      "      - -5.699999999999982\n",
      "      - 16.199999999999935\n",
      "      - 5.400000000000016\n",
      "      - 17.399999999999935\n",
      "      - 21.29999999999997\n",
      "      - 15.59999999999994\n",
      "      - 22.499999999999908\n",
      "      - 9.59999999999996\n",
      "      - -1.7999999999999847\n",
      "      - 13.20000000000003\n",
      "      - 15.299999999999972\n",
      "      - 14.399999999999956\n",
      "      - 15.599999999999918\n",
      "      - 11.09999999999993\n",
      "      - 14.39999999999994\n",
      "      - 7.800000000000031\n",
      "      - 15.60000000000003\n",
      "      - 7.499999999999989\n",
      "      - 10.499999999999952\n",
      "      - -1.499999999999981\n",
      "      - 20.699999999999946\n",
      "      - 5.700000000000008\n",
      "      - -0.29999999999998084\n",
      "      - 8.100000000000032\n",
      "      - 10.500000000000012\n",
      "      - 5.10000000000002\n",
      "      - 14.699999999999973\n",
      "      - 2.4000000000000132\n",
      "      - 23.699999999999914\n",
      "      - 39.2999999999999\n",
      "      - 25.499999999999893\n",
      "      - -13.199999999999976\n",
      "      - 9.600000000000028\n",
      "      - 5.999999999999998\n",
      "      - 17.999999999999982\n",
      "      - 12.900000000000025\n",
      "      policy_policy1_reward:\n",
      "      - 14.5\n",
      "      - -1.0\n",
      "      - 7.0\n",
      "      - 19.5\n",
      "      - 13.5\n",
      "      - 5.0\n",
      "      - 12.0\n",
      "      - 20.5\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      - 16.0\n",
      "      - -14.0\n",
      "      - 22.5\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 20.5\n",
      "      - 25.5\n",
      "      - 7.0\n",
      "      - 24.5\n",
      "      - 13.0\n",
      "      - 16.0\n",
      "      - 19.0\n",
      "      - 8.0\n",
      "      - -6.5\n",
      "      - 12.0\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - -4.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 23.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      - 34.5\n",
      "      - 15.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - -1.5\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 37.0\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 9.5\n",
      "      - 18.5\n",
      "      - 8.5\n",
      "      - 6.5\n",
      "      - 33.5\n",
      "      - 15.0\n",
      "      - 29.5\n",
      "      - 16.5\n",
      "      - 21.5\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 29.5\n",
      "      - 1.0\n",
      "      - 24.0\n",
      "      - 11.0\n",
      "      - 12.0\n",
      "      - 22.5\n",
      "      - 13.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 6.0\n",
      "      - 21.0\n",
      "      - 22.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 14.5\n",
      "      - 13.5\n",
      "      - -15.5\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 23.0\n",
      "      - 13.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 2.5\n",
      "      - 26.0\n",
      "      - 46.0\n",
      "      - 35.5\n",
      "      - -6.5\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 28.0\n",
      "      - 18.5\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000011\n",
      "      - -0.1000000000000015\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - 14.20000000000001\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999985\n",
      "      - -3.3999999999999955\n",
      "      - -1.2000000000000035\n",
      "      - -6.699999999999994\n",
      "      - 22.99999999999996\n",
      "      - -7.799999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999994\n",
      "      - -4.5000000000000036\n",
      "      - -6.699999999999993\n",
      "      - -7.799999999999981\n",
      "      - -3.3999999999999844\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999984\n",
      "      - -6.6999999999999895\n",
      "      - -2.299999999999998\n",
      "      - -6.699999999999986\n",
      "      - -0.09999999999999831\n",
      "      - -6.69999999999999\n",
      "      - -5.599999999999995\n",
      "      - -9.99999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999997\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999983\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - 11.999999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000001\n",
      "      - 0.9999999999999954\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -3.3999999999999857\n",
      "      - -4.500000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999987\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - 5.4\n",
      "      - -1.2000000000000053\n",
      "      - 2.1000000000000014\n",
      "      - 1.0000000000000027\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000264\n",
      "      - -6.69999999999999\n",
      "      - 2.1000000000000036\n",
      "      - 22.999999999999993\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999936\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000492\n",
      "      - -2.2999999999999954\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - 1.0000000000000022\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 22.999999999999993\n",
      "    policy_reward_mean:\n",
      "      policy1: 15.65\n",
      "      policy2: -4.972999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -15.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1767443726944412\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07530252538284074\n",
      "      mean_inference_ms: 1.862300692881612\n",
      "      mean_raw_obs_processing_ms: 0.34829074537065735\n",
      "  time_since_restore: 249.67962622642517\n",
      "  time_this_iter_s: 17.472522020339966\n",
      "  time_total_s: 249.67962622642517\n",
      "  timers:\n",
      "    learn_throughput: 379.64\n",
      "    learn_time_ms: 7902.229\n",
      "    synch_weights_time_ms: 4.92\n",
      "    training_iteration_time_ms: 16810.186\n",
      "  timestamp: 1658917301\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 51000\n",
      "  training_iteration: 17\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 108000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_env_steps_sampled: 54000\n",
      "    num_env_steps_trained: 54000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-55\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.39999999999991\n",
      "  episode_reward_mean: 17.621999999999947\n",
      "  episode_reward_min: 1.1999999999999962\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 540\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8165760636329651\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013262784108519554\n",
      "          model: {}\n",
      "          policy_loss: -0.03836923465132713\n",
      "          total_loss: 7.027626991271973\n",
      "          vf_explained_var: 0.24449878931045532\n",
      "          vf_loss: 7.063344478607178\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6782395243644714\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01252430584281683\n",
      "          model: {}\n",
      "          policy_loss: -0.0364043191075325\n",
      "          total_loss: 3.1474719047546387\n",
      "          vf_explained_var: 0.08943495154380798\n",
      "          vf_loss: 3.182623863220215\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_env_steps_sampled: 54000\n",
      "    num_env_steps_trained: 54000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 108000\n",
      "  num_agent_steps_trained: 108000\n",
      "  num_env_steps_sampled: 54000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 54000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.55909090909092\n",
      "    ram_util_percent: 62.15000000000002\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 40.0\n",
      "    policy2: 13.100000000000005\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.65\n",
      "    policy2: -5.027999999999992\n",
      "  policy_reward_min:\n",
      "    policy1: 0.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17535557583346814\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07699203777221592\n",
      "    mean_inference_ms: 1.8552772483655773\n",
      "    mean_raw_obs_processing_ms: 0.3449871138605022\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.39999999999991\n",
      "    episode_reward_mean: 17.621999999999947\n",
      "    episode_reward_min: 1.1999999999999962\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 10.2\n",
      "      - 21.299999999999912\n",
      "      - 20.999999999999893\n",
      "      - 6.30000000000002\n",
      "      - 7.200000000000022\n",
      "      - 18.599999999999902\n",
      "      - 22.199999999999896\n",
      "      - 19.199999999999932\n",
      "      - 6.899999999999954\n",
      "      - 26.999999999999936\n",
      "      - 16.49999999999992\n",
      "      - 19.499999999999982\n",
      "      - 1.8000000000000127\n",
      "      - 30.89999999999995\n",
      "      - 9.599999999999968\n",
      "      - 7.799999999999953\n",
      "      - 18.599999999999895\n",
      "      - 14.100000000000005\n",
      "      - 9.299999999999986\n",
      "      - 19.199999999999918\n",
      "      - 23.699999999999896\n",
      "      - 13.200000000000003\n",
      "      - 17.999999999999908\n",
      "      - 15.899999999999936\n",
      "      - 20.099999999999923\n",
      "      - 20.099999999999945\n",
      "      - 23.09999999999994\n",
      "      - 16.799999999999905\n",
      "      - 25.499999999999908\n",
      "      - 10.799999999999988\n",
      "      - 24.599999999999913\n",
      "      - 8.100000000000025\n",
      "      - 13.799999999999992\n",
      "      - 18.599999999999902\n",
      "      - 16.799999999999976\n",
      "      - 26.3999999999999\n",
      "      - 2.100000000000011\n",
      "      - 12.899999999999935\n",
      "      - 19.49999999999992\n",
      "      - 29.399999999999906\n",
      "      - 8.399999999999956\n",
      "      - 25.199999999999932\n",
      "      - 16.79999999999996\n",
      "      - 31.19999999999993\n",
      "      - 12.29999999999997\n",
      "      - 13.499999999999945\n",
      "      - 13.799999999999962\n",
      "      - 27.899999999999938\n",
      "      - 11.099999999999925\n",
      "      - 20.700000000000017\n",
      "      - 18.599999999999973\n",
      "      - 26.69999999999991\n",
      "      - 26.39999999999993\n",
      "      - 15.899999999999997\n",
      "      - 6.600000000000019\n",
      "      - 13.799999999999924\n",
      "      - 23.09999999999998\n",
      "      - 12.600000000000014\n",
      "      - 21.299999999999905\n",
      "      - 24.299999999999923\n",
      "      - 25.4999999999999\n",
      "      - 23.999999999999893\n",
      "      - 29.999999999999915\n",
      "      - 20.699999999999896\n",
      "      - 15.89999999999993\n",
      "      - 14.699999999999923\n",
      "      - 24.899999999999903\n",
      "      - 21.000000000000004\n",
      "      - 15.59999999999996\n",
      "      - 16.199999999999967\n",
      "      - 11.699999999999955\n",
      "      - 1.1999999999999962\n",
      "      - 10.799999999999997\n",
      "      - 20.399999999999906\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 11.099999999999946\n",
      "      - 15.9\n",
      "      - 15.899999999999944\n",
      "      - 11.699999999999987\n",
      "      - 29.099999999999923\n",
      "      - 12.599999999999959\n",
      "      - 32.39999999999991\n",
      "      - 13.199999999999996\n",
      "      - 25.499999999999943\n",
      "      - 25.499999999999893\n",
      "      - 13.499999999999973\n",
      "      - 22.199999999999907\n",
      "      - 16.499999999999908\n",
      "      - 31.19999999999991\n",
      "      - 8.099999999999978\n",
      "      - 9.00000000000002\n",
      "      - 4.7999999999999865\n",
      "      - 12.599999999999996\n",
      "      - 12.599999999999914\n",
      "      - 25.199999999999903\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 13.799999999999937\n",
      "      - 18.599999999999973\n",
      "      policy_policy1_reward:\n",
      "      - 18.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 13.0\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 31.5\n",
      "      - 26.5\n",
      "      - 29.5\n",
      "      - 8.5\n",
      "      - 36.5\n",
      "      - 13.0\n",
      "      - 9.0\n",
      "      - 27.5\n",
      "      - 17.5\n",
      "      - 16.0\n",
      "      - 16.0\n",
      "      - 31.5\n",
      "      - 10.0\n",
      "      - 22.5\n",
      "      - 21.5\n",
      "      - 7.0\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 23.5\n",
      "      - 35.5\n",
      "      - 12.0\n",
      "      - 33.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 23.5\n",
      "      - 32.0\n",
      "      - 0.0\n",
      "      - 18.5\n",
      "      - 24.0\n",
      "      - 35.0\n",
      "      - 8.5\n",
      "      - 33.0\n",
      "      - 18.0\n",
      "      - 39.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 20.5\n",
      "      - 33.5\n",
      "      - 20.0\n",
      "      - 28.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 20.5\n",
      "      - 26.5\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 25.5\n",
      "      - 30.0\n",
      "      - 34.0\n",
      "      - 40.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 17.0\n",
      "      - 30.5\n",
      "      - 25.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 29.0\n",
      "      - 32.5\n",
      "      - 20.0\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 19.5\n",
      "      - 32.5\n",
      "      - 16.0\n",
      "      - 27.0\n",
      "      - 21.0\n",
      "      - 30.0\n",
      "      - 35.5\n",
      "      - 23.5\n",
      "      - 30.0\n",
      "      - 15.5\n",
      "      - 39.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 27.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.79999999999999\n",
      "      - -1.1999999999999953\n",
      "      - -4.49999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999986\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000002\n",
      "      - -7.799999999999989\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999985\n",
      "      - -5.599999999999984\n",
      "      - -3.399999999999995\n",
      "      - -1.2000000000000028\n",
      "      - -8.89999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -6.6999999999999895\n",
      "      - 3.2\n",
      "      - -7.799999999999989\n",
      "      - 3.2000000000000064\n",
      "      - -4.499999999999984\n",
      "      - -5.599999999999995\n",
      "      - 13.100000000000005\n",
      "      - 2.1\n",
      "      - -3.4000000000000044\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -1.199999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999998\n",
      "      - -0.10000000000000153\n",
      "      - -7.799999999999986\n",
      "      - -1.2000000000000035\n",
      "      - -7.799999999999984\n",
      "      - -6.699999999999983\n",
      "      - -4.500000000000002\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - 10.899999999999997\n",
      "      - -0.09999999999999254\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -1.200000000000004\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999988\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000052\n",
      "      - -2.3000000000000025\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999895\n",
      "      - -5.599999999999999\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999991\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -3.400000000000005\n",
      "      - -3.4000000000000057\n",
      "      - 5.4000000000000075\n",
      "      - -7.79999999999999\n",
      "      - -4.5000000000000036\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999966\n",
      "      - -7.79999999999999\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999993\n",
      "      - -3.4000000000000066\n",
      "      - -8.89999999999998\n",
      "      - -2.299999999999991\n",
      "      - -5.599999999999991\n",
      "      - -4.499999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 40.0\n",
      "      policy2: 13.100000000000005\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.65\n",
      "      policy2: -5.027999999999992\n",
      "    policy_reward_min:\n",
      "      policy1: 0.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17535557583346814\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07699203777221592\n",
      "      mean_inference_ms: 1.8552772483655773\n",
      "      mean_raw_obs_processing_ms: 0.3449871138605022\n",
      "  time_since_restore: 262.88365507125854\n",
      "  time_this_iter_s: 14.964309930801392\n",
      "  time_total_s: 262.88365507125854\n",
      "  timers:\n",
      "    learn_throughput: 371.797\n",
      "    learn_time_ms: 8068.915\n",
      "    synch_weights_time_ms: 9.154\n",
      "    training_iteration_time_ms: 16593.242\n",
      "  timestamp: 1658917315\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 54000\n",
      "  training_iteration: 18\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 108000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_env_steps_sampled: 54000\n",
      "    num_env_steps_trained: 54000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-21-57\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.2999999999999\n",
      "  episode_reward_mean: 11.897999999999977\n",
      "  episode_reward_min: -13.199999999999976\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 540\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8287246823310852\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016747789457440376\n",
      "          model: {}\n",
      "          policy_loss: -0.04980391263961792\n",
      "          total_loss: 7.013765335083008\n",
      "          vf_explained_var: 0.10184626281261444\n",
      "          vf_loss: 7.056033611297607\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.78919917345047\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016163136810064316\n",
      "          model: {}\n",
      "          policy_loss: -0.04391711205244064\n",
      "          total_loss: 3.2719552516937256\n",
      "          vf_explained_var: 0.05714638903737068\n",
      "          vf_loss: 3.3085992336273193\n",
      "    num_agent_steps_sampled: 108000\n",
      "    num_agent_steps_trained: 108000\n",
      "    num_env_steps_sampled: 54000\n",
      "    num_env_steps_trained: 54000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 108000\n",
      "  num_agent_steps_trained: 108000\n",
      "  num_env_steps_sampled: 54000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 54000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.69545454545453\n",
      "    ram_util_percent: 62.08636363636364\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 28.49999999999998\n",
      "  policy_reward_mean:\n",
      "    policy1: 16.75\n",
      "    policy2: -4.851999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -22.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17915938216010902\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07628711552084619\n",
      "    mean_inference_ms: 1.8865455186938036\n",
      "    mean_raw_obs_processing_ms: 0.35307409468234946\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.2999999999999\n",
      "    episode_reward_mean: 11.897999999999977\n",
      "    episode_reward_min: -13.199999999999976\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -3.5999999999999908\n",
      "      - 3.0000000000000284\n",
      "      - -9.59999999999999\n",
      "      - 20.699999999999974\n",
      "      - 15.900000000000007\n",
      "      - 6.000000000000018\n",
      "      - 4.199999999999944\n",
      "      - 13.499999999999973\n",
      "      - 22.79999999999989\n",
      "      - 2.400000000000024\n",
      "      - 26.699999999999903\n",
      "      - 6.600000000000028\n",
      "      - 16.499999999999986\n",
      "      - 10.200000000000033\n",
      "      - 3.0000000000000187\n",
      "      - 5.100000000000001\n",
      "      - 10.499999999999991\n",
      "      - 14.699999999999934\n",
      "      - 2.0999999999999863\n",
      "      - 26.999999999999922\n",
      "      - 14.099999999999968\n",
      "      - 7.2000000000000135\n",
      "      - 0.6000000000000233\n",
      "      - 9.599999999999959\n",
      "      - 5.10000000000003\n",
      "      - 7.500000000000021\n",
      "      - 24.599999999999902\n",
      "      - 7.1999999999999815\n",
      "      - 26.099999999999913\n",
      "      - 12.000000000000005\n",
      "      - 12.599999999999905\n",
      "      - 10.199999999999998\n",
      "      - 5.099999999999998\n",
      "      - 19.49999999999998\n",
      "      - -5.699999999999982\n",
      "      - 16.199999999999935\n",
      "      - 5.400000000000016\n",
      "      - 17.399999999999935\n",
      "      - 21.29999999999997\n",
      "      - 15.59999999999994\n",
      "      - 22.499999999999908\n",
      "      - 9.59999999999996\n",
      "      - -1.7999999999999847\n",
      "      - 13.20000000000003\n",
      "      - 15.299999999999972\n",
      "      - 14.399999999999956\n",
      "      - 15.599999999999918\n",
      "      - 11.09999999999993\n",
      "      - 14.39999999999994\n",
      "      - 7.800000000000031\n",
      "      - 15.60000000000003\n",
      "      - 7.499999999999989\n",
      "      - 10.499999999999952\n",
      "      - -1.499999999999981\n",
      "      - 20.699999999999946\n",
      "      - 5.700000000000008\n",
      "      - -0.29999999999998084\n",
      "      - 8.100000000000032\n",
      "      - 10.500000000000012\n",
      "      - 5.10000000000002\n",
      "      - 14.699999999999973\n",
      "      - 2.4000000000000132\n",
      "      - 23.699999999999914\n",
      "      - 39.2999999999999\n",
      "      - 25.499999999999893\n",
      "      - -13.199999999999976\n",
      "      - 9.600000000000028\n",
      "      - 5.999999999999998\n",
      "      - 17.999999999999982\n",
      "      - 12.900000000000025\n",
      "      - 22.799999999999905\n",
      "      - 17.999999999999936\n",
      "      - 17.99999999999993\n",
      "      - 7.200000000000015\n",
      "      - 15.299999999999994\n",
      "      - 8.700000000000026\n",
      "      - -3.2999999999999847\n",
      "      - 16.500000000000007\n",
      "      - 18.299999999999983\n",
      "      - 15.29999999999998\n",
      "      - 20.999999999999908\n",
      "      - 11.099999999999989\n",
      "      - 7.499999999999938\n",
      "      - 8.09999999999992\n",
      "      - 3.0000000000000244\n",
      "      - 15.000000000000004\n",
      "      - 37.19999999999994\n",
      "      - 11.09999999999995\n",
      "      - 10.8\n",
      "      - 30.29999999999991\n",
      "      - 20.69999999999994\n",
      "      - 13.799999999999912\n",
      "      - 11.099999999999921\n",
      "      - 6.000000000000018\n",
      "      - 17.699999999999946\n",
      "      - 12.299999999999935\n",
      "      - 10.799999999999933\n",
      "      - 14.100000000000035\n",
      "      - 11.999999999999979\n",
      "      - 7.200000000000026\n",
      "      policy_policy1_reward:\n",
      "      - 2.0\n",
      "      - 13.0\n",
      "      - -4.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 23.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      - 34.5\n",
      "      - 15.5\n",
      "      - 21.0\n",
      "      - 18.0\n",
      "      - 7.5\n",
      "      - 14.0\n",
      "      - -1.5\n",
      "      - 17.0\n",
      "      - 11.0\n",
      "      - 37.0\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 9.5\n",
      "      - 18.5\n",
      "      - 8.5\n",
      "      - 6.5\n",
      "      - 33.5\n",
      "      - 15.0\n",
      "      - 29.5\n",
      "      - 16.5\n",
      "      - 21.5\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 29.5\n",
      "      - 1.0\n",
      "      - 24.0\n",
      "      - 11.0\n",
      "      - 12.0\n",
      "      - 22.5\n",
      "      - 13.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 6.0\n",
      "      - 21.0\n",
      "      - 22.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 14.5\n",
      "      - 13.5\n",
      "      - -15.5\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 23.0\n",
      "      - 13.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 2.5\n",
      "      - 26.0\n",
      "      - 46.0\n",
      "      - 35.5\n",
      "      - -6.5\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 28.0\n",
      "      - 18.5\n",
      "      - 29.5\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 16.5\n",
      "      - 16.5\n",
      "      - -6.5\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 3.5\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 7.5\n",
      "      - 19.5\n",
      "      - 39.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 37.0\n",
      "      - 28.5\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - -22.5\n",
      "      - 20.0\n",
      "      - 8.0\n",
      "      - 17.5\n",
      "      - 23.0\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      policy_policy2_reward:\n",
      "      - -5.599999999999997\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999983\n",
      "      - -7.7999999999999865\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999997\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999983\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999992\n",
      "      - -8.89999999999998\n",
      "      - 11.999999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000001\n",
      "      - 0.9999999999999954\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999982\n",
      "      - -3.3999999999999857\n",
      "      - -4.500000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999987\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - 5.4\n",
      "      - -1.2000000000000053\n",
      "      - 2.1000000000000014\n",
      "      - 1.0000000000000027\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000264\n",
      "      - -6.69999999999999\n",
      "      - 2.1000000000000036\n",
      "      - 22.999999999999993\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999936\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000492\n",
      "      - -2.2999999999999954\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - 1.0000000000000022\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.699999999999984\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000033\n",
      "      - -7.799999999999982\n",
      "      - 3.1999999999999975\n",
      "      - -9.99999999999998\n",
      "      - 9.800000000000006\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999997\n",
      "      - 7.6000000000000085\n",
      "      - -4.49999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999991\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -3.399999999999983\n",
      "      - -6.699999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 28.49999999999998\n",
      "      - -2.3000000000000025\n",
      "      - 4.30000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 28.49999999999998\n",
      "    policy_reward_mean:\n",
      "      policy1: 16.75\n",
      "      policy2: -4.851999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -22.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17915938216010902\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07628711552084619\n",
      "      mean_inference_ms: 1.8865455186938036\n",
      "      mean_raw_obs_processing_ms: 0.35307409468234946\n",
      "  time_since_restore: 265.1436622142792\n",
      "  time_this_iter_s: 15.464035987854004\n",
      "  time_total_s: 265.1436622142792\n",
      "  timers:\n",
      "    learn_throughput: 371.335\n",
      "    learn_time_ms: 8078.954\n",
      "    synch_weights_time_ms: 5.213\n",
      "    training_iteration_time_ms: 16762.997\n",
      "  timestamp: 1658917317\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 54000\n",
      "  training_iteration: 18\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 104000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_env_steps_sampled: 52000\n",
      "    num_env_steps_trained: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 35.69999999999993\n",
      "  episode_reward_mean: 9.37799999999998\n",
      "  episode_reward_min: -14.999999999999982\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 520\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9467511773109436\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018139928579330444\n",
      "          model: {}\n",
      "          policy_loss: -0.051240935921669006\n",
      "          total_loss: 6.705901622772217\n",
      "          vf_explained_var: 0.2698594629764557\n",
      "          vf_loss: 6.748979568481445\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9537777304649353\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017280546948313713\n",
      "          model: {}\n",
      "          policy_loss: -0.04510551318526268\n",
      "          total_loss: 2.865410089492798\n",
      "          vf_explained_var: 0.06127746403217316\n",
      "          vf_loss: 2.9027395248413086\n",
      "    num_agent_steps_sampled: 104000\n",
      "    num_agent_steps_trained: 104000\n",
      "    num_env_steps_sampled: 52000\n",
      "    num_env_steps_trained: 52000\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 104000\n",
      "  num_agent_steps_trained: 104000\n",
      "  num_env_steps_sampled: 52000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 52000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 61.13000000000001\n",
      "    ram_util_percent: 61.33\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 38.0\n",
      "    policy2: 8.700000000000014\n",
      "  policy_reward_mean:\n",
      "    policy1: 15.495\n",
      "    policy2: -6.116999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -7.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18006513759551582\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07706372918077568\n",
      "    mean_inference_ms: 1.9149464462147194\n",
      "    mean_raw_obs_processing_ms: 0.3546914290639467\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 35.69999999999993\n",
      "    episode_reward_mean: 9.37799999999998\n",
      "    episode_reward_min: -14.999999999999982\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 23.99999999999989\n",
      "      - 3.300000000000022\n",
      "      - 4.199999999999976\n",
      "      - -14.999999999999982\n",
      "      - 4.200000000000024\n",
      "      - 14.099999999999948\n",
      "      - 12.599999999999921\n",
      "      - 2.700000000000014\n",
      "      - -3.899999999999985\n",
      "      - 16.799999999999955\n",
      "      - 11.999999999999961\n",
      "      - 9.900000000000022\n",
      "      - -13.500000000000005\n",
      "      - 1.499999999999996\n",
      "      - -5.399999999999986\n",
      "      - 13.19999999999994\n",
      "      - -4.19999999999999\n",
      "      - 6.899999999999954\n",
      "      - 8.999999999999963\n",
      "      - -2.9999999999999725\n",
      "      - 19.499999999999915\n",
      "      - -5.399999999999977\n",
      "      - 13.800000000000022\n",
      "      - 0.9000000000000173\n",
      "      - 14.100000000000016\n",
      "      - 18.59999999999998\n",
      "      - 3.0000000000000107\n",
      "      - 18.00000000000002\n",
      "      - -8.69999999999998\n",
      "      - 4.200000000000031\n",
      "      - 16.199999999999953\n",
      "      - 1.2000000000000148\n",
      "      - 3.0000000000000173\n",
      "      - 15.299999999999969\n",
      "      - 5.7000000000000295\n",
      "      - 4.500000000000032\n",
      "      - 7.800000000000011\n",
      "      - 9.00000000000003\n",
      "      - -7.799999999999995\n",
      "      - 5.079270337660091e-15\n",
      "      - -6.899999999999981\n",
      "      - 12.899999999999995\n",
      "      - 1.1999999999999633\n",
      "      - 7.800000000000033\n",
      "      - 18.299999999999912\n",
      "      - 14.099999999999941\n",
      "      - -6.899999999999996\n",
      "      - 6.59999999999998\n",
      "      - 15.59999999999993\n",
      "      - 1.200000000000003\n",
      "      - 27.59999999999991\n",
      "      - 22.499999999999893\n",
      "      - 3.300000000000032\n",
      "      - 12.60000000000002\n",
      "      - 10.499999999999961\n",
      "      - 1.2000000000000235\n",
      "      - 14.39999999999996\n",
      "      - 15.599999999999914\n",
      "      - 18.8999999999999\n",
      "      - 17.099999999999994\n",
      "      - 14.099999999999945\n",
      "      - 11.399999999999968\n",
      "      - 27.599999999999937\n",
      "      - 21.299999999999947\n",
      "      - 27.59999999999995\n",
      "      - 5.1\n",
      "      - 8.999999999999943\n",
      "      - 19.199999999999946\n",
      "      - 9.899999999999958\n",
      "      - 10.799999999999988\n",
      "      - 23.699999999999914\n",
      "      - 16.50000000000002\n",
      "      - 35.69999999999993\n",
      "      - 25.799999999999912\n",
      "      - 14.699999999999946\n",
      "      - 11.099999999999927\n",
      "      - 2.6999999999999935\n",
      "      - 21.599999999999902\n",
      "      - 2.700000000000028\n",
      "      - 7.79999999999996\n",
      "      - 17.099999999999973\n",
      "      - 6.60000000000001\n",
      "      - 0.3000000000000227\n",
      "      - 19.499999999999993\n",
      "      - 6.300000000000033\n",
      "      - 2.7000000000000175\n",
      "      - 17.399999999999913\n",
      "      - 6.299999999999976\n",
      "      - 8.700000000000019\n",
      "      - 9.59999999999995\n",
      "      - 16.49999999999995\n",
      "      - 7.200000000000026\n",
      "      - -2.999999999999972\n",
      "      - 12.299999999999923\n",
      "      - 19.799999999999926\n",
      "      - -1.4999999999999862\n",
      "      - 7.499999999999995\n",
      "      - 15.599999999999975\n",
      "      - 11.700000000000033\n",
      "      - 8.999999999999924\n",
      "      policy_policy1_reward:\n",
      "      - 34.0\n",
      "      - 4.5\n",
      "      - 12.0\n",
      "      - -5.0\n",
      "      - 6.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 5.0\n",
      "      - 5.0\n",
      "      - 23.5\n",
      "      - 22.0\n",
      "      - 10.0\n",
      "      - -3.5\n",
      "      - 11.5\n",
      "      - 3.5\n",
      "      - 15.5\n",
      "      - 2.5\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 24.0\n",
      "      - -2.0\n",
      "      - 20.5\n",
      "      - 6.5\n",
      "      - 17.5\n",
      "      - 22.0\n",
      "      - 13.0\n",
      "      - 28.0\n",
      "      - -7.5\n",
      "      - 12.0\n",
      "      - 24.0\n",
      "      - 3.5\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 13.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 19.0\n",
      "      - -5.5\n",
      "      - 4.5\n",
      "      - 2.0\n",
      "      - 18.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 25.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 9.0\n",
      "      - 36.5\n",
      "      - 32.5\n",
      "      - 10.0\n",
      "      - 16.0\n",
      "      - 9.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 24.5\n",
      "      - 15.0\n",
      "      - 23.0\n",
      "      - 11.5\n",
      "      - 36.5\n",
      "      - 28.0\n",
      "      - 20.0\n",
      "      - 14.0\n",
      "      - 13.5\n",
      "      - 27.0\n",
      "      - 15.5\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 26.5\n",
      "      - 38.0\n",
      "      - 32.5\n",
      "      - 22.5\n",
      "      - 14.5\n",
      "      - 5.0\n",
      "      - 30.5\n",
      "      - 5.0\n",
      "      - 14.5\n",
      "      - 26.0\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 24.0\n",
      "      - 13.0\n",
      "      - -6.0\n",
      "      - 23.0\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 13.0\n",
      "      - 21.0\n",
      "      - 15.0\n",
      "      - 7.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 19.5\n",
      "      - 19.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000026\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999923\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.2999999999999927\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999993\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000286\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.300000000000004\n",
      "      - -6.6999999999999815\n",
      "      - -5.59999999999999\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000003\n",
      "      - -3.400000000000003\n",
      "      - -6.699999999999991\n",
      "      - -5.599999999999993\n",
      "      - -3.4000000000000057\n",
      "      - -3.400000000000004\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -1.200000000000002\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999984\n",
      "      - -2.3000000000000047\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000028\n",
      "      - -7.799999999999987\n",
      "      - -4.499999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -4.500000000000003\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 1.0\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999987\n",
      "      - 2.100000000000002\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000464\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999986\n",
      "      - 7.60000000000001\n",
      "      - -8.899999999999983\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -5.6\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999954\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999847\n",
      "      - -6.699999999999988\n",
      "      - -7.79999999999999\n",
      "      - -3.400000000000006\n",
      "      - -2.3\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000056\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000006\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999993\n",
      "      - 8.700000000000014\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -3.4000000000000057\n",
      "      - -4.4999999999999885\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -6.699999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999993\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.0\n",
      "      policy2: 8.700000000000014\n",
      "    policy_reward_mean:\n",
      "      policy1: 15.495\n",
      "      policy2: -6.116999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -7.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18006513759551582\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07706372918077568\n",
      "      mean_inference_ms: 1.9149464462147194\n",
      "      mean_raw_obs_processing_ms: 0.3546914290639467\n",
      "  time_since_restore: 261.089457988739\n",
      "  time_this_iter_s: 21.131559133529663\n",
      "  time_total_s: 261.089457988739\n",
      "  timers:\n",
      "    learn_throughput: 391.862\n",
      "    learn_time_ms: 10207.688\n",
      "    synch_weights_time_ms: 4.052\n",
      "    training_iteration_time_ms: 21221.963\n",
      "  timestamp: 1658917321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 13\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 112000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_env_steps_sampled: 56000\n",
      "    num_env_steps_trained: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-01\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.099999999999916\n",
      "  episode_reward_mean: 14.930999999999957\n",
      "  episode_reward_min: -2.3999999999999955\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 560\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.9060572385787964\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01250305213034153\n",
      "          model: {}\n",
      "          policy_loss: -0.033173516392707825\n",
      "          total_loss: 6.887732028961182\n",
      "          vf_explained_var: 0.26672542095184326\n",
      "          vf_loss: 6.917154788970947\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8907146453857422\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014259804971516132\n",
      "          model: {}\n",
      "          policy_loss: -0.03495679050683975\n",
      "          total_loss: 3.9453375339508057\n",
      "          vf_explained_var: 0.08629368245601654\n",
      "          vf_loss: 3.9774422645568848\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_env_steps_sampled: 56000\n",
      "    num_env_steps_trained: 56000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 112000\n",
      "  num_agent_steps_trained: 112000\n",
      "  num_env_steps_sampled: 56000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 56000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.9483870967742\n",
      "    ram_util_percent: 61.232258064516124\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 36.0\n",
      "    policy2: 51.59999999999997\n",
      "  policy_reward_mean:\n",
      "    policy1: 17.935\n",
      "    policy2: -3.003999999999993\n",
      "  policy_reward_min:\n",
      "    policy1: -39.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.176830400584535\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07574515027198056\n",
      "    mean_inference_ms: 1.8554019923351666\n",
      "    mean_raw_obs_processing_ms: 0.3466184777521771\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.099999999999916\n",
      "    episode_reward_mean: 14.930999999999957\n",
      "    episode_reward_min: -2.3999999999999955\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 13.19999999999996\n",
      "      - 20.69999999999994\n",
      "      - 32.099999999999916\n",
      "      - 10.799999999999935\n",
      "      - 23.399999999999906\n",
      "      - 6.899999999999963\n",
      "      - 10.200000000000024\n",
      "      - 20.09999999999998\n",
      "      - 22.1999999999999\n",
      "      - 10.200000000000026\n",
      "      - 8.999999999999986\n",
      "      - 9.900000000000022\n",
      "      - 1.5000000000000187\n",
      "      - 26.999999999999922\n",
      "      - 23.099999999999902\n",
      "      - 14.399999999999912\n",
      "      - 25.199999999999907\n",
      "      - 1.8000000000000114\n",
      "      - 29.9999999999999\n",
      "      - 12.600000000000014\n",
      "      - 16.19999999999991\n",
      "      - 11.69999999999995\n",
      "      - 9.899999999999963\n",
      "      - 18.899999999999913\n",
      "      - -2.3999999999999955\n",
      "      - 15.299999999999912\n",
      "      - 15.599999999999914\n",
      "      - 14.099999999999982\n",
      "      - 8.99999999999996\n",
      "      - 6.2999999999999705\n",
      "      - 17.399999999999952\n",
      "      - 12.899999999999947\n",
      "      - 14.69999999999992\n",
      "      - 21.299999999999912\n",
      "      - 23.999999999999968\n",
      "      - 7.799999999999953\n",
      "      - 15.899999999999972\n",
      "      - 18.59999999999996\n",
      "      - 16.499999999999897\n",
      "      - 15.3\n",
      "      - 6.300000000000022\n",
      "      - 15.299999999999962\n",
      "      - 3.300000000000032\n",
      "      - 10.800000000000031\n",
      "      - 15.5999999999999\n",
      "      - 5.400000000000004\n",
      "      - 13.50000000000003\n",
      "      - 17.39999999999992\n",
      "      - 16.19999999999999\n",
      "      - 20.999999999999922\n",
      "      - 6.000000000000014\n",
      "      - 17.099999999999945\n",
      "      - 6.900000000000016\n",
      "      - -0.9000000000000163\n",
      "      - 10.500000000000025\n",
      "      - 28.499999999999908\n",
      "      - 14.400000000000025\n",
      "      - 11.999999999999998\n",
      "      - 12.299999999999931\n",
      "      - 15.899999999999993\n",
      "      - 16.4999999999999\n",
      "      - 21.29999999999996\n",
      "      - 12.299999999999923\n",
      "      - 20.9999999999999\n",
      "      - 16.799999999999905\n",
      "      - 28.199999999999925\n",
      "      - 14.999999999999961\n",
      "      - 15.299999999999972\n",
      "      - 4.199999999999998\n",
      "      - 18.599999999999937\n",
      "      - 13.199999999999928\n",
      "      - 7.499999999999977\n",
      "      - 27.899999999999892\n",
      "      - 14.999999999999954\n",
      "      - 1.7999999999999616\n",
      "      - 22.499999999999954\n",
      "      - 15.599999999999925\n",
      "      - 18.59999999999993\n",
      "      - 15.299999999999908\n",
      "      - 16.799999999999912\n",
      "      - 7.500000000000027\n",
      "      - 16.19999999999991\n",
      "      - 20.699999999999903\n",
      "      - 12.599999999999913\n",
      "      - 11.999999999999988\n",
      "      - 7.500000000000025\n",
      "      - 18.89999999999992\n",
      "      - 10.199999999999964\n",
      "      - 23.39999999999993\n",
      "      - 22.199999999999946\n",
      "      - 16.499999999999954\n",
      "      - 17.69999999999999\n",
      "      - 9.00000000000003\n",
      "      - 20.099999999999994\n",
      "      - 21.599999999999895\n",
      "      - 14.699999999999923\n",
      "      - 16.800000000000026\n",
      "      - 22.199999999999903\n",
      "      - 9.899999999999984\n",
      "      - 19.1999999999999\n",
      "      policy_policy1_reward:\n",
      "      - 21.0\n",
      "      - 28.5\n",
      "      - 30.0\n",
      "      - 12.0\n",
      "      - 29.0\n",
      "      - 12.5\n",
      "      - -4.0\n",
      "      - 29.0\n",
      "      - 24.5\n",
      "      - 12.5\n",
      "      - 13.5\n",
      "      - 15.5\n",
      "      - 11.5\n",
      "      - 31.5\n",
      "      - 32.0\n",
      "      - 20.0\n",
      "      - 33.0\n",
      "      - 3.0\n",
      "      - 29.0\n",
      "      - -39.0\n",
      "      - 24.0\n",
      "      - 14.0\n",
      "      - 10.0\n",
      "      - 24.5\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 19.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 13.0\n",
      "      - 23.0\n",
      "      - 18.5\n",
      "      - 22.5\n",
      "      - 22.5\n",
      "      - 34.0\n",
      "      - 3.5\n",
      "      - 21.5\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 22.0\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 5.5\n",
      "      - 18.0\n",
      "      - 23.0\n",
      "      - 18.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 12.5\n",
      "      - 2.5\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 21.0\n",
      "      - 28.0\n",
      "      - 19.0\n",
      "      - 25.5\n",
      "      - 23.5\n",
      "      - 36.0\n",
      "      - 25.0\n",
      "      - 22.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 12.0\n",
      "      - 33.5\n",
      "      - 19.5\n",
      "      - 8.5\n",
      "      - 21.5\n",
      "      - 24.5\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 12.5\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 0.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 15.5\n",
      "      - 25.5\n",
      "      - 13.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 17.0\n",
      "      - 18.0\n",
      "      - 24.5\n",
      "      - 15.5\n",
      "      - 27.0\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999983\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999997\n",
      "      - -1.2000000000000017\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999982\n",
      "      - 14.199999999999996\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -2.300000000000003\n",
      "      - -4.499999999999998\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -4.4999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999988\n",
      "      - -1.2000000000000046\n",
      "      - 0.9999999999999948\n",
      "      - 51.59999999999997\n",
      "      - -7.7999999999999865\n",
      "      - -2.3000000000000043\n",
      "      - -0.09999999999999765\n",
      "      - -5.599999999999991\n",
      "      - -3.400000000000005\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999986\n",
      "      - 2.0999999999999943\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999995\n",
      "      - -5.599999999999988\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000042\n",
      "      - -9.99999999999998\n",
      "      - 4.300000000000004\n",
      "      - -5.599999999999983\n",
      "      - -3.400000000000001\n",
      "      - -4.5000000000000036\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999986\n",
      "      - -1.2000000000000042\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - -3.400000000000003\n",
      "      - -0.10000000000000464\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999998\n",
      "      - -2.300000000000003\n",
      "      - 0.9999999999999952\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999853\n",
      "      - -5.599999999999998\n",
      "      - -3.3999999999999964\n",
      "      - -4.500000000000002\n",
      "      - 0.9999999999999974\n",
      "      - -0.10000000000000009\n",
      "      - -4.499999999999993\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - -4.499999999999991\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999992\n",
      "      - -4.49999999999999\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 3.200000000000001\n",
      "      - -3.400000000000007\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999988\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -6.6999999999999815\n",
      "      - 1.000000000000007\n",
      "      - -8.89999999999998\n",
      "      - 7.600000000000011\n",
      "      - -6.6999999999999815\n",
      "      - 4.299999999999999\n",
      "      - 0.9999999999999979\n",
      "      - -2.3\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999986\n",
      "      - 12.000000000000016\n",
      "      - -4.499999999999992\n",
      "      - -0.10000000000000286\n",
      "      - 3.2000000000000046\n",
      "      - 10.900000000000016\n",
      "      - 3.1999999999999984\n",
      "      - 0.999999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999996\n",
      "      - 7.600000000000007\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -1.199999999999986\n",
      "      - -2.300000000000006\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 36.0\n",
      "      policy2: 51.59999999999997\n",
      "    policy_reward_mean:\n",
      "      policy1: 17.935\n",
      "      policy2: -3.003999999999993\n",
      "    policy_reward_min:\n",
      "      policy1: -39.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.176830400584535\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07574515027198056\n",
      "      mean_inference_ms: 1.8554019923351666\n",
      "      mean_raw_obs_processing_ms: 0.3466184777521771\n",
      "  time_since_restore: 271.8927183151245\n",
      "  time_this_iter_s: 20.968719244003296\n",
      "  time_total_s: 271.8927183151245\n",
      "  timers:\n",
      "    learn_throughput: 392.691\n",
      "    learn_time_ms: 10186.135\n",
      "    synch_weights_time_ms: 10.837\n",
      "    training_iteration_time_ms: 21299.318\n",
      "  timestamp: 1658917321\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 114000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 114000\n",
      "    num_agent_steps_trained: 114000\n",
      "    num_env_steps_sampled: 57000\n",
      "    num_env_steps_trained: 57000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-12\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 37.79999999999992\n",
      "  episode_reward_mean: 19.250999999999948\n",
      "  episode_reward_min: 1.1999999999999962\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 570\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8165506720542908\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013039949350059032\n",
      "          model: {}\n",
      "          policy_loss: -0.041601527482271194\n",
      "          total_loss: 7.608661651611328\n",
      "          vf_explained_var: 0.08596038818359375\n",
      "          vf_loss: 7.647655010223389\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6627693176269531\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01268936786800623\n",
      "          model: {}\n",
      "          policy_loss: -0.036256711930036545\n",
      "          total_loss: 3.3243014812469482\n",
      "          vf_explained_var: 0.10654602199792862\n",
      "          vf_loss: 3.3592891693115234\n",
      "    num_agent_steps_sampled: 114000\n",
      "    num_agent_steps_trained: 114000\n",
      "    num_env_steps_sampled: 57000\n",
      "    num_env_steps_trained: 57000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 114000\n",
      "  num_agent_steps_trained: 114000\n",
      "  num_env_steps_sampled: 57000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 57000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.26086956521739\n",
      "    ram_util_percent: 59.67391304347825\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 44.5\n",
      "    policy2: 10.899999999999997\n",
      "  policy_reward_mean:\n",
      "    policy1: 24.675\n",
      "    policy2: -5.423999999999993\n",
      "  policy_reward_min:\n",
      "    policy1: 0.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17675139603762982\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07768200935814396\n",
      "    mean_inference_ms: 1.8676382046880053\n",
      "    mean_raw_obs_processing_ms: 0.3480107568598876\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 37.79999999999992\n",
      "    episode_reward_mean: 19.250999999999948\n",
      "    episode_reward_min: 1.1999999999999962\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 24.599999999999913\n",
      "      - 8.100000000000025\n",
      "      - 13.799999999999992\n",
      "      - 18.599999999999902\n",
      "      - 16.799999999999976\n",
      "      - 26.3999999999999\n",
      "      - 2.100000000000011\n",
      "      - 12.899999999999935\n",
      "      - 19.49999999999992\n",
      "      - 29.399999999999906\n",
      "      - 8.399999999999956\n",
      "      - 25.199999999999932\n",
      "      - 16.79999999999996\n",
      "      - 31.19999999999993\n",
      "      - 12.29999999999997\n",
      "      - 13.499999999999945\n",
      "      - 13.799999999999962\n",
      "      - 27.899999999999938\n",
      "      - 11.099999999999925\n",
      "      - 20.700000000000017\n",
      "      - 18.599999999999973\n",
      "      - 26.69999999999991\n",
      "      - 26.39999999999993\n",
      "      - 15.899999999999997\n",
      "      - 6.600000000000019\n",
      "      - 13.799999999999924\n",
      "      - 23.09999999999998\n",
      "      - 12.600000000000014\n",
      "      - 21.299999999999905\n",
      "      - 24.299999999999923\n",
      "      - 25.4999999999999\n",
      "      - 23.999999999999893\n",
      "      - 29.999999999999915\n",
      "      - 20.699999999999896\n",
      "      - 15.89999999999993\n",
      "      - 14.699999999999923\n",
      "      - 24.899999999999903\n",
      "      - 21.000000000000004\n",
      "      - 15.59999999999996\n",
      "      - 16.199999999999967\n",
      "      - 11.699999999999955\n",
      "      - 1.1999999999999962\n",
      "      - 10.799999999999997\n",
      "      - 20.399999999999906\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 11.099999999999946\n",
      "      - 15.9\n",
      "      - 15.899999999999944\n",
      "      - 11.699999999999987\n",
      "      - 29.099999999999923\n",
      "      - 12.599999999999959\n",
      "      - 32.39999999999991\n",
      "      - 13.199999999999996\n",
      "      - 25.499999999999943\n",
      "      - 25.499999999999893\n",
      "      - 13.499999999999973\n",
      "      - 22.199999999999907\n",
      "      - 16.499999999999908\n",
      "      - 31.19999999999991\n",
      "      - 8.099999999999978\n",
      "      - 9.00000000000002\n",
      "      - 4.7999999999999865\n",
      "      - 12.599999999999996\n",
      "      - 12.599999999999914\n",
      "      - 25.199999999999903\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 13.799999999999937\n",
      "      - 18.599999999999973\n",
      "      - 28.499999999999904\n",
      "      - 18.899999999999967\n",
      "      - 20.69999999999991\n",
      "      - 12.89999999999997\n",
      "      - 7.500000000000027\n",
      "      - 22.499999999999925\n",
      "      - 6.599999999999964\n",
      "      - 37.79999999999992\n",
      "      - 23.099999999999895\n",
      "      - 19.199999999999967\n",
      "      - 4.199999999999971\n",
      "      - 16.500000000000007\n",
      "      - 32.099999999999895\n",
      "      - 23.999999999999915\n",
      "      - 27.599999999999916\n",
      "      - 22.499999999999893\n",
      "      - 29.699999999999896\n",
      "      - 19.499999999999922\n",
      "      - 19.799999999999926\n",
      "      - 27.299999999999912\n",
      "      - 26.99999999999995\n",
      "      - 30.59999999999993\n",
      "      - 12.299999999999972\n",
      "      - 22.499999999999943\n",
      "      - 13.200000000000006\n",
      "      - 26.999999999999925\n",
      "      - 31.799999999999898\n",
      "      - 23.999999999999986\n",
      "      - 22.499999999999908\n",
      "      - 25.499999999999908\n",
      "      policy_policy1_reward:\n",
      "      - 33.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 23.5\n",
      "      - 32.0\n",
      "      - 0.0\n",
      "      - 18.5\n",
      "      - 24.0\n",
      "      - 35.0\n",
      "      - 8.5\n",
      "      - 33.0\n",
      "      - 18.0\n",
      "      - 39.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 20.5\n",
      "      - 33.5\n",
      "      - 20.0\n",
      "      - 28.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 15.5\n",
      "      - 16.0\n",
      "      - 4.5\n",
      "      - 20.5\n",
      "      - 26.5\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 25.5\n",
      "      - 30.0\n",
      "      - 34.0\n",
      "      - 40.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 17.0\n",
      "      - 30.5\n",
      "      - 25.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 29.0\n",
      "      - 32.5\n",
      "      - 20.0\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 19.5\n",
      "      - 32.5\n",
      "      - 16.0\n",
      "      - 27.0\n",
      "      - 21.0\n",
      "      - 30.0\n",
      "      - 35.5\n",
      "      - 23.5\n",
      "      - 30.0\n",
      "      - 15.5\n",
      "      - 39.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 27.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 38.5\n",
      "      - 24.5\n",
      "      - 28.5\n",
      "      - 13.0\n",
      "      - 17.5\n",
      "      - 32.5\n",
      "      - 10.0\n",
      "      - 44.5\n",
      "      - 26.5\n",
      "      - 27.0\n",
      "      - 1.0\n",
      "      - 26.5\n",
      "      - 35.5\n",
      "      - 34.0\n",
      "      - 31.0\n",
      "      - 32.5\n",
      "      - 37.5\n",
      "      - 24.0\n",
      "      - 26.5\n",
      "      - 28.5\n",
      "      - 31.5\n",
      "      - 34.0\n",
      "      - 19.0\n",
      "      - 27.0\n",
      "      - 15.5\n",
      "      - 26.0\n",
      "      - 38.5\n",
      "      - 34.0\n",
      "      - 27.0\n",
      "      - 35.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999998\n",
      "      - -0.10000000000000153\n",
      "      - -7.799999999999986\n",
      "      - -1.2000000000000035\n",
      "      - -7.799999999999984\n",
      "      - -6.699999999999983\n",
      "      - -4.500000000000002\n",
      "      - -6.699999999999994\n",
      "      - -5.599999999999984\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - 10.899999999999997\n",
      "      - -0.09999999999999254\n",
      "      - 2.099999999999996\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999986\n",
      "      - -1.200000000000004\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999988\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000052\n",
      "      - -2.3000000000000025\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999895\n",
      "      - -5.599999999999999\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999991\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -3.400000000000005\n",
      "      - -3.4000000000000057\n",
      "      - 5.4000000000000075\n",
      "      - -7.79999999999999\n",
      "      - -4.5000000000000036\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999966\n",
      "      - -7.79999999999999\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999993\n",
      "      - -3.4000000000000066\n",
      "      - -8.89999999999998\n",
      "      - -2.299999999999991\n",
      "      - -5.599999999999991\n",
      "      - -4.499999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000242\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000004\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000044\n",
      "      - -7.799999999999985\n",
      "      - 3.200000000000002\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000005\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999994\n",
      "      - -6.699999999999994\n",
      "      - -1.1999999999999997\n",
      "      - -4.499999999999983\n",
      "      - -3.4000000000000044\n",
      "      - -6.699999999999987\n",
      "      - -4.500000000000002\n",
      "      - -2.2999999999999856\n",
      "      - 1.0000000000000029\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999996\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 44.5\n",
      "      policy2: 10.899999999999997\n",
      "    policy_reward_mean:\n",
      "      policy1: 24.675\n",
      "      policy2: -5.423999999999993\n",
      "    policy_reward_min:\n",
      "      policy1: 0.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17675139603762982\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07768200935814396\n",
      "      mean_inference_ms: 1.8676382046880053\n",
      "      mean_raw_obs_processing_ms: 0.3480107568598876\n",
      "  time_since_restore: 279.062038898468\n",
      "  time_this_iter_s: 16.178383827209473\n",
      "  time_total_s: 279.062038898468\n",
      "  timers:\n",
      "    learn_throughput: 373.704\n",
      "    learn_time_ms: 8027.735\n",
      "    synch_weights_time_ms: 9.296\n",
      "    training_iteration_time_ms: 16731.365\n",
      "  timestamp: 1658917332\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57000\n",
      "  training_iteration: 19\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 114000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 114000\n",
      "    num_agent_steps_trained: 114000\n",
      "    num_env_steps_sampled: 57000\n",
      "    num_env_steps_trained: 57000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-13\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.2999999999999\n",
      "  episode_reward_mean: 12.560999999999973\n",
      "  episode_reward_min: -13.199999999999976\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 570\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8065294027328491\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.020479340106248856\n",
      "          model: {}\n",
      "          policy_loss: -0.054049666970968246\n",
      "          total_loss: 6.815600395202637\n",
      "          vf_explained_var: 0.11960592120885849\n",
      "          vf_loss: 6.860434532165527\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7601019740104675\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016272583976387978\n",
      "          model: {}\n",
      "          policy_loss: -0.03962133824825287\n",
      "          total_loss: 3.753347396850586\n",
      "          vf_explained_var: 0.07547309994697571\n",
      "          vf_loss: 3.785646677017212\n",
      "    num_agent_steps_sampled: 114000\n",
      "    num_agent_steps_trained: 114000\n",
      "    num_env_steps_sampled: 57000\n",
      "    num_env_steps_trained: 57000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 114000\n",
      "  num_agent_steps_trained: 114000\n",
      "  num_env_steps_sampled: 57000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 57000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 66.73043478260868\n",
      "    ram_util_percent: 59.75652173913042\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 28.49999999999999\n",
      "  policy_reward_mean:\n",
      "    policy1: 16.39\n",
      "    policy2: -3.8289999999999895\n",
      "  policy_reward_min:\n",
      "    policy1: -22.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1804397178086781\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07684737186486044\n",
      "    mean_inference_ms: 1.8982641373030895\n",
      "    mean_raw_obs_processing_ms: 0.35539153727402595\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.2999999999999\n",
      "    episode_reward_mean: 12.560999999999973\n",
      "    episode_reward_min: -13.199999999999976\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 12.599999999999905\n",
      "      - 10.199999999999998\n",
      "      - 5.099999999999998\n",
      "      - 19.49999999999998\n",
      "      - -5.699999999999982\n",
      "      - 16.199999999999935\n",
      "      - 5.400000000000016\n",
      "      - 17.399999999999935\n",
      "      - 21.29999999999997\n",
      "      - 15.59999999999994\n",
      "      - 22.499999999999908\n",
      "      - 9.59999999999996\n",
      "      - -1.7999999999999847\n",
      "      - 13.20000000000003\n",
      "      - 15.299999999999972\n",
      "      - 14.399999999999956\n",
      "      - 15.599999999999918\n",
      "      - 11.09999999999993\n",
      "      - 14.39999999999994\n",
      "      - 7.800000000000031\n",
      "      - 15.60000000000003\n",
      "      - 7.499999999999989\n",
      "      - 10.499999999999952\n",
      "      - -1.499999999999981\n",
      "      - 20.699999999999946\n",
      "      - 5.700000000000008\n",
      "      - -0.29999999999998084\n",
      "      - 8.100000000000032\n",
      "      - 10.500000000000012\n",
      "      - 5.10000000000002\n",
      "      - 14.699999999999973\n",
      "      - 2.4000000000000132\n",
      "      - 23.699999999999914\n",
      "      - 39.2999999999999\n",
      "      - 25.499999999999893\n",
      "      - -13.199999999999976\n",
      "      - 9.600000000000028\n",
      "      - 5.999999999999998\n",
      "      - 17.999999999999982\n",
      "      - 12.900000000000025\n",
      "      - 22.799999999999905\n",
      "      - 17.999999999999936\n",
      "      - 17.99999999999993\n",
      "      - 7.200000000000015\n",
      "      - 15.299999999999994\n",
      "      - 8.700000000000026\n",
      "      - -3.2999999999999847\n",
      "      - 16.500000000000007\n",
      "      - 18.299999999999983\n",
      "      - 15.29999999999998\n",
      "      - 20.999999999999908\n",
      "      - 11.099999999999989\n",
      "      - 7.499999999999938\n",
      "      - 8.09999999999992\n",
      "      - 3.0000000000000244\n",
      "      - 15.000000000000004\n",
      "      - 37.19999999999994\n",
      "      - 11.09999999999995\n",
      "      - 10.8\n",
      "      - 30.29999999999991\n",
      "      - 20.69999999999994\n",
      "      - 13.799999999999912\n",
      "      - 11.099999999999921\n",
      "      - 6.000000000000018\n",
      "      - 17.699999999999946\n",
      "      - 12.299999999999935\n",
      "      - 10.799999999999933\n",
      "      - 14.100000000000035\n",
      "      - 11.999999999999979\n",
      "      - 7.200000000000026\n",
      "      - 21.29999999999996\n",
      "      - 27.299999999999912\n",
      "      - 11.399999999999975\n",
      "      - 15.89999999999995\n",
      "      - 13.500000000000009\n",
      "      - 5.700000000000019\n",
      "      - 13.199999999999989\n",
      "      - 2.1000000000000245\n",
      "      - 11.100000000000021\n",
      "      - -0.8999999999999886\n",
      "      - 19.1999999999999\n",
      "      - 17.999999999999957\n",
      "      - 18.89999999999992\n",
      "      - -0.2999999999999968\n",
      "      - -6.899999999999972\n",
      "      - 15.599999999999971\n",
      "      - 12.600000000000025\n",
      "      - 12.299999999999962\n",
      "      - 12.59999999999991\n",
      "      - 8.699999999999935\n",
      "      - 29.999999999999893\n",
      "      - 20.09999999999993\n",
      "      - -5.099999999999985\n",
      "      - 15.899999999999947\n",
      "      - 17.999999999999925\n",
      "      - 17.999999999999964\n",
      "      - 13.500000000000016\n",
      "      - 14.399999999999988\n",
      "      - 14.999999999999956\n",
      "      - 6.9000000000000234\n",
      "      policy_policy1_reward:\n",
      "      - 21.5\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 29.5\n",
      "      - 1.0\n",
      "      - 24.0\n",
      "      - 11.0\n",
      "      - 12.0\n",
      "      - 22.5\n",
      "      - 13.5\n",
      "      - 21.5\n",
      "      - 18.5\n",
      "      - 6.0\n",
      "      - 21.0\n",
      "      - 22.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 14.5\n",
      "      - 14.5\n",
      "      - 13.5\n",
      "      - -15.5\n",
      "      - 20.5\n",
      "      - 8.5\n",
      "      - 23.0\n",
      "      - 13.5\n",
      "      - 7.5\n",
      "      - 17.0\n",
      "      - 15.0\n",
      "      - 14.0\n",
      "      - 22.5\n",
      "      - 2.5\n",
      "      - 26.0\n",
      "      - 46.0\n",
      "      - 35.5\n",
      "      - -6.5\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 28.0\n",
      "      - 18.5\n",
      "      - 29.5\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 16.5\n",
      "      - 16.5\n",
      "      - -6.5\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 3.5\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 7.5\n",
      "      - 19.5\n",
      "      - 39.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 37.0\n",
      "      - 28.5\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - -22.5\n",
      "      - 20.0\n",
      "      - 8.0\n",
      "      - 17.5\n",
      "      - 23.0\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      - 28.0\n",
      "      - 28.5\n",
      "      - 17.0\n",
      "      - 21.5\n",
      "      - 23.5\n",
      "      - 13.5\n",
      "      - 15.5\n",
      "      - 11.0\n",
      "      - 20.0\n",
      "      - 8.0\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 24.5\n",
      "      - -9.0\n",
      "      - 2.0\n",
      "      - 2.5\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 16.5\n",
      "      - 40.0\n",
      "      - 23.5\n",
      "      - 0.5\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 6.0\n",
      "      - -15.0\n",
      "      - 20.0\n",
      "      - 19.5\n",
      "      - 1.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999987\n",
      "      - -3.399999999999983\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - 5.4\n",
      "      - -1.2000000000000053\n",
      "      - 2.1000000000000014\n",
      "      - 1.0000000000000027\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999995\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -0.10000000000000264\n",
      "      - -6.69999999999999\n",
      "      - 2.1000000000000036\n",
      "      - 22.999999999999993\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999936\n",
      "      - -7.799999999999982\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999986\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000492\n",
      "      - -2.2999999999999954\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - 1.0000000000000022\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.699999999999984\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000033\n",
      "      - -7.799999999999982\n",
      "      - 3.1999999999999975\n",
      "      - -9.99999999999998\n",
      "      - 9.800000000000006\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999997\n",
      "      - 7.6000000000000085\n",
      "      - -4.49999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999991\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -3.399999999999983\n",
      "      - -6.699999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 28.49999999999998\n",
      "      - -2.3000000000000025\n",
      "      - 4.30000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -6.699999999999993\n",
      "      - -1.1999999999999909\n",
      "      - -5.599999999999982\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000034\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - 8.70000000000001\n",
      "      - -8.89999999999998\n",
      "      - 13.100000000000017\n",
      "      - 7.600000000000012\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -5.599999999999993\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 12.000000000000009\n",
      "      - 28.49999999999999\n",
      "      - -5.599999999999987\n",
      "      - -4.499999999999993\n",
      "      - 5.399999999999999\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 28.49999999999999\n",
      "    policy_reward_mean:\n",
      "      policy1: 16.39\n",
      "      policy2: -3.8289999999999895\n",
      "    policy_reward_min:\n",
      "      policy1: -22.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1804397178086781\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07684737186486044\n",
      "      mean_inference_ms: 1.8982641373030895\n",
      "      mean_raw_obs_processing_ms: 0.35539153727402595\n",
      "  time_since_restore: 281.0512282848358\n",
      "  time_this_iter_s: 15.90756607055664\n",
      "  time_total_s: 281.0512282848358\n",
      "  timers:\n",
      "    learn_throughput: 371.946\n",
      "    learn_time_ms: 8065.687\n",
      "    synch_weights_time_ms: 5.369\n",
      "    training_iteration_time_ms: 16850.417\n",
      "  timestamp: 1658917333\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 57000\n",
      "  training_iteration: 19\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 112000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_env_steps_sampled: 56000\n",
      "    num_env_steps_trained: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-24\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 35.69999999999993\n",
      "  episode_reward_mean: 12.191999999999972\n",
      "  episode_reward_min: -14.99999999999998\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 560\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9122447967529297\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016983574256300926\n",
      "          model: {}\n",
      "          policy_loss: -0.041594814509153366\n",
      "          total_loss: 7.195669651031494\n",
      "          vf_explained_var: 0.12491907924413681\n",
      "          vf_loss: 7.229621887207031\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.9173164367675781\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016333146020770073\n",
      "          model: {}\n",
      "          policy_loss: -0.043428197503089905\n",
      "          total_loss: 2.8732080459594727\n",
      "          vf_explained_var: 0.16057339310646057\n",
      "          vf_loss: 2.9092864990234375\n",
      "    num_agent_steps_sampled: 112000\n",
      "    num_agent_steps_trained: 112000\n",
      "    num_env_steps_sampled: 56000\n",
      "    num_env_steps_trained: 56000\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 112000\n",
      "  num_agent_steps_trained: 112000\n",
      "  num_env_steps_sampled: 56000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 56000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 69.51470588235294\n",
      "    ram_util_percent: 61.07941176470589\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 38.0\n",
      "    policy2: 15.299999999999983\n",
      "  policy_reward_mean:\n",
      "    policy1: 18.32\n",
      "    policy2: -6.1279999999999895\n",
      "  policy_reward_min:\n",
      "    policy1: -6.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18278988483534087\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0782018360326856\n",
      "    mean_inference_ms: 1.9412481109478716\n",
      "    mean_raw_obs_processing_ms: 0.3598863240334507\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 35.69999999999993\n",
      "    episode_reward_mean: 12.191999999999972\n",
      "    episode_reward_min: -14.99999999999998\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - -6.899999999999981\n",
      "      - 12.899999999999995\n",
      "      - 1.1999999999999633\n",
      "      - 7.800000000000033\n",
      "      - 18.299999999999912\n",
      "      - 14.099999999999941\n",
      "      - -6.899999999999996\n",
      "      - 6.59999999999998\n",
      "      - 15.59999999999993\n",
      "      - 1.200000000000003\n",
      "      - 27.59999999999991\n",
      "      - 22.499999999999893\n",
      "      - 3.300000000000032\n",
      "      - 12.60000000000002\n",
      "      - 10.499999999999961\n",
      "      - 1.2000000000000235\n",
      "      - 14.39999999999996\n",
      "      - 15.599999999999914\n",
      "      - 18.8999999999999\n",
      "      - 17.099999999999994\n",
      "      - 14.099999999999945\n",
      "      - 11.399999999999968\n",
      "      - 27.599999999999937\n",
      "      - 21.299999999999947\n",
      "      - 27.59999999999995\n",
      "      - 5.1\n",
      "      - 8.999999999999943\n",
      "      - 19.199999999999946\n",
      "      - 9.899999999999958\n",
      "      - 10.799999999999988\n",
      "      - 23.699999999999914\n",
      "      - 16.50000000000002\n",
      "      - 35.69999999999993\n",
      "      - 25.799999999999912\n",
      "      - 14.699999999999946\n",
      "      - 11.099999999999927\n",
      "      - 2.6999999999999935\n",
      "      - 21.599999999999902\n",
      "      - 2.700000000000028\n",
      "      - 7.79999999999996\n",
      "      - 17.099999999999973\n",
      "      - 6.60000000000001\n",
      "      - 0.3000000000000227\n",
      "      - 19.499999999999993\n",
      "      - 6.300000000000033\n",
      "      - 2.7000000000000175\n",
      "      - 17.399999999999913\n",
      "      - 6.299999999999976\n",
      "      - 8.700000000000019\n",
      "      - 9.59999999999995\n",
      "      - 16.49999999999995\n",
      "      - 7.200000000000026\n",
      "      - -2.999999999999972\n",
      "      - 12.299999999999923\n",
      "      - 19.799999999999926\n",
      "      - -1.4999999999999862\n",
      "      - 7.499999999999995\n",
      "      - 15.599999999999975\n",
      "      - 11.700000000000033\n",
      "      - 8.999999999999924\n",
      "      - 16.199999999999932\n",
      "      - 5.100000000000016\n",
      "      - -2.999999999999987\n",
      "      - -4.499999999999982\n",
      "      - 12.299999999999924\n",
      "      - 14.699999999999962\n",
      "      - -2.914335439641036e-15\n",
      "      - 9.300000000000027\n",
      "      - 19.499999999999975\n",
      "      - 8.099999999999978\n",
      "      - 18.599999999999923\n",
      "      - 26.099999999999945\n",
      "      - 26.099999999999916\n",
      "      - 21.599999999999902\n",
      "      - -14.99999999999998\n",
      "      - 16.799999999999912\n",
      "      - 12.600000000000026\n",
      "      - 0.30000000000000937\n",
      "      - 8.100000000000032\n",
      "      - 6.29999999999999\n",
      "      - 25.499999999999908\n",
      "      - 16.199999999999932\n",
      "      - 25.49999999999993\n",
      "      - 21.599999999999937\n",
      "      - -5.399999999999972\n",
      "      - -11.399999999999975\n",
      "      - 19.49999999999995\n",
      "      - 22.19999999999998\n",
      "      - 22.79999999999994\n",
      "      - 16.49999999999995\n",
      "      - 14.999999999999938\n",
      "      - 8.699999999999969\n",
      "      - 11.400000000000032\n",
      "      - 15.899999999999986\n",
      "      - 18.599999999999945\n",
      "      - 16.500000000000007\n",
      "      - 27.29999999999992\n",
      "      - 12.000000000000034\n",
      "      - 12.000000000000028\n",
      "      - 14.099999999999934\n",
      "      policy_policy1_reward:\n",
      "      - 2.0\n",
      "      - 18.5\n",
      "      - 9.0\n",
      "      - 14.5\n",
      "      - 25.0\n",
      "      - 23.0\n",
      "      - 2.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 9.0\n",
      "      - 36.5\n",
      "      - 32.5\n",
      "      - 10.0\n",
      "      - 16.0\n",
      "      - 9.5\n",
      "      - 9.0\n",
      "      - 20.0\n",
      "      - 24.5\n",
      "      - 24.5\n",
      "      - 15.0\n",
      "      - 23.0\n",
      "      - 11.5\n",
      "      - 36.5\n",
      "      - 28.0\n",
      "      - 20.0\n",
      "      - 14.0\n",
      "      - 13.5\n",
      "      - 27.0\n",
      "      - 15.5\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 26.5\n",
      "      - 38.0\n",
      "      - 32.5\n",
      "      - 22.5\n",
      "      - 14.5\n",
      "      - 5.0\n",
      "      - 30.5\n",
      "      - 5.0\n",
      "      - 14.5\n",
      "      - 26.0\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 24.0\n",
      "      - 13.0\n",
      "      - -6.0\n",
      "      - 23.0\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 13.0\n",
      "      - 21.0\n",
      "      - 15.0\n",
      "      - 7.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 19.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 14.0\n",
      "      - 7.0\n",
      "      - 5.5\n",
      "      - 19.0\n",
      "      - 22.5\n",
      "      - 10.0\n",
      "      - 16.0\n",
      "      - 29.5\n",
      "      - 17.0\n",
      "      - 27.5\n",
      "      - 35.0\n",
      "      - 35.0\n",
      "      - 25.0\n",
      "      - -5.0\n",
      "      - 18.0\n",
      "      - 21.5\n",
      "      - 7.0\n",
      "      - 17.0\n",
      "      - 13.0\n",
      "      - 35.5\n",
      "      - 24.0\n",
      "      - 35.5\n",
      "      - 30.5\n",
      "      - 3.5\n",
      "      - -2.5\n",
      "      - 29.5\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 21.0\n",
      "      - 8.5\n",
      "      - 16.5\n",
      "      - 17.0\n",
      "      - 21.5\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999994\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999995\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999984\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999989\n",
      "      - -8.899999999999984\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 1.0\n",
      "      - -7.79999999999999\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999987\n",
      "      - 2.100000000000002\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000464\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999986\n",
      "      - 7.60000000000001\n",
      "      - -8.899999999999983\n",
      "      - -4.500000000000002\n",
      "      - -7.799999999999981\n",
      "      - -5.6\n",
      "      - -6.6999999999999815\n",
      "      - -2.2999999999999954\n",
      "      - -9.99999999999998\n",
      "      - -2.2999999999999847\n",
      "      - -6.699999999999988\n",
      "      - -7.79999999999999\n",
      "      - -3.400000000000006\n",
      "      - -2.3\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000056\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000006\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999993\n",
      "      - 8.700000000000014\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -3.4000000000000057\n",
      "      - -4.4999999999999885\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -6.699999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999993\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -3.4000000000000017\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000037\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - 15.299999999999983\n",
      "      - -4.499999999999992\n",
      "      - 6.500000000000001\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999996\n",
      "      - -3.400000000000002\n",
      "      - -4.499999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999939\n",
      "      - -3.400000000000004\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.0\n",
      "      policy2: 15.299999999999983\n",
      "    policy_reward_mean:\n",
      "      policy1: 18.32\n",
      "      policy2: -6.1279999999999895\n",
      "    policy_reward_min:\n",
      "      policy1: -6.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18278988483534087\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0782018360326856\n",
      "      mean_inference_ms: 1.9412481109478716\n",
      "      mean_raw_obs_processing_ms: 0.3598863240334507\n",
      "  time_since_restore: 284.5990219116211\n",
      "  time_this_iter_s: 23.50956392288208\n",
      "  time_total_s: 284.5990219116211\n",
      "  timers:\n",
      "    learn_throughput: 384.036\n",
      "    learn_time_ms: 10415.697\n",
      "    synch_weights_time_ms: 4.463\n",
      "    training_iteration_time_ms: 21854.799\n",
      "  timestamp: 1658917344\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 14\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 120000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-25\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.99999999999992\n",
      "  episode_reward_mean: 14.741999999999956\n",
      "  episode_reward_min: -2.0999999999999748\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 600\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8726131916046143\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011619922704994678\n",
      "          model: {}\n",
      "          policy_loss: -0.03320620208978653\n",
      "          total_loss: 7.3104352951049805\n",
      "          vf_explained_var: 0.264553040266037\n",
      "          vf_loss: 7.340155601501465\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8628222346305847\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014857974834740162\n",
      "          model: {}\n",
      "          policy_loss: -0.03666728362441063\n",
      "          total_loss: 3.4875030517578125\n",
      "          vf_explained_var: 0.14306388795375824\n",
      "          vf_loss: 3.5211985111236572\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 60000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 70.31176470588235\n",
      "    ram_util_percent: 61.3764705882353\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 37.5\n",
      "    policy2: 12.000000000000016\n",
      "  policy_reward_mean:\n",
      "    policy1: 18.065\n",
      "    policy2: -3.322999999999992\n",
      "  policy_reward_min:\n",
      "    policy1: 0.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17984312632596017\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07695515707840656\n",
      "    mean_inference_ms: 1.8870411694410156\n",
      "    mean_raw_obs_processing_ms: 0.35298225946914386\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.99999999999992\n",
      "    episode_reward_mean: 14.741999999999956\n",
      "    episode_reward_min: -2.0999999999999748\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 6.300000000000022\n",
      "      - 15.299999999999962\n",
      "      - 3.300000000000032\n",
      "      - 10.800000000000031\n",
      "      - 15.5999999999999\n",
      "      - 5.400000000000004\n",
      "      - 13.50000000000003\n",
      "      - 17.39999999999992\n",
      "      - 16.19999999999999\n",
      "      - 20.999999999999922\n",
      "      - 6.000000000000014\n",
      "      - 17.099999999999945\n",
      "      - 6.900000000000016\n",
      "      - -0.9000000000000163\n",
      "      - 10.500000000000025\n",
      "      - 28.499999999999908\n",
      "      - 14.400000000000025\n",
      "      - 11.999999999999998\n",
      "      - 12.299999999999931\n",
      "      - 15.899999999999993\n",
      "      - 16.4999999999999\n",
      "      - 21.29999999999996\n",
      "      - 12.299999999999923\n",
      "      - 20.9999999999999\n",
      "      - 16.799999999999905\n",
      "      - 28.199999999999925\n",
      "      - 14.999999999999961\n",
      "      - 15.299999999999972\n",
      "      - 4.199999999999998\n",
      "      - 18.599999999999937\n",
      "      - 13.199999999999928\n",
      "      - 7.499999999999977\n",
      "      - 27.899999999999892\n",
      "      - 14.999999999999954\n",
      "      - 1.7999999999999616\n",
      "      - 22.499999999999954\n",
      "      - 15.599999999999925\n",
      "      - 18.59999999999993\n",
      "      - 15.299999999999908\n",
      "      - 16.799999999999912\n",
      "      - 7.500000000000027\n",
      "      - 16.19999999999991\n",
      "      - 20.699999999999903\n",
      "      - 12.599999999999913\n",
      "      - 11.999999999999988\n",
      "      - 7.500000000000025\n",
      "      - 18.89999999999992\n",
      "      - 10.199999999999964\n",
      "      - 23.39999999999993\n",
      "      - 22.199999999999946\n",
      "      - 16.499999999999954\n",
      "      - 17.69999999999999\n",
      "      - 9.00000000000003\n",
      "      - 20.099999999999994\n",
      "      - 21.599999999999895\n",
      "      - 14.699999999999923\n",
      "      - 16.800000000000026\n",
      "      - 22.199999999999903\n",
      "      - 9.899999999999984\n",
      "      - 19.1999999999999\n",
      "      - 19.499999999999936\n",
      "      - 12.299999999999917\n",
      "      - 17.399999999999913\n",
      "      - 32.99999999999992\n",
      "      - 17.09999999999991\n",
      "      - 8.999999999999915\n",
      "      - 24.599999999999916\n",
      "      - 13.500000000000028\n",
      "      - 15.9\n",
      "      - 15.59999999999992\n",
      "      - 14.09999999999993\n",
      "      - 18.599999999999945\n",
      "      - 13.199999999999939\n",
      "      - 9.899999999999979\n",
      "      - 12.000000000000002\n",
      "      - 8.400000000000027\n",
      "      - -2.0999999999999748\n",
      "      - 15.599999999999918\n",
      "      - 2.70000000000003\n",
      "      - 20.69999999999996\n",
      "      - 20.699999999999896\n",
      "      - 15.299999999999969\n",
      "      - 2.400000000000012\n",
      "      - 11.99999999999995\n",
      "      - 12.00000000000002\n",
      "      - 25.199999999999953\n",
      "      - 14.100000000000025\n",
      "      - 3.599999999999955\n",
      "      - 13.200000000000001\n",
      "      - 11.09999999999995\n",
      "      - 17.99999999999997\n",
      "      - 3.299999999999997\n",
      "      - 19.79999999999992\n",
      "      - 20.699999999999953\n",
      "      - 9.000000000000025\n",
      "      - 21.899999999999935\n",
      "      - 29.09999999999991\n",
      "      - 15.599999999999968\n",
      "      - 9.59999999999995\n",
      "      - 16.799999999999912\n",
      "      policy_policy1_reward:\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 10.0\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 5.5\n",
      "      - 18.0\n",
      "      - 23.0\n",
      "      - 18.5\n",
      "      - 20.0\n",
      "      - 16.0\n",
      "      - 20.5\n",
      "      - 12.5\n",
      "      - 2.5\n",
      "      - 15.0\n",
      "      - 27.5\n",
      "      - 14.5\n",
      "      - 16.5\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 21.0\n",
      "      - 28.0\n",
      "      - 19.0\n",
      "      - 25.5\n",
      "      - 23.5\n",
      "      - 36.0\n",
      "      - 25.0\n",
      "      - 22.0\n",
      "      - 1.0\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 12.0\n",
      "      - 33.5\n",
      "      - 19.5\n",
      "      - 8.5\n",
      "      - 21.5\n",
      "      - 24.5\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 12.5\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 0.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 15.5\n",
      "      - 25.5\n",
      "      - 13.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 17.0\n",
      "      - 18.0\n",
      "      - 24.5\n",
      "      - 15.5\n",
      "      - 27.0\n",
      "      - 24.0\n",
      "      - 8.0\n",
      "      - 17.5\n",
      "      - 37.5\n",
      "      - 26.0\n",
      "      - 13.5\n",
      "      - 28.0\n",
      "      - 23.5\n",
      "      - 21.5\n",
      "      - 19.0\n",
      "      - 6.5\n",
      "      - 27.5\n",
      "      - 15.5\n",
      "      - 15.5\n",
      "      - 16.5\n",
      "      - 8.5\n",
      "      - 3.5\n",
      "      - 19.0\n",
      "      - 5.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 22.0\n",
      "      - 8.0\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 33.0\n",
      "      - 6.5\n",
      "      - 12.5\n",
      "      - 21.0\n",
      "      - 14.5\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 26.5\n",
      "      - 28.5\n",
      "      - 13.5\n",
      "      - 27.5\n",
      "      - 32.5\n",
      "      - 24.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      policy_policy2_reward:\n",
      "      - -6.699999999999986\n",
      "      - -1.2000000000000042\n",
      "      - -6.6999999999999815\n",
      "      - -6.6999999999999895\n",
      "      - -3.400000000000003\n",
      "      - -0.10000000000000464\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999998\n",
      "      - -2.300000000000003\n",
      "      - 0.9999999999999952\n",
      "      - -9.99999999999998\n",
      "      - -3.3999999999999853\n",
      "      - -5.599999999999998\n",
      "      - -3.3999999999999964\n",
      "      - -4.500000000000002\n",
      "      - 0.9999999999999974\n",
      "      - -0.10000000000000009\n",
      "      - -4.499999999999993\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999998\n",
      "      - -4.499999999999991\n",
      "      - -6.699999999999984\n",
      "      - -6.699999999999992\n",
      "      - -4.49999999999999\n",
      "      - -6.699999999999995\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 3.200000000000001\n",
      "      - -3.400000000000007\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999988\n",
      "      - -5.599999999999993\n",
      "      - -4.499999999999997\n",
      "      - -6.6999999999999815\n",
      "      - 1.000000000000007\n",
      "      - -8.89999999999998\n",
      "      - 7.600000000000011\n",
      "      - -6.6999999999999815\n",
      "      - 4.299999999999999\n",
      "      - 0.9999999999999979\n",
      "      - -2.3\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999986\n",
      "      - 12.000000000000016\n",
      "      - -4.499999999999992\n",
      "      - -0.10000000000000286\n",
      "      - 3.2000000000000046\n",
      "      - 10.900000000000016\n",
      "      - 3.1999999999999984\n",
      "      - 0.999999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999996\n",
      "      - 7.600000000000007\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -1.199999999999986\n",
      "      - -2.300000000000006\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 4.299999999999998\n",
      "      - -0.09999999999999232\n",
      "      - -4.4999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000044\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -3.4000000000000026\n",
      "      - 7.600000000000012\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000025\n",
      "      - -5.6\n",
      "      - -4.500000000000003\n",
      "      - -0.10000000000000342\n",
      "      - -5.6\n",
      "      - -3.3999999999999897\n",
      "      - -2.29999999999999\n",
      "      - 3.199999999999996\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999988\n",
      "      - -5.599999999999987\n",
      "      - 0.9999999999999974\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 7.600000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4000000000000057\n",
      "      - 6.500000000000014\n",
      "      - -1.1999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999982\n",
      "      - -5.599999999999982\n",
      "      - -3.4000000000000044\n",
      "      - -8.899999999999983\n",
      "      - 2.099999999999995\n",
      "      - -1.199999999999993\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 37.5\n",
      "      policy2: 12.000000000000016\n",
      "    policy_reward_mean:\n",
      "      policy1: 18.065\n",
      "      policy2: -3.322999999999992\n",
      "    policy_reward_min:\n",
      "      policy1: 0.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17984312632596017\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07695515707840656\n",
      "      mean_inference_ms: 1.8870411694410156\n",
      "      mean_raw_obs_processing_ms: 0.35298225946914386\n",
      "  time_since_restore: 295.8088002204895\n",
      "  time_this_iter_s: 23.91608190536499\n",
      "  time_total_s: 295.8088002204895\n",
      "  timers:\n",
      "    learn_throughput: 385.117\n",
      "    learn_time_ms: 10386.443\n",
      "    synch_weights_time_ms: 11.388\n",
      "    training_iteration_time_ms: 21968.37\n",
      "  timestamp: 1658917345\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00000:\n",
      "  agent_timesteps_total: 120000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-33\n",
      "  done: true\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 37.79999999999992\n",
      "  episode_reward_mean: 20.141999999999936\n",
      "  episode_reward_min: 1.1999999999999962\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 600\n",
      "  experiment_id: dddc0988b52440af8e96f1d839fcaa67\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7705796360969543\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013689862564206123\n",
      "          model: {}\n",
      "          policy_loss: -0.04113609343767166\n",
      "          total_loss: 7.155774116516113\n",
      "          vf_explained_var: 0.08909749239683151\n",
      "          vf_loss: 7.194171905517578\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.10000000149011612\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.6475610733032227\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014202267862856388\n",
      "          model: {}\n",
      "          policy_loss: -0.034183092415332794\n",
      "          total_loss: 3.982307195663452\n",
      "          vf_explained_var: 0.05957954376935959\n",
      "          vf_loss: 4.01507043838501\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 60000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 67.86333333333334\n",
      "    ram_util_percent: 63.29333333333332\n",
      "  pid: 48430\n",
      "  policy_reward_max:\n",
      "    policy1: 44.5\n",
      "    policy2: 13.100000000000012\n",
      "  policy_reward_mean:\n",
      "    policy1: 25.445\n",
      "    policy2: -5.302999999999992\n",
      "  policy_reward_min:\n",
      "    policy1: 1.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1792618983566972\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07872861952804393\n",
      "    mean_inference_ms: 1.8914599851870588\n",
      "    mean_raw_obs_processing_ms: 0.35285135472266377\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 37.79999999999992\n",
      "    episode_reward_mean: 20.141999999999936\n",
      "    episode_reward_min: 1.1999999999999962\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 25.4999999999999\n",
      "      - 23.999999999999893\n",
      "      - 29.999999999999915\n",
      "      - 20.699999999999896\n",
      "      - 15.89999999999993\n",
      "      - 14.699999999999923\n",
      "      - 24.899999999999903\n",
      "      - 21.000000000000004\n",
      "      - 15.59999999999996\n",
      "      - 16.199999999999967\n",
      "      - 11.699999999999955\n",
      "      - 1.1999999999999962\n",
      "      - 10.799999999999997\n",
      "      - 20.399999999999906\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 11.099999999999946\n",
      "      - 15.9\n",
      "      - 15.899999999999944\n",
      "      - 11.699999999999987\n",
      "      - 29.099999999999923\n",
      "      - 12.599999999999959\n",
      "      - 32.39999999999991\n",
      "      - 13.199999999999996\n",
      "      - 25.499999999999943\n",
      "      - 25.499999999999893\n",
      "      - 13.499999999999973\n",
      "      - 22.199999999999907\n",
      "      - 16.499999999999908\n",
      "      - 31.19999999999991\n",
      "      - 8.099999999999978\n",
      "      - 9.00000000000002\n",
      "      - 4.7999999999999865\n",
      "      - 12.599999999999996\n",
      "      - 12.599999999999914\n",
      "      - 25.199999999999903\n",
      "      - 23.3999999999999\n",
      "      - 22.499999999999922\n",
      "      - 13.799999999999937\n",
      "      - 18.599999999999973\n",
      "      - 28.499999999999904\n",
      "      - 18.899999999999967\n",
      "      - 20.69999999999991\n",
      "      - 12.89999999999997\n",
      "      - 7.500000000000027\n",
      "      - 22.499999999999925\n",
      "      - 6.599999999999964\n",
      "      - 37.79999999999992\n",
      "      - 23.099999999999895\n",
      "      - 19.199999999999967\n",
      "      - 4.199999999999971\n",
      "      - 16.500000000000007\n",
      "      - 32.099999999999895\n",
      "      - 23.999999999999915\n",
      "      - 27.599999999999916\n",
      "      - 22.499999999999893\n",
      "      - 29.699999999999896\n",
      "      - 19.499999999999922\n",
      "      - 19.799999999999926\n",
      "      - 27.299999999999912\n",
      "      - 26.99999999999995\n",
      "      - 30.59999999999993\n",
      "      - 12.299999999999972\n",
      "      - 22.499999999999943\n",
      "      - 13.200000000000006\n",
      "      - 26.999999999999925\n",
      "      - 31.799999999999898\n",
      "      - 23.999999999999986\n",
      "      - 22.499999999999908\n",
      "      - 25.499999999999908\n",
      "      - 23.999999999999936\n",
      "      - 9.899999999999919\n",
      "      - 19.49999999999994\n",
      "      - 23.99999999999995\n",
      "      - 11.699999999999918\n",
      "      - 23.999999999999886\n",
      "      - 17.399999999999913\n",
      "      - 23.09999999999994\n",
      "      - 18.89999999999997\n",
      "      - 34.199999999999896\n",
      "      - 15.899999999999915\n",
      "      - 26.399999999999913\n",
      "      - 20.999999999999893\n",
      "      - 25.499999999999922\n",
      "      - 26.69999999999989\n",
      "      - 17.09999999999996\n",
      "      - 24.8999999999999\n",
      "      - 29.09999999999991\n",
      "      - 23.699999999999925\n",
      "      - 25.799999999999912\n",
      "      - 25.199999999999946\n",
      "      - 20.999999999999915\n",
      "      - 18.899999999999928\n",
      "      - 27.599999999999945\n",
      "      - 16.499999999999957\n",
      "      - 16.499999999999936\n",
      "      - 11.099999999999937\n",
      "      - 25.49999999999993\n",
      "      - 17.399999999999924\n",
      "      - 8.999999999999943\n",
      "      policy_policy1_reward:\n",
      "      - 30.0\n",
      "      - 34.0\n",
      "      - 40.0\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 17.0\n",
      "      - 30.5\n",
      "      - 25.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 9.0\n",
      "      - 17.5\n",
      "      - 26.0\n",
      "      - 29.0\n",
      "      - 32.5\n",
      "      - 20.0\n",
      "      - 21.5\n",
      "      - 21.5\n",
      "      - 19.5\n",
      "      - 32.5\n",
      "      - 16.0\n",
      "      - 27.0\n",
      "      - 21.0\n",
      "      - 30.0\n",
      "      - 35.5\n",
      "      - 23.5\n",
      "      - 30.0\n",
      "      - 15.5\n",
      "      - 39.0\n",
      "      - 6.0\n",
      "      - 19.0\n",
      "      - 11.5\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 29.0\n",
      "      - 27.0\n",
      "      - 20.5\n",
      "      - 27.5\n",
      "      - 38.5\n",
      "      - 24.5\n",
      "      - 28.5\n",
      "      - 13.0\n",
      "      - 17.5\n",
      "      - 32.5\n",
      "      - 10.0\n",
      "      - 44.5\n",
      "      - 26.5\n",
      "      - 27.0\n",
      "      - 1.0\n",
      "      - 26.5\n",
      "      - 35.5\n",
      "      - 34.0\n",
      "      - 31.0\n",
      "      - 32.5\n",
      "      - 37.5\n",
      "      - 24.0\n",
      "      - 26.5\n",
      "      - 28.5\n",
      "      - 31.5\n",
      "      - 34.0\n",
      "      - 19.0\n",
      "      - 27.0\n",
      "      - 15.5\n",
      "      - 26.0\n",
      "      - 38.5\n",
      "      - 34.0\n",
      "      - 27.0\n",
      "      - 35.5\n",
      "      - 34.0\n",
      "      - 15.5\n",
      "      - 18.5\n",
      "      - 23.0\n",
      "      - 19.5\n",
      "      - 34.0\n",
      "      - 23.0\n",
      "      - 26.5\n",
      "      - 24.5\n",
      "      - 42.0\n",
      "      - 16.0\n",
      "      - 32.0\n",
      "      - 25.5\n",
      "      - 30.0\n",
      "      - 34.5\n",
      "      - 4.0\n",
      "      - 30.5\n",
      "      - 38.0\n",
      "      - 15.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 25.5\n",
      "      - 24.5\n",
      "      - 25.5\n",
      "      - 26.5\n",
      "      - 26.5\n",
      "      - 20.0\n",
      "      - 35.5\n",
      "      - 23.0\n",
      "      - 19.0\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999997\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999982\n",
      "      - -2.3000000000000043\n",
      "      - -5.599999999999988\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000052\n",
      "      - -2.3000000000000025\n",
      "      - -7.799999999999981\n",
      "      - -7.799999999999989\n",
      "      - -6.6999999999999895\n",
      "      - -5.599999999999999\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999991\n",
      "      - -5.599999999999999\n",
      "      - -7.79999999999999\n",
      "      - -3.400000000000005\n",
      "      - -3.4000000000000057\n",
      "      - 5.4000000000000075\n",
      "      - -7.79999999999999\n",
      "      - -4.5000000000000036\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999966\n",
      "      - -7.79999999999999\n",
      "      - 2.099999999999997\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999993\n",
      "      - -3.4000000000000066\n",
      "      - -8.89999999999998\n",
      "      - -2.299999999999991\n",
      "      - -5.599999999999991\n",
      "      - -4.499999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000242\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000004\n",
      "      - -6.699999999999986\n",
      "      - -3.4000000000000044\n",
      "      - -7.799999999999985\n",
      "      - 3.200000000000002\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000052\n",
      "      - -9.99999999999998\n",
      "      - -3.400000000000005\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999994\n",
      "      - -6.699999999999994\n",
      "      - -1.1999999999999997\n",
      "      - -4.499999999999983\n",
      "      - -3.4000000000000044\n",
      "      - -6.699999999999987\n",
      "      - -4.500000000000002\n",
      "      - -2.2999999999999856\n",
      "      - 1.0000000000000029\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -4.499999999999996\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - 0.9999999999999943\n",
      "      - 1.000000000000004\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999986\n",
      "      - -3.4000000000000035\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999989\n",
      "      - -0.10000000000000142\n",
      "      - -5.599999999999982\n",
      "      - -4.499999999999995\n",
      "      - -4.500000000000003\n",
      "      - -7.79999999999999\n",
      "      - 13.100000000000012\n",
      "      - -5.599999999999999\n",
      "      - -8.89999999999998\n",
      "      - 8.699999999999996\n",
      "      - 4.300000000000022\n",
      "      - -2.3000000000000043\n",
      "      - -4.499999999999993\n",
      "      - -5.599999999999991\n",
      "      - 2.0999999999999965\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999999\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 44.5\n",
      "      policy2: 13.100000000000012\n",
      "    policy_reward_mean:\n",
      "      policy1: 25.445\n",
      "      policy2: -5.302999999999992\n",
      "    policy_reward_min:\n",
      "      policy1: 1.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1792618983566972\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07872861952804393\n",
      "      mean_inference_ms: 1.8914599851870588\n",
      "      mean_raw_obs_processing_ms: 0.35285135472266377\n",
      "  time_since_restore: 299.7298729419708\n",
      "  time_this_iter_s: 20.667834043502808\n",
      "  time_total_s: 299.7298729419708\n",
      "  timers:\n",
      "    learn_throughput: 374.164\n",
      "    learn_time_ms: 8017.866\n",
      "    synch_weights_time_ms: 8.895\n",
      "    training_iteration_time_ms: 17346.639\n",
      "  timestamp: 1658917353\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 20\n",
      "  trial_id: 1dedd_00000\n",
      "  warmup_time: 12.642973899841309\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00001:\n",
      "  agent_timesteps_total: 120000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-34\n",
      "  done: true\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.2999999999999\n",
      "  episode_reward_mean: 12.524999999999975\n",
      "  episode_reward_min: -13.199999999999976\n",
      "  episodes_this_iter: 30\n",
      "  episodes_total: 600\n",
      "  experiment_id: 5ce86766e6df4bbc883c7489a2650206\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.675000011920929\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7923619747161865\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014257634058594704\n",
      "          model: {}\n",
      "          policy_loss: -0.050688572227954865\n",
      "          total_loss: 6.784381866455078\n",
      "          vf_explained_var: 0.011525950394570827\n",
      "          vf_loss: 6.825446128845215\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7678247094154358\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.019669318571686745\n",
      "          model: {}\n",
      "          policy_loss: -0.05298725143074989\n",
      "          total_loss: 2.8456969261169434\n",
      "          vf_explained_var: 0.14976643025875092\n",
      "          vf_loss: 2.889833688735962\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_sampled_this_iter: 3000\n",
      "  num_env_steps_trained: 60000\n",
      "  num_env_steps_trained_this_iter: 3000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 3000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 75.17333333333335\n",
      "    ram_util_percent: 63.38999999999999\n",
      "  pid: 48438\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 28.49999999999999\n",
      "  policy_reward_mean:\n",
      "    policy1: 16.585\n",
      "    policy2: -4.059999999999991\n",
      "  policy_reward_min:\n",
      "    policy1: -22.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18274265861023703\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07778952739403566\n",
      "    mean_inference_ms: 1.9211366260496368\n",
      "    mean_raw_obs_processing_ms: 0.3595487678218501\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.2999999999999\n",
      "    episode_reward_mean: 12.524999999999975\n",
      "    episode_reward_min: -13.199999999999976\n",
      "    episodes_this_iter: 30\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 14.699999999999973\n",
      "      - 2.4000000000000132\n",
      "      - 23.699999999999914\n",
      "      - 39.2999999999999\n",
      "      - 25.499999999999893\n",
      "      - -13.199999999999976\n",
      "      - 9.600000000000028\n",
      "      - 5.999999999999998\n",
      "      - 17.999999999999982\n",
      "      - 12.900000000000025\n",
      "      - 22.799999999999905\n",
      "      - 17.999999999999936\n",
      "      - 17.99999999999993\n",
      "      - 7.200000000000015\n",
      "      - 15.299999999999994\n",
      "      - 8.700000000000026\n",
      "      - -3.2999999999999847\n",
      "      - 16.500000000000007\n",
      "      - 18.299999999999983\n",
      "      - 15.29999999999998\n",
      "      - 20.999999999999908\n",
      "      - 11.099999999999989\n",
      "      - 7.499999999999938\n",
      "      - 8.09999999999992\n",
      "      - 3.0000000000000244\n",
      "      - 15.000000000000004\n",
      "      - 37.19999999999994\n",
      "      - 11.09999999999995\n",
      "      - 10.8\n",
      "      - 30.29999999999991\n",
      "      - 20.69999999999994\n",
      "      - 13.799999999999912\n",
      "      - 11.099999999999921\n",
      "      - 6.000000000000018\n",
      "      - 17.699999999999946\n",
      "      - 12.299999999999935\n",
      "      - 10.799999999999933\n",
      "      - 14.100000000000035\n",
      "      - 11.999999999999979\n",
      "      - 7.200000000000026\n",
      "      - 21.29999999999996\n",
      "      - 27.299999999999912\n",
      "      - 11.399999999999975\n",
      "      - 15.89999999999995\n",
      "      - 13.500000000000009\n",
      "      - 5.700000000000019\n",
      "      - 13.199999999999989\n",
      "      - 2.1000000000000245\n",
      "      - 11.100000000000021\n",
      "      - -0.8999999999999886\n",
      "      - 19.1999999999999\n",
      "      - 17.999999999999957\n",
      "      - 18.89999999999992\n",
      "      - -0.2999999999999968\n",
      "      - -6.899999999999972\n",
      "      - 15.599999999999971\n",
      "      - 12.600000000000025\n",
      "      - 12.299999999999962\n",
      "      - 12.59999999999991\n",
      "      - 8.699999999999935\n",
      "      - 29.999999999999893\n",
      "      - 20.09999999999993\n",
      "      - -5.099999999999985\n",
      "      - 15.899999999999947\n",
      "      - 17.999999999999925\n",
      "      - 17.999999999999964\n",
      "      - 13.500000000000016\n",
      "      - 14.399999999999988\n",
      "      - 14.999999999999956\n",
      "      - 6.9000000000000234\n",
      "      - -2.999999999999982\n",
      "      - 20.099999999999987\n",
      "      - -9.599999999999984\n",
      "      - 0.6000000000000273\n",
      "      - 1.200000000000013\n",
      "      - 15.899999999999944\n",
      "      - 7.200000000000021\n",
      "      - 12.600000000000026\n",
      "      - 12.300000000000031\n",
      "      - 9.299999999999955\n",
      "      - -2.999999999999981\n",
      "      - 8.699999999999994\n",
      "      - 9.599999999999966\n",
      "      - 3.300000000000023\n",
      "      - 17.39999999999992\n",
      "      - 15.900000000000007\n",
      "      - 19.19999999999992\n",
      "      - 23.399999999999938\n",
      "      - 18.000000000000014\n",
      "      - -0.5999999999999833\n",
      "      - 5.400000000000006\n",
      "      - 5.100000000000002\n",
      "      - 21.599999999999945\n",
      "      - 34.19999999999998\n",
      "      - 9.600000000000014\n",
      "      - 14.99999999999991\n",
      "      - 11.099999999999929\n",
      "      - 16.19999999999999\n",
      "      - 7.800000000000027\n",
      "      - 13.50000000000001\n",
      "      policy_policy1_reward:\n",
      "      - 22.5\n",
      "      - 2.5\n",
      "      - 26.0\n",
      "      - 46.0\n",
      "      - 35.5\n",
      "      - -6.5\n",
      "      - 18.5\n",
      "      - 5.0\n",
      "      - 28.0\n",
      "      - 18.5\n",
      "      - 29.5\n",
      "      - 22.5\n",
      "      - 28.0\n",
      "      - 15.0\n",
      "      - 16.5\n",
      "      - 16.5\n",
      "      - -6.5\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 22.0\n",
      "      - 25.5\n",
      "      - 3.5\n",
      "      - 12.0\n",
      "      - 17.0\n",
      "      - 7.5\n",
      "      - 19.5\n",
      "      - 39.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 37.0\n",
      "      - 28.5\n",
      "      - 20.5\n",
      "      - 14.5\n",
      "      - -22.5\n",
      "      - 20.0\n",
      "      - 8.0\n",
      "      - 17.5\n",
      "      - 23.0\n",
      "      - 22.0\n",
      "      - 15.0\n",
      "      - 28.0\n",
      "      - 28.5\n",
      "      - 17.0\n",
      "      - 21.5\n",
      "      - 23.5\n",
      "      - 13.5\n",
      "      - 15.5\n",
      "      - 11.0\n",
      "      - 20.0\n",
      "      - 8.0\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 24.5\n",
      "      - -9.0\n",
      "      - 2.0\n",
      "      - 2.5\n",
      "      - 5.0\n",
      "      - 19.0\n",
      "      - 21.5\n",
      "      - 16.5\n",
      "      - 40.0\n",
      "      - 23.5\n",
      "      - 0.5\n",
      "      - 21.5\n",
      "      - 28.0\n",
      "      - 6.0\n",
      "      - -15.0\n",
      "      - 20.0\n",
      "      - 19.5\n",
      "      - 1.5\n",
      "      - 1.5\n",
      "      - 29.0\n",
      "      - -4.0\n",
      "      - 9.5\n",
      "      - 9.0\n",
      "      - 16.0\n",
      "      - 15.0\n",
      "      - 21.5\n",
      "      - 13.5\n",
      "      - 10.5\n",
      "      - 1.5\n",
      "      - 16.5\n",
      "      - 18.5\n",
      "      - 4.5\n",
      "      - 23.0\n",
      "      - 21.5\n",
      "      - 27.0\n",
      "      - 23.5\n",
      "      - 22.5\n",
      "      - 5.0\n",
      "      - 5.5\n",
      "      - 8.5\n",
      "      - 30.5\n",
      "      - 36.5\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 20.0\n",
      "      - 24.0\n",
      "      - 9.0\n",
      "      - 23.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000492\n",
      "      - -2.2999999999999954\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - 1.0000000000000022\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999995\n",
      "      - -6.699999999999984\n",
      "      - -4.499999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.79999999999999\n",
      "      - -1.2000000000000033\n",
      "      - -7.799999999999982\n",
      "      - 3.1999999999999975\n",
      "      - -9.99999999999998\n",
      "      - 9.800000000000006\n",
      "      - -6.699999999999982\n",
      "      - -4.499999999999997\n",
      "      - 7.6000000000000085\n",
      "      - -4.49999999999999\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999991\n",
      "      - -4.499999999999998\n",
      "      - -2.3000000000000056\n",
      "      - -3.399999999999983\n",
      "      - -6.699999999999994\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -3.400000000000005\n",
      "      - 28.49999999999998\n",
      "      - -2.3000000000000025\n",
      "      - 4.30000000000002\n",
      "      - -6.699999999999995\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -6.699999999999993\n",
      "      - -1.1999999999999909\n",
      "      - -5.599999999999982\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -2.3000000000000034\n",
      "      - -8.899999999999986\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - 8.70000000000001\n",
      "      - -8.89999999999998\n",
      "      - 13.100000000000017\n",
      "      - 7.600000000000012\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.79999999999999\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -5.599999999999993\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - 12.000000000000009\n",
      "      - 28.49999999999999\n",
      "      - -5.599999999999987\n",
      "      - -4.499999999999993\n",
      "      - 5.399999999999999\n",
      "      - -4.499999999999988\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -0.10000000000000298\n",
      "      - -7.799999999999981\n",
      "      - -8.89999999999998\n",
      "      - -1.2000000000000048\n",
      "      - -1.200000000000004\n",
      "      - -4.500000000000001\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -1.1999999999999964\n",
      "      - -5.599999999999982\n",
      "      - -5.599999999999986\n",
      "      - -7.799999999999989\n",
      "      - -0.09999999999999765\n",
      "      - -4.499999999999991\n",
      "      - -5.599999999999982\n",
      "      - -0.10000000000000375\n",
      "      - -3.400000000000004\n",
      "      - -8.89999999999998\n",
      "      - -2.3000000000000043\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -1.1999999999999977\n",
      "      - -9.99999999999998\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 28.49999999999999\n",
      "    policy_reward_mean:\n",
      "      policy1: 16.585\n",
      "      policy2: -4.059999999999991\n",
      "    policy_reward_min:\n",
      "      policy1: -22.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18274265861023703\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07778952739403566\n",
      "      mean_inference_ms: 1.9211366260496368\n",
      "      mean_raw_obs_processing_ms: 0.3595487678218501\n",
      "  time_since_restore: 301.6047673225403\n",
      "  time_this_iter_s: 20.553539037704468\n",
      "  time_total_s: 301.6047673225403\n",
      "  timers:\n",
      "    learn_throughput: 374.625\n",
      "    learn_time_ms: 8008.015\n",
      "    synch_weights_time_ms: 5.081\n",
      "    training_iteration_time_ms: 17417.422\n",
      "  timestamp: 1658917354\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 20\n",
      "  trial_id: 1dedd_00001\n",
      "  warmup_time: 12.453135013580322\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 120000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 34.49999999999993\n",
      "  episode_reward_mean: 13.037999999999977\n",
      "  episode_reward_min: -14.99999999999998\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 600\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8768475651741028\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016584523022174835\n",
      "          model: {}\n",
      "          policy_loss: -0.04217934235930443\n",
      "          total_loss: 6.749269485473633\n",
      "          vf_explained_var: 0.22471733391284943\n",
      "          vf_loss: 6.7839860916137695\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8825547695159912\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016592834144830704\n",
      "          model: {}\n",
      "          policy_loss: -0.04186544567346573\n",
      "          total_loss: 3.007169246673584\n",
      "          vf_explained_var: 0.0826554000377655\n",
      "          vf_loss: 3.0415682792663574\n",
      "    num_agent_steps_sampled: 120000\n",
      "    num_agent_steps_trained: 120000\n",
      "    num_env_steps_sampled: 60000\n",
      "    num_env_steps_trained: 60000\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 120000\n",
      "  num_agent_steps_trained: 120000\n",
      "  num_env_steps_sampled: 60000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 60000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 59.14666666666666\n",
      "    ram_util_percent: 64.74\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 44.5\n",
      "    policy2: 15.299999999999983\n",
      "  policy_reward_mean:\n",
      "    policy1: 18.77\n",
      "    policy2: -5.731999999999989\n",
      "  policy_reward_min:\n",
      "    policy1: -6.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18536887593468454\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07918280350776573\n",
      "    mean_inference_ms: 1.9626351621202371\n",
      "    mean_raw_obs_processing_ms: 0.36453579640227707\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 34.49999999999993\n",
      "    episode_reward_mean: 13.037999999999977\n",
      "    episode_reward_min: -14.99999999999998\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 17.099999999999973\n",
      "      - 6.60000000000001\n",
      "      - 0.3000000000000227\n",
      "      - 19.499999999999993\n",
      "      - 6.300000000000033\n",
      "      - 2.7000000000000175\n",
      "      - 17.399999999999913\n",
      "      - 6.299999999999976\n",
      "      - 8.700000000000019\n",
      "      - 9.59999999999995\n",
      "      - 16.49999999999995\n",
      "      - 7.200000000000026\n",
      "      - -2.999999999999972\n",
      "      - 12.299999999999923\n",
      "      - 19.799999999999926\n",
      "      - -1.4999999999999862\n",
      "      - 7.499999999999995\n",
      "      - 15.599999999999975\n",
      "      - 11.700000000000033\n",
      "      - 8.999999999999924\n",
      "      - 16.199999999999932\n",
      "      - 5.100000000000016\n",
      "      - -2.999999999999987\n",
      "      - -4.499999999999982\n",
      "      - 12.299999999999924\n",
      "      - 14.699999999999962\n",
      "      - -2.914335439641036e-15\n",
      "      - 9.300000000000027\n",
      "      - 19.499999999999975\n",
      "      - 8.099999999999978\n",
      "      - 18.599999999999923\n",
      "      - 26.099999999999945\n",
      "      - 26.099999999999916\n",
      "      - 21.599999999999902\n",
      "      - -14.99999999999998\n",
      "      - 16.799999999999912\n",
      "      - 12.600000000000026\n",
      "      - 0.30000000000000937\n",
      "      - 8.100000000000032\n",
      "      - 6.29999999999999\n",
      "      - 25.499999999999908\n",
      "      - 16.199999999999932\n",
      "      - 25.49999999999993\n",
      "      - 21.599999999999937\n",
      "      - -5.399999999999972\n",
      "      - -11.399999999999975\n",
      "      - 19.49999999999995\n",
      "      - 22.19999999999998\n",
      "      - 22.79999999999994\n",
      "      - 16.49999999999995\n",
      "      - 14.999999999999938\n",
      "      - 8.699999999999969\n",
      "      - 11.400000000000032\n",
      "      - 15.899999999999986\n",
      "      - 18.599999999999945\n",
      "      - 16.500000000000007\n",
      "      - 27.29999999999992\n",
      "      - 12.000000000000034\n",
      "      - 12.000000000000028\n",
      "      - 14.099999999999934\n",
      "      - 2.1000000000000267\n",
      "      - 34.49999999999993\n",
      "      - 22.5\n",
      "      - 16.19999999999992\n",
      "      - 15.299999999999986\n",
      "      - 14.700000000000015\n",
      "      - 11.700000000000014\n",
      "      - 23.999999999999908\n",
      "      - 14.099999999999923\n",
      "      - 15.900000000000011\n",
      "      - 4.500000000000025\n",
      "      - 15.599999999999934\n",
      "      - 2.399999999999983\n",
      "      - 7.199999999999953\n",
      "      - 16.199999999999974\n",
      "      - 18.899999999999913\n",
      "      - 10.199999999999994\n",
      "      - 8.400000000000016\n",
      "      - 10.500000000000021\n",
      "      - 15.599999999999996\n",
      "      - 8.999999999999963\n",
      "      - 14.399999999999972\n",
      "      - 32.69999999999991\n",
      "      - 11.100000000000014\n",
      "      - 10.800000000000013\n",
      "      - 7.1999999999999815\n",
      "      - 9.900000000000025\n",
      "      - 15.599999999999973\n",
      "      - 23.3999999999999\n",
      "      - 11.999999999999982\n",
      "      - 21.900000000000006\n",
      "      - 18.89999999999995\n",
      "      - 20.69999999999994\n",
      "      - 29.399999999999963\n",
      "      - 29.999999999999915\n",
      "      - 16.799999999999947\n",
      "      - 2.1000000000000214\n",
      "      - 11.699999999999948\n",
      "      - 16.499999999999947\n",
      "      - 15.899999999999986\n",
      "      policy_policy1_reward:\n",
      "      - 26.0\n",
      "      - 10.0\n",
      "      - 7.0\n",
      "      - 24.0\n",
      "      - 13.0\n",
      "      - -6.0\n",
      "      - 23.0\n",
      "      - 13.0\n",
      "      - 16.5\n",
      "      - 13.0\n",
      "      - 21.0\n",
      "      - 15.0\n",
      "      - 7.0\n",
      "      - 19.0\n",
      "      - 26.5\n",
      "      - 8.5\n",
      "      - 17.5\n",
      "      - 19.0\n",
      "      - 19.5\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 14.0\n",
      "      - 7.0\n",
      "      - 5.5\n",
      "      - 19.0\n",
      "      - 22.5\n",
      "      - 10.0\n",
      "      - 16.0\n",
      "      - 29.5\n",
      "      - 17.0\n",
      "      - 27.5\n",
      "      - 35.0\n",
      "      - 35.0\n",
      "      - 25.0\n",
      "      - -5.0\n",
      "      - 18.0\n",
      "      - 21.5\n",
      "      - 7.0\n",
      "      - 17.0\n",
      "      - 13.0\n",
      "      - 35.5\n",
      "      - 24.0\n",
      "      - 35.5\n",
      "      - 30.5\n",
      "      - 3.5\n",
      "      - -2.5\n",
      "      - 29.5\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 21.0\n",
      "      - 8.5\n",
      "      - 16.5\n",
      "      - 17.0\n",
      "      - 21.5\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      - 5.5\n",
      "      - 44.5\n",
      "      - 27.0\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 17.0\n",
      "      - 19.5\n",
      "      - 23.0\n",
      "      - 17.5\n",
      "      - 21.5\n",
      "      - 14.5\n",
      "      - 24.5\n",
      "      - 8.0\n",
      "      - 15.0\n",
      "      - 13.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 15.0\n",
      "      - 19.0\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 40.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 29.0\n",
      "      - 16.5\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 35.0\n",
      "      - 40.0\n",
      "      - 23.5\n",
      "      - 11.0\n",
      "      - 19.5\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      policy_policy2_reward:\n",
      "      - -8.89999999999998\n",
      "      - -3.400000000000006\n",
      "      - -6.6999999999999815\n",
      "      - -4.499999999999999\n",
      "      - -6.699999999999993\n",
      "      - 8.700000000000014\n",
      "      - -5.599999999999982\n",
      "      - -6.6999999999999815\n",
      "      - -7.79999999999999\n",
      "      - -3.4000000000000057\n",
      "      - -4.4999999999999885\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -6.699999999999992\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -3.399999999999993\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000034\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999989\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999986\n",
      "      - -3.4000000000000017\n",
      "      - -9.99999999999998\n",
      "      - -1.2000000000000037\n",
      "      - -8.89999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999995\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - 15.299999999999983\n",
      "      - -4.499999999999992\n",
      "      - 6.500000000000001\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999996\n",
      "      - -3.400000000000002\n",
      "      - -4.499999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999939\n",
      "      - -3.400000000000004\n",
      "      - -3.3999999999999932\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999987\n",
      "      - -2.3000000000000016\n",
      "      - -7.799999999999981\n",
      "      - 1.0000000000000044\n",
      "      - -3.4000000000000026\n",
      "      - -5.5999999999999845\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -7.79999999999999\n",
      "      - 3.200000000000007\n",
      "      - -0.10000000000000331\n",
      "      - -7.799999999999981\n",
      "      - -0.09999999999999831\n",
      "      - -4.499999999999999\n",
      "      - -3.400000000000004\n",
      "      - -4.500000000000004\n",
      "      - -0.10000000000000375\n",
      "      - -7.799999999999982\n",
      "      - -3.400000000000006\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999993\n",
      "      - -4.500000000000003\n",
      "      - -5.59999999999999\n",
      "      - -5.599999999999986\n",
      "      - 3.199999999999999\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 5.400000000000006\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 44.5\n",
      "      policy2: 15.299999999999983\n",
      "    policy_reward_mean:\n",
      "      policy1: 18.77\n",
      "      policy2: -5.731999999999989\n",
      "    policy_reward_min:\n",
      "      policy1: -6.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18536887593468454\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07918280350776573\n",
      "      mean_inference_ms: 1.9626351621202371\n",
      "      mean_raw_obs_processing_ms: 0.36453579640227707\n",
      "  time_since_restore: 305.6816928386688\n",
      "  time_this_iter_s: 21.08267092704773\n",
      "  time_total_s: 305.6816928386688\n",
      "  timers:\n",
      "    learn_throughput: 384.22\n",
      "    learn_time_ms: 10410.694\n",
      "    synch_weights_time_ms: 4.489\n",
      "    training_iteration_time_ms: 22210.43\n",
      "  timestamp: 1658917366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 60000\n",
      "  training_iteration: 15\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 128000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_env_steps_sampled: 64000\n",
      "    num_env_steps_trained: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-22-46\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.99999999999992\n",
      "  episode_reward_mean: 15.875999999999951\n",
      "  episode_reward_min: -2.0999999999999748\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 640\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8614575862884521\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01319832168519497\n",
      "          model: {}\n",
      "          policy_loss: -0.033939179033041\n",
      "          total_loss: 6.980712890625\n",
      "          vf_explained_var: 0.31793296337127686\n",
      "          vf_loss: 7.010693073272705\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.8157382607460022\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01136698853224516\n",
      "          model: {}\n",
      "          policy_loss: -0.030026094987988472\n",
      "          total_loss: 3.768040895462036\n",
      "          vf_explained_var: 0.12040721625089645\n",
      "          vf_loss: 3.7957937717437744\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_env_steps_sampled: 64000\n",
      "    num_env_steps_trained: 64000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 128000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_env_steps_sampled: 64000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 64000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.143333333333324\n",
      "    ram_util_percent: 64.68666666666667\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 14.199999999999998\n",
      "  policy_reward_mean:\n",
      "    policy1: 18.44\n",
      "    policy2: -2.563999999999993\n",
      "  policy_reward_min:\n",
      "    policy1: -5.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18235089548414515\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07799453797091185\n",
      "    mean_inference_ms: 1.9127455708287255\n",
      "    mean_raw_obs_processing_ms: 0.35822814990847646\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.99999999999992\n",
      "    episode_reward_mean: 15.875999999999951\n",
      "    episode_reward_min: -2.0999999999999748\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 7.500000000000027\n",
      "      - 16.19999999999991\n",
      "      - 20.699999999999903\n",
      "      - 12.599999999999913\n",
      "      - 11.999999999999988\n",
      "      - 7.500000000000025\n",
      "      - 18.89999999999992\n",
      "      - 10.199999999999964\n",
      "      - 23.39999999999993\n",
      "      - 22.199999999999946\n",
      "      - 16.499999999999954\n",
      "      - 17.69999999999999\n",
      "      - 9.00000000000003\n",
      "      - 20.099999999999994\n",
      "      - 21.599999999999895\n",
      "      - 14.699999999999923\n",
      "      - 16.800000000000026\n",
      "      - 22.199999999999903\n",
      "      - 9.899999999999984\n",
      "      - 19.1999999999999\n",
      "      - 19.499999999999936\n",
      "      - 12.299999999999917\n",
      "      - 17.399999999999913\n",
      "      - 32.99999999999992\n",
      "      - 17.09999999999991\n",
      "      - 8.999999999999915\n",
      "      - 24.599999999999916\n",
      "      - 13.500000000000028\n",
      "      - 15.9\n",
      "      - 15.59999999999992\n",
      "      - 14.09999999999993\n",
      "      - 18.599999999999945\n",
      "      - 13.199999999999939\n",
      "      - 9.899999999999979\n",
      "      - 12.000000000000002\n",
      "      - 8.400000000000027\n",
      "      - -2.0999999999999748\n",
      "      - 15.599999999999918\n",
      "      - 2.70000000000003\n",
      "      - 20.69999999999996\n",
      "      - 20.699999999999896\n",
      "      - 15.299999999999969\n",
      "      - 2.400000000000012\n",
      "      - 11.99999999999995\n",
      "      - 12.00000000000002\n",
      "      - 25.199999999999953\n",
      "      - 14.100000000000025\n",
      "      - 3.599999999999955\n",
      "      - 13.200000000000001\n",
      "      - 11.09999999999995\n",
      "      - 17.99999999999997\n",
      "      - 3.299999999999997\n",
      "      - 19.79999999999992\n",
      "      - 20.699999999999953\n",
      "      - 9.000000000000025\n",
      "      - 21.899999999999935\n",
      "      - 29.09999999999991\n",
      "      - 15.599999999999968\n",
      "      - 9.59999999999995\n",
      "      - 16.799999999999912\n",
      "      - 16.19999999999994\n",
      "      - 27.599999999999902\n",
      "      - 19.199999999999918\n",
      "      - 14.699999999999912\n",
      "      - 10.800000000000024\n",
      "      - 15.299999999999923\n",
      "      - 19.19999999999995\n",
      "      - 17.999999999999982\n",
      "      - 21.59999999999992\n",
      "      - 15.899999999999919\n",
      "      - 26.9999999999999\n",
      "      - 13.50000000000003\n",
      "      - 11.699999999999942\n",
      "      - 26.999999999999922\n",
      "      - 25.49999999999992\n",
      "      - 23.3999999999999\n",
      "      - 16.499999999999964\n",
      "      - 8.69999999999999\n",
      "      - 30.599999999999916\n",
      "      - 24.899999999999906\n",
      "      - 18.59999999999991\n",
      "      - 10.799999999999978\n",
      "      - 23.399999999999906\n",
      "      - 11.399999999999974\n",
      "      - 10.799999999999928\n",
      "      - 7.799999999999958\n",
      "      - 3.8999999999999857\n",
      "      - 19.799999999999955\n",
      "      - 23.399999999999906\n",
      "      - 21.599999999999902\n",
      "      - 15.599999999999932\n",
      "      - 12.899999999999945\n",
      "      - 2.9999999999999725\n",
      "      - 29.69999999999996\n",
      "      - 17.699999999999903\n",
      "      - 13.79999999999998\n",
      "      - 25.799999999999905\n",
      "      - 5.399999999999988\n",
      "      - 6.299999999999972\n",
      "      - 15.299999999999908\n",
      "      policy_policy1_reward:\n",
      "      - 6.5\n",
      "      - 18.5\n",
      "      - 28.5\n",
      "      - 21.5\n",
      "      - 0.0\n",
      "      - 12.0\n",
      "      - 19.0\n",
      "      - 7.0\n",
      "      - 12.5\n",
      "      - 19.0\n",
      "      - 15.5\n",
      "      - 25.5\n",
      "      - 13.5\n",
      "      - 12.5\n",
      "      - 30.5\n",
      "      - 17.0\n",
      "      - 18.0\n",
      "      - 24.5\n",
      "      - 15.5\n",
      "      - 27.0\n",
      "      - 24.0\n",
      "      - 8.0\n",
      "      - 17.5\n",
      "      - 37.5\n",
      "      - 26.0\n",
      "      - 13.5\n",
      "      - 28.0\n",
      "      - 23.5\n",
      "      - 21.5\n",
      "      - 19.0\n",
      "      - 6.5\n",
      "      - 27.5\n",
      "      - 15.5\n",
      "      - 15.5\n",
      "      - 16.5\n",
      "      - 8.5\n",
      "      - 3.5\n",
      "      - 19.0\n",
      "      - 5.0\n",
      "      - 17.5\n",
      "      - 28.5\n",
      "      - 22.0\n",
      "      - 8.0\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 33.0\n",
      "      - 6.5\n",
      "      - 12.5\n",
      "      - 21.0\n",
      "      - 14.5\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 26.5\n",
      "      - 28.5\n",
      "      - 13.5\n",
      "      - 27.5\n",
      "      - 32.5\n",
      "      - 24.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      - 18.5\n",
      "      - 31.0\n",
      "      - 27.0\n",
      "      - 17.0\n",
      "      - 12.0\n",
      "      - 16.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 14.0\n",
      "      - 16.0\n",
      "      - 37.0\n",
      "      - 12.5\n",
      "      - 19.5\n",
      "      - 26.0\n",
      "      - 24.5\n",
      "      - 29.0\n",
      "      - 21.0\n",
      "      - -5.5\n",
      "      - 39.5\n",
      "      - 30.5\n",
      "      - 16.5\n",
      "      - 17.5\n",
      "      - 23.5\n",
      "      - 6.0\n",
      "      - 17.5\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 30.5\n",
      "      - 24.5\n",
      "      - 18.5\n",
      "      - -3.5\n",
      "      - 37.5\n",
      "      - 14.5\n",
      "      - 15.0\n",
      "      - 32.5\n",
      "      - 11.0\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      policy_policy2_reward:\n",
      "      - 0.9999999999999979\n",
      "      - -2.3\n",
      "      - -7.7999999999999865\n",
      "      - -8.899999999999986\n",
      "      - 12.000000000000016\n",
      "      - -4.499999999999992\n",
      "      - -0.10000000000000286\n",
      "      - 3.2000000000000046\n",
      "      - 10.900000000000016\n",
      "      - 3.1999999999999984\n",
      "      - 0.999999999999997\n",
      "      - -7.79999999999999\n",
      "      - -4.499999999999996\n",
      "      - 7.600000000000007\n",
      "      - -8.899999999999986\n",
      "      - -2.300000000000004\n",
      "      - -1.199999999999986\n",
      "      - -2.300000000000006\n",
      "      - -5.599999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 4.299999999999998\n",
      "      - -0.09999999999999232\n",
      "      - -4.4999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -3.4000000000000044\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -3.4000000000000026\n",
      "      - 7.600000000000012\n",
      "      - -8.899999999999986\n",
      "      - -2.3000000000000025\n",
      "      - -5.6\n",
      "      - -4.500000000000003\n",
      "      - -0.10000000000000342\n",
      "      - -5.6\n",
      "      - -3.3999999999999897\n",
      "      - -2.29999999999999\n",
      "      - 3.199999999999996\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999988\n",
      "      - -5.599999999999987\n",
      "      - 0.9999999999999974\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 7.600000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4000000000000057\n",
      "      - 6.500000000000014\n",
      "      - -1.1999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999982\n",
      "      - -5.599999999999982\n",
      "      - -3.4000000000000044\n",
      "      - -8.899999999999983\n",
      "      - 2.099999999999995\n",
      "      - -1.199999999999993\n",
      "      - -2.299999999999988\n",
      "      - -3.399999999999992\n",
      "      - -7.799999999999981\n",
      "      - -2.300000000000002\n",
      "      - -1.2000000000000046\n",
      "      - -1.1999999999999842\n",
      "      - 3.2000000000000046\n",
      "      - 1.0000000000000049\n",
      "      - 7.600000000000021\n",
      "      - -0.10000000000000497\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000002\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999939\n",
      "      - 0.9999999999999952\n",
      "      - -5.599999999999997\n",
      "      - -4.49999999999999\n",
      "      - 14.199999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - 2.099999999999995\n",
      "      - -6.699999999999987\n",
      "      - -0.09999999999999762\n",
      "      - 5.400000000000018\n",
      "      - -6.699999999999985\n",
      "      - -1.2000000000000055\n",
      "      - -5.599999999999983\n",
      "      - -1.200000000000005\n",
      "      - -5.6\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999986\n",
      "      - 6.5000000000000036\n",
      "      - -7.799999999999981\n",
      "      - 3.200000000000001\n",
      "      - -1.1999999999999977\n",
      "      - -6.6999999999999895\n",
      "      - -5.6\n",
      "      - -1.200000000000003\n",
      "      - -1.2000000000000004\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 14.199999999999998\n",
      "    policy_reward_mean:\n",
      "      policy1: 18.44\n",
      "      policy2: -2.563999999999993\n",
      "    policy_reward_min:\n",
      "      policy1: -5.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18235089548414515\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07799453797091185\n",
      "      mean_inference_ms: 1.9127455708287255\n",
      "      mean_raw_obs_processing_ms: 0.35822814990847646\n",
      "  time_since_restore: 316.6268880367279\n",
      "  time_this_iter_s: 20.818087816238403\n",
      "  time_total_s: 316.6268880367279\n",
      "  timers:\n",
      "    learn_throughput: 385.526\n",
      "    learn_time_ms: 10375.445\n",
      "    synch_weights_time_ms: 11.368\n",
      "    training_iteration_time_ms: 22291.114\n",
      "  timestamp: 1658917366\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 128000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_env_steps_sampled: 64000\n",
      "    num_env_steps_trained: 64000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 42.59999999999992\n",
      "  episode_reward_mean: 16.80299999999996\n",
      "  episode_reward_min: -11.399999999999975\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 640\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8578160405158997\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01706632971763611\n",
      "          model: {}\n",
      "          policy_loss: -0.04406963288784027\n",
      "          total_loss: 7.241642475128174\n",
      "          vf_explained_var: 0.1780860275030136\n",
      "          vf_loss: 7.278032302856445\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8550809621810913\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01470764447003603\n",
      "          model: {}\n",
      "          policy_loss: -0.03673020377755165\n",
      "          total_loss: 2.8730592727661133\n",
      "          vf_explained_var: 0.11109302192926407\n",
      "          vf_loss: 2.9031710624694824\n",
      "    num_agent_steps_sampled: 128000\n",
      "    num_agent_steps_trained: 128000\n",
      "    num_env_steps_sampled: 64000\n",
      "    num_env_steps_trained: 64000\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 128000\n",
      "  num_agent_steps_trained: 128000\n",
      "  num_env_steps_sampled: 64000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 64000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.81666666666667\n",
      "    ram_util_percent: 62.57499999999999\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 51.5\n",
      "    policy2: 15.299999999999983\n",
      "  policy_reward_mean:\n",
      "    policy1: 21.82\n",
      "    policy2: -5.0169999999999915\n",
      "  policy_reward_min:\n",
      "    policy1: -2.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.186251077408035\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07949115087339693\n",
      "    mean_inference_ms: 1.9670263085284194\n",
      "    mean_raw_obs_processing_ms: 0.36611682913561294\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 42.59999999999992\n",
      "    episode_reward_mean: 16.80299999999996\n",
      "    episode_reward_min: -11.399999999999975\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 25.499999999999908\n",
      "      - 16.199999999999932\n",
      "      - 25.49999999999993\n",
      "      - 21.599999999999937\n",
      "      - -5.399999999999972\n",
      "      - -11.399999999999975\n",
      "      - 19.49999999999995\n",
      "      - 22.19999999999998\n",
      "      - 22.79999999999994\n",
      "      - 16.49999999999995\n",
      "      - 14.999999999999938\n",
      "      - 8.699999999999969\n",
      "      - 11.400000000000032\n",
      "      - 15.899999999999986\n",
      "      - 18.599999999999945\n",
      "      - 16.500000000000007\n",
      "      - 27.29999999999992\n",
      "      - 12.000000000000034\n",
      "      - 12.000000000000028\n",
      "      - 14.099999999999934\n",
      "      - 2.1000000000000267\n",
      "      - 34.49999999999993\n",
      "      - 22.5\n",
      "      - 16.19999999999992\n",
      "      - 15.299999999999986\n",
      "      - 14.700000000000015\n",
      "      - 11.700000000000014\n",
      "      - 23.999999999999908\n",
      "      - 14.099999999999923\n",
      "      - 15.900000000000011\n",
      "      - 4.500000000000025\n",
      "      - 15.599999999999934\n",
      "      - 2.399999999999983\n",
      "      - 7.199999999999953\n",
      "      - 16.199999999999974\n",
      "      - 18.899999999999913\n",
      "      - 10.199999999999994\n",
      "      - 8.400000000000016\n",
      "      - 10.500000000000021\n",
      "      - 15.599999999999996\n",
      "      - 8.999999999999963\n",
      "      - 14.399999999999972\n",
      "      - 32.69999999999991\n",
      "      - 11.100000000000014\n",
      "      - 10.800000000000013\n",
      "      - 7.1999999999999815\n",
      "      - 9.900000000000025\n",
      "      - 15.599999999999973\n",
      "      - 23.3999999999999\n",
      "      - 11.999999999999982\n",
      "      - 21.900000000000006\n",
      "      - 18.89999999999995\n",
      "      - 20.69999999999994\n",
      "      - 29.399999999999963\n",
      "      - 29.999999999999915\n",
      "      - 16.799999999999947\n",
      "      - 2.1000000000000214\n",
      "      - 11.699999999999948\n",
      "      - 16.499999999999947\n",
      "      - 15.899999999999986\n",
      "      - 22.79999999999995\n",
      "      - 5.700000000000015\n",
      "      - 9.000000000000009\n",
      "      - 42.59999999999992\n",
      "      - 22.499999999999908\n",
      "      - 22.499999999999957\n",
      "      - 24.29999999999992\n",
      "      - 27.899999999999963\n",
      "      - 21.29999999999994\n",
      "      - 20.09999999999989\n",
      "      - 12.899999999999991\n",
      "      - 18.899999999999928\n",
      "      - 26.69999999999991\n",
      "      - 24.299999999999955\n",
      "      - 26.09999999999997\n",
      "      - 22.499999999999922\n",
      "      - 20.699999999999946\n",
      "      - 10.499999999999964\n",
      "      - 22.199999999999932\n",
      "      - 17.100000000000016\n",
      "      - 24.8999999999999\n",
      "      - 13.499999999999917\n",
      "      - 12.299999999999988\n",
      "      - 18.599999999999994\n",
      "      - 8.699999999999967\n",
      "      - 17.099999999999913\n",
      "      - 29.39999999999993\n",
      "      - 20.999999999999957\n",
      "      - 12.59999999999999\n",
      "      - 18.299999999999923\n",
      "      - 15.899999999999965\n",
      "      - 20.099999999999905\n",
      "      - 16.79999999999999\n",
      "      - 23.99999999999993\n",
      "      - 18.59999999999994\n",
      "      - -3.599999999999992\n",
      "      - 22.199999999999918\n",
      "      - -0.29999999999998084\n",
      "      - 28.799999999999912\n",
      "      - 25.79999999999994\n",
      "      policy_policy1_reward:\n",
      "      - 35.5\n",
      "      - 24.0\n",
      "      - 35.5\n",
      "      - 30.5\n",
      "      - 3.5\n",
      "      - -2.5\n",
      "      - 29.5\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 21.0\n",
      "      - 8.5\n",
      "      - 16.5\n",
      "      - 17.0\n",
      "      - 21.5\n",
      "      - 22.0\n",
      "      - 21.0\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 11.0\n",
      "      - 17.5\n",
      "      - 5.5\n",
      "      - 44.5\n",
      "      - 27.0\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 17.0\n",
      "      - 19.5\n",
      "      - 23.0\n",
      "      - 17.5\n",
      "      - 21.5\n",
      "      - 14.5\n",
      "      - 24.5\n",
      "      - 8.0\n",
      "      - 15.0\n",
      "      - 13.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 8.5\n",
      "      - 15.0\n",
      "      - 19.0\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 40.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 29.0\n",
      "      - 16.5\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 35.0\n",
      "      - 40.0\n",
      "      - 23.5\n",
      "      - 11.0\n",
      "      - 19.5\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      - 19.0\n",
      "      - 51.5\n",
      "      - 27.0\n",
      "      - 27.0\n",
      "      - 31.0\n",
      "      - 33.5\n",
      "      - 22.5\n",
      "      - 29.0\n",
      "      - 2.0\n",
      "      - 24.5\n",
      "      - 34.5\n",
      "      - 25.5\n",
      "      - 35.0\n",
      "      - 32.5\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 30.0\n",
      "      - 15.0\n",
      "      - 30.5\n",
      "      - 18.0\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 16.5\n",
      "      - 26.0\n",
      "      - 35.0\n",
      "      - 25.5\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 29.0\n",
      "      - 23.5\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 2.0\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 35.5\n",
      "      - 27.0\n",
      "      policy_policy2_reward:\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.899999999999984\n",
      "      - -8.899999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999989\n",
      "      - 15.299999999999983\n",
      "      - -4.499999999999992\n",
      "      - 6.500000000000001\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999983\n",
      "      - -5.599999999999996\n",
      "      - -3.400000000000002\n",
      "      - -4.499999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - 0.9999999999999939\n",
      "      - -3.400000000000004\n",
      "      - -3.3999999999999932\n",
      "      - -9.99999999999998\n",
      "      - -4.500000000000002\n",
      "      - -7.79999999999999\n",
      "      - -6.699999999999987\n",
      "      - -2.3000000000000016\n",
      "      - -7.799999999999981\n",
      "      - 1.0000000000000044\n",
      "      - -3.4000000000000026\n",
      "      - -5.5999999999999845\n",
      "      - -9.99999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999984\n",
      "      - -7.79999999999999\n",
      "      - 3.200000000000007\n",
      "      - -0.10000000000000331\n",
      "      - -7.799999999999981\n",
      "      - -0.09999999999999831\n",
      "      - -4.499999999999999\n",
      "      - -3.400000000000004\n",
      "      - -4.500000000000004\n",
      "      - -0.10000000000000375\n",
      "      - -7.799999999999982\n",
      "      - -3.400000000000006\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999993\n",
      "      - -4.500000000000003\n",
      "      - -5.59999999999999\n",
      "      - -5.599999999999986\n",
      "      - 3.199999999999999\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 5.400000000000006\n",
      "      - -6.699999999999982\n",
      "      - -2.299999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999987\n",
      "      - -4.5\n",
      "      - -6.699999999999986\n",
      "      - -5.59999999999999\n",
      "      - -1.200000000000002\n",
      "      - -8.899999999999983\n",
      "      - 10.900000000000013\n",
      "      - -5.599999999999995\n",
      "      - -7.79999999999999\n",
      "      - -1.200000000000001\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000002\n",
      "      - -4.499999999999987\n",
      "      - -7.79999999999999\n",
      "      - 2.1000000000000116\n",
      "      - -5.599999999999995\n",
      "      - -4.500000000000004\n",
      "      - -6.699999999999986\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999985\n",
      "      - -3.4000000000000035\n",
      "      - -6.6999999999999895\n",
      "      - 10.900000000000013\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -5.599999999999988\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000044\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 51.5\n",
      "      policy2: 15.299999999999983\n",
      "    policy_reward_mean:\n",
      "      policy1: 21.82\n",
      "      policy2: -5.0169999999999915\n",
      "    policy_reward_min:\n",
      "      policy1: -2.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.186251077408035\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07949115087339693\n",
      "      mean_inference_ms: 1.9670263085284194\n",
      "      mean_raw_obs_processing_ms: 0.36611682913561294\n",
      "  time_since_restore: 322.1235010623932\n",
      "  time_this_iter_s: 16.441808223724365\n",
      "  time_total_s: 322.1235010623932\n",
      "  timers:\n",
      "    learn_throughput: 389.345\n",
      "    learn_time_ms: 10273.663\n",
      "    synch_weights_time_ms: 4.993\n",
      "    training_iteration_time_ms: 21817.029\n",
      "  timestamp: 1658917383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 64000\n",
      "  training_iteration: 16\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 136000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_env_steps_sampled: 68000\n",
      "    num_env_steps_trained: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-03\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 31.799999999999898\n",
      "  episode_reward_mean: 16.45499999999994\n",
      "  episode_reward_min: 1.2000000000000108\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 680\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7916848063468933\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011793727055191994\n",
      "          model: {}\n",
      "          policy_loss: -0.03288508579134941\n",
      "          total_loss: 7.05780553817749\n",
      "          vf_explained_var: 0.3424544632434845\n",
      "          vf_loss: 7.087152004241943\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7969801425933838\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014385406859219074\n",
      "          model: {}\n",
      "          policy_loss: -0.037240028381347656\n",
      "          total_loss: 3.033869504928589\n",
      "          vf_explained_var: 0.13326121866703033\n",
      "          vf_loss: 3.068232536315918\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_env_steps_sampled: 68000\n",
      "    num_env_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 136000\n",
      "  num_agent_steps_trained: 136000\n",
      "  num_env_steps_sampled: 68000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 68000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.425000000000004\n",
      "    ram_util_percent: 61.929166666666674\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 39.5\n",
      "    policy2: 14.199999999999998\n",
      "  policy_reward_mean:\n",
      "    policy1: 19.965\n",
      "    policy2: -3.5099999999999913\n",
      "  policy_reward_min:\n",
      "    policy1: -5.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.1832448007605162\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07839264947014847\n",
      "    mean_inference_ms: 1.9213854922971336\n",
      "    mean_raw_obs_processing_ms: 0.36037548886564363\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 31.799999999999898\n",
      "    episode_reward_mean: 16.45499999999994\n",
      "    episode_reward_min: 1.2000000000000108\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 20.699999999999896\n",
      "      - 15.299999999999969\n",
      "      - 2.400000000000012\n",
      "      - 11.99999999999995\n",
      "      - 12.00000000000002\n",
      "      - 25.199999999999953\n",
      "      - 14.100000000000025\n",
      "      - 3.599999999999955\n",
      "      - 13.200000000000001\n",
      "      - 11.09999999999995\n",
      "      - 17.99999999999997\n",
      "      - 3.299999999999997\n",
      "      - 19.79999999999992\n",
      "      - 20.699999999999953\n",
      "      - 9.000000000000025\n",
      "      - 21.899999999999935\n",
      "      - 29.09999999999991\n",
      "      - 15.599999999999968\n",
      "      - 9.59999999999995\n",
      "      - 16.799999999999912\n",
      "      - 16.19999999999994\n",
      "      - 27.599999999999902\n",
      "      - 19.199999999999918\n",
      "      - 14.699999999999912\n",
      "      - 10.800000000000024\n",
      "      - 15.299999999999923\n",
      "      - 19.19999999999995\n",
      "      - 17.999999999999982\n",
      "      - 21.59999999999992\n",
      "      - 15.899999999999919\n",
      "      - 26.9999999999999\n",
      "      - 13.50000000000003\n",
      "      - 11.699999999999942\n",
      "      - 26.999999999999922\n",
      "      - 25.49999999999992\n",
      "      - 23.3999999999999\n",
      "      - 16.499999999999964\n",
      "      - 8.69999999999999\n",
      "      - 30.599999999999916\n",
      "      - 24.899999999999906\n",
      "      - 18.59999999999991\n",
      "      - 10.799999999999978\n",
      "      - 23.399999999999906\n",
      "      - 11.399999999999974\n",
      "      - 10.799999999999928\n",
      "      - 7.799999999999958\n",
      "      - 3.8999999999999857\n",
      "      - 19.799999999999955\n",
      "      - 23.399999999999906\n",
      "      - 21.599999999999902\n",
      "      - 15.599999999999932\n",
      "      - 12.899999999999945\n",
      "      - 2.9999999999999725\n",
      "      - 29.69999999999996\n",
      "      - 17.699999999999903\n",
      "      - 13.79999999999998\n",
      "      - 25.799999999999905\n",
      "      - 5.399999999999988\n",
      "      - 6.299999999999972\n",
      "      - 15.299999999999908\n",
      "      - 22.49999999999997\n",
      "      - 8.699999999999966\n",
      "      - 6.59999999999998\n",
      "      - 19.799999999999905\n",
      "      - 17.999999999999957\n",
      "      - 26.999999999999908\n",
      "      - 12.299999999999917\n",
      "      - 11.399999999999967\n",
      "      - 24.59999999999991\n",
      "      - 31.799999999999898\n",
      "      - 26.699999999999946\n",
      "      - 16.499999999999915\n",
      "      - 19.799999999999912\n",
      "      - 13.799999999999962\n",
      "      - 19.799999999999923\n",
      "      - 25.199999999999925\n",
      "      - 17.1\n",
      "      - 22.499999999999908\n",
      "      - 3.300000000000007\n",
      "      - 16.799999999999915\n",
      "      - 18.89999999999991\n",
      "      - 13.499999999999938\n",
      "      - 13.49999999999996\n",
      "      - 11.400000000000032\n",
      "      - 29.99999999999993\n",
      "      - 2.0999999999999828\n",
      "      - 27.599999999999895\n",
      "      - 22.799999999999947\n",
      "      - 20.999999999999908\n",
      "      - 24.299999999999912\n",
      "      - 13.199999999999912\n",
      "      - 9.899999999999968\n",
      "      - 29.999999999999897\n",
      "      - 15.599999999999897\n",
      "      - 17.9999999999999\n",
      "      - 1.2000000000000108\n",
      "      - 6.8999999999999435\n",
      "      - 3.000000000000024\n",
      "      - 10.199999999999914\n",
      "      - 10.49999999999994\n",
      "      policy_policy1_reward:\n",
      "      - 28.5\n",
      "      - 22.0\n",
      "      - 8.0\n",
      "      - 11.0\n",
      "      - 22.0\n",
      "      - 33.0\n",
      "      - 6.5\n",
      "      - 12.5\n",
      "      - 21.0\n",
      "      - 14.5\n",
      "      - 11.5\n",
      "      - 4.5\n",
      "      - 26.5\n",
      "      - 28.5\n",
      "      - 13.5\n",
      "      - 27.5\n",
      "      - 32.5\n",
      "      - 24.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      - 18.5\n",
      "      - 31.0\n",
      "      - 27.0\n",
      "      - 17.0\n",
      "      - 12.0\n",
      "      - 16.5\n",
      "      - 16.0\n",
      "      - 17.0\n",
      "      - 14.0\n",
      "      - 16.0\n",
      "      - 37.0\n",
      "      - 12.5\n",
      "      - 19.5\n",
      "      - 26.0\n",
      "      - 24.5\n",
      "      - 29.0\n",
      "      - 21.0\n",
      "      - -5.5\n",
      "      - 39.5\n",
      "      - 30.5\n",
      "      - 16.5\n",
      "      - 17.5\n",
      "      - 23.5\n",
      "      - 6.0\n",
      "      - 17.5\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 30.5\n",
      "      - 24.5\n",
      "      - 18.5\n",
      "      - -3.5\n",
      "      - 37.5\n",
      "      - 14.5\n",
      "      - 15.0\n",
      "      - 32.5\n",
      "      - 11.0\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      - 27.0\n",
      "      - 5.5\n",
      "      - 15.5\n",
      "      - 26.5\n",
      "      - 11.5\n",
      "      - 31.5\n",
      "      - 13.5\n",
      "      - 17.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 34.5\n",
      "      - 26.5\n",
      "      - 26.5\n",
      "      - 15.0\n",
      "      - 21.0\n",
      "      - 33.0\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 10.0\n",
      "      - 18.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 29.0\n",
      "      - 11.0\n",
      "      - 36.5\n",
      "      - 29.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 21.0\n",
      "      - 15.5\n",
      "      - 34.5\n",
      "      - 24.5\n",
      "      - 22.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      policy_policy2_reward:\n",
      "      - -7.799999999999981\n",
      "      - -6.699999999999988\n",
      "      - -5.599999999999987\n",
      "      - 0.9999999999999974\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - 7.600000000000001\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -3.4000000000000057\n",
      "      - 6.500000000000014\n",
      "      - -1.1999999999999895\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999981\n",
      "      - -4.499999999999982\n",
      "      - -5.599999999999982\n",
      "      - -3.4000000000000044\n",
      "      - -8.899999999999983\n",
      "      - 2.099999999999995\n",
      "      - -1.199999999999993\n",
      "      - -2.299999999999988\n",
      "      - -3.399999999999992\n",
      "      - -7.799999999999981\n",
      "      - -2.300000000000002\n",
      "      - -1.2000000000000046\n",
      "      - -1.1999999999999842\n",
      "      - 3.2000000000000046\n",
      "      - 1.0000000000000049\n",
      "      - 7.600000000000021\n",
      "      - -0.10000000000000497\n",
      "      - -9.99999999999998\n",
      "      - 1.0000000000000002\n",
      "      - -7.799999999999981\n",
      "      - 0.9999999999999939\n",
      "      - 0.9999999999999952\n",
      "      - -5.599999999999997\n",
      "      - -4.49999999999999\n",
      "      - 14.199999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999999\n",
      "      - 2.099999999999995\n",
      "      - -6.699999999999987\n",
      "      - -0.09999999999999762\n",
      "      - 5.400000000000018\n",
      "      - -6.699999999999985\n",
      "      - -1.2000000000000055\n",
      "      - -5.599999999999983\n",
      "      - -1.200000000000005\n",
      "      - -5.6\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999986\n",
      "      - 6.5000000000000036\n",
      "      - -7.799999999999981\n",
      "      - 3.200000000000001\n",
      "      - -1.1999999999999977\n",
      "      - -6.6999999999999895\n",
      "      - -5.6\n",
      "      - -1.200000000000003\n",
      "      - -1.2000000000000004\n",
      "      - -4.499999999999999\n",
      "      - 3.199999999999999\n",
      "      - -8.899999999999984\n",
      "      - -6.699999999999994\n",
      "      - 6.500000000000007\n",
      "      - -4.499999999999983\n",
      "      - -1.2000000000000037\n",
      "      - -5.599999999999986\n",
      "      - -3.3999999999999875\n",
      "      - -1.1999999999999988\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.200000000000004\n",
      "      - -1.1999999999999877\n",
      "      - -7.799999999999986\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -6.699999999999989\n",
      "      - -1.2000000000000033\n",
      "      - -0.10000000000000289\n",
      "      - -4.5\n",
      "      - -4.499999999999994\n",
      "      - -5.5999999999999845\n",
      "      - 0.9999999999999963\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -4.500000000000003\n",
      "      - -1.1999999999999833\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - -4.499999999999996\n",
      "      - -7.79999999999999\n",
      "      - 0.9999999999999966\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 39.5\n",
      "      policy2: 14.199999999999998\n",
      "    policy_reward_mean:\n",
      "      policy1: 19.965\n",
      "      policy2: -3.5099999999999913\n",
      "    policy_reward_min:\n",
      "      policy1: -5.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.1832448007605162\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07839264947014847\n",
      "      mean_inference_ms: 1.9213854922971336\n",
      "      mean_raw_obs_processing_ms: 0.36037548886564363\n",
      "  time_since_restore: 333.19838190078735\n",
      "  time_this_iter_s: 16.57149386405945\n",
      "  time_total_s: 333.19838190078735\n",
      "  timers:\n",
      "    learn_throughput: 391.124\n",
      "    learn_time_ms: 10226.928\n",
      "    synch_weights_time_ms: 11.287\n",
      "    training_iteration_time_ms: 21901.185\n",
      "  timestamp: 1658917383\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 136000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_env_steps_sampled: 68000\n",
      "    num_env_steps_trained: 68000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-19\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 42.59999999999992\n",
      "  episode_reward_mean: 18.569999999999954\n",
      "  episode_reward_min: -3.599999999999992\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 680\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8260336518287659\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.018269939348101616\n",
      "          model: {}\n",
      "          policy_loss: -0.0457068532705307\n",
      "          total_loss: 7.361355781555176\n",
      "          vf_explained_var: 0.16720227897167206\n",
      "          vf_loss: 7.398841381072998\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8263782858848572\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01659713126718998\n",
      "          model: {}\n",
      "          policy_loss: -0.04130517691373825\n",
      "          total_loss: 3.3831775188446045\n",
      "          vf_explained_var: 0.07265127450227737\n",
      "          vf_loss: 3.4170141220092773\n",
      "    num_agent_steps_sampled: 136000\n",
      "    num_agent_steps_trained: 136000\n",
      "    num_env_steps_sampled: 68000\n",
      "    num_env_steps_trained: 68000\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 136000\n",
      "  num_agent_steps_trained: 136000\n",
      "  num_env_steps_sampled: 68000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 68000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.112500000000004\n",
      "    ram_util_percent: 56.125\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 51.5\n",
      "    policy2: 10.900000000000013\n",
      "  policy_reward_mean:\n",
      "    policy1: 23.18\n",
      "    policy2: -4.609999999999991\n",
      "  policy_reward_min:\n",
      "    policy1: 0.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18513408005031642\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07904263837115072\n",
      "    mean_inference_ms: 1.951782420298977\n",
      "    mean_raw_obs_processing_ms: 0.3641268678289744\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 42.59999999999992\n",
      "    episode_reward_mean: 18.569999999999954\n",
      "    episode_reward_min: -3.599999999999992\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 8.999999999999963\n",
      "      - 14.399999999999972\n",
      "      - 32.69999999999991\n",
      "      - 11.100000000000014\n",
      "      - 10.800000000000013\n",
      "      - 7.1999999999999815\n",
      "      - 9.900000000000025\n",
      "      - 15.599999999999973\n",
      "      - 23.3999999999999\n",
      "      - 11.999999999999982\n",
      "      - 21.900000000000006\n",
      "      - 18.89999999999995\n",
      "      - 20.69999999999994\n",
      "      - 29.399999999999963\n",
      "      - 29.999999999999915\n",
      "      - 16.799999999999947\n",
      "      - 2.1000000000000214\n",
      "      - 11.699999999999948\n",
      "      - 16.499999999999947\n",
      "      - 15.899999999999986\n",
      "      - 22.79999999999995\n",
      "      - 5.700000000000015\n",
      "      - 9.000000000000009\n",
      "      - 42.59999999999992\n",
      "      - 22.499999999999908\n",
      "      - 22.499999999999957\n",
      "      - 24.29999999999992\n",
      "      - 27.899999999999963\n",
      "      - 21.29999999999994\n",
      "      - 20.09999999999989\n",
      "      - 12.899999999999991\n",
      "      - 18.899999999999928\n",
      "      - 26.69999999999991\n",
      "      - 24.299999999999955\n",
      "      - 26.09999999999997\n",
      "      - 22.499999999999922\n",
      "      - 20.699999999999946\n",
      "      - 10.499999999999964\n",
      "      - 22.199999999999932\n",
      "      - 17.100000000000016\n",
      "      - 24.8999999999999\n",
      "      - 13.499999999999917\n",
      "      - 12.299999999999988\n",
      "      - 18.599999999999994\n",
      "      - 8.699999999999967\n",
      "      - 17.099999999999913\n",
      "      - 29.39999999999993\n",
      "      - 20.999999999999957\n",
      "      - 12.59999999999999\n",
      "      - 18.299999999999923\n",
      "      - 15.899999999999965\n",
      "      - 20.099999999999905\n",
      "      - 16.79999999999999\n",
      "      - 23.99999999999993\n",
      "      - 18.59999999999994\n",
      "      - -3.599999999999992\n",
      "      - 22.199999999999918\n",
      "      - -0.29999999999998084\n",
      "      - 28.799999999999912\n",
      "      - 25.79999999999994\n",
      "      - 6.000000000000016\n",
      "      - 15.899999999999997\n",
      "      - 15.600000000000009\n",
      "      - 27.299999999999898\n",
      "      - 24.599999999999934\n",
      "      - 37.19999999999992\n",
      "      - 23.099999999999902\n",
      "      - 6.300000000000026\n",
      "      - -1.799999999999978\n",
      "      - 36.299999999999905\n",
      "      - 24.599999999999895\n",
      "      - 23.999999999999936\n",
      "      - 24.299999999999926\n",
      "      - 28.799999999999926\n",
      "      - 16.200000000000024\n",
      "      - 5.099999999999994\n",
      "      - 18.89999999999992\n",
      "      - 29.69999999999994\n",
      "      - 13.199999999999955\n",
      "      - 24.29999999999994\n",
      "      - 28.499999999999908\n",
      "      - 18.000000000000014\n",
      "      - 9.900000000000015\n",
      "      - 27.899999999999913\n",
      "      - 6.899999999999988\n",
      "      - 24.299999999999926\n",
      "      - 17.40000000000002\n",
      "      - 19.199999999999932\n",
      "      - 35.9999999999999\n",
      "      - 29.39999999999992\n",
      "      - 2.731148640577885e-14\n",
      "      - 10.199999999999935\n",
      "      - 19.800000000000004\n",
      "      - 18.299999999999947\n",
      "      - 24.299999999999905\n",
      "      - 13.199999999999918\n",
      "      - 13.499999999999966\n",
      "      - 22.199999999999925\n",
      "      - 14.100000000000014\n",
      "      - 9.0\n",
      "      policy_policy1_reward:\n",
      "      - 13.5\n",
      "      - 14.5\n",
      "      - 40.5\n",
      "      - 14.5\n",
      "      - 17.5\n",
      "      - 15.0\n",
      "      - 15.5\n",
      "      - 24.5\n",
      "      - 29.0\n",
      "      - 16.5\n",
      "      - 27.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 35.0\n",
      "      - 40.0\n",
      "      - 23.5\n",
      "      - 11.0\n",
      "      - 19.5\n",
      "      - 21.0\n",
      "      - 10.5\n",
      "      - 29.5\n",
      "      - 8.0\n",
      "      - 19.0\n",
      "      - 51.5\n",
      "      - 27.0\n",
      "      - 27.0\n",
      "      - 31.0\n",
      "      - 33.5\n",
      "      - 22.5\n",
      "      - 29.0\n",
      "      - 2.0\n",
      "      - 24.5\n",
      "      - 34.5\n",
      "      - 25.5\n",
      "      - 35.0\n",
      "      - 32.5\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 30.0\n",
      "      - 15.0\n",
      "      - 30.5\n",
      "      - 18.0\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 16.5\n",
      "      - 26.0\n",
      "      - 35.0\n",
      "      - 25.5\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 29.0\n",
      "      - 23.5\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 2.0\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 35.5\n",
      "      - 27.0\n",
      "      - 10.5\n",
      "      - 16.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 39.5\n",
      "      - 32.0\n",
      "      - 7.5\n",
      "      - 0.5\n",
      "      - 43.0\n",
      "      - 33.5\n",
      "      - 34.0\n",
      "      - 31.0\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 3.0\n",
      "      - 24.5\n",
      "      - 37.5\n",
      "      - 4.5\n",
      "      - 25.5\n",
      "      - 33.0\n",
      "      - 11.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 7.0\n",
      "      - 25.5\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 46.0\n",
      "      - 35.0\n",
      "      - 4.5\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 25.0\n",
      "      - 31.0\n",
      "      - 10.0\n",
      "      - 23.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 13.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.500000000000004\n",
      "      - -0.10000000000000375\n",
      "      - -7.799999999999982\n",
      "      - -3.400000000000006\n",
      "      - -6.699999999999984\n",
      "      - -7.799999999999986\n",
      "      - -5.599999999999998\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999993\n",
      "      - -4.500000000000003\n",
      "      - -5.59999999999999\n",
      "      - -5.599999999999986\n",
      "      - 3.199999999999999\n",
      "      - -5.599999999999993\n",
      "      - -9.99999999999998\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -4.5000000000000036\n",
      "      - 5.400000000000006\n",
      "      - -6.699999999999982\n",
      "      - -2.299999999999993\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999986\n",
      "      - -4.499999999999987\n",
      "      - -4.5\n",
      "      - -6.699999999999986\n",
      "      - -5.59999999999999\n",
      "      - -1.200000000000002\n",
      "      - -8.899999999999983\n",
      "      - 10.900000000000013\n",
      "      - -5.599999999999995\n",
      "      - -7.79999999999999\n",
      "      - -1.200000000000001\n",
      "      - -8.89999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000002\n",
      "      - -4.499999999999987\n",
      "      - -7.79999999999999\n",
      "      - 2.1000000000000116\n",
      "      - -5.599999999999995\n",
      "      - -4.500000000000004\n",
      "      - -6.699999999999986\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999985\n",
      "      - -3.4000000000000035\n",
      "      - -6.6999999999999895\n",
      "      - 10.900000000000013\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -5.599999999999988\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000044\n",
      "      - -4.500000000000003\n",
      "      - -0.10000000000000009\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999989\n",
      "      - -3.400000000000006\n",
      "      - -2.3000000000000047\n",
      "      - -8.89999999999998\n",
      "      - -1.1999999999999935\n",
      "      - -2.3000000000000047\n",
      "      - -6.699999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 9.800000000000015\n",
      "      - -2.3000000000000007\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - 8.699999999999996\n",
      "      - -1.2000000000000022\n",
      "      - -4.500000000000002\n",
      "      - 6.5000000000000036\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999999\n",
      "      - -0.1000000000000042\n",
      "      - -1.2000000000000013\n",
      "      - -5.599999999999995\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -4.4999999999999964\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - 3.2000000000000055\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000001\n",
      "      - -3.400000000000004\n",
      "      - -4.4999999999999885\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 51.5\n",
      "      policy2: 10.900000000000013\n",
      "    policy_reward_mean:\n",
      "      policy1: 23.18\n",
      "      policy2: -4.609999999999991\n",
      "    policy_reward_min:\n",
      "      policy1: 0.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18513408005031642\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07904263837115072\n",
      "      mean_inference_ms: 1.951782420298977\n",
      "      mean_raw_obs_processing_ms: 0.3641268678289744\n",
      "  time_since_restore: 338.4696469306946\n",
      "  time_this_iter_s: 16.34614586830139\n",
      "  time_total_s: 338.4696469306946\n",
      "  timers:\n",
      "    learn_throughput: 400.101\n",
      "    learn_time_ms: 9997.477\n",
      "    synch_weights_time_ms: 5.07\n",
      "    training_iteration_time_ms: 21427.868\n",
      "  timestamp: 1658917399\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 68000\n",
      "  training_iteration: 17\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 144000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_env_steps_sampled: 72000\n",
      "    num_env_steps_trained: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-20\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.9999999999999\n",
      "  episode_reward_mean: 17.219999999999942\n",
      "  episode_reward_min: -1.500000000000007\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 720\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7732895016670227\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01276063546538353\n",
      "          model: {}\n",
      "          policy_loss: -0.03548599034547806\n",
      "          total_loss: 6.864075183868408\n",
      "          vf_explained_var: 0.3718656003475189\n",
      "          vf_loss: 6.895732402801514\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7711622714996338\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.011402360163629055\n",
      "          model: {}\n",
      "          policy_loss: -0.02842370793223381\n",
      "          total_loss: 3.9737067222595215\n",
      "          vf_explained_var: 0.08027991652488708\n",
      "          vf_loss: 3.999850034713745\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_env_steps_sampled: 72000\n",
      "    num_env_steps_trained: 72000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 144000\n",
      "  num_agent_steps_trained: 144000\n",
      "  num_env_steps_sampled: 72000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 72000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.16521739130435\n",
      "    ram_util_percent: 56.217391304347814\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 37.5\n",
      "    policy2: 22.999999999999964\n",
      "  policy_reward_mean:\n",
      "    policy1: 20.73\n",
      "    policy2: -3.5099999999999927\n",
      "  policy_reward_min:\n",
      "    policy1: -8.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18232208391929128\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07807972782454865\n",
      "    mean_inference_ms: 1.9104675219620333\n",
      "    mean_raw_obs_processing_ms: 0.3588888204926016\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.9999999999999\n",
      "    episode_reward_mean: 17.219999999999942\n",
      "    episode_reward_min: -1.500000000000007\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 18.59999999999991\n",
      "      - 10.799999999999978\n",
      "      - 23.399999999999906\n",
      "      - 11.399999999999974\n",
      "      - 10.799999999999928\n",
      "      - 7.799999999999958\n",
      "      - 3.8999999999999857\n",
      "      - 19.799999999999955\n",
      "      - 23.399999999999906\n",
      "      - 21.599999999999902\n",
      "      - 15.599999999999932\n",
      "      - 12.899999999999945\n",
      "      - 2.9999999999999725\n",
      "      - 29.69999999999996\n",
      "      - 17.699999999999903\n",
      "      - 13.79999999999998\n",
      "      - 25.799999999999905\n",
      "      - 5.399999999999988\n",
      "      - 6.299999999999972\n",
      "      - 15.299999999999908\n",
      "      - 22.49999999999997\n",
      "      - 8.699999999999966\n",
      "      - 6.59999999999998\n",
      "      - 19.799999999999905\n",
      "      - 17.999999999999957\n",
      "      - 26.999999999999908\n",
      "      - 12.299999999999917\n",
      "      - 11.399999999999967\n",
      "      - 24.59999999999991\n",
      "      - 31.799999999999898\n",
      "      - 26.699999999999946\n",
      "      - 16.499999999999915\n",
      "      - 19.799999999999912\n",
      "      - 13.799999999999962\n",
      "      - 19.799999999999923\n",
      "      - 25.199999999999925\n",
      "      - 17.1\n",
      "      - 22.499999999999908\n",
      "      - 3.300000000000007\n",
      "      - 16.799999999999915\n",
      "      - 18.89999999999991\n",
      "      - 13.499999999999938\n",
      "      - 13.49999999999996\n",
      "      - 11.400000000000032\n",
      "      - 29.99999999999993\n",
      "      - 2.0999999999999828\n",
      "      - 27.599999999999895\n",
      "      - 22.799999999999947\n",
      "      - 20.999999999999908\n",
      "      - 24.299999999999912\n",
      "      - 13.199999999999912\n",
      "      - 9.899999999999968\n",
      "      - 29.999999999999897\n",
      "      - 15.599999999999897\n",
      "      - 17.9999999999999\n",
      "      - 1.2000000000000108\n",
      "      - 6.8999999999999435\n",
      "      - 3.000000000000024\n",
      "      - 10.199999999999914\n",
      "      - 10.49999999999994\n",
      "      - 31.799999999999923\n",
      "      - 15.299999999999944\n",
      "      - -1.500000000000007\n",
      "      - 23.399999999999913\n",
      "      - 12.299999999999988\n",
      "      - 12.000000000000028\n",
      "      - 22.499999999999908\n",
      "      - 23.399999999999906\n",
      "      - 22.499999999999915\n",
      "      - 23.9999999999999\n",
      "      - 4.2000000000000295\n",
      "      - 15.89999999999994\n",
      "      - 21.599999999999923\n",
      "      - 30.599999999999902\n",
      "      - 24.8999999999999\n",
      "      - 26.9999999999999\n",
      "      - 24.59999999999992\n",
      "      - 18.29999999999991\n",
      "      - 11.999999999999972\n",
      "      - 17.699999999999935\n",
      "      - 7.500000000000032\n",
      "      - 25.199999999999925\n",
      "      - 25.799999999999905\n",
      "      - 24.299999999999905\n",
      "      - 15.89999999999993\n",
      "      - 14.999999999999968\n",
      "      - 15.599999999999943\n",
      "      - 11.099999999999934\n",
      "      - 8.099999999999943\n",
      "      - 26.09999999999991\n",
      "      - 26.099999999999902\n",
      "      - 15.299999999999928\n",
      "      - 7.799999999999965\n",
      "      - 22.19999999999991\n",
      "      - 20.09999999999993\n",
      "      - 32.9999999999999\n",
      "      - 19.5\n",
      "      - 26.09999999999993\n",
      "      - 14.999999999999911\n",
      "      - 14.999999999999911\n",
      "      policy_policy1_reward:\n",
      "      - 16.5\n",
      "      - 17.5\n",
      "      - 23.5\n",
      "      - 6.0\n",
      "      - 17.5\n",
      "      - 9.0\n",
      "      - 9.5\n",
      "      - 21.0\n",
      "      - 29.0\n",
      "      - 30.5\n",
      "      - 24.5\n",
      "      - 18.5\n",
      "      - -3.5\n",
      "      - 37.5\n",
      "      - 14.5\n",
      "      - 15.0\n",
      "      - 32.5\n",
      "      - 11.0\n",
      "      - 7.5\n",
      "      - 16.5\n",
      "      - 27.0\n",
      "      - 5.5\n",
      "      - 15.5\n",
      "      - 26.5\n",
      "      - 11.5\n",
      "      - 31.5\n",
      "      - 13.5\n",
      "      - 17.0\n",
      "      - 28.0\n",
      "      - 33.0\n",
      "      - 34.5\n",
      "      - 26.5\n",
      "      - 26.5\n",
      "      - 15.0\n",
      "      - 21.0\n",
      "      - 33.0\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 10.0\n",
      "      - 18.0\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 29.0\n",
      "      - 11.0\n",
      "      - 36.5\n",
      "      - 29.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 21.0\n",
      "      - 15.5\n",
      "      - 34.5\n",
      "      - 24.5\n",
      "      - 22.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - 27.5\n",
      "      - 22.0\n",
      "      - 8.5\n",
      "      - 29.0\n",
      "      - 2.5\n",
      "      - 11.0\n",
      "      - 32.5\n",
      "      - 23.5\n",
      "      - 32.5\n",
      "      - 34.0\n",
      "      - 6.5\n",
      "      - 21.5\n",
      "      - 30.5\n",
      "      - 34.0\n",
      "      - 30.5\n",
      "      - 26.0\n",
      "      - 28.0\n",
      "      - 14.0\n",
      "      - 16.5\n",
      "      - 20.0\n",
      "      - 12.0\n",
      "      - 27.5\n",
      "      - 27.0\n",
      "      - 25.5\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 35.0\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 9.0\n",
      "      - 30.0\n",
      "      - 18.0\n",
      "      - 32.0\n",
      "      - 24.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 19.5\n",
      "      policy_policy2_reward:\n",
      "      - 2.099999999999995\n",
      "      - -6.699999999999987\n",
      "      - -0.09999999999999762\n",
      "      - 5.400000000000018\n",
      "      - -6.699999999999985\n",
      "      - -1.2000000000000055\n",
      "      - -5.599999999999983\n",
      "      - -1.200000000000005\n",
      "      - -5.6\n",
      "      - -8.899999999999986\n",
      "      - -8.899999999999983\n",
      "      - -5.599999999999986\n",
      "      - 6.5000000000000036\n",
      "      - -7.799999999999981\n",
      "      - 3.200000000000001\n",
      "      - -1.1999999999999977\n",
      "      - -6.6999999999999895\n",
      "      - -5.6\n",
      "      - -1.200000000000003\n",
      "      - -1.2000000000000004\n",
      "      - -4.499999999999999\n",
      "      - 3.199999999999999\n",
      "      - -8.899999999999984\n",
      "      - -6.699999999999994\n",
      "      - 6.500000000000007\n",
      "      - -4.499999999999983\n",
      "      - -1.2000000000000037\n",
      "      - -5.599999999999986\n",
      "      - -3.3999999999999875\n",
      "      - -1.1999999999999988\n",
      "      - -7.799999999999986\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - -1.200000000000004\n",
      "      - -1.1999999999999877\n",
      "      - -7.799999999999986\n",
      "      - -8.89999999999998\n",
      "      - -4.500000000000003\n",
      "      - -6.699999999999989\n",
      "      - -1.2000000000000033\n",
      "      - -0.10000000000000289\n",
      "      - -4.5\n",
      "      - -4.499999999999994\n",
      "      - -5.5999999999999845\n",
      "      - 0.9999999999999963\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -4.500000000000003\n",
      "      - -1.1999999999999833\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - -4.499999999999996\n",
      "      - -7.79999999999999\n",
      "      - 0.9999999999999966\n",
      "      - 4.300000000000008\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - 9.800000000000013\n",
      "      - 1.0000000000000093\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000198\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000025\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -3.4\n",
      "      - -5.5999999999999845\n",
      "      - 0.9999999999999974\n",
      "      - -3.399999999999997\n",
      "      - 4.299999999999995\n",
      "      - -4.5\n",
      "      - -2.3000000000000034\n",
      "      - -4.499999999999997\n",
      "      - -2.3000000000000034\n",
      "      - -1.2000000000000017\n",
      "      - -1.2000000000000044\n",
      "      - -5.599999999999991\n",
      "      - 22.999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 2.0999999999999934\n",
      "      - -6.699999999999991\n",
      "      - -1.200000000000001\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999995\n",
      "      - 0.9999999999999934\n",
      "      - -4.499999999999995\n",
      "      - 7.6000000000000005\n",
      "      - -4.499999999999986\n",
      "      - -4.500000000000003\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 37.5\n",
      "      policy2: 22.999999999999964\n",
      "    policy_reward_mean:\n",
      "      policy1: 20.73\n",
      "      policy2: -3.5099999999999927\n",
      "    policy_reward_min:\n",
      "      policy1: -8.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18232208391929128\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07807972782454865\n",
      "      mean_inference_ms: 1.9104675219620333\n",
      "      mean_raw_obs_processing_ms: 0.3588888204926016\n",
      "  time_since_restore: 349.5913577079773\n",
      "  time_this_iter_s: 16.39297580718994\n",
      "  time_total_s: 349.5913577079773\n",
      "  timers:\n",
      "    learn_throughput: 401.437\n",
      "    learn_time_ms: 9964.201\n",
      "    synch_weights_time_ms: 11.289\n",
      "    training_iteration_time_ms: 21517.547\n",
      "  timestamp: 1658917400\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 144000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_env_steps_sampled: 72000\n",
      "    num_env_steps_trained: 72000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-35\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 37.19999999999992\n",
      "  episode_reward_mean: 18.07199999999995\n",
      "  episode_reward_min: -20.099999999999994\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 720\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7865012884140015\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017169926315546036\n",
      "          model: {}\n",
      "          policy_loss: -0.0448937863111496\n",
      "          total_loss: 7.279630184173584\n",
      "          vf_explained_var: 0.1520516723394394\n",
      "          vf_loss: 7.316797256469727\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.8073180317878723\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01645735092461109\n",
      "          model: {}\n",
      "          policy_loss: -0.043863870203495026\n",
      "          total_loss: 3.255671501159668\n",
      "          vf_explained_var: 0.1329066902399063\n",
      "          vf_loss: 3.2921295166015625\n",
      "    num_agent_steps_sampled: 144000\n",
      "    num_agent_steps_trained: 144000\n",
      "    num_env_steps_sampled: 72000\n",
      "    num_env_steps_trained: 72000\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 144000\n",
      "  num_agent_steps_trained: 144000\n",
      "  num_env_steps_sampled: 72000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 72000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 34.372727272727275\n",
      "    ram_util_percent: 59.940909090909095\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 10.900000000000013\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.77\n",
      "    policy2: -4.6979999999999915\n",
      "  policy_reward_min:\n",
      "    policy1: -14.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18301246230425722\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07823205426155734\n",
      "    mean_inference_ms: 1.92791473177\n",
      "    mean_raw_obs_processing_ms: 0.3603296234659849\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 37.19999999999992\n",
      "    episode_reward_mean: 18.07199999999995\n",
      "    episode_reward_min: -20.099999999999994\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 24.8999999999999\n",
      "      - 13.499999999999917\n",
      "      - 12.299999999999988\n",
      "      - 18.599999999999994\n",
      "      - 8.699999999999967\n",
      "      - 17.099999999999913\n",
      "      - 29.39999999999993\n",
      "      - 20.999999999999957\n",
      "      - 12.59999999999999\n",
      "      - 18.299999999999923\n",
      "      - 15.899999999999965\n",
      "      - 20.099999999999905\n",
      "      - 16.79999999999999\n",
      "      - 23.99999999999993\n",
      "      - 18.59999999999994\n",
      "      - -3.599999999999992\n",
      "      - 22.199999999999918\n",
      "      - -0.29999999999998084\n",
      "      - 28.799999999999912\n",
      "      - 25.79999999999994\n",
      "      - 6.000000000000016\n",
      "      - 15.899999999999997\n",
      "      - 15.600000000000009\n",
      "      - 27.299999999999898\n",
      "      - 24.599999999999934\n",
      "      - 37.19999999999992\n",
      "      - 23.099999999999902\n",
      "      - 6.300000000000026\n",
      "      - -1.799999999999978\n",
      "      - 36.299999999999905\n",
      "      - 24.599999999999895\n",
      "      - 23.999999999999936\n",
      "      - 24.299999999999926\n",
      "      - 28.799999999999926\n",
      "      - 16.200000000000024\n",
      "      - 5.099999999999994\n",
      "      - 18.89999999999992\n",
      "      - 29.69999999999994\n",
      "      - 13.199999999999955\n",
      "      - 24.29999999999994\n",
      "      - 28.499999999999908\n",
      "      - 18.000000000000014\n",
      "      - 9.900000000000015\n",
      "      - 27.899999999999913\n",
      "      - 6.899999999999988\n",
      "      - 24.299999999999926\n",
      "      - 17.40000000000002\n",
      "      - 19.199999999999932\n",
      "      - 35.9999999999999\n",
      "      - 29.39999999999992\n",
      "      - 2.731148640577885e-14\n",
      "      - 10.199999999999935\n",
      "      - 19.800000000000004\n",
      "      - 18.299999999999947\n",
      "      - 24.299999999999905\n",
      "      - 13.199999999999918\n",
      "      - 13.499999999999966\n",
      "      - 22.199999999999925\n",
      "      - 14.100000000000014\n",
      "      - 9.0\n",
      "      - 21.29999999999994\n",
      "      - 16.500000000000018\n",
      "      - 3.083644450896372e-14\n",
      "      - 4.800000000000008\n",
      "      - 15.299999999999976\n",
      "      - 30.299999999999898\n",
      "      - 30.599999999999937\n",
      "      - 15.8999999999999\n",
      "      - 17.699999999999974\n",
      "      - 20.099999999999945\n",
      "      - 17.99999999999994\n",
      "      - 17.09999999999991\n",
      "      - 18.29999999999992\n",
      "      - 31.799999999999905\n",
      "      - 26.999999999999915\n",
      "      - 12.300000000000024\n",
      "      - 20.99999999999993\n",
      "      - 18.000000000000014\n",
      "      - 17.69999999999989\n",
      "      - 15.599999999999918\n",
      "      - 30.89999999999994\n",
      "      - 28.19999999999991\n",
      "      - 23.6999999999999\n",
      "      - 20.999999999999957\n",
      "      - 18.29999999999999\n",
      "      - 18.299999999999933\n",
      "      - 5.4000000000000155\n",
      "      - 24.89999999999992\n",
      "      - 3.299999999999943\n",
      "      - 13.499999999999906\n",
      "      - 17.999999999999908\n",
      "      - 11.400000000000025\n",
      "      - -20.099999999999994\n",
      "      - 26.99999999999993\n",
      "      - 29.699999999999903\n",
      "      - 15.599999999999918\n",
      "      - 9.299999999999999\n",
      "      - 12.600000000000016\n",
      "      - 22.799999999999905\n",
      "      - 17.699999999999925\n",
      "      policy_policy1_reward:\n",
      "      - 30.5\n",
      "      - 18.0\n",
      "      - 19.0\n",
      "      - 27.5\n",
      "      - 16.5\n",
      "      - 26.0\n",
      "      - 35.0\n",
      "      - 25.5\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 5.0\n",
      "      - 29.0\n",
      "      - 23.5\n",
      "      - 34.0\n",
      "      - 22.0\n",
      "      - 2.0\n",
      "      - 30.0\n",
      "      - 7.5\n",
      "      - 35.5\n",
      "      - 27.0\n",
      "      - 10.5\n",
      "      - 16.0\n",
      "      - 24.5\n",
      "      - 34.0\n",
      "      - 28.0\n",
      "      - 39.5\n",
      "      - 32.0\n",
      "      - 7.5\n",
      "      - 0.5\n",
      "      - 43.0\n",
      "      - 33.5\n",
      "      - 34.0\n",
      "      - 31.0\n",
      "      - 19.0\n",
      "      - 18.5\n",
      "      - 3.0\n",
      "      - 24.5\n",
      "      - 37.5\n",
      "      - 4.5\n",
      "      - 25.5\n",
      "      - 33.0\n",
      "      - 11.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 7.0\n",
      "      - 25.5\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 46.0\n",
      "      - 35.0\n",
      "      - 4.5\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 25.0\n",
      "      - 31.0\n",
      "      - 10.0\n",
      "      - 23.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 13.5\n",
      "      - 28.0\n",
      "      - 15.5\n",
      "      - 10.0\n",
      "      - 6.0\n",
      "      - 22.0\n",
      "      - 37.0\n",
      "      - 34.0\n",
      "      - 21.5\n",
      "      - 20.0\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 25.0\n",
      "      - 38.5\n",
      "      - 37.0\n",
      "      - 13.5\n",
      "      - 25.5\n",
      "      - 28.0\n",
      "      - 25.5\n",
      "      - 24.5\n",
      "      - 36.5\n",
      "      - 30.5\n",
      "      - 31.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 25.0\n",
      "      - 11.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 23.5\n",
      "      - 28.0\n",
      "      - 6.0\n",
      "      - -14.5\n",
      "      - 37.0\n",
      "      - 37.5\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      policy_policy2_reward:\n",
      "      - -5.599999999999995\n",
      "      - -4.500000000000004\n",
      "      - -6.699999999999986\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999981\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999985\n",
      "      - -3.4000000000000035\n",
      "      - -6.6999999999999895\n",
      "      - 10.900000000000013\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000012\n",
      "      - -5.599999999999988\n",
      "      - -7.7999999999999865\n",
      "      - -7.79999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -1.2000000000000044\n",
      "      - -4.500000000000003\n",
      "      - -0.10000000000000009\n",
      "      - -8.899999999999986\n",
      "      - -6.699999999999989\n",
      "      - -3.400000000000006\n",
      "      - -2.3000000000000047\n",
      "      - -8.89999999999998\n",
      "      - -1.1999999999999935\n",
      "      - -2.3000000000000047\n",
      "      - -6.699999999999986\n",
      "      - -8.899999999999986\n",
      "      - -9.99999999999998\n",
      "      - -6.6999999999999815\n",
      "      - 9.800000000000015\n",
      "      - -2.3000000000000007\n",
      "      - 2.099999999999996\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - 8.699999999999996\n",
      "      - -1.2000000000000022\n",
      "      - -4.500000000000002\n",
      "      - 6.5000000000000036\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999999\n",
      "      - -0.1000000000000042\n",
      "      - -1.2000000000000013\n",
      "      - -5.599999999999995\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -4.4999999999999964\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - 3.2000000000000055\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000001\n",
      "      - -3.400000000000004\n",
      "      - -4.4999999999999885\n",
      "      - -6.699999999999995\n",
      "      - 0.9999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999946\n",
      "      - -6.699999999999995\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999884\n",
      "      - -5.599999999999991\n",
      "      - -2.300000000000006\n",
      "      - -3.4000000000000026\n",
      "      - 0.9999999999999934\n",
      "      - -3.400000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999982\n",
      "      - -4.499999999999993\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999997\n",
      "      - -2.2999999999999963\n",
      "      - -7.7999999999999865\n",
      "      - -4.500000000000003\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999982\n",
      "      - -0.10000000000000347\n",
      "      - -1.2000000000000037\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000002\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -3.3999999999999955\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -1.199999999999995\n",
      "      - -2.2999999999999994\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 10.900000000000013\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.77\n",
      "      policy2: -4.6979999999999915\n",
      "    policy_reward_min:\n",
      "      policy1: -14.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18301246230425722\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07823205426155734\n",
      "      mean_inference_ms: 1.92791473177\n",
      "      mean_raw_obs_processing_ms: 0.3603296234659849\n",
      "  time_since_restore: 353.7750129699707\n",
      "  time_this_iter_s: 15.305366039276123\n",
      "  time_total_s: 353.7750129699707\n",
      "  timers:\n",
      "    learn_throughput: 408.247\n",
      "    learn_time_ms: 9798.0\n",
      "    synch_weights_time_ms: 5.058\n",
      "    training_iteration_time_ms: 20907.839\n",
      "  timestamp: 1658917415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 72000\n",
      "  training_iteration: 18\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 152000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_env_steps_sampled: 76000\n",
      "    num_env_steps_trained: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-35\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 32.9999999999999\n",
      "  episode_reward_mean: 18.407999999999937\n",
      "  episode_reward_min: -1.500000000000007\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 760\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7484294772148132\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.012534977868199348\n",
      "          model: {}\n",
      "          policy_loss: -0.03207249194383621\n",
      "          total_loss: 6.804152488708496\n",
      "          vf_explained_var: 0.27786892652511597\n",
      "          vf_loss: 6.832464694976807\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7363443970680237\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.013475889340043068\n",
      "          model: {}\n",
      "          policy_loss: -0.03274105489253998\n",
      "          total_loss: 3.38501238822937\n",
      "          vf_explained_var: 0.07642468810081482\n",
      "          vf_loss: 3.4150583744049072\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_env_steps_sampled: 76000\n",
      "    num_env_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 152000\n",
      "  num_agent_steps_trained: 152000\n",
      "  num_env_steps_sampled: 76000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 76000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.26363636363636\n",
      "    ram_util_percent: 60.01818181818182\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 38.5\n",
      "    policy2: 22.999999999999964\n",
      "  policy_reward_mean:\n",
      "    policy1: 21.995\n",
      "    policy2: -3.5869999999999935\n",
      "  policy_reward_min:\n",
      "    policy1: -8.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18054656443745187\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07743224638083547\n",
      "    mean_inference_ms: 1.8906018490464431\n",
      "    mean_raw_obs_processing_ms: 0.355648609442037\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 32.9999999999999\n",
      "    episode_reward_mean: 18.407999999999937\n",
      "    episode_reward_min: -1.500000000000007\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 18.89999999999991\n",
      "      - 13.499999999999938\n",
      "      - 13.49999999999996\n",
      "      - 11.400000000000032\n",
      "      - 29.99999999999993\n",
      "      - 2.0999999999999828\n",
      "      - 27.599999999999895\n",
      "      - 22.799999999999947\n",
      "      - 20.999999999999908\n",
      "      - 24.299999999999912\n",
      "      - 13.199999999999912\n",
      "      - 9.899999999999968\n",
      "      - 29.999999999999897\n",
      "      - 15.599999999999897\n",
      "      - 17.9999999999999\n",
      "      - 1.2000000000000108\n",
      "      - 6.8999999999999435\n",
      "      - 3.000000000000024\n",
      "      - 10.199999999999914\n",
      "      - 10.49999999999994\n",
      "      - 31.799999999999923\n",
      "      - 15.299999999999944\n",
      "      - -1.500000000000007\n",
      "      - 23.399999999999913\n",
      "      - 12.299999999999988\n",
      "      - 12.000000000000028\n",
      "      - 22.499999999999908\n",
      "      - 23.399999999999906\n",
      "      - 22.499999999999915\n",
      "      - 23.9999999999999\n",
      "      - 4.2000000000000295\n",
      "      - 15.89999999999994\n",
      "      - 21.599999999999923\n",
      "      - 30.599999999999902\n",
      "      - 24.8999999999999\n",
      "      - 26.9999999999999\n",
      "      - 24.59999999999992\n",
      "      - 18.29999999999991\n",
      "      - 11.999999999999972\n",
      "      - 17.699999999999935\n",
      "      - 7.500000000000032\n",
      "      - 25.199999999999925\n",
      "      - 25.799999999999905\n",
      "      - 24.299999999999905\n",
      "      - 15.89999999999993\n",
      "      - 14.999999999999968\n",
      "      - 15.599999999999943\n",
      "      - 11.099999999999934\n",
      "      - 8.099999999999943\n",
      "      - 26.09999999999991\n",
      "      - 26.099999999999902\n",
      "      - 15.299999999999928\n",
      "      - 7.799999999999965\n",
      "      - 22.19999999999991\n",
      "      - 20.09999999999993\n",
      "      - 32.9999999999999\n",
      "      - 19.5\n",
      "      - 26.09999999999993\n",
      "      - 14.999999999999911\n",
      "      - 14.999999999999911\n",
      "      - 23.699999999999903\n",
      "      - 26.399999999999892\n",
      "      - 26.3999999999999\n",
      "      - 15.899999999999922\n",
      "      - 21.59999999999993\n",
      "      - 21.899999999999917\n",
      "      - 27.899999999999913\n",
      "      - 20.69999999999991\n",
      "      - 17.09999999999994\n",
      "      - 2.999999999999962\n",
      "      - 23.699999999999932\n",
      "      - 26.999999999999893\n",
      "      - 15.29999999999999\n",
      "      - 28.4999999999999\n",
      "      - 14.699999999999969\n",
      "      - 16.500000000000007\n",
      "      - 14.700000000000001\n",
      "      - 11.399999999999919\n",
      "      - 20.099999999999916\n",
      "      - 31.499999999999908\n",
      "      - 9.89999999999998\n",
      "      - 17.999999999999932\n",
      "      - 19.199999999999967\n",
      "      - 7.199999999999953\n",
      "      - 17.699999999999925\n",
      "      - 26.9999999999999\n",
      "      - 14.700000000000012\n",
      "      - 17.999999999999908\n",
      "      - 20.9999999999999\n",
      "      - 20.999999999999915\n",
      "      - 19.199999999999903\n",
      "      - 18.599999999999902\n",
      "      - 21.29999999999997\n",
      "      - 23.69999999999996\n",
      "      - 22.499999999999908\n",
      "      - 5.100000000000032\n",
      "      - 11.999999999999941\n",
      "      - 20.399999999999956\n",
      "      - 30.899999999999892\n",
      "      - 24.599999999999962\n",
      "      policy_policy1_reward:\n",
      "      - 19.0\n",
      "      - 18.0\n",
      "      - 18.0\n",
      "      - 17.0\n",
      "      - 29.0\n",
      "      - 11.0\n",
      "      - 36.5\n",
      "      - 29.5\n",
      "      - 25.5\n",
      "      - 25.5\n",
      "      - 21.0\n",
      "      - 15.5\n",
      "      - 34.5\n",
      "      - 24.5\n",
      "      - 22.5\n",
      "      - 9.0\n",
      "      - 12.5\n",
      "      - 7.5\n",
      "      - 18.0\n",
      "      - 9.5\n",
      "      - 27.5\n",
      "      - 22.0\n",
      "      - 8.5\n",
      "      - 29.0\n",
      "      - 2.5\n",
      "      - 11.0\n",
      "      - 32.5\n",
      "      - 23.5\n",
      "      - 32.5\n",
      "      - 34.0\n",
      "      - 6.5\n",
      "      - 21.5\n",
      "      - 30.5\n",
      "      - 34.0\n",
      "      - 30.5\n",
      "      - 26.0\n",
      "      - 28.0\n",
      "      - 14.0\n",
      "      - 16.5\n",
      "      - 20.0\n",
      "      - 12.0\n",
      "      - 27.5\n",
      "      - 27.0\n",
      "      - 25.5\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 35.0\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 9.0\n",
      "      - 30.0\n",
      "      - 18.0\n",
      "      - 32.0\n",
      "      - 24.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 19.5\n",
      "      - 31.5\n",
      "      - 32.0\n",
      "      - 26.5\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 27.5\n",
      "      - 28.0\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 7.5\n",
      "      - 20.5\n",
      "      - 37.0\n",
      "      - 22.0\n",
      "      - 38.5\n",
      "      - 22.5\n",
      "      - 26.5\n",
      "      - 22.5\n",
      "      - 17.0\n",
      "      - 29.0\n",
      "      - 36.0\n",
      "      - 15.5\n",
      "      - 17.0\n",
      "      - 27.0\n",
      "      - 15.0\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 17.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 20.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 17.0\n",
      "      - 26.0\n",
      "      - 21.5\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 26.0\n",
      "      - 36.5\n",
      "      - 22.5\n",
      "      policy_policy2_reward:\n",
      "      - -0.10000000000000289\n",
      "      - -4.5\n",
      "      - -4.499999999999994\n",
      "      - -5.5999999999999845\n",
      "      - 0.9999999999999963\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -6.699999999999984\n",
      "      - -4.500000000000003\n",
      "      - -1.1999999999999833\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999999\n",
      "      - -4.499999999999984\n",
      "      - -8.899999999999983\n",
      "      - -4.499999999999991\n",
      "      - -7.799999999999981\n",
      "      - -5.599999999999983\n",
      "      - -4.499999999999996\n",
      "      - -7.79999999999999\n",
      "      - 0.9999999999999966\n",
      "      - 4.300000000000008\n",
      "      - -6.699999999999991\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - 9.800000000000013\n",
      "      - 1.0000000000000093\n",
      "      - -9.99999999999998\n",
      "      - -0.10000000000000198\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000025\n",
      "      - -5.599999999999982\n",
      "      - -8.89999999999998\n",
      "      - -3.4\n",
      "      - -5.5999999999999845\n",
      "      - 0.9999999999999974\n",
      "      - -3.399999999999997\n",
      "      - 4.299999999999995\n",
      "      - -4.5\n",
      "      - -2.3000000000000034\n",
      "      - -4.499999999999997\n",
      "      - -2.3000000000000034\n",
      "      - -1.2000000000000017\n",
      "      - -1.2000000000000044\n",
      "      - -5.599999999999991\n",
      "      - 22.999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 2.0999999999999934\n",
      "      - -6.699999999999991\n",
      "      - -1.200000000000001\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999995\n",
      "      - 0.9999999999999934\n",
      "      - -4.499999999999995\n",
      "      - 7.6000000000000005\n",
      "      - -4.499999999999986\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -0.10000000000000248\n",
      "      - -0.09999999999999876\n",
      "      - -3.400000000000004\n",
      "      - -5.6\n",
      "      - -0.10000000000000508\n",
      "      - -2.300000000000003\n",
      "      - 2.0999999999999943\n",
      "      - -4.499999999999996\n",
      "      - 3.1999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999993\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999994\n",
      "      - 0.9999999999999943\n",
      "      - -7.799999999999981\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999983\n",
      "      - -4.499999999999991\n",
      "      - -2.300000000000002\n",
      "      - -4.500000000000003\n",
      "      - -4.499999999999987\n",
      "      - 0.9999999999999934\n",
      "      - -2.300000000000003\n",
      "      - -8.89999999999998\n",
      "      - 4.3000000000000025\n",
      "      - -2.299999999999995\n",
      "      - 0.9999999999999952\n",
      "      - -3.400000000000004\n",
      "      - 12.000000000000016\n",
      "      - -5.599999999999998\n",
      "      - -5.599999999999995\n",
      "      - 2.0999999999999965\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.5\n",
      "      policy2: 22.999999999999964\n",
      "    policy_reward_mean:\n",
      "      policy1: 21.995\n",
      "      policy2: -3.5869999999999935\n",
      "    policy_reward_min:\n",
      "      policy1: -8.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18054656443745187\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07743224638083547\n",
      "      mean_inference_ms: 1.8906018490464431\n",
      "      mean_raw_obs_processing_ms: 0.355648609442037\n",
      "  time_since_restore: 364.8240475654602\n",
      "  time_this_iter_s: 15.23268985748291\n",
      "  time_total_s: 364.8240475654602\n",
      "  timers:\n",
      "    learn_throughput: 409.606\n",
      "    learn_time_ms: 9765.472\n",
      "    synch_weights_time_ms: 11.304\n",
      "    training_iteration_time_ms: 20975.687\n",
      "  timestamp: 1658917415\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 152000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_env_steps_sampled: 76000\n",
      "    num_env_steps_trained: 76000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-49\n",
      "  done: false\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.8999999999999\n",
      "  episode_reward_mean: 17.084999999999958\n",
      "  episode_reward_min: -20.099999999999994\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 760\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.760287344455719\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.017550406977534294\n",
      "          model: {}\n",
      "          policy_loss: -0.043560151010751724\n",
      "          total_loss: 7.3473219871521\n",
      "          vf_explained_var: 0.06247890740633011\n",
      "          vf_loss: 7.382984638214111\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7872135043144226\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.014867367222905159\n",
      "          model: {}\n",
      "          policy_loss: -0.03776460513472557\n",
      "          total_loss: 3.3759944438934326\n",
      "          vf_explained_var: 0.04302907735109329\n",
      "          vf_loss: 3.407068967819214\n",
      "    num_agent_steps_sampled: 152000\n",
      "    num_agent_steps_trained: 152000\n",
      "    num_env_steps_sampled: 76000\n",
      "    num_env_steps_trained: 76000\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 152000\n",
      "  num_agent_steps_trained: 152000\n",
      "  num_env_steps_sampled: 76000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 76000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 30.744999999999997\n",
      "    ram_util_percent: 62.42999999999999\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 46.0\n",
      "    policy2: 18.599999999999994\n",
      "  policy_reward_mean:\n",
      "    policy1: 21.255\n",
      "    policy2: -4.169999999999992\n",
      "  policy_reward_min:\n",
      "    policy1: -14.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.18072125747975737\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07733881775747528\n",
      "    mean_inference_ms: 1.9024257850931425\n",
      "    mean_raw_obs_processing_ms: 0.35613443897198493\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.8999999999999\n",
      "    episode_reward_mean: 17.084999999999958\n",
      "    episode_reward_min: -20.099999999999994\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 28.499999999999908\n",
      "      - 18.000000000000014\n",
      "      - 9.900000000000015\n",
      "      - 27.899999999999913\n",
      "      - 6.899999999999988\n",
      "      - 24.299999999999926\n",
      "      - 17.40000000000002\n",
      "      - 19.199999999999932\n",
      "      - 35.9999999999999\n",
      "      - 29.39999999999992\n",
      "      - 2.731148640577885e-14\n",
      "      - 10.199999999999935\n",
      "      - 19.800000000000004\n",
      "      - 18.299999999999947\n",
      "      - 24.299999999999905\n",
      "      - 13.199999999999918\n",
      "      - 13.499999999999966\n",
      "      - 22.199999999999925\n",
      "      - 14.100000000000014\n",
      "      - 9.0\n",
      "      - 21.29999999999994\n",
      "      - 16.500000000000018\n",
      "      - 3.083644450896372e-14\n",
      "      - 4.800000000000008\n",
      "      - 15.299999999999976\n",
      "      - 30.299999999999898\n",
      "      - 30.599999999999937\n",
      "      - 15.8999999999999\n",
      "      - 17.699999999999974\n",
      "      - 20.099999999999945\n",
      "      - 17.99999999999994\n",
      "      - 17.09999999999991\n",
      "      - 18.29999999999992\n",
      "      - 31.799999999999905\n",
      "      - 26.999999999999915\n",
      "      - 12.300000000000024\n",
      "      - 20.99999999999993\n",
      "      - 18.000000000000014\n",
      "      - 17.69999999999989\n",
      "      - 15.599999999999918\n",
      "      - 30.89999999999994\n",
      "      - 28.19999999999991\n",
      "      - 23.6999999999999\n",
      "      - 20.999999999999957\n",
      "      - 18.29999999999999\n",
      "      - 18.299999999999933\n",
      "      - 5.4000000000000155\n",
      "      - 24.89999999999992\n",
      "      - 3.299999999999943\n",
      "      - 13.499999999999906\n",
      "      - 17.999999999999908\n",
      "      - 11.400000000000025\n",
      "      - -20.099999999999994\n",
      "      - 26.99999999999993\n",
      "      - 29.699999999999903\n",
      "      - 15.599999999999918\n",
      "      - 9.299999999999999\n",
      "      - 12.600000000000016\n",
      "      - 22.799999999999905\n",
      "      - 17.699999999999925\n",
      "      - 5.700000000000003\n",
      "      - 12.899999999999928\n",
      "      - 12.90000000000002\n",
      "      - 6.900000000000027\n",
      "      - 22.199999999999996\n",
      "      - 25.799999999999912\n",
      "      - 8.099999999999941\n",
      "      - 20.699999999999967\n",
      "      - 17.09999999999998\n",
      "      - 7.499999999999989\n",
      "      - 24.599999999999973\n",
      "      - 13.49999999999997\n",
      "      - 21.599999999999966\n",
      "      - 5.3999999999999755\n",
      "      - 19.499999999999975\n",
      "      - 9.300000000000026\n",
      "      - 1.2000000000000202\n",
      "      - 25.49999999999992\n",
      "      - 23.099999999999987\n",
      "      - 15.599999999999932\n",
      "      - 28.49999999999995\n",
      "      - 24.599999999999937\n",
      "      - -10.799999999999976\n",
      "      - 19.199999999999935\n",
      "      - 10.800000000000017\n",
      "      - 8.70000000000001\n",
      "      - 28.799999999999955\n",
      "      - 20.999999999999936\n",
      "      - -17.39999999999999\n",
      "      - 12.899999999999997\n",
      "      - 26.999999999999915\n",
      "      - 20.39999999999992\n",
      "      - 27.599999999999962\n",
      "      - 39.8999999999999\n",
      "      - 30.299999999999905\n",
      "      - 11.999999999999906\n",
      "      - -2.1000000000000294\n",
      "      - 29.099999999999895\n",
      "      - 16.199999999999974\n",
      "      - 19.8\n",
      "      policy_policy1_reward:\n",
      "      - 33.0\n",
      "      - 11.5\n",
      "      - 15.5\n",
      "      - 33.5\n",
      "      - 7.0\n",
      "      - 25.5\n",
      "      - 23.0\n",
      "      - 27.0\n",
      "      - 46.0\n",
      "      - 35.0\n",
      "      - 4.5\n",
      "      - 18.0\n",
      "      - 26.5\n",
      "      - 25.0\n",
      "      - 31.0\n",
      "      - 10.0\n",
      "      - 23.5\n",
      "      - 24.5\n",
      "      - 17.5\n",
      "      - 13.5\n",
      "      - 28.0\n",
      "      - 15.5\n",
      "      - 10.0\n",
      "      - 6.0\n",
      "      - 22.0\n",
      "      - 37.0\n",
      "      - 34.0\n",
      "      - 21.5\n",
      "      - 20.0\n",
      "      - 23.5\n",
      "      - 17.0\n",
      "      - 20.5\n",
      "      - 25.0\n",
      "      - 38.5\n",
      "      - 37.0\n",
      "      - 13.5\n",
      "      - 25.5\n",
      "      - 28.0\n",
      "      - 25.5\n",
      "      - 24.5\n",
      "      - 36.5\n",
      "      - 30.5\n",
      "      - 31.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 25.0\n",
      "      - 11.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 23.5\n",
      "      - 28.0\n",
      "      - 6.0\n",
      "      - -14.5\n",
      "      - 37.0\n",
      "      - 37.5\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      - 2.5\n",
      "      - 18.5\n",
      "      - -3.5\n",
      "      - 12.5\n",
      "      - 30.0\n",
      "      - 27.0\n",
      "      - 17.0\n",
      "      - 28.5\n",
      "      - 26.0\n",
      "      - 12.0\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - 30.5\n",
      "      - 5.5\n",
      "      - 24.0\n",
      "      - 16.0\n",
      "      - 3.5\n",
      "      - 30.0\n",
      "      - 26.5\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 28.0\n",
      "      - -3.0\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 16.5\n",
      "      - 35.5\n",
      "      - 25.5\n",
      "      - -8.5\n",
      "      - 18.5\n",
      "      - 31.5\n",
      "      - 20.5\n",
      "      - 31.0\n",
      "      - 45.5\n",
      "      - 37.0\n",
      "      - 16.5\n",
      "      - 3.5\n",
      "      - 38.0\n",
      "      - 24.0\n",
      "      - 26.5\n",
      "      policy_policy2_reward:\n",
      "      - -4.500000000000002\n",
      "      - 6.5000000000000036\n",
      "      - -5.5999999999999845\n",
      "      - -5.599999999999999\n",
      "      - -0.1000000000000042\n",
      "      - -1.2000000000000013\n",
      "      - -5.599999999999995\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -5.599999999999982\n",
      "      - -4.4999999999999964\n",
      "      - -7.799999999999989\n",
      "      - -6.699999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999988\n",
      "      - 3.2000000000000055\n",
      "      - -9.99999999999998\n",
      "      - -2.300000000000001\n",
      "      - -3.400000000000004\n",
      "      - -4.4999999999999885\n",
      "      - -6.699999999999995\n",
      "      - 0.9999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999946\n",
      "      - -6.699999999999995\n",
      "      - -6.6999999999999815\n",
      "      - -3.3999999999999884\n",
      "      - -5.599999999999991\n",
      "      - -2.300000000000006\n",
      "      - -3.4000000000000026\n",
      "      - 0.9999999999999934\n",
      "      - -3.400000000000003\n",
      "      - -6.6999999999999815\n",
      "      - -6.699999999999994\n",
      "      - -9.99999999999998\n",
      "      - -1.1999999999999982\n",
      "      - -4.499999999999993\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999982\n",
      "      - -8.899999999999986\n",
      "      - -5.599999999999997\n",
      "      - -2.2999999999999963\n",
      "      - -7.7999999999999865\n",
      "      - -4.500000000000003\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999982\n",
      "      - -0.10000000000000347\n",
      "      - -1.2000000000000037\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000002\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -3.3999999999999955\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -1.199999999999995\n",
      "      - -2.2999999999999994\n",
      "      - 3.200000000000017\n",
      "      - -5.599999999999997\n",
      "      - 16.399999999999963\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000015\n",
      "      - -8.899999999999984\n",
      "      - -7.799999999999982\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999995\n",
      "      - 18.599999999999994\n",
      "      - 6.499999999999999\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000409\n",
      "      - -4.499999999999993\n",
      "      - -6.699999999999989\n",
      "      - -2.300000000000004\n",
      "      - -4.499999999999992\n",
      "      - -3.399999999999988\n",
      "      - 2.100000000000006\n",
      "      - 6.500000000000009\n",
      "      - -3.400000000000005\n",
      "      - -7.799999999999981\n",
      "      - 3.1999999999999984\n",
      "      - -1.199999999999995\n",
      "      - -7.799999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -4.49999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999988\n",
      "      - -4.499999999999992\n",
      "      - -0.10000000000000109\n",
      "      - -3.4000000000000044\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999997\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -6.6999999999999815\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 46.0\n",
      "      policy2: 18.599999999999994\n",
      "    policy_reward_mean:\n",
      "      policy1: 21.255\n",
      "      policy2: -4.169999999999992\n",
      "    policy_reward_min:\n",
      "      policy1: -14.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.18072125747975737\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07733881775747528\n",
      "      mean_inference_ms: 1.9024257850931425\n",
      "      mean_raw_obs_processing_ms: 0.35613443897198493\n",
      "  time_since_restore: 367.8119058609009\n",
      "  time_this_iter_s: 14.036892890930176\n",
      "  time_total_s: 367.8119058609009\n",
      "  timers:\n",
      "    learn_throughput: 428.942\n",
      "    learn_time_ms: 9325.267\n",
      "    synch_weights_time_ms: 4.967\n",
      "    training_iteration_time_ms: 19969.636\n",
      "  timestamp: 1658917429\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 76000\n",
      "  training_iteration: 19\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n",
      "Result for PPO_MultiAgentArena_1dedd_00002:\n",
      "  agent_timesteps_total: 160000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_env_steps_sampled: 80000\n",
      "    num_env_steps_trained: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-23-51\n",
      "  done: true\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 36.599999999999916\n",
      "  episode_reward_mean: 19.010999999999935\n",
      "  episode_reward_min: -10.799999999999997\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 800\n",
      "  experiment_id: c17cd36a0e4f4dc2990f672fbf10b128\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.30000001192092896\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7354329228401184\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01220855675637722\n",
      "          model: {}\n",
      "          policy_loss: -0.032390523701906204\n",
      "          total_loss: 6.692912578582764\n",
      "          vf_explained_var: 0.32757478952407837\n",
      "          vf_loss: 6.7216410636901855\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.20000000298023224\n",
      "          cur_lr: 4.999999873689376e-05\n",
      "          entropy: 0.7246304154396057\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.01398431695997715\n",
      "          model: {}\n",
      "          policy_loss: -0.03477243706583977\n",
      "          total_loss: 3.212170362472534\n",
      "          vf_explained_var: 0.13444466888904572\n",
      "          vf_loss: 3.2441461086273193\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_env_steps_sampled: 80000\n",
      "    num_env_steps_trained: 80000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 160000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_env_steps_sampled: 80000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 80000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.75909090909091\n",
      "    ram_util_percent: 62.51818181818181\n",
      "  pid: 48452\n",
      "  policy_reward_max:\n",
      "    policy1: 38.5\n",
      "    policy2: 22.999999999999964\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.345\n",
      "    policy2: -3.3339999999999934\n",
      "  policy_reward_min:\n",
      "    policy1: -8.0\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17860583158559287\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0767034369093879\n",
      "    mean_inference_ms: 1.873229246871866\n",
      "    mean_raw_obs_processing_ms: 0.35208457614060557\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 36.599999999999916\n",
      "    episode_reward_mean: 19.010999999999935\n",
      "    episode_reward_min: -10.799999999999997\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 7.500000000000032\n",
      "      - 25.199999999999925\n",
      "      - 25.799999999999905\n",
      "      - 24.299999999999905\n",
      "      - 15.89999999999993\n",
      "      - 14.999999999999968\n",
      "      - 15.599999999999943\n",
      "      - 11.099999999999934\n",
      "      - 8.099999999999943\n",
      "      - 26.09999999999991\n",
      "      - 26.099999999999902\n",
      "      - 15.299999999999928\n",
      "      - 7.799999999999965\n",
      "      - 22.19999999999991\n",
      "      - 20.09999999999993\n",
      "      - 32.9999999999999\n",
      "      - 19.5\n",
      "      - 26.09999999999993\n",
      "      - 14.999999999999911\n",
      "      - 14.999999999999911\n",
      "      - 23.699999999999903\n",
      "      - 26.399999999999892\n",
      "      - 26.3999999999999\n",
      "      - 15.899999999999922\n",
      "      - 21.59999999999993\n",
      "      - 21.899999999999917\n",
      "      - 27.899999999999913\n",
      "      - 20.69999999999991\n",
      "      - 17.09999999999994\n",
      "      - 2.999999999999962\n",
      "      - 23.699999999999932\n",
      "      - 26.999999999999893\n",
      "      - 15.29999999999999\n",
      "      - 28.4999999999999\n",
      "      - 14.699999999999969\n",
      "      - 16.500000000000007\n",
      "      - 14.700000000000001\n",
      "      - 11.399999999999919\n",
      "      - 20.099999999999916\n",
      "      - 31.499999999999908\n",
      "      - 9.89999999999998\n",
      "      - 17.999999999999932\n",
      "      - 19.199999999999967\n",
      "      - 7.199999999999953\n",
      "      - 17.699999999999925\n",
      "      - 26.9999999999999\n",
      "      - 14.700000000000012\n",
      "      - 17.999999999999908\n",
      "      - 20.9999999999999\n",
      "      - 20.999999999999915\n",
      "      - 19.199999999999903\n",
      "      - 18.599999999999902\n",
      "      - 21.29999999999997\n",
      "      - 23.69999999999996\n",
      "      - 22.499999999999908\n",
      "      - 5.100000000000032\n",
      "      - 11.999999999999941\n",
      "      - 20.399999999999956\n",
      "      - 30.899999999999892\n",
      "      - 24.599999999999962\n",
      "      - 15.59999999999993\n",
      "      - 17.099999999999902\n",
      "      - 11.399999999999928\n",
      "      - 22.499999999999908\n",
      "      - 20.39999999999992\n",
      "      - 28.799999999999905\n",
      "      - 22.499999999999908\n",
      "      - 7.2000000000000295\n",
      "      - 16.199999999999942\n",
      "      - 23.6999999999999\n",
      "      - 18.299999999999912\n",
      "      - 26.399999999999935\n",
      "      - 14.100000000000003\n",
      "      - 33.299999999999905\n",
      "      - 12.299999999999926\n",
      "      - 24.59999999999993\n",
      "      - 22.199999999999946\n",
      "      - 15.599999999999925\n",
      "      - 0.30000000000000493\n",
      "      - 6.300000000000026\n",
      "      - 18.299999999999926\n",
      "      - 24.899999999999906\n",
      "      - 20.6999999999999\n",
      "      - 23.699999999999918\n",
      "      - 20.099999999999937\n",
      "      - 33.299999999999926\n",
      "      - 11.100000000000023\n",
      "      - 26.9999999999999\n",
      "      - 14.699999999999916\n",
      "      - 13.200000000000001\n",
      "      - 30.29999999999989\n",
      "      - 24.2999999999999\n",
      "      - 36.599999999999916\n",
      "      - 6.900000000000004\n",
      "      - 20.09999999999993\n",
      "      - 24.899999999999906\n",
      "      - 18.599999999999916\n",
      "      - 11.700000000000012\n",
      "      - 17.999999999999943\n",
      "      - -10.799999999999997\n",
      "      policy_policy1_reward:\n",
      "      - 12.0\n",
      "      - 27.5\n",
      "      - 27.0\n",
      "      - 25.5\n",
      "      - 21.5\n",
      "      - -8.0\n",
      "      - 24.5\n",
      "      - 20.0\n",
      "      - 17.0\n",
      "      - 35.0\n",
      "      - 24.0\n",
      "      - 22.0\n",
      "      - 9.0\n",
      "      - 30.0\n",
      "      - 18.0\n",
      "      - 32.0\n",
      "      - 24.0\n",
      "      - 18.5\n",
      "      - 19.5\n",
      "      - 19.5\n",
      "      - 31.5\n",
      "      - 32.0\n",
      "      - 26.5\n",
      "      - 16.0\n",
      "      - 25.0\n",
      "      - 27.5\n",
      "      - 28.0\n",
      "      - 23.0\n",
      "      - 15.0\n",
      "      - 7.5\n",
      "      - 20.5\n",
      "      - 37.0\n",
      "      - 22.0\n",
      "      - 38.5\n",
      "      - 22.5\n",
      "      - 26.5\n",
      "      - 22.5\n",
      "      - 17.0\n",
      "      - 29.0\n",
      "      - 36.0\n",
      "      - 15.5\n",
      "      - 17.0\n",
      "      - 27.0\n",
      "      - 15.0\n",
      "      - 25.5\n",
      "      - 31.5\n",
      "      - 17.0\n",
      "      - 22.5\n",
      "      - 25.5\n",
      "      - 20.0\n",
      "      - 21.5\n",
      "      - 27.5\n",
      "      - 17.0\n",
      "      - 26.0\n",
      "      - 21.5\n",
      "      - 8.5\n",
      "      - 0.0\n",
      "      - 26.0\n",
      "      - 36.5\n",
      "      - 22.5\n",
      "      - 19.0\n",
      "      - 20.5\n",
      "      - 17.0\n",
      "      - 32.5\n",
      "      - 26.0\n",
      "      - 35.5\n",
      "      - 27.0\n",
      "      - 15.0\n",
      "      - 18.5\n",
      "      - 31.5\n",
      "      - 19.5\n",
      "      - 26.5\n",
      "      - 17.5\n",
      "      - 34.5\n",
      "      - 19.0\n",
      "      - 28.0\n",
      "      - 24.5\n",
      "      - 8.0\n",
      "      - 7.0\n",
      "      - 13.0\n",
      "      - 25.0\n",
      "      - 25.0\n",
      "      - 23.0\n",
      "      - 26.0\n",
      "      - 23.5\n",
      "      - 34.5\n",
      "      - 20.0\n",
      "      - 31.5\n",
      "      - 22.5\n",
      "      - 15.5\n",
      "      - 37.0\n",
      "      - 25.5\n",
      "      - 34.5\n",
      "      - 12.5\n",
      "      - 18.0\n",
      "      - 25.0\n",
      "      - 16.5\n",
      "      - 19.5\n",
      "      - 17.0\n",
      "      - -3.0\n",
      "      policy_policy2_reward:\n",
      "      - -4.499999999999997\n",
      "      - -2.3000000000000034\n",
      "      - -1.2000000000000017\n",
      "      - -1.2000000000000044\n",
      "      - -5.599999999999991\n",
      "      - 22.999999999999964\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 2.0999999999999934\n",
      "      - -6.699999999999991\n",
      "      - -1.200000000000001\n",
      "      - -7.799999999999981\n",
      "      - 2.099999999999995\n",
      "      - 0.9999999999999934\n",
      "      - -4.499999999999995\n",
      "      - 7.6000000000000005\n",
      "      - -4.499999999999986\n",
      "      - -4.500000000000003\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999986\n",
      "      - -0.10000000000000248\n",
      "      - -0.09999999999999876\n",
      "      - -3.400000000000004\n",
      "      - -5.6\n",
      "      - -0.10000000000000508\n",
      "      - -2.300000000000003\n",
      "      - 2.0999999999999943\n",
      "      - -4.499999999999996\n",
      "      - 3.1999999999999966\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999986\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999983\n",
      "      - -9.99999999999998\n",
      "      - -7.7999999999999865\n",
      "      - -5.599999999999993\n",
      "      - -8.89999999999998\n",
      "      - -4.5000000000000036\n",
      "      - -5.599999999999994\n",
      "      - 0.9999999999999943\n",
      "      - -7.799999999999981\n",
      "      - -7.7999999999999865\n",
      "      - -7.799999999999983\n",
      "      - -4.499999999999991\n",
      "      - -2.300000000000002\n",
      "      - -4.500000000000003\n",
      "      - -4.499999999999987\n",
      "      - 0.9999999999999934\n",
      "      - -2.300000000000003\n",
      "      - -8.89999999999998\n",
      "      - 4.3000000000000025\n",
      "      - -2.299999999999995\n",
      "      - 0.9999999999999952\n",
      "      - -3.400000000000004\n",
      "      - 12.000000000000016\n",
      "      - -5.599999999999998\n",
      "      - -5.599999999999995\n",
      "      - 2.0999999999999965\n",
      "      - -3.400000000000004\n",
      "      - -3.399999999999999\n",
      "      - -5.6\n",
      "      - -9.99999999999998\n",
      "      - -5.5999999999999845\n",
      "      - -6.699999999999984\n",
      "      - -4.500000000000003\n",
      "      - -7.799999999999981\n",
      "      - -2.299999999999992\n",
      "      - -7.799999999999988\n",
      "      - -1.1999999999999964\n",
      "      - -0.10000000000000442\n",
      "      - -3.3999999999999893\n",
      "      - -1.199999999999994\n",
      "      - -6.699999999999985\n",
      "      - -3.400000000000004\n",
      "      - -2.300000000000003\n",
      "      - 7.599999999999996\n",
      "      - -6.699999999999987\n",
      "      - -6.699999999999987\n",
      "      - -6.6999999999999815\n",
      "      - -0.09999999999999076\n",
      "      - -2.3000000000000003\n",
      "      - -2.3000000000000007\n",
      "      - -3.4000000000000057\n",
      "      - -1.1999999999999957\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999993\n",
      "      - -7.799999999999985\n",
      "      - -2.3000000000000056\n",
      "      - -6.69999999999999\n",
      "      - -1.1999999999999944\n",
      "      - 2.1000000000000028\n",
      "      - -5.599999999999994\n",
      "      - 2.0999999999999948\n",
      "      - -0.10000000000000045\n",
      "      - 2.100000000000007\n",
      "      - -7.799999999999981\n",
      "      - 1.0000000000000027\n",
      "      - -7.799999999999981\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 38.5\n",
      "      policy2: 22.999999999999964\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.345\n",
      "      policy2: -3.3339999999999934\n",
      "    policy_reward_min:\n",
      "      policy1: -8.0\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17860583158559287\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0767034369093879\n",
      "      mean_inference_ms: 1.873229246871866\n",
      "      mean_raw_obs_processing_ms: 0.35208457614060557\n",
      "  time_since_restore: 380.0700924396515\n",
      "  time_this_iter_s: 15.246044874191284\n",
      "  time_total_s: 380.0700924396515\n",
      "  timers:\n",
      "    learn_throughput: 429.866\n",
      "    learn_time_ms: 9305.228\n",
      "    synch_weights_time_ms: 11.189\n",
      "    training_iteration_time_ms: 20153.655\n",
      "  timestamp: 1658917431\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: 1dedd_00002\n",
      "  warmup_time: 12.495357990264893\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m E0727 12:23:52.105539000 123145558564864 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m 2022-07-27 12:23:52,124\tERROR worker.py:754 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 623, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 663, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 674, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"python/ray/_raylet.pyx\", line 621, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/actor.py\", line 1244, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/actor.py\", line 1296, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/worker.py\", line 2036, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     worker.gcs_function_key_subscriber.close()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/gcs_pubsub.py\", line 281, in close\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     self._stub.GcsSubscriberCommandBatch(req, timeout=5)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/grpc/_channel.py\", line 944, in __call__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     state, call, = self._blocking(request, timeout, metadata, credentials,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/grpc/_channel.py\", line 933, in _blocking\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     event = call.next_event()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 338, in grpc._cython.cygrpc.SegregatedCall.next_event\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 171, in grpc._cython.cygrpc._next_call_event\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/threading.py\", line 256, in __enter__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     def __enter__(self):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/worker.py\", line 751, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48455)\u001b[0m SystemExit: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_MultiAgentArena_1dedd_00003:\n",
      "  agent_timesteps_total: 160000\n",
      "  counters:\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_env_steps_sampled: 80000\n",
      "    num_env_steps_trained: 80000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-07-27_12-24-03\n",
      "  done: true\n",
      "  episode_len_mean: 100.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 39.8999999999999\n",
      "  episode_reward_mean: 18.680999999999948\n",
      "  episode_reward_min: -20.099999999999994\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 800\n",
      "  experiment_id: fbe69d4d3a824fb887bd9c2a22ba3d7e\n",
      "  hostname: Svens-MacBook-Pro.local\n",
      "  info:\n",
      "    learner:\n",
      "      policy1:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7442521452903748\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.016393013298511505\n",
      "          model: {}\n",
      "          policy_loss: -0.045085858553647995\n",
      "          total_loss: 7.268309593200684\n",
      "          vf_explained_var: 0.10392039269208908\n",
      "          vf_loss: 7.306019306182861\n",
      "      policy2:\n",
      "        learner_stats:\n",
      "          cur_kl_coeff: 0.44999998807907104\n",
      "          cur_lr: 9.999999747378752e-05\n",
      "          entropy: 0.7523970007896423\n",
      "          entropy_coeff: 0.0\n",
      "          kl: 0.015674538910388947\n",
      "          model: {}\n",
      "          policy_loss: -0.040970899164676666\n",
      "          total_loss: 3.475785493850708\n",
      "          vf_explained_var: 0.051884301006793976\n",
      "          vf_loss: 3.5097031593322754\n",
      "    num_agent_steps_sampled: 160000\n",
      "    num_agent_steps_trained: 160000\n",
      "    num_env_steps_sampled: 80000\n",
      "    num_env_steps_trained: 80000\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 127.0.0.1\n",
      "  num_agent_steps_sampled: 160000\n",
      "  num_agent_steps_trained: 160000\n",
      "  num_env_steps_sampled: 80000\n",
      "  num_env_steps_sampled_this_iter: 4000\n",
      "  num_env_steps_trained: 80000\n",
      "  num_env_steps_trained_this_iter: 4000\n",
      "  num_healthy_workers: 1\n",
      "  num_steps_trained_this_iter: 4000\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 26.405\n",
      "    ram_util_percent: 62.93499999999999\n",
      "  pid: 48457\n",
      "  policy_reward_max:\n",
      "    policy1: 45.5\n",
      "    policy2: 18.599999999999994\n",
      "  policy_reward_mean:\n",
      "    policy1: 22.95\n",
      "    policy2: -4.268999999999992\n",
      "  policy_reward_min:\n",
      "    policy1: -14.5\n",
      "    policy2: -9.99999999999998\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.17837394967344633\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.07641286421360051\n",
      "    mean_inference_ms: 1.8804174585066071\n",
      "    mean_raw_obs_processing_ms: 0.35178002832751\n",
      "  sampler_results:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 100.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 39.8999999999999\n",
      "    episode_reward_mean: 18.680999999999948\n",
      "    episode_reward_min: -20.099999999999994\n",
      "    episodes_this_iter: 40\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      - 100\n",
      "      episode_reward:\n",
      "      - 30.89999999999994\n",
      "      - 28.19999999999991\n",
      "      - 23.6999999999999\n",
      "      - 20.999999999999957\n",
      "      - 18.29999999999999\n",
      "      - 18.299999999999933\n",
      "      - 5.4000000000000155\n",
      "      - 24.89999999999992\n",
      "      - 3.299999999999943\n",
      "      - 13.499999999999906\n",
      "      - 17.999999999999908\n",
      "      - 11.400000000000025\n",
      "      - -20.099999999999994\n",
      "      - 26.99999999999993\n",
      "      - 29.699999999999903\n",
      "      - 15.599999999999918\n",
      "      - 9.299999999999999\n",
      "      - 12.600000000000016\n",
      "      - 22.799999999999905\n",
      "      - 17.699999999999925\n",
      "      - 5.700000000000003\n",
      "      - 12.899999999999928\n",
      "      - 12.90000000000002\n",
      "      - 6.900000000000027\n",
      "      - 22.199999999999996\n",
      "      - 25.799999999999912\n",
      "      - 8.099999999999941\n",
      "      - 20.699999999999967\n",
      "      - 17.09999999999998\n",
      "      - 7.499999999999989\n",
      "      - 24.599999999999973\n",
      "      - 13.49999999999997\n",
      "      - 21.599999999999966\n",
      "      - 5.3999999999999755\n",
      "      - 19.499999999999975\n",
      "      - 9.300000000000026\n",
      "      - 1.2000000000000202\n",
      "      - 25.49999999999992\n",
      "      - 23.099999999999987\n",
      "      - 15.599999999999932\n",
      "      - 28.49999999999995\n",
      "      - 24.599999999999937\n",
      "      - -10.799999999999976\n",
      "      - 19.199999999999935\n",
      "      - 10.800000000000017\n",
      "      - 8.70000000000001\n",
      "      - 28.799999999999955\n",
      "      - 20.999999999999936\n",
      "      - -17.39999999999999\n",
      "      - 12.899999999999997\n",
      "      - 26.999999999999915\n",
      "      - 20.39999999999992\n",
      "      - 27.599999999999962\n",
      "      - 39.8999999999999\n",
      "      - 30.299999999999905\n",
      "      - 11.999999999999906\n",
      "      - -2.1000000000000294\n",
      "      - 29.099999999999895\n",
      "      - 16.199999999999974\n",
      "      - 19.8\n",
      "      - 19.199999999999896\n",
      "      - 21.599999999999916\n",
      "      - 32.0999999999999\n",
      "      - 28.799999999999912\n",
      "      - 19.200000000000006\n",
      "      - 20.099999999999902\n",
      "      - 26.699999999999946\n",
      "      - 22.199999999999903\n",
      "      - 23.999999999999957\n",
      "      - 23.09999999999995\n",
      "      - 20.999999999999893\n",
      "      - 25.499999999999957\n",
      "      - 26.999999999999936\n",
      "      - 29.699999999999918\n",
      "      - 12.899999999999975\n",
      "      - 29.3999999999999\n",
      "      - 9.59999999999992\n",
      "      - 29.399999999999906\n",
      "      - 11.10000000000002\n",
      "      - 23.09999999999997\n",
      "      - 5.699999999999973\n",
      "      - 17.699999999999974\n",
      "      - 20.39999999999996\n",
      "      - 19.199999999999903\n",
      "      - 16.79999999999994\n",
      "      - 29.999999999999908\n",
      "      - 23.09999999999993\n",
      "      - 16.79999999999994\n",
      "      - 30.299999999999933\n",
      "      - 30.299999999999955\n",
      "      - 14.999999999999996\n",
      "      - 25.79999999999992\n",
      "      - 26.699999999999907\n",
      "      - 22.499999999999986\n",
      "      - 31.19999999999989\n",
      "      - 19.79999999999991\n",
      "      - 32.69999999999989\n",
      "      - 11.399999999999942\n",
      "      - 21.899999999999913\n",
      "      - 17.99999999999993\n",
      "      policy_policy1_reward:\n",
      "      - 36.5\n",
      "      - 30.5\n",
      "      - 31.5\n",
      "      - 25.5\n",
      "      - 25.0\n",
      "      - 25.0\n",
      "      - 11.0\n",
      "      - 25.0\n",
      "      - 4.5\n",
      "      - 23.5\n",
      "      - 28.0\n",
      "      - 6.0\n",
      "      - -14.5\n",
      "      - 37.0\n",
      "      - 37.5\n",
      "      - 19.0\n",
      "      - 16.0\n",
      "      - 21.5\n",
      "      - 24.0\n",
      "      - 20.0\n",
      "      - 2.5\n",
      "      - 18.5\n",
      "      - -3.5\n",
      "      - 12.5\n",
      "      - 30.0\n",
      "      - 27.0\n",
      "      - 17.0\n",
      "      - 28.5\n",
      "      - 26.0\n",
      "      - 12.0\n",
      "      - 6.0\n",
      "      - 7.0\n",
      "      - 30.5\n",
      "      - 5.5\n",
      "      - 24.0\n",
      "      - 16.0\n",
      "      - 3.5\n",
      "      - 30.0\n",
      "      - 26.5\n",
      "      - 13.5\n",
      "      - 22.0\n",
      "      - 28.0\n",
      "      - -3.0\n",
      "      - 16.0\n",
      "      - 12.0\n",
      "      - 16.5\n",
      "      - 35.5\n",
      "      - 25.5\n",
      "      - -8.5\n",
      "      - 18.5\n",
      "      - 31.5\n",
      "      - 20.5\n",
      "      - 31.0\n",
      "      - 45.5\n",
      "      - 37.0\n",
      "      - 16.5\n",
      "      - 3.5\n",
      "      - 38.0\n",
      "      - 24.0\n",
      "      - 26.5\n",
      "      - 21.5\n",
      "      - 30.5\n",
      "      - 35.5\n",
      "      - 24.5\n",
      "      - 27.0\n",
      "      - 23.5\n",
      "      - 29.0\n",
      "      - 30.0\n",
      "      - 34.0\n",
      "      - 26.5\n",
      "      - 25.5\n",
      "      - 30.0\n",
      "      - 37.0\n",
      "      - 32.0\n",
      "      - 18.5\n",
      "      - 35.0\n",
      "      - 13.0\n",
      "      - 29.5\n",
      "      - 20.0\n",
      "      - 32.0\n",
      "      - 2.5\n",
      "      - 20.0\n",
      "      - 26.0\n",
      "      - 27.0\n",
      "      - 12.5\n",
      "      - 40.0\n",
      "      - 32.0\n",
      "      - 23.5\n",
      "      - 31.5\n",
      "      - 26.0\n",
      "      - 25.0\n",
      "      - 32.5\n",
      "      - 34.5\n",
      "      - 32.5\n",
      "      - 39.0\n",
      "      - 26.5\n",
      "      - 40.5\n",
      "      - 17.0\n",
      "      - 27.5\n",
      "      - 22.5\n",
      "      policy_policy2_reward:\n",
      "      - -5.599999999999997\n",
      "      - -2.2999999999999963\n",
      "      - -7.7999999999999865\n",
      "      - -4.500000000000003\n",
      "      - -6.69999999999999\n",
      "      - -6.6999999999999815\n",
      "      - -5.599999999999982\n",
      "      - -0.10000000000000347\n",
      "      - -1.2000000000000037\n",
      "      - -9.99999999999998\n",
      "      - -9.99999999999998\n",
      "      - 5.400000000000002\n",
      "      - -5.599999999999982\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999986\n",
      "      - -3.3999999999999955\n",
      "      - -6.69999999999999\n",
      "      - -8.89999999999998\n",
      "      - -1.199999999999995\n",
      "      - -2.2999999999999994\n",
      "      - 3.200000000000017\n",
      "      - -5.599999999999997\n",
      "      - 16.399999999999963\n",
      "      - -5.599999999999982\n",
      "      - -7.799999999999981\n",
      "      - -1.2000000000000015\n",
      "      - -8.899999999999984\n",
      "      - -7.799999999999982\n",
      "      - -8.89999999999998\n",
      "      - -4.499999999999995\n",
      "      - 18.599999999999994\n",
      "      - 6.499999999999999\n",
      "      - -8.89999999999998\n",
      "      - -0.10000000000000409\n",
      "      - -4.499999999999993\n",
      "      - -6.699999999999989\n",
      "      - -2.300000000000004\n",
      "      - -4.499999999999992\n",
      "      - -3.399999999999988\n",
      "      - 2.100000000000006\n",
      "      - 6.500000000000009\n",
      "      - -3.400000000000005\n",
      "      - -7.799999999999981\n",
      "      - 3.1999999999999984\n",
      "      - -1.199999999999995\n",
      "      - -7.799999999999988\n",
      "      - -6.6999999999999815\n",
      "      - -4.49999999999999\n",
      "      - -8.89999999999998\n",
      "      - -5.599999999999988\n",
      "      - -4.499999999999992\n",
      "      - -0.10000000000000109\n",
      "      - -3.4000000000000044\n",
      "      - -5.599999999999998\n",
      "      - -6.699999999999986\n",
      "      - -4.499999999999997\n",
      "      - -5.599999999999997\n",
      "      - -8.89999999999998\n",
      "      - -7.799999999999986\n",
      "      - -6.6999999999999815\n",
      "      - -2.299999999999995\n",
      "      - -8.899999999999986\n",
      "      - -3.400000000000004\n",
      "      - 4.299999999999997\n",
      "      - -7.799999999999984\n",
      "      - -3.4000000000000026\n",
      "      - -2.300000000000002\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -3.4000000000000057\n",
      "      - -4.500000000000003\n",
      "      - -4.499999999999988\n",
      "      - -9.99999999999998\n",
      "      - -2.3000000000000025\n",
      "      - -5.599999999999999\n",
      "      - -5.599999999999996\n",
      "      - -3.3999999999999986\n",
      "      - -0.10000000000000331\n",
      "      - -8.89999999999998\n",
      "      - -8.89999999999998\n",
      "      - 3.2000000000000064\n",
      "      - -2.300000000000002\n",
      "      - -5.599999999999983\n",
      "      - -7.799999999999986\n",
      "      - 4.299999999999996\n",
      "      - -9.99999999999998\n",
      "      - -8.899999999999983\n",
      "      - -6.699999999999985\n",
      "      - -1.1999999999999984\n",
      "      - 4.300000000000005\n",
      "      - -9.99999999999998\n",
      "      - -6.699999999999995\n",
      "      - -7.799999999999989\n",
      "      - -9.99999999999998\n",
      "      - -7.799999999999981\n",
      "      - -6.6999999999999815\n",
      "      - -7.799999999999988\n",
      "      - -5.599999999999991\n",
      "      - -5.599999999999987\n",
      "      - -4.500000000000002\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max:\n",
      "      policy1: 45.5\n",
      "      policy2: 18.599999999999994\n",
      "    policy_reward_mean:\n",
      "      policy1: 22.95\n",
      "      policy2: -4.268999999999992\n",
      "    policy_reward_min:\n",
      "      policy1: -14.5\n",
      "      policy2: -9.99999999999998\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.17837394967344633\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.07641286421360051\n",
      "      mean_inference_ms: 1.8804174585066071\n",
      "      mean_raw_obs_processing_ms: 0.35178002832751\n",
      "  time_since_restore: 381.54527592658997\n",
      "  time_this_iter_s: 13.733370065689087\n",
      "  time_total_s: 381.54527592658997\n",
      "  timers:\n",
      "    learn_throughput: 464.195\n",
      "    learn_time_ms: 8617.067\n",
      "    synch_weights_time_ms: 4.673\n",
      "    training_iteration_time_ms: 18983.864\n",
      "  timestamp: 1658917443\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 80000\n",
      "  training_iteration: 20\n",
      "  trial_id: 1dedd_00003\n",
      "  warmup_time: 12.709256887435913\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m E0727 12:24:03.854680000 123145604460544 chttp2_transport.cc:1103]     Received a GOAWAY with error code ENHANCE_YOUR_CALM and debug data equal to \"too_many_pings\"\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2022-07-27 12:24:03,863\tERROR worker.py:754 -- Worker exits with an exit code 1.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 812, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 623, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 663, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 670, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 674, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"python/ray/_raylet.pyx\", line 621, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/actor.py\", line 1244, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/actor.py\", line 1296, in exit_actor\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     ray._private.worker.disconnect()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/worker.py\", line 2036, in disconnect\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     worker.gcs_function_key_subscriber.close()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/gcs_pubsub.py\", line 281, in close\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     self._stub.GcsSubscriberCommandBatch(req, timeout=5)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/grpc/_channel.py\", line 944, in __call__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     state, call, = self._blocking(request, timeout, metadata, credentials,\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/grpc/_channel.py\", line 933, in _blocking\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     event = call.next_event()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 338, in grpc._cython.cygrpc.SegregatedCall.next_event\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 171, in grpc._cython.cygrpc._next_call_event\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 173, in grpc._cython.cygrpc._next_call_event\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/threading.py\", line 374, in notify_all\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     def notify_all(self):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m   File \"/Users/sven/opt/anaconda3/envs/rllib_tutorial/lib/python3.9/site-packages/ray/_private/worker.py\", line 751, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m [2022-07-27 12:24:03,879 C 48459 2099737] core_worker.cc:612:  Check failed: _s.ok() Bad status: IOError: Broken pipe\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 0   _raylet.so                          0x000000010fde4571 _ZN3raylsERNSt3__113basic_ostreamIcNS0_11char_traitsIcEEEERKNS_10StackTraceE + 65 ray::operator<<()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 1   _raylet.so                          0x000000010fe15ac2 _ZN3ray13SpdLogMessage5FlushEv + 114 ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 2   _raylet.so                          0x000000010fe15992 _ZN3ray13SpdLogMessageD2Ev + 18 ray::SpdLogMessage::~SpdLogMessage()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 3   _raylet.so                          0x000000010fde7f8f _ZN3ray6RayLogD2Ev + 47 ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 4   _raylet.so                          0x000000010f60b1b8 _ZN3ray4core10CoreWorker4ExitENS_3rpc14WorkerExitTypeERKNSt3__112basic_stringIcNS4_11char_traitsIcEENS4_9allocatorIcEEEERKNS4_10shared_ptrINS_17LocalMemoryBufferEEE + 856 ray::core::CoreWorker::Exit()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 5   _raylet.so                          0x000000010f607953 _ZN3ray4core10CoreWorker11ExecuteTaskERKNS_17TaskSpecificationERKNSt3__110shared_ptrINS5_13unordered_mapINS5_12basic_stringIcNS5_11char_traitsIcEENS5_9allocatorIcEEEENS5_6vectorINS5_4pairIxdEENSB_ISG_EEEENS5_4hashISD_EENS5_8equal_toISD_EENSB_INSF_IKSD_SI_EEEEEEEEPNSE_INS6_INS_9RayObjectEEENSB_ISV_EEEEPN6google8protobuf16RepeatedPtrFieldINS_3rpc20ObjectReferenceCountEEEPb + 6691 ray::core::CoreWorker::ExecuteTask()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 6   _raylet.so                          0x000000010f678d50 _ZNSt3__110__function6__funcINS_6__bindIMN3ray4core10CoreWorkerEFNS3_6StatusERKNS3_17TaskSpecificationERKNS_10shared_ptrINS_13unordered_mapINS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEENS_6vectorINS_4pairIxdEENSF_ISK_EEEENS_4hashISH_EENS_8equal_toISH_EENSF_INSJ_IKSH_SM_EEEEEEEEPNSI_INSA_INS3_9RayObjectEEENSF_ISZ_EEEEPN6google8protobuf16RepeatedPtrFieldINS3_3rpc20ObjectReferenceCountEEEPbEJPS5_RKNS_12placeholders4__phILi1EEERKNS1F_ILi2EEERKNS1F_ILi3EEERKNS1F_ILi4EEERKNS1F_ILi5EEEEEENSF_IS1V_EEFS6_S9_SV_S12_S19_S1A_EEclES9_OSV_OS12_OS19_OS1A_ + 64 std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 7   _raylet.so                          0x000000010f71f6f9 _ZNSt3__110__function6__funcIZN3ray4core28CoreWorkerDirectTaskReceiver10HandleTaskERKNS2_3rpc15PushTaskRequestEPNS5_13PushTaskReplyENS_8functionIFvNS2_6StatusENSB_IFvvEEESE_EEEE3$_0NS_9allocatorISH_EEFvSG_EEclEOSG_ + 441 std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 8   _raylet.so                          0x000000010f7042ce _ZN3ray4core14InboundRequest6AcceptEv + 110 ray::core::InboundRequest::Accept()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 9   _raylet.so                          0x000000010f6fecbc _ZN3ray4core20ActorSchedulingQueue16ScheduleRequestsEv + 1564 ray::core::ActorSchedulingQueue::ScheduleRequests()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 10  _raylet.so                          0x000000010f6fe44e _ZN3ray4core20ActorSchedulingQueue3AddExxNSt3__18functionIFvNS3_IFvNS_6StatusENS3_IFvvEEES6_EEEEEESA_S8_RKNS2_12basic_stringIcNS2_11char_traitsIcEENS2_9allocatorIcEEEERKNS2_10shared_ptrINS_27FunctionDescriptorInterfaceEEENS_6TaskIDERKNS2_6vectorINS_3rpc15ObjectReferenceENSE_ISR_EEEE + 2206 ray::core::ActorSchedulingQueue::Add()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 11  _raylet.so                          0x000000010f71d3a1 _ZN3ray4core28CoreWorkerDirectTaskReceiver10HandleTaskERKNS_3rpc15PushTaskRequestEPNS2_13PushTaskReplyENSt3__18functionIFvNS_6StatusENS9_IFvvEEESC_EEE + 3329 ray::core::CoreWorkerDirectTaskReceiver::HandleTask()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 12  _raylet.so                          0x000000010f6a360f _ZNSt3__110__function6__funcIZN3ray4core10CoreWorker14HandlePushTaskERKNS2_3rpc15PushTaskRequestEPNS5_13PushTaskReplyENS_8functionIFvNS2_6StatusENSB_IFvvEEESE_EEEE4$_37NS_9allocatorISH_EESD_EclEv + 143 std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 13  _raylet.so                          0x000000010f9050a6 _ZN12EventTracker15RecordExecutionERKNSt3__18functionIFvvEEENS0_10shared_ptrI11StatsHandleEE + 86 EventTracker::RecordExecution()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 14  _raylet.so                          0x000000010f8e9db0 _ZNSt3__110__function6__funcIZN23instrumented_io_context4postENS_8functionIFvvEEENS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEEE3$_0NS9_ISC_EES4_EclEv + 48 std::__1::__function::__func<>::operator()()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 15  _raylet.so                          0x000000010f8e83a7 _ZN5boost4asio6detail18completion_handlerINSt3__18functionIFvvEEENS0_10io_context19basic_executor_typeINS3_9allocatorIvEELj0EEEE11do_completeEPvPNS1_19scheduler_operationERKNS_6system10error_codeEm + 167 boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 16  _raylet.so                          0x000000010fe33ff5 _ZN5boost4asio6detail9scheduler10do_run_oneERNS1_27conditionally_enabled_mutex11scoped_lockERNS1_21scheduler_thread_infoERKNS_6system10error_codeE + 725 boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 17  _raylet.so                          0x000000010fe2a621 _ZN5boost4asio6detail9scheduler3runERNS_6system10error_codeE + 241 boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 18  _raylet.so                          0x000000010fe2a51b _ZN5boost4asio10io_context3runEv + 43 boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 19  _raylet.so                          0x000000010f61e2a8 _ZN3ray4core10CoreWorker20RunTaskExecutionLoopEv + 24 ray::core::CoreWorker::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 20  _raylet.so                          0x000000010f6aa596 _ZN3ray4core21CoreWorkerProcessImpl26RunWorkerTaskExecutionLoopEv + 310 ray::core::CoreWorkerProcessImpl::RunWorkerTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 21  _raylet.so                          0x000000010f6aa429 _ZN3ray4core17CoreWorkerProcess20RunTaskExecutionLoopEv + 25 ray::core::CoreWorkerProcess::RunTaskExecutionLoop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 22  _raylet.so                          0x000000010f5509b3 _ZL50__pyx_pw_3ray_7_raylet_10CoreWorker_7run_task_loopP7_objectS0_ + 19 __pyx_pw_3ray_7_raylet_10CoreWorker_7run_task_loop()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 23  python                              0x000000010ec9cc83 method_vectorcall_NOARGS + 115 method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 24  python                              0x000000010edbd22c call_function + 172 call_function\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 25  python                              0x000000010edbacb9 _PyEval_EvalFrameDefault + 44009 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 26  python                              0x000000010ec8ee78 _PyFunction_Vectorcall + 248 _PyFunction_Vectorcall\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 27  python                              0x000000010edbd22c call_function + 172 call_function\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 28  python                              0x000000010edbacb9 _PyEval_EvalFrameDefault + 44009 _PyEval_EvalFrameDefault\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 29  python                              0x000000010edaec6d _PyEval_EvalCode + 557 _PyEval_EvalCode\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 30  python                              0x000000010ee1e0b1 pyrun_file + 321 pyrun_file\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 31  python                              0x000000010ee1d90a pyrun_simple_file + 394 pyrun_simple_file\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 32  python                              0x000000010ee1d72d PyRun_SimpleFileExFlags + 109 PyRun_SimpleFileExFlags\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 33  python                              0x000000010ee454d9 pymain_run_file + 329 pymain_run_file\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 34  python                              0x000000010ee44a7b pymain_run_python + 443 pymain_run_python\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 35  python                              0x000000010ee44865 Py_RunMain + 37 Py_RunMain\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 36  python                              0x000000010ee45f11 pymain_main + 49 pymain_main\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 37  python                              0x000000010ec1de98 main + 56 main\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 38  libdyld.dylib                       0x00007fff205cef3d start + 1 start\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m 39  ???                                 0x0000000000000010 0x0 + 16 0x0\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=48459)\u001b[0m \n",
      "2022-07-27 12:24:03,980\tINFO tune.py:737 -- Total run time: 482.04 seconds (481.03 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n",
      "Best checkpoint:  <ray.air.checkpoint.Checkpoint object at 0x7fc076210100>\n"
     ]
    }
   ],
   "source": [
    "# Example using Ray tune API (`tune.run()`) until some stopping condition is met.\n",
    "# This will create one (or more) Algorithms under the hood automatically w/o us having to\n",
    "# build these algos from the config.\n",
    "\n",
    "experiment_results = tune.run(\n",
    "    \"PPO\",\n",
    "\n",
    "    # training config params (translated into a python dict!)\n",
    "    config=config.to_dict(),\n",
    "\n",
    "    # Stopping criteria whichever occurs first: average reward over training episodes, or ...\n",
    "    stop={\n",
    "        \"training_iteration\": 6,     # stop after n training iterations (calls to `Algorithm.train()`)\n",
    "        #\"episode_reward_mean\": 400, # stop if average (sum of) rewards in an episode is 400 or more\n",
    "        #\"timesteps_total\": 100000,  # stop if reached 100,000 sampling timesteps\n",
    "    },  \n",
    "\n",
    "    # redirect logs instead of default ~/ray_results/\n",
    "    local_dir=\"results\",\n",
    "         \n",
    "    # Every how many train() calls do we create a checkpoint?\n",
    "    checkpoint_freq=1,\n",
    "    # Always save last checkpoint (no matter the frequency).\n",
    "    checkpoint_at_end=True,\n",
    "\n",
    "    ###############\n",
    "    # Note about Ray Tune verbosity.\n",
    "    # Screen verbosity in Ray Tune is defined as verbose = 0, 1, 2, or 3, where:\n",
    "    # 0 = silent\n",
    "    # 1 = only status updates, no logging messages\n",
    "    # 2 = status and brief trial results, includes logging messages\n",
    "    # 3 = status and detailed trial results, includes logging messages\n",
    "    # Defaults to 3.\n",
    "    ###############\n",
    "    verbose=3,\n",
    "                   \n",
    "    # Define what we are comparing for, when we search for the\n",
    "    # \"best\" checkpoint at the end.\n",
    "    metric=\"episode_reward_mean\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")\n",
    "print(\"Best checkpoint: \", experiment_results.best_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/j4/brrn254576lgnbqqtp5p1z280000gn/T/checkpoint_tmp_6vs48i96'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results.best_checkpoint.to_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The details behind Ray RLlib resource allocation <a class=\"anchor\" id=\"resource_allocation\"></a>\n",
    "\n",
    "#### Why did we use 8 CPUs in the tune run above (2 CPUs per trial)?\n",
    "\n",
    "```\n",
    "== Status ==\n",
    "Current time: 2022-07-24 18:18:28 (running for 00:02:09.35)\n",
    "Memory usage on this node: 9.9/16.0 GiB\n",
    "Using FIFO scheduling algorithm.\n",
    "Resources requested: 8/16 CPUs, 0/0 GPUs, 0.5/3.97 GiB heap, 0.5/1.98 GiB objects\n",
    "```\n",
    "\n",
    "By default, the PPO Algorithm uses 2 so called `RolloutWorkers` (you can change this via `config.rollouts(num_rollout_workers=2)`) for collecting samples from\n",
    "environments in parallel.\n",
    "We changed this setting to only 1 worker via the `config.rollouts(num_rollout_workers=1)` call in the cell above.\n",
    "\n",
    "`RolloutWorkers` are Ray Actors that have their own copies of the environment and step through episodes in parallel. Each Actor in Ray normally uses a single CPU, but besides `RolloutWorker`s, an Algorithm in RLlib also always has one local process (aka. the \"driver\" process or the \"local worker\"), which - in case of PPO -\n",
    "handles the model/policy learning updates.\n",
    "\n",
    "For our experiment above, this gives us 2 CPUs (1 rollout worker + 1 local learner) per Algorithm instance.\n",
    "\n",
    "Since our config specifies two `grid_search` with 2 different learning rates AND 2 different batch sizes, we were running 4 Algorithms in parallel above (2 learning rates x 2 batch sizes = 4 trials), hence 8 CPUs were required (4 algos x 2 CPUs each = 8).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook, we have learnt, how to:\n",
    "\n",
    "* Use Ray Tune in combination with RLlib for hyperparameter tuning\n",
    "* How RLlib and Tune determine the required computational resources for some `tune.run()` experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises <a ></a>\n",
    "\n",
    "#### 1. Using the `config` that we have built so far, let's run another `tune.run()`.\n",
    "\n",
    "But this time, apply the following changes to our setup:\n",
    "\n",
    "- Setup only 1 learning rate using the `config.training(lr=...)` method call. Chose the (seemingly) best value from the run in the previous cell (the one that yielded the highest avg. reward).\n",
    "- Setup only 1 train batch size using the `config.training(train_batch_size=...)` method call. Chose the (seemingly) best value from the run in the previous cell (the one that yielded the highest avg. reward).\n",
    "- Set the number of RolloutWorkers to 5 using the `config.rollouts(num_rollout_workers=5)` method call, which will allow us to collect more environment samples in parallel.\n",
    "- Set the `num_envs_per_worker` config parameter to 5 using the `config.rollouts(num_envs_per_worker=...)` method call. This will batch our environment on each rollout worker, and thus parallelize action computing forward passes through our neural networks.\n",
    "\n",
    "Other than that, use the exact same args as in our `tune.run()` call in the previous cell.\n",
    "\n",
    "**Good luck! :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## References\n",
    " * [Tune, Scalable Hyperparameter Tuning](https://docs.ray.io/en/latest/tune/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚¨ÖÔ∏è [Previous notebook](./ex_02_create_multiagent_rllib_env.ipynb) <br>\n",
    "‚û°Ô∏è [Next notebook](./ex_04_offline_rl_with_rllib.ipynb) <br>\n",
    "\n",
    "üìñ [Back to Table of Contents](./ex_00_rllib_notebooks_table_of_contents.ipynb)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
